{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dataset=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 170886 entries, 0 to 170885\n",
      "Data columns (total 31 columns):\n",
      "Time      170886 non-null float64\n",
      "V1        170886 non-null float64\n",
      "V2        170886 non-null float64\n",
      "V3        170886 non-null float64\n",
      "V4        170886 non-null float64\n",
      "V5        170886 non-null float64\n",
      "V6        170886 non-null float64\n",
      "V7        170886 non-null float64\n",
      "V8        170886 non-null float64\n",
      "V9        170886 non-null float64\n",
      "V10       170886 non-null float64\n",
      "V11       170886 non-null float64\n",
      "V12       170886 non-null float64\n",
      "V13       170886 non-null float64\n",
      "V14       170886 non-null float64\n",
      "V15       170886 non-null float64\n",
      "V16       170886 non-null float64\n",
      "V17       170886 non-null float64\n",
      "V18       170886 non-null float64\n",
      "V19       170886 non-null float64\n",
      "V20       170886 non-null float64\n",
      "V21       170886 non-null float64\n",
      "V22       170886 non-null float64\n",
      "V23       170886 non-null float64\n",
      "V24       170886 non-null float64\n",
      "V25       170886 non-null float64\n",
      "V26       170886 non-null float64\n",
      "V27       170886 non-null float64\n",
      "V28       170886 non-null float64\n",
      "Amount    170886 non-null float64\n",
      "Class     170886 non-null float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 40.4 MB\n"
     ]
    }
   ],
   "source": [
    "Dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61092.608212</td>\n",
       "      <td>-0.169856</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>0.493038</td>\n",
       "      <td>0.117430</td>\n",
       "      <td>-0.176091</td>\n",
       "      <td>0.058238</td>\n",
       "      <td>-0.080670</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028273</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.022461</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>87.336246</td>\n",
       "      <td>0.002107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27828.974490</td>\n",
       "      <td>1.850523</td>\n",
       "      <td>1.610865</td>\n",
       "      <td>1.383248</td>\n",
       "      <td>1.371899</td>\n",
       "      <td>1.338609</td>\n",
       "      <td>1.295132</td>\n",
       "      <td>1.208518</td>\n",
       "      <td>1.227627</td>\n",
       "      <td>1.152289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743723</td>\n",
       "      <td>0.667322</td>\n",
       "      <td>0.584511</td>\n",
       "      <td>0.598757</td>\n",
       "      <td>0.465511</td>\n",
       "      <td>0.490667</td>\n",
       "      <td>0.391952</td>\n",
       "      <td>0.307317</td>\n",
       "      <td>245.952377</td>\n",
       "      <td>0.045850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-11.710896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41217.000000</td>\n",
       "      <td>-0.986678</td>\n",
       "      <td>-0.539179</td>\n",
       "      <td>-0.064757</td>\n",
       "      <td>-0.743469</td>\n",
       "      <td>-0.828769</td>\n",
       "      <td>-0.691130</td>\n",
       "      <td>-0.586318</td>\n",
       "      <td>-0.162642</td>\n",
       "      <td>-0.660087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230719</td>\n",
       "      <td>-0.546772</td>\n",
       "      <td>-0.170303</td>\n",
       "      <td>-0.332459</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.330347</td>\n",
       "      <td>-0.065124</td>\n",
       "      <td>-0.027056</td>\n",
       "      <td>5.480000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60776.000000</td>\n",
       "      <td>-0.183596</td>\n",
       "      <td>0.109687</td>\n",
       "      <td>0.623352</td>\n",
       "      <td>0.124322</td>\n",
       "      <td>-0.226226</td>\n",
       "      <td>-0.202623</td>\n",
       "      <td>-0.031930</td>\n",
       "      <td>0.056663</td>\n",
       "      <td>-0.078965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054461</td>\n",
       "      <td>-0.066777</td>\n",
       "      <td>-0.036215</td>\n",
       "      <td>0.059467</td>\n",
       "      <td>0.135677</td>\n",
       "      <td>-0.058970</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>21.895000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78622.750000</td>\n",
       "      <td>1.184444</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>1.297353</td>\n",
       "      <td>0.937619</td>\n",
       "      <td>0.374481</td>\n",
       "      <td>0.449208</td>\n",
       "      <td>0.462624</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128339</td>\n",
       "      <td>0.363171</td>\n",
       "      <td>0.098701</td>\n",
       "      <td>0.415855</td>\n",
       "      <td>0.399459</td>\n",
       "      <td>0.272940</td>\n",
       "      <td>0.089729</td>\n",
       "      <td>0.078303</td>\n",
       "      <td>76.720000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120396.000000</td>\n",
       "      <td>2.439207</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>19.002942</td>\n",
       "      <td>4.022866</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>19656.530000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean    61092.608212      -0.169856       0.040770       0.493038   \n",
       "std     27828.974490       1.850523       1.610865       1.383248   \n",
       "min         0.000000     -56.407510     -72.715728     -33.680984   \n",
       "25%     41217.000000      -0.986678      -0.539179      -0.064757   \n",
       "50%     60776.000000      -0.183596       0.109687       0.623352   \n",
       "75%     78622.750000       1.184444       0.804222       1.297353   \n",
       "max    120396.000000       2.439207      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean        0.117430      -0.176091       0.058238      -0.080670   \n",
       "std         1.371899       1.338609       1.295132       1.208518   \n",
       "min        -5.519697     -42.147898     -26.160506     -43.557242   \n",
       "25%        -0.743469      -0.828769      -0.691130      -0.586318   \n",
       "50%         0.124322      -0.226226      -0.202623      -0.031930   \n",
       "75%         0.937619       0.374481       0.449208       0.462624   \n",
       "max        16.875344      34.801666      22.529298      36.677268   \n",
       "\n",
       "                  V8             V9      ...                  V21  \\\n",
       "count  170886.000000  170886.000000      ...        170886.000000   \n",
       "mean        0.032215       0.018873      ...            -0.028273   \n",
       "std         1.227627       1.152289      ...             0.743723   \n",
       "min       -73.216718     -13.434066      ...           -34.830382   \n",
       "25%        -0.162642      -0.660087      ...            -0.230719   \n",
       "50%         0.056663      -0.078965      ...            -0.054461   \n",
       "75%         0.350995       0.641342      ...             0.128339   \n",
       "max        20.007208      15.594995      ...            27.202839   \n",
       "\n",
       "                 V22            V23            V24            V25  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean       -0.083738      -0.022461       0.009004       0.092271   \n",
       "std         0.667322       0.584511       0.598757       0.465511   \n",
       "min       -10.933144     -44.807735      -2.836627     -10.295397   \n",
       "25%        -0.546772      -0.170303      -0.332459      -0.195935   \n",
       "50%        -0.066777      -0.036215       0.059467       0.135677   \n",
       "75%         0.363171       0.098701       0.415855       0.399459   \n",
       "max        10.503090      19.002942       4.022866       7.519589   \n",
       "\n",
       "                 V26            V27            V28         Amount  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean        0.012607       0.002100       0.002443      87.336246   \n",
       "std         0.490667       0.391952       0.307317     245.952377   \n",
       "min        -2.604551     -22.565679     -11.710896       0.000000   \n",
       "25%        -0.330347      -0.065124      -0.027056       5.480000   \n",
       "50%        -0.058970       0.008693       0.021151      21.895000   \n",
       "75%         0.272940       0.089729       0.078303      76.720000   \n",
       "max         3.517346      12.152401      33.847808   19656.530000   \n",
       "\n",
       "               Class  \n",
       "count  170886.000000  \n",
       "mean        0.002107  \n",
       "std         0.045850  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "5  0.260314 -0.568671  ...   -0.208254 -0.559825 -0.026398 -0.371427   \n",
       "6  0.081213  0.464960  ...   -0.167716 -0.270710 -0.154104 -0.780055   \n",
       "7 -3.807864  0.615375  ...    1.943465 -1.015455  0.057504 -0.649709   \n",
       "8  0.851084 -0.392048  ...   -0.073425 -0.268092 -0.204233  1.011592   \n",
       "9  0.069539 -0.736727  ...   -0.246914 -0.633753 -0.120794 -0.385050   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69    0.0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50    0.0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99    0.0  \n",
       "5 -0.232794  0.105915  0.253844  0.081080    3.67    0.0  \n",
       "6  0.750137 -0.257237  0.034507  0.005168    4.99    0.0  \n",
       "7 -0.415267 -0.051634 -1.206921 -1.085339   40.80    0.0  \n",
       "8  0.373205 -0.384157  0.011747  0.142404   93.20    0.0  \n",
       "9 -0.069733  0.094199  0.246219  0.083076    3.68    0.0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fe0ae73e890>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9b94410>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9b1c510>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9b2c9d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9a144d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a999b350>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a990f050>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9896090>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a97fb750>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9780790>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a976af50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a967d150>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9664ad0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a95e7d90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a95fe590>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a94e0a90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a949ded0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a93cdd90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9356dd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a92c7d50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a924dd90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a91c4650>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9149810>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a90be1d0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a9042490>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a90d1a50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8f9d9d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8f26850>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8e968d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8e1d910>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8d930d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8d19290>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8c80c10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8c05ed0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8c9d090>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fe0a8afebd0>]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.hist(bins=50,figsize=(20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correMatrx=Dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077141</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>-0.228333</td>\n",
       "      <td>-0.049947</td>\n",
       "      <td>0.109344</td>\n",
       "      <td>-0.037377</td>\n",
       "      <td>0.046764</td>\n",
       "      <td>-0.031142</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>0.034717</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.133370</td>\n",
       "      <td>-0.043491</td>\n",
       "      <td>-0.001390</td>\n",
       "      <td>-0.001486</td>\n",
       "      <td>-0.024559</td>\n",
       "      <td>-0.007336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>0.077141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021874</td>\n",
       "      <td>0.110065</td>\n",
       "      <td>-0.032010</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.040518</td>\n",
       "      <td>0.085595</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>-0.011199</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013703</td>\n",
       "      <td>-0.032654</td>\n",
       "      <td>-0.076057</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>0.122406</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>-0.001745</td>\n",
       "      <td>0.097715</td>\n",
       "      <td>-0.233275</td>\n",
       "      <td>-0.145422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>0.013975</td>\n",
       "      <td>-0.021874</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.093282</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>-0.037410</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.020339</td>\n",
       "      <td>-0.017466</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024398</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-0.010293</td>\n",
       "      <td>-0.067000</td>\n",
       "      <td>-0.024394</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>-0.544872</td>\n",
       "      <td>0.124537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>-0.228333</td>\n",
       "      <td>0.110065</td>\n",
       "      <td>-0.093282</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.049566</td>\n",
       "      <td>0.091778</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>0.157133</td>\n",
       "      <td>-0.045784</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.128603</td>\n",
       "      <td>-0.003169</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>-0.093891</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.019721</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>-0.197158</td>\n",
       "      <td>-0.281333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>-0.049947</td>\n",
       "      <td>-0.032010</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>-0.049566</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007985</td>\n",
       "      <td>-0.018759</td>\n",
       "      <td>-0.037686</td>\n",
       "      <td>0.017649</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016424</td>\n",
       "      <td>0.032775</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>-0.013589</td>\n",
       "      <td>-0.014515</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>-0.004932</td>\n",
       "      <td>0.096241</td>\n",
       "      <td>0.159813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>0.109344</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>-0.037410</td>\n",
       "      <td>0.091778</td>\n",
       "      <td>-0.007985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051699</td>\n",
       "      <td>0.035185</td>\n",
       "      <td>-0.010601</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028887</td>\n",
       "      <td>-0.052573</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>-0.010975</td>\n",
       "      <td>-0.024344</td>\n",
       "      <td>-0.038380</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>-0.008315</td>\n",
       "      <td>-0.377240</td>\n",
       "      <td>-0.143884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>-0.037377</td>\n",
       "      <td>0.040518</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.038365</td>\n",
       "      <td>-0.018759</td>\n",
       "      <td>0.051699</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019489</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>-0.011800</td>\n",
       "      <td>-0.008718</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>-0.021799</td>\n",
       "      <td>-0.004309</td>\n",
       "      <td>0.196986</td>\n",
       "      <td>-0.053040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>0.046764</td>\n",
       "      <td>0.085595</td>\n",
       "      <td>-0.020339</td>\n",
       "      <td>0.157133</td>\n",
       "      <td>-0.037686</td>\n",
       "      <td>0.035185</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042987</td>\n",
       "      <td>0.052235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025214</td>\n",
       "      <td>-0.043410</td>\n",
       "      <td>0.028541</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.066814</td>\n",
       "      <td>-0.026282</td>\n",
       "      <td>-0.049039</td>\n",
       "      <td>-0.027001</td>\n",
       "      <td>0.352925</td>\n",
       "      <td>-0.263717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>-0.031142</td>\n",
       "      <td>0.009353</td>\n",
       "      <td>-0.017466</td>\n",
       "      <td>-0.045784</td>\n",
       "      <td>0.017649</td>\n",
       "      <td>-0.010601</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>0.042987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.020149</td>\n",
       "      <td>-0.036521</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.015134</td>\n",
       "      <td>0.014576</td>\n",
       "      <td>0.030332</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>-0.084011</td>\n",
       "      <td>0.026688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>0.020806</td>\n",
       "      <td>-0.011199</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>-0.001170</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>0.019854</td>\n",
       "      <td>0.052235</td>\n",
       "      <td>-0.013006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>0.044522</td>\n",
       "      <td>-0.023592</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.053311</td>\n",
       "      <td>0.044132</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.029320</td>\n",
       "      <td>-0.032619</td>\n",
       "      <td>-0.114936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>0.016899</td>\n",
       "      <td>-0.005948</td>\n",
       "      <td>0.019214</td>\n",
       "      <td>0.083621</td>\n",
       "      <td>-0.058673</td>\n",
       "      <td>0.058786</td>\n",
       "      <td>-0.006460</td>\n",
       "      <td>0.089272</td>\n",
       "      <td>-0.007441</td>\n",
       "      <td>-0.002048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.041671</td>\n",
       "      <td>-0.006180</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.025425</td>\n",
       "      <td>0.002403</td>\n",
       "      <td>-0.014305</td>\n",
       "      <td>-0.030029</td>\n",
       "      <td>-0.113239</td>\n",
       "      <td>-0.275925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>-0.124215</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.027789</td>\n",
       "      <td>-0.071985</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>-0.011589</td>\n",
       "      <td>-0.068325</td>\n",
       "      <td>-0.013916</td>\n",
       "      <td>-0.002259</td>\n",
       "      <td>0.004814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.042750</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.024506</td>\n",
       "      <td>-0.081842</td>\n",
       "      <td>-0.009105</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>-0.008334</td>\n",
       "      <td>-0.010576</td>\n",
       "      <td>0.181916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>0.037198</td>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.035437</td>\n",
       "      <td>0.119982</td>\n",
       "      <td>-0.010700</td>\n",
       "      <td>-0.024715</td>\n",
       "      <td>0.013590</td>\n",
       "      <td>0.048422</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.115582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001144</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>-0.014621</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>0.066186</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.015841</td>\n",
       "      <td>-0.287090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>-0.002090</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>-0.073209</td>\n",
       "      <td>0.006876</td>\n",
       "      <td>0.069249</td>\n",
       "      <td>-0.015698</td>\n",
       "      <td>0.029104</td>\n",
       "      <td>-0.012813</td>\n",
       "      <td>0.063453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>-0.004748</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>-0.024777</td>\n",
       "      <td>-0.012577</td>\n",
       "      <td>-0.003286</td>\n",
       "      <td>-0.001221</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.005217</td>\n",
       "      <td>-0.003223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>-0.021609</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>-0.007976</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>-0.011357</td>\n",
       "      <td>0.056922</td>\n",
       "      <td>0.012488</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>-0.028450</td>\n",
       "      <td>0.095579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032772</td>\n",
       "      <td>-0.032049</td>\n",
       "      <td>0.023849</td>\n",
       "      <td>0.013741</td>\n",
       "      <td>-0.073370</td>\n",
       "      <td>-0.003623</td>\n",
       "      <td>-0.005933</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>-0.345632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>-0.080531</td>\n",
       "      <td>0.031371</td>\n",
       "      <td>0.043736</td>\n",
       "      <td>-0.078336</td>\n",
       "      <td>-0.036166</td>\n",
       "      <td>0.047088</td>\n",
       "      <td>-0.079339</td>\n",
       "      <td>0.046375</td>\n",
       "      <td>-0.014028</td>\n",
       "      <td>-0.131398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>-0.019926</td>\n",
       "      <td>0.014036</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>-0.025952</td>\n",
       "      <td>-0.020350</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>-0.009370</td>\n",
       "      <td>-0.027629</td>\n",
       "      <td>-0.010299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.043005</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>-0.011915</td>\n",
       "      <td>-0.063915</td>\n",
       "      <td>0.093050</td>\n",
       "      <td>-0.012121</td>\n",
       "      <td>0.065945</td>\n",
       "      <td>-0.022499</td>\n",
       "      <td>-0.035560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007530</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>-0.006387</td>\n",
       "      <td>-0.008569</td>\n",
       "      <td>0.063534</td>\n",
       "      <td>0.030306</td>\n",
       "      <td>0.004681</td>\n",
       "      <td>-0.004553</td>\n",
       "      <td>-0.020581</td>\n",
       "      <td>-0.256484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>-0.055348</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>-0.055384</td>\n",
       "      <td>0.092038</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>0.008995</td>\n",
       "      <td>0.060620</td>\n",
       "      <td>-0.016158</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009381</td>\n",
       "      <td>0.035790</td>\n",
       "      <td>0.023544</td>\n",
       "      <td>-0.009268</td>\n",
       "      <td>-0.056530</td>\n",
       "      <td>-0.049267</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>-0.001966</td>\n",
       "      <td>0.018883</td>\n",
       "      <td>-0.412952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>0.065701</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>-0.025575</td>\n",
       "      <td>-0.007288</td>\n",
       "      <td>-0.026872</td>\n",
       "      <td>0.050364</td>\n",
       "      <td>0.037276</td>\n",
       "      <td>0.047140</td>\n",
       "      <td>-0.013234</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031417</td>\n",
       "      <td>-0.068420</td>\n",
       "      <td>-0.004565</td>\n",
       "      <td>-0.013255</td>\n",
       "      <td>0.007904</td>\n",
       "      <td>-0.003133</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>0.046260</td>\n",
       "      <td>-0.156766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>0.010181</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>-0.011610</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>0.010451</td>\n",
       "      <td>0.063082</td>\n",
       "      <td>-0.033966</td>\n",
       "      <td>0.025777</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>-0.003361</td>\n",
       "      <td>-0.010344</td>\n",
       "      <td>-0.001012</td>\n",
       "      <td>-0.004933</td>\n",
       "      <td>-0.005502</td>\n",
       "      <td>-0.005923</td>\n",
       "      <td>-0.060385</td>\n",
       "      <td>0.048401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>-0.027639</td>\n",
       "      <td>-0.071902</td>\n",
       "      <td>-0.065292</td>\n",
       "      <td>-0.083324</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>-0.060794</td>\n",
       "      <td>0.041025</td>\n",
       "      <td>0.053773</td>\n",
       "      <td>-0.023337</td>\n",
       "      <td>0.013878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049776</td>\n",
       "      <td>-0.009782</td>\n",
       "      <td>-0.046398</td>\n",
       "      <td>-0.003983</td>\n",
       "      <td>-0.023342</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>-0.010692</td>\n",
       "      <td>0.076921</td>\n",
       "      <td>0.432146</td>\n",
       "      <td>0.023689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>0.020324</td>\n",
       "      <td>-0.013703</td>\n",
       "      <td>-0.024398</td>\n",
       "      <td>0.027125</td>\n",
       "      <td>0.016424</td>\n",
       "      <td>-0.028887</td>\n",
       "      <td>0.019489</td>\n",
       "      <td>0.025214</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.013723</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.077490</td>\n",
       "      <td>-0.011113</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>-0.007465</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>0.128074</td>\n",
       "      <td>0.050749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>0.083971</td>\n",
       "      <td>-0.032654</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>0.128603</td>\n",
       "      <td>0.032775</td>\n",
       "      <td>-0.052573</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>-0.043410</td>\n",
       "      <td>0.020149</td>\n",
       "      <td>0.044522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.029946</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>-0.019909</td>\n",
       "      <td>-0.077164</td>\n",
       "      <td>-0.016457</td>\n",
       "      <td>-0.028022</td>\n",
       "      <td>-0.078848</td>\n",
       "      <td>0.003980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>0.034717</td>\n",
       "      <td>-0.076057</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-0.003169</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>-0.011800</td>\n",
       "      <td>0.028541</td>\n",
       "      <td>-0.036521</td>\n",
       "      <td>-0.023592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011113</td>\n",
       "      <td>0.029946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>0.045107</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>-0.000615</td>\n",
       "      <td>0.025979</td>\n",
       "      <td>-0.128896</td>\n",
       "      <td>-0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.010842</td>\n",
       "      <td>-0.010293</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>-0.010975</td>\n",
       "      <td>-0.008718</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020695</td>\n",
       "      <td>-0.007793</td>\n",
       "      <td>-0.008699</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.010531</td>\n",
       "      <td>-0.006352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>-0.133370</td>\n",
       "      <td>0.122406</td>\n",
       "      <td>-0.067000</td>\n",
       "      <td>-0.093891</td>\n",
       "      <td>-0.013589</td>\n",
       "      <td>-0.024344</td>\n",
       "      <td>0.032492</td>\n",
       "      <td>-0.066814</td>\n",
       "      <td>0.015134</td>\n",
       "      <td>0.053311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007465</td>\n",
       "      <td>-0.019909</td>\n",
       "      <td>0.045107</td>\n",
       "      <td>-0.020695</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.086498</td>\n",
       "      <td>0.045403</td>\n",
       "      <td>0.041472</td>\n",
       "      <td>-0.056076</td>\n",
       "      <td>-0.001201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>-0.043491</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>-0.024394</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>-0.014515</td>\n",
       "      <td>-0.038380</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>-0.026282</td>\n",
       "      <td>0.014576</td>\n",
       "      <td>0.044132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>-0.077164</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>-0.007793</td>\n",
       "      <td>-0.086498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.002471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>-0.001390</td>\n",
       "      <td>-0.001745</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>-0.019721</td>\n",
       "      <td>0.004942</td>\n",
       "      <td>0.018106</td>\n",
       "      <td>-0.021799</td>\n",
       "      <td>-0.049039</td>\n",
       "      <td>0.030332</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>-0.016457</td>\n",
       "      <td>-0.000615</td>\n",
       "      <td>-0.008699</td>\n",
       "      <td>0.045403</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085580</td>\n",
       "      <td>-0.008025</td>\n",
       "      <td>0.021195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>-0.001486</td>\n",
       "      <td>0.097715</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>-0.004932</td>\n",
       "      <td>-0.008315</td>\n",
       "      <td>-0.004309</td>\n",
       "      <td>-0.027001</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>-0.029320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>-0.028022</td>\n",
       "      <td>0.025979</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.041472</td>\n",
       "      <td>0.008807</td>\n",
       "      <td>0.085580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>0.007481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>-0.024559</td>\n",
       "      <td>-0.233275</td>\n",
       "      <td>-0.544872</td>\n",
       "      <td>-0.197158</td>\n",
       "      <td>0.096241</td>\n",
       "      <td>-0.377240</td>\n",
       "      <td>0.196986</td>\n",
       "      <td>0.352925</td>\n",
       "      <td>-0.084011</td>\n",
       "      <td>-0.032619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128074</td>\n",
       "      <td>-0.078848</td>\n",
       "      <td>-0.128896</td>\n",
       "      <td>0.010531</td>\n",
       "      <td>-0.056076</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>-0.008025</td>\n",
       "      <td>0.027765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>-0.007336</td>\n",
       "      <td>-0.145422</td>\n",
       "      <td>0.124537</td>\n",
       "      <td>-0.281333</td>\n",
       "      <td>0.159813</td>\n",
       "      <td>-0.143884</td>\n",
       "      <td>-0.053040</td>\n",
       "      <td>-0.263717</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>-0.114936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050749</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>-0.006352</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.021195</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "Time    1.000000  0.077141  0.013975 -0.228333 -0.049947  0.109344 -0.037377   \n",
       "V1      0.077141  1.000000 -0.021874  0.110065 -0.032010  0.015608  0.040518   \n",
       "V2      0.013975 -0.021874  1.000000 -0.093282  0.032671 -0.037410  0.011722   \n",
       "V3     -0.228333  0.110065 -0.093282  1.000000 -0.049566  0.091778 -0.038365   \n",
       "V4     -0.049947 -0.032010  0.032671 -0.049566  1.000000 -0.007985 -0.018759   \n",
       "V5      0.109344  0.015608 -0.037410  0.091778 -0.007985  1.000000  0.051699   \n",
       "V6     -0.037377  0.040518  0.011722 -0.038365 -0.018759  0.051699  1.000000   \n",
       "V7      0.046764  0.085595 -0.020339  0.157133 -0.037686  0.035185  0.004333   \n",
       "V8     -0.031142  0.009353 -0.017466 -0.045784  0.017649 -0.010601 -0.029669   \n",
       "V9      0.020806 -0.011199  0.000438  0.029301 -0.001170  0.056063  0.019854   \n",
       "V10     0.016899 -0.005948  0.019214  0.083621 -0.058673  0.058786 -0.006460   \n",
       "V11    -0.124215  0.003531  0.027789 -0.071985  0.004016 -0.011589 -0.068325   \n",
       "V12     0.037198 -0.011142 -0.035437  0.119982 -0.010700 -0.024715  0.013590   \n",
       "V13    -0.002090  0.024001  0.032248 -0.073209  0.006876  0.069249 -0.015698   \n",
       "V14    -0.021609  0.060189 -0.007976  0.018038 -0.011357  0.056922  0.012488   \n",
       "V15    -0.080531  0.031371  0.043736 -0.078336 -0.036166  0.047088 -0.079339   \n",
       "V16     0.004659  0.043005  0.007490 -0.011915 -0.063915  0.093050 -0.012121   \n",
       "V17    -0.055348  0.050022 -0.055384  0.092038  0.000854 -0.001121  0.008995   \n",
       "V18     0.065701  0.012706 -0.025575 -0.007288 -0.026872  0.050364  0.037276   \n",
       "V19     0.010181 -0.000399  0.006527 -0.011610  0.012340  0.010451  0.063082   \n",
       "V20    -0.027639 -0.071902 -0.065292 -0.083324  0.013649 -0.060794  0.041025   \n",
       "V21     0.020324 -0.013703 -0.024398  0.027125  0.016424 -0.028887  0.019489   \n",
       "V22     0.083971 -0.032654 -0.016189  0.128603  0.032775 -0.052573  0.029604   \n",
       "V23     0.034717 -0.076057  0.010350 -0.003169  0.004231  0.001824 -0.011800   \n",
       "V24    -0.005517 -0.010842 -0.010293  0.012462 -0.001971 -0.010975 -0.008718   \n",
       "V25    -0.133370  0.122406 -0.067000 -0.093891 -0.013589 -0.024344  0.032492   \n",
       "V26    -0.043491 -0.001845 -0.024394  0.034885 -0.014515 -0.038380  0.012248   \n",
       "V27    -0.001390 -0.001745 -0.001581 -0.019721  0.004942  0.018106 -0.021799   \n",
       "V28    -0.001486  0.097715  0.007363  0.017112 -0.004932 -0.008315 -0.004309   \n",
       "Amount -0.024559 -0.233275 -0.544872 -0.197158  0.096241 -0.377240  0.196986   \n",
       "Class  -0.007336 -0.145422  0.124537 -0.281333  0.159813 -0.143884 -0.053040   \n",
       "\n",
       "              V7        V8        V9    ...          V21       V22       V23  \\\n",
       "Time    0.046764 -0.031142  0.020806    ...     0.020324  0.083971  0.034717   \n",
       "V1      0.085595  0.009353 -0.011199    ...    -0.013703 -0.032654 -0.076057   \n",
       "V2     -0.020339 -0.017466  0.000438    ...    -0.024398 -0.016189  0.010350   \n",
       "V3      0.157133 -0.045784  0.029301    ...     0.027125  0.128603 -0.003169   \n",
       "V4     -0.037686  0.017649 -0.001170    ...     0.016424  0.032775  0.004231   \n",
       "V5      0.035185 -0.010601  0.056063    ...    -0.028887 -0.052573  0.001824   \n",
       "V6      0.004333 -0.029669  0.019854    ...     0.019489  0.029604 -0.011800   \n",
       "V7      1.000000  0.042987  0.052235    ...     0.025214 -0.043410  0.028541   \n",
       "V8      0.042987  1.000000 -0.013006    ...     0.001163  0.020149 -0.036521   \n",
       "V9      0.052235 -0.013006  1.000000    ...     0.013723  0.044522 -0.023592   \n",
       "V10     0.089272 -0.007441 -0.002048    ...     0.000019 -0.041671 -0.006180   \n",
       "V11    -0.013916 -0.002259  0.004814    ...     0.023383  0.042750  0.027186   \n",
       "V12     0.048422 -0.000717 -0.115582    ...    -0.001144  0.010133 -0.014621   \n",
       "V13     0.029104 -0.012813  0.063453    ...     0.003015 -0.004748  0.000397   \n",
       "V14     0.039553 -0.028450  0.095579    ...    -0.032772 -0.032049  0.023849   \n",
       "V15     0.046375 -0.014028 -0.131398    ...     0.007250 -0.019926  0.014036   \n",
       "V16     0.065945 -0.022499 -0.035560    ...    -0.007530  0.004451 -0.006387   \n",
       "V17     0.060620 -0.016158  0.085185    ...    -0.009381  0.035790  0.023544   \n",
       "V18     0.047140 -0.013234  0.019684    ...    -0.031417 -0.068420 -0.004565   \n",
       "V19    -0.033966  0.025777 -0.000381    ...     0.007331  0.012406 -0.003361   \n",
       "V20     0.053773 -0.023337  0.013878    ...    -0.049776 -0.009782 -0.046398   \n",
       "V21     0.025214  0.001163  0.013723    ...     1.000000 -0.077490 -0.011113   \n",
       "V22    -0.043410  0.020149  0.044522    ...    -0.077490  1.000000  0.029946   \n",
       "V23     0.028541 -0.036521 -0.023592    ...    -0.011113  0.029946  1.000000   \n",
       "V24    -0.000163  0.009313  0.003199    ...     0.006600  0.005757  0.012941   \n",
       "V25    -0.066814  0.015134  0.053311    ...    -0.007465 -0.019909  0.045107   \n",
       "V26    -0.026282  0.014576  0.044132    ...    -0.019163 -0.077164  0.030483   \n",
       "V27    -0.049039  0.030332 -0.000084    ...     0.011199 -0.016457 -0.000615   \n",
       "V28    -0.027001  0.015092 -0.029320    ...     0.043743 -0.028022  0.025979   \n",
       "Amount  0.352925 -0.084011 -0.032619    ...     0.128074 -0.078848 -0.128896   \n",
       "Class  -0.263717  0.026688 -0.114936    ...     0.050749  0.003980 -0.001187   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount     Class  \n",
       "Time   -0.005517 -0.133370 -0.043491 -0.001390 -0.001486 -0.024559 -0.007336  \n",
       "V1     -0.010842  0.122406 -0.001845 -0.001745  0.097715 -0.233275 -0.145422  \n",
       "V2     -0.010293 -0.067000 -0.024394 -0.001581  0.007363 -0.544872  0.124537  \n",
       "V3      0.012462 -0.093891  0.034885 -0.019721  0.017112 -0.197158 -0.281333  \n",
       "V4     -0.001971 -0.013589 -0.014515  0.004942 -0.004932  0.096241  0.159813  \n",
       "V5     -0.010975 -0.024344 -0.038380  0.018106 -0.008315 -0.377240 -0.143884  \n",
       "V6     -0.008718  0.032492  0.012248 -0.021799 -0.004309  0.196986 -0.053040  \n",
       "V7     -0.000163 -0.066814 -0.026282 -0.049039 -0.027001  0.352925 -0.263717  \n",
       "V8      0.009313  0.015134  0.014576  0.030332  0.015092 -0.084011  0.026688  \n",
       "V9      0.003199  0.053311  0.044132 -0.000084 -0.029320 -0.032619 -0.114936  \n",
       "V10     0.005355  0.025425  0.002403 -0.014305 -0.030029 -0.113239 -0.275925  \n",
       "V11     0.024506 -0.081842 -0.009105  0.000883 -0.008334 -0.010576  0.181916  \n",
       "V12     0.014653  0.066186  0.032362  0.007556  0.001778  0.015841 -0.287090  \n",
       "V13    -0.024777 -0.012577 -0.003286 -0.001221 -0.002704 -0.005217 -0.003223  \n",
       "V14     0.013741 -0.073370 -0.003623 -0.005933  0.018385  0.013653 -0.345632  \n",
       "V15     0.005275 -0.025952 -0.020350  0.003859 -0.009370 -0.027629 -0.010299  \n",
       "V16    -0.008569  0.063534  0.030306  0.004681 -0.004553 -0.020581 -0.256484  \n",
       "V17    -0.009268 -0.056530 -0.049267  0.013769 -0.001966  0.018883 -0.412952  \n",
       "V18    -0.013255  0.007904 -0.003133 -0.000162  0.007626  0.046260 -0.156766  \n",
       "V19    -0.010344 -0.001012 -0.004933 -0.005502 -0.005923 -0.060385  0.048401  \n",
       "V20    -0.003983 -0.023342  0.007144 -0.010692  0.076921  0.432146  0.023689  \n",
       "V21     0.006600 -0.007465 -0.019163  0.011199  0.043743  0.128074  0.050749  \n",
       "V22     0.005757 -0.019909 -0.077164 -0.016457 -0.028022 -0.078848  0.003980  \n",
       "V23     0.012941  0.045107  0.030483 -0.000615  0.025979 -0.128896 -0.001187  \n",
       "V24     1.000000 -0.020695 -0.007793 -0.008699  0.002247  0.010531 -0.006352  \n",
       "V25    -0.020695  1.000000 -0.086498  0.045403  0.041472 -0.056076 -0.001201  \n",
       "V26    -0.007793 -0.086498  1.000000  0.005137  0.008807  0.009877  0.002471  \n",
       "V27    -0.008699  0.045403  0.005137  1.000000  0.085580 -0.008025  0.021195  \n",
       "V28     0.002247  0.041472  0.008807  0.085580  1.000000  0.027765  0.007481  \n",
       "Amount  0.010531 -0.056076  0.009877 -0.008025  0.027765  1.000000  0.004528  \n",
       "Class  -0.006352 -0.001201  0.002471  0.021195  0.007481  0.004528  1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correMatrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class     1.000000\n",
       "V17       0.412952\n",
       "V14       0.345632\n",
       "V12       0.287090\n",
       "V3        0.281333\n",
       "V10       0.275925\n",
       "V7        0.263717\n",
       "V16       0.256484\n",
       "V11       0.181916\n",
       "V4        0.159813\n",
       "V18       0.156766\n",
       "V1        0.145422\n",
       "V5        0.143884\n",
       "V2        0.124537\n",
       "V9        0.114936\n",
       "V6        0.053040\n",
       "V21       0.050749\n",
       "V19       0.048401\n",
       "V8        0.026688\n",
       "V20       0.023689\n",
       "V27       0.021195\n",
       "V15       0.010299\n",
       "V28       0.007481\n",
       "Time      0.007336\n",
       "V24       0.006352\n",
       "Amount    0.004528\n",
       "V22       0.003980\n",
       "V13       0.003223\n",
       "V26       0.002471\n",
       "V25       0.001201\n",
       "V23       0.001187\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(correMatrx[\"Class\"]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can notice that some attributes are a bit correlated with the target attribute V17 V14 And V12 we will go deeper to see what it can ook like with  thr target attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6f12eb4ad0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1a8faf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset.plot(kind=\"scatter\", x=\"V17\", y=\"Class\",\n",
    "alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6f12c47190>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMxaDgUzM2s5FMzMrOVQMDOz1v8HbdGsPa+6GNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1a947190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset.plot(kind=\"scatter\", x=\"V14\", y=\"Class\",\n",
    "alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V23       0.001187\n",
       "V25       0.001201\n",
       "V26       0.002471\n",
       "V13       0.003223\n",
       "V22       0.003980\n",
       "Amount    0.004528\n",
       "V24       0.006352\n",
       "Time      0.007336\n",
       "V28       0.007481\n",
       "V15       0.010299\n",
       "V27       0.021195\n",
       "V20       0.023689\n",
       "V8        0.026688\n",
       "V19       0.048401\n",
       "V21       0.050749\n",
       "V6        0.053040\n",
       "V9        0.114936\n",
       "V2        0.124537\n",
       "V5        0.143884\n",
       "V1        0.145422\n",
       "V18       0.156766\n",
       "V4        0.159813\n",
       "V11       0.181916\n",
       "V16       0.256484\n",
       "V7        0.263717\n",
       "V10       0.275925\n",
       "V3        0.281333\n",
       "V12       0.287090\n",
       "V14       0.345632\n",
       "V17       0.412952\n",
       "Class     1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(correMatrx[\"Class\"]).sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let try to see the plot with an non correlatred value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6f16298a10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f16304750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dataset.plot(kind=\"scatter\", x=\"V23\", y=\"Class\",\n",
    "alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let try another correlation attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correMatrxK=Dataset.corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class     1.000000\n",
       "V14       0.059165\n",
       "V12       0.057735\n",
       "V4        0.057680\n",
       "V3        0.055809\n",
       "V11       0.055265\n",
       "V10       0.054866\n",
       "V2        0.049706\n",
       "V16       0.048168\n",
       "V7        0.046542\n",
       "V9        0.044636\n",
       "V17       0.043074\n",
       "V1        0.042611\n",
       "V18       0.038566\n",
       "V6        0.036030\n",
       "V5        0.035627\n",
       "V21       0.032267\n",
       "V27       0.024839\n",
       "V19       0.024598\n",
       "V8        0.021780\n",
       "V20       0.017955\n",
       "V28       0.015765\n",
       "V15       0.007393\n",
       "V24       0.007095\n",
       "Amount    0.006864\n",
       "Time      0.005269\n",
       "V22       0.004880\n",
       "V23       0.004377\n",
       "V26       0.004018\n",
       "V13       0.001332\n",
       "V25       0.000403\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(correMatrxK[\"Class\"]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correMatrxK=Dataset.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class     1.000000\n",
       "V14       0.072461\n",
       "V12       0.070711\n",
       "V4        0.070643\n",
       "V3        0.068351\n",
       "V11       0.067686\n",
       "V10       0.067196\n",
       "V2        0.060877\n",
       "V16       0.058994\n",
       "V7        0.057002\n",
       "V9        0.054667\n",
       "V17       0.052755\n",
       "V1        0.052187\n",
       "V18       0.047234\n",
       "V6        0.044127\n",
       "V5        0.043634\n",
       "V21       0.039519\n",
       "V27       0.030422\n",
       "V19       0.030126\n",
       "V8        0.026675\n",
       "V20       0.021990\n",
       "V28       0.019308\n",
       "V15       0.009055\n",
       "V24       0.008689\n",
       "Amount    0.008386\n",
       "Time      0.006453\n",
       "V22       0.005976\n",
       "V23       0.005361\n",
       "V26       0.004921\n",
       "V13       0.001631\n",
       "V25       0.000493\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(correMatrxK[\"Class\"]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let drop the class attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=Dataset.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y=Dataset['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use skit learn StandardScaller this pipeline will transform the data for us and scale it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([('std_scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XScale=num_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let check what the the scalling di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61092.608212</td>\n",
       "      <td>-0.169856</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>0.493038</td>\n",
       "      <td>0.117430</td>\n",
       "      <td>-0.176091</td>\n",
       "      <td>0.058238</td>\n",
       "      <td>-0.080670</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030943</td>\n",
       "      <td>-0.028273</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.022461</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>87.336246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27828.974490</td>\n",
       "      <td>1.850523</td>\n",
       "      <td>1.610865</td>\n",
       "      <td>1.383248</td>\n",
       "      <td>1.371899</td>\n",
       "      <td>1.338609</td>\n",
       "      <td>1.295132</td>\n",
       "      <td>1.208518</td>\n",
       "      <td>1.227627</td>\n",
       "      <td>1.152289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725832</td>\n",
       "      <td>0.743723</td>\n",
       "      <td>0.667322</td>\n",
       "      <td>0.584511</td>\n",
       "      <td>0.598757</td>\n",
       "      <td>0.465511</td>\n",
       "      <td>0.490667</td>\n",
       "      <td>0.391952</td>\n",
       "      <td>0.307317</td>\n",
       "      <td>245.952377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.838548</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-11.710896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41217.000000</td>\n",
       "      <td>-0.986678</td>\n",
       "      <td>-0.539179</td>\n",
       "      <td>-0.064757</td>\n",
       "      <td>-0.743469</td>\n",
       "      <td>-0.828769</td>\n",
       "      <td>-0.691130</td>\n",
       "      <td>-0.586318</td>\n",
       "      <td>-0.162642</td>\n",
       "      <td>-0.660087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183587</td>\n",
       "      <td>-0.230719</td>\n",
       "      <td>-0.546772</td>\n",
       "      <td>-0.170303</td>\n",
       "      <td>-0.332459</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.330347</td>\n",
       "      <td>-0.065124</td>\n",
       "      <td>-0.027056</td>\n",
       "      <td>5.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60776.000000</td>\n",
       "      <td>-0.183596</td>\n",
       "      <td>0.109687</td>\n",
       "      <td>0.623352</td>\n",
       "      <td>0.124322</td>\n",
       "      <td>-0.226226</td>\n",
       "      <td>-0.202623</td>\n",
       "      <td>-0.031930</td>\n",
       "      <td>0.056663</td>\n",
       "      <td>-0.078965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036163</td>\n",
       "      <td>-0.054461</td>\n",
       "      <td>-0.066777</td>\n",
       "      <td>-0.036215</td>\n",
       "      <td>0.059467</td>\n",
       "      <td>0.135677</td>\n",
       "      <td>-0.058970</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>21.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78622.750000</td>\n",
       "      <td>1.184444</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>1.297353</td>\n",
       "      <td>0.937619</td>\n",
       "      <td>0.374481</td>\n",
       "      <td>0.449208</td>\n",
       "      <td>0.462624</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155774</td>\n",
       "      <td>0.128339</td>\n",
       "      <td>0.363171</td>\n",
       "      <td>0.098701</td>\n",
       "      <td>0.415855</td>\n",
       "      <td>0.399459</td>\n",
       "      <td>0.272940</td>\n",
       "      <td>0.089729</td>\n",
       "      <td>0.078303</td>\n",
       "      <td>76.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120396.000000</td>\n",
       "      <td>2.439207</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>19.002942</td>\n",
       "      <td>4.022866</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>19656.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean    61092.608212      -0.169856       0.040770       0.493038   \n",
       "std     27828.974490       1.850523       1.610865       1.383248   \n",
       "min         0.000000     -56.407510     -72.715728     -33.680984   \n",
       "25%     41217.000000      -0.986678      -0.539179      -0.064757   \n",
       "50%     60776.000000      -0.183596       0.109687       0.623352   \n",
       "75%     78622.750000       1.184444       0.804222       1.297353   \n",
       "max    120396.000000       2.439207      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean        0.117430      -0.176091       0.058238      -0.080670   \n",
       "std         1.371899       1.338609       1.295132       1.208518   \n",
       "min        -5.519697     -42.147898     -26.160506     -43.557242   \n",
       "25%        -0.743469      -0.828769      -0.691130      -0.586318   \n",
       "50%         0.124322      -0.226226      -0.202623      -0.031930   \n",
       "75%         0.937619       0.374481       0.449208       0.462624   \n",
       "max        16.875344      34.801666      22.529298      36.677268   \n",
       "\n",
       "                  V8             V9      ...                  V20  \\\n",
       "count  170886.000000  170886.000000      ...        170886.000000   \n",
       "mean        0.032215       0.018873      ...             0.030943   \n",
       "std         1.227627       1.152289      ...             0.725832   \n",
       "min       -73.216718     -13.434066      ...           -22.838548   \n",
       "25%        -0.162642      -0.660087      ...            -0.183587   \n",
       "50%         0.056663      -0.078965      ...            -0.036163   \n",
       "75%         0.350995       0.641342      ...             0.155774   \n",
       "max        20.007208      15.594995      ...            39.420904   \n",
       "\n",
       "                 V21            V22            V23            V24  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean       -0.028273      -0.083738      -0.022461       0.009004   \n",
       "std         0.743723       0.667322       0.584511       0.598757   \n",
       "min       -34.830382     -10.933144     -44.807735      -2.836627   \n",
       "25%        -0.230719      -0.546772      -0.170303      -0.332459   \n",
       "50%        -0.054461      -0.066777      -0.036215       0.059467   \n",
       "75%         0.128339       0.363171       0.098701       0.415855   \n",
       "max        27.202839      10.503090      19.002942       4.022866   \n",
       "\n",
       "                 V25            V26            V27            V28  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean        0.092271       0.012607       0.002100       0.002443   \n",
       "std         0.465511       0.490667       0.391952       0.307317   \n",
       "min       -10.295397      -2.604551     -22.565679     -11.710896   \n",
       "25%        -0.195935      -0.330347      -0.065124      -0.027056   \n",
       "50%         0.135677      -0.058970       0.008693       0.021151   \n",
       "75%         0.399459       0.272940       0.089729       0.078303   \n",
       "max         7.519589       3.517346      12.152401      33.847808   \n",
       "\n",
       "              Amount  \n",
       "count  170886.000000  \n",
       "mean       87.336246  \n",
       "std       245.952377  \n",
       "min         0.000000  \n",
       "25%         5.480000  \n",
       "50%        21.895000  \n",
       "75%        76.720000  \n",
       "max     19656.530000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170886, 30)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XScale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.19529422, -0.64303651, -0.07049098, ...,  0.33539638,\n",
       "        -0.07645474,  0.25323576],\n",
       "       [-2.19529422,  0.73585535,  0.13991333, ..., -0.02827577,\n",
       "         0.03996343, -0.34415806],\n",
       "       [-2.19525829, -0.64225129, -0.85726444, ..., -0.14658076,\n",
       "        -0.20237961,  1.18447567],\n",
       "       ..., \n",
       "       [ 2.13100074, -1.21103126, -0.81019027, ...,  0.20808908,\n",
       "        -1.99666837,  0.15305347],\n",
       "       [ 2.13100074, -0.66179801,  0.15148461, ...,  1.16556586,\n",
       "        -0.24066059, -0.15180319],\n",
       "       [ 2.13100074,  0.16764755,  0.58900466, ...,  1.37478336,\n",
       "         1.04590189, -0.31976302]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Scaller=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XPrepared=Scaller.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170886, 30)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XScale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Time', u'V1', u'V2', u'V3', u'V4', u'V5', u'V6', u'V7', u'V8', u'V9',\n",
       "       u'V10', u'V11', u'V12', u'V13', u'V14', u'V15', u'V16', u'V17', u'V18',\n",
       "       u'V19', u'V20', u'V21', u'V22', u'V23', u'V24', u'V25', u'V26', u'V27',\n",
       "       u'V28', u'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XSc=pd.DataFrame(XScale,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.195294</td>\n",
       "      <td>-0.643037</td>\n",
       "      <td>-0.070491</td>\n",
       "      <td>1.477187</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>-0.121193</td>\n",
       "      <td>0.312054</td>\n",
       "      <td>0.265010</td>\n",
       "      <td>0.054155</td>\n",
       "      <td>0.299331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303747</td>\n",
       "      <td>0.013401</td>\n",
       "      <td>0.541832</td>\n",
       "      <td>-0.150576</td>\n",
       "      <td>0.096740</td>\n",
       "      <td>0.077910</td>\n",
       "      <td>-0.411119</td>\n",
       "      <td>0.335396</td>\n",
       "      <td>-0.076455</td>\n",
       "      <td>0.253236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.195294</td>\n",
       "      <td>0.735855</td>\n",
       "      <td>0.139913</td>\n",
       "      <td>-0.236081</td>\n",
       "      <td>0.241071</td>\n",
       "      <td>0.176384</td>\n",
       "      <td>-0.108559</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>-0.238046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137810</td>\n",
       "      <td>-0.265560</td>\n",
       "      <td>-0.831587</td>\n",
       "      <td>0.211714</td>\n",
       "      <td>-0.582627</td>\n",
       "      <td>0.160897</td>\n",
       "      <td>0.230885</td>\n",
       "      <td>-0.028276</td>\n",
       "      <td>0.039963</td>\n",
       "      <td>-0.344158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.195258</td>\n",
       "      <td>-0.642251</td>\n",
       "      <td>-0.857264</td>\n",
       "      <td>0.925485</td>\n",
       "      <td>0.191231</td>\n",
       "      <td>-0.244364</td>\n",
       "      <td>1.345242</td>\n",
       "      <td>0.721656</td>\n",
       "      <td>0.175510</td>\n",
       "      <td>-1.330856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680650</td>\n",
       "      <td>0.371472</td>\n",
       "      <td>1.281870</td>\n",
       "      <td>1.594282</td>\n",
       "      <td>-1.166229</td>\n",
       "      <td>-0.902051</td>\n",
       "      <td>-0.309179</td>\n",
       "      <td>-0.146581</td>\n",
       "      <td>-0.202380</td>\n",
       "      <td>1.184476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.195258</td>\n",
       "      <td>-0.430374</td>\n",
       "      <td>-0.140295</td>\n",
       "      <td>0.939788</td>\n",
       "      <td>-0.714867</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>0.918029</td>\n",
       "      <td>0.263364</td>\n",
       "      <td>0.281210</td>\n",
       "      <td>-1.220093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329252</td>\n",
       "      <td>-0.107604</td>\n",
       "      <td>0.133386</td>\n",
       "      <td>-0.287180</td>\n",
       "      <td>-1.978405</td>\n",
       "      <td>1.192466</td>\n",
       "      <td>-0.477995</td>\n",
       "      <td>0.154671</td>\n",
       "      <td>0.192033</td>\n",
       "      <td>0.147036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.195222</td>\n",
       "      <td>-0.534108</td>\n",
       "      <td>0.519578</td>\n",
       "      <td>0.763192</td>\n",
       "      <td>0.208182</td>\n",
       "      <td>-0.172644</td>\n",
       "      <td>0.029097</td>\n",
       "      <td>0.557388</td>\n",
       "      <td>-0.246613</td>\n",
       "      <td>0.693289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520231</td>\n",
       "      <td>0.025335</td>\n",
       "      <td>1.321730</td>\n",
       "      <td>-0.196741</td>\n",
       "      <td>0.220896</td>\n",
       "      <td>-0.640762</td>\n",
       "      <td>0.998002</td>\n",
       "      <td>0.554465</td>\n",
       "      <td>0.692154</td>\n",
       "      <td>-0.070527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.195222</td>\n",
       "      <td>-0.138399</td>\n",
       "      <td>0.570970</td>\n",
       "      <td>0.468516</td>\n",
       "      <td>-0.208239</td>\n",
       "      <td>0.446045</td>\n",
       "      <td>-0.067920</td>\n",
       "      <td>0.460790</td>\n",
       "      <td>0.185805</td>\n",
       "      <td>-0.509894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074431</td>\n",
       "      <td>-0.242000</td>\n",
       "      <td>-0.713432</td>\n",
       "      <td>-0.006735</td>\n",
       "      <td>-0.635370</td>\n",
       "      <td>-0.698300</td>\n",
       "      <td>0.190166</td>\n",
       "      <td>0.642287</td>\n",
       "      <td>0.255884</td>\n",
       "      <td>-0.340174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.195150</td>\n",
       "      <td>0.756282</td>\n",
       "      <td>0.062224</td>\n",
       "      <td>-0.323636</td>\n",
       "      <td>0.791010</td>\n",
       "      <td>0.274892</td>\n",
       "      <td>0.165598</td>\n",
       "      <td>0.062483</td>\n",
       "      <td>0.039913</td>\n",
       "      <td>0.387133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345227</td>\n",
       "      <td>-0.187494</td>\n",
       "      <td>-0.280184</td>\n",
       "      <td>-0.225219</td>\n",
       "      <td>-1.317834</td>\n",
       "      <td>1.413216</td>\n",
       "      <td>-0.549954</td>\n",
       "      <td>0.082683</td>\n",
       "      <td>0.008867</td>\n",
       "      <td>-0.334807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.195043</td>\n",
       "      <td>-0.256368</td>\n",
       "      <td>0.854943</td>\n",
       "      <td>0.420275</td>\n",
       "      <td>-0.444371</td>\n",
       "      <td>0.840446</td>\n",
       "      <td>0.285594</td>\n",
       "      <td>0.994032</td>\n",
       "      <td>-3.128060</td>\n",
       "      <td>0.517668</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258580</td>\n",
       "      <td>2.651181</td>\n",
       "      <td>-1.396208</td>\n",
       "      <td>0.136806</td>\n",
       "      <td>-1.100138</td>\n",
       "      <td>-1.090285</td>\n",
       "      <td>-0.130927</td>\n",
       "      <td>-3.084626</td>\n",
       "      <td>-3.539615</td>\n",
       "      <td>-0.189209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.195043</td>\n",
       "      <td>-0.391474</td>\n",
       "      <td>0.152333</td>\n",
       "      <td>-0.438267</td>\n",
       "      <td>-0.283518</td>\n",
       "      <td>2.125862</td>\n",
       "      <td>2.828739</td>\n",
       "      <td>0.373033</td>\n",
       "      <td>0.667036</td>\n",
       "      <td>-0.356613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030024</td>\n",
       "      <td>-0.060711</td>\n",
       "      <td>-0.276260</td>\n",
       "      <td>-0.310981</td>\n",
       "      <td>1.674454</td>\n",
       "      <td>0.603496</td>\n",
       "      <td>-0.808624</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.455431</td>\n",
       "      <td>0.023841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.194971</td>\n",
       "      <td>-0.091004</td>\n",
       "      <td>0.669719</td>\n",
       "      <td>0.398577</td>\n",
       "      <td>-0.247554</td>\n",
       "      <td>0.504594</td>\n",
       "      <td>-0.235497</td>\n",
       "      <td>0.605912</td>\n",
       "      <td>0.030403</td>\n",
       "      <td>-0.655740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.238028</td>\n",
       "      <td>-0.293982</td>\n",
       "      <td>-0.824215</td>\n",
       "      <td>-0.168232</td>\n",
       "      <td>-0.658123</td>\n",
       "      <td>-0.348015</td>\n",
       "      <td>0.166288</td>\n",
       "      <td>0.622833</td>\n",
       "      <td>0.262377</td>\n",
       "      <td>-0.340133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.194935</td>\n",
       "      <td>0.874836</td>\n",
       "      <td>-0.755565</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>-1.088347</td>\n",
       "      <td>-1.341166</td>\n",
       "      <td>-0.530750</td>\n",
       "      <td>-1.110923</td>\n",
       "      <td>0.013229</td>\n",
       "      <td>-1.509418</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576126</td>\n",
       "      <td>0.025508</td>\n",
       "      <td>0.595865</td>\n",
       "      <td>0.085886</td>\n",
       "      <td>0.820883</td>\n",
       "      <td>0.341767</td>\n",
       "      <td>-0.289576</td>\n",
       "      <td>0.103968</td>\n",
       "      <td>0.044939</td>\n",
       "      <td>-0.323382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.194935</td>\n",
       "      <td>0.299827</td>\n",
       "      <td>0.357163</td>\n",
       "      <td>-0.988501</td>\n",
       "      <td>-0.154129</td>\n",
       "      <td>2.316348</td>\n",
       "      <td>2.516190</td>\n",
       "      <td>0.456035</td>\n",
       "      <td>0.412204</td>\n",
       "      <td>-0.501409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130951</td>\n",
       "      <td>0.105143</td>\n",
       "      <td>0.482766</td>\n",
       "      <td>0.054047</td>\n",
       "      <td>1.649600</td>\n",
       "      <td>-1.846549</td>\n",
       "      <td>-1.028837</td>\n",
       "      <td>0.103005</td>\n",
       "      <td>-0.184761</td>\n",
       "      <td>-0.314477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.194935</td>\n",
       "      <td>0.767274</td>\n",
       "      <td>-0.783685</td>\n",
       "      <td>-0.078878</td>\n",
       "      <td>-0.985738</td>\n",
       "      <td>-0.978128</td>\n",
       "      <td>-0.626554</td>\n",
       "      <td>-0.503705</td>\n",
       "      <td>-0.211549</td>\n",
       "      <td>-1.833644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184202</td>\n",
       "      <td>-0.273673</td>\n",
       "      <td>-0.598735</td>\n",
       "      <td>0.183280</td>\n",
       "      <td>0.641041</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>-0.749180</td>\n",
       "      <td>0.062038</td>\n",
       "      <td>0.130092</td>\n",
       "      <td>0.138904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-2.194899</td>\n",
       "      <td>0.669667</td>\n",
       "      <td>0.153305</td>\n",
       "      <td>0.242600</td>\n",
       "      <td>1.891610</td>\n",
       "      <td>-0.001723</td>\n",
       "      <td>0.215659</td>\n",
       "      <td>-0.013278</td>\n",
       "      <td>0.068235</td>\n",
       "      <td>-0.208243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253696</td>\n",
       "      <td>-0.011567</td>\n",
       "      <td>0.236993</td>\n",
       "      <td>-0.083739</td>\n",
       "      <td>0.159898</td>\n",
       "      <td>0.979557</td>\n",
       "      <td>0.186455</td>\n",
       "      <td>0.049474</td>\n",
       "      <td>0.061339</td>\n",
       "      <td>-0.243285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.194863</td>\n",
       "      <td>-1.416900</td>\n",
       "      <td>-0.228785</td>\n",
       "      <td>0.830448</td>\n",
       "      <td>1.202747</td>\n",
       "      <td>0.029511</td>\n",
       "      <td>0.578598</td>\n",
       "      <td>-0.283192</td>\n",
       "      <td>-1.579737</td>\n",
       "      <td>0.639460</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.222374</td>\n",
       "      <td>1.586531</td>\n",
       "      <td>0.458431</td>\n",
       "      <td>1.784482</td>\n",
       "      <td>0.032254</td>\n",
       "      <td>-0.698198</td>\n",
       "      <td>-0.505770</td>\n",
       "      <td>-0.425761</td>\n",
       "      <td>-0.106068</td>\n",
       "      <td>-0.116024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.194863</td>\n",
       "      <td>-0.314809</td>\n",
       "      <td>0.189163</td>\n",
       "      <td>1.130882</td>\n",
       "      <td>-1.156119</td>\n",
       "      <td>-0.733825</td>\n",
       "      <td>-0.105076</td>\n",
       "      <td>-0.436827</td>\n",
       "      <td>-0.023307</td>\n",
       "      <td>-0.394901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320333</td>\n",
       "      <td>0.709807</td>\n",
       "      <td>2.153973</td>\n",
       "      <td>-0.400528</td>\n",
       "      <td>-0.123737</td>\n",
       "      <td>-0.282262</td>\n",
       "      <td>-0.203180</td>\n",
       "      <td>-0.467143</td>\n",
       "      <td>0.413096</td>\n",
       "      <td>-0.290082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.194863</td>\n",
       "      <td>0.687954</td>\n",
       "      <td>-0.050325</td>\n",
       "      <td>0.559767</td>\n",
       "      <td>0.854046</td>\n",
       "      <td>-0.418275</td>\n",
       "      <td>0.177458</td>\n",
       "      <td>-0.418189</td>\n",
       "      <td>0.128023</td>\n",
       "      <td>0.662561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199569</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.419199</td>\n",
       "      <td>0.062039</td>\n",
       "      <td>0.158252</td>\n",
       "      <td>0.584362</td>\n",
       "      <td>-0.804759</td>\n",
       "      <td>0.231431</td>\n",
       "      <td>0.112613</td>\n",
       "      <td>-0.302280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-2.194827</td>\n",
       "      <td>-0.144310</td>\n",
       "      <td>0.545172</td>\n",
       "      <td>0.311986</td>\n",
       "      <td>-0.615681</td>\n",
       "      <td>0.815603</td>\n",
       "      <td>-0.143696</td>\n",
       "      <td>0.652298</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>-0.593727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.107414</td>\n",
       "      <td>-0.223905</td>\n",
       "      <td>-0.882486</td>\n",
       "      <td>-0.229930</td>\n",
       "      <td>-1.498761</td>\n",
       "      <td>-0.933782</td>\n",
       "      <td>-0.125612</td>\n",
       "      <td>0.197966</td>\n",
       "      <td>0.418399</td>\n",
       "      <td>-0.351477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-2.194791</td>\n",
       "      <td>-2.826993</td>\n",
       "      <td>-3.408687</td>\n",
       "      <td>0.501189</td>\n",
       "      <td>1.179980</td>\n",
       "      <td>2.409371</td>\n",
       "      <td>-1.406534</td>\n",
       "      <td>-1.223873</td>\n",
       "      <td>0.104777</td>\n",
       "      <td>1.053746</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.069302</td>\n",
       "      <td>-0.639121</td>\n",
       "      <td>1.600729</td>\n",
       "      <td>4.244668</td>\n",
       "      <td>0.055306</td>\n",
       "      <td>-1.232847</td>\n",
       "      <td>-1.291875</td>\n",
       "      <td>0.994905</td>\n",
       "      <td>3.082007</td>\n",
       "      <td>-0.164814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-2.194755</td>\n",
       "      <td>0.898555</td>\n",
       "      <td>-0.664313</td>\n",
       "      <td>-0.027647</td>\n",
       "      <td>-1.133802</td>\n",
       "      <td>-1.030433</td>\n",
       "      <td>-0.601638</td>\n",
       "      <td>-0.827458</td>\n",
       "      <td>-0.069518</td>\n",
       "      <td>-1.733557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.577068</td>\n",
       "      <td>-0.200851</td>\n",
       "      <td>-0.136870</td>\n",
       "      <td>0.106864</td>\n",
       "      <td>0.479010</td>\n",
       "      <td>0.516980</td>\n",
       "      <td>-0.474848</td>\n",
       "      <td>0.051534</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>-0.334766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-2.194719</td>\n",
       "      <td>0.467297</td>\n",
       "      <td>-0.870708</td>\n",
       "      <td>0.387628</td>\n",
       "      <td>0.522437</td>\n",
       "      <td>-0.758339</td>\n",
       "      <td>0.965828</td>\n",
       "      <td>-0.660245</td>\n",
       "      <td>0.336483</td>\n",
       "      <td>-0.403605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233219</td>\n",
       "      <td>-0.359422</td>\n",
       "      <td>-0.731609</td>\n",
       "      <td>-0.048621</td>\n",
       "      <td>-0.523117</td>\n",
       "      <td>-0.043545</td>\n",
       "      <td>-0.886227</td>\n",
       "      <td>0.215471</td>\n",
       "      <td>0.198674</td>\n",
       "      <td>0.587001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-2.194683</td>\n",
       "      <td>0.611911</td>\n",
       "      <td>0.178595</td>\n",
       "      <td>-0.480405</td>\n",
       "      <td>1.451842</td>\n",
       "      <td>0.975386</td>\n",
       "      <td>1.264585</td>\n",
       "      <td>0.155879</td>\n",
       "      <td>0.398564</td>\n",
       "      <td>-1.050246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.413684</td>\n",
       "      <td>0.231633</td>\n",
       "      <td>0.728631</td>\n",
       "      <td>-0.044562</td>\n",
       "      <td>-2.306237</td>\n",
       "      <td>0.641324</td>\n",
       "      <td>0.381842</td>\n",
       "      <td>0.036410</td>\n",
       "      <td>-0.055474</td>\n",
       "      <td>-0.216491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-2.194647</td>\n",
       "      <td>0.722216</td>\n",
       "      <td>0.286400</td>\n",
       "      <td>-0.405090</td>\n",
       "      <td>1.562904</td>\n",
       "      <td>0.451885</td>\n",
       "      <td>0.024118</td>\n",
       "      <td>0.266291</td>\n",
       "      <td>0.086237</td>\n",
       "      <td>-0.874813</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.465828</td>\n",
       "      <td>0.063162</td>\n",
       "      <td>0.032616</td>\n",
       "      <td>-0.139252</td>\n",
       "      <td>-0.633681</td>\n",
       "      <td>1.097569</td>\n",
       "      <td>0.195548</td>\n",
       "      <td>-0.108739</td>\n",
       "      <td>-0.045102</td>\n",
       "      <td>-0.345825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-2.194647</td>\n",
       "      <td>0.225530</td>\n",
       "      <td>0.147062</td>\n",
       "      <td>0.500587</td>\n",
       "      <td>-0.153097</td>\n",
       "      <td>-0.850364</td>\n",
       "      <td>-0.160875</td>\n",
       "      <td>-0.716330</td>\n",
       "      <td>-1.344183</td>\n",
       "      <td>1.323629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360865</td>\n",
       "      <td>2.256833</td>\n",
       "      <td>0.425871</td>\n",
       "      <td>-0.278681</td>\n",
       "      <td>0.691550</td>\n",
       "      <td>1.564564</td>\n",
       "      <td>-0.489618</td>\n",
       "      <td>0.853513</td>\n",
       "      <td>0.807092</td>\n",
       "      <td>-0.262597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-2.194504</td>\n",
       "      <td>-0.960093</td>\n",
       "      <td>-0.053183</td>\n",
       "      <td>-0.649638</td>\n",
       "      <td>-0.824034</td>\n",
       "      <td>2.329334</td>\n",
       "      <td>2.236701</td>\n",
       "      <td>0.014569</td>\n",
       "      <td>0.670671</td>\n",
       "      <td>0.026985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341207</td>\n",
       "      <td>-0.741209</td>\n",
       "      <td>-1.072187</td>\n",
       "      <td>1.527368</td>\n",
       "      <td>1.627406</td>\n",
       "      <td>0.491783</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>1.799766</td>\n",
       "      <td>0.039559</td>\n",
       "      <td>-0.351477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.194504</td>\n",
       "      <td>-1.029138</td>\n",
       "      <td>-0.100724</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.213265</td>\n",
       "      <td>0.352075</td>\n",
       "      <td>-0.785848</td>\n",
       "      <td>0.516879</td>\n",
       "      <td>-0.111469</td>\n",
       "      <td>0.396422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.575392</td>\n",
       "      <td>-0.504714</td>\n",
       "      <td>-0.215288</td>\n",
       "      <td>1.308611</td>\n",
       "      <td>0.650568</td>\n",
       "      <td>0.337137</td>\n",
       "      <td>0.533555</td>\n",
       "      <td>0.913048</td>\n",
       "      <td>0.783521</td>\n",
       "      <td>-0.247635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-2.194468</td>\n",
       "      <td>0.725819</td>\n",
       "      <td>0.194137</td>\n",
       "      <td>-0.151190</td>\n",
       "      <td>0.740679</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>-0.752274</td>\n",
       "      <td>0.372106</td>\n",
       "      <td>-0.292822</td>\n",
       "      <td>-0.230432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004223</td>\n",
       "      <td>0.128108</td>\n",
       "      <td>0.466867</td>\n",
       "      <td>-0.219032</td>\n",
       "      <td>0.711545</td>\n",
       "      <td>1.358840</td>\n",
       "      <td>-0.712683</td>\n",
       "      <td>0.036405</td>\n",
       "      <td>0.089805</td>\n",
       "      <td>-0.184818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-2.194468</td>\n",
       "      <td>0.806565</td>\n",
       "      <td>-0.133352</td>\n",
       "      <td>-0.042279</td>\n",
       "      <td>0.334288</td>\n",
       "      <td>-0.493548</td>\n",
       "      <td>-0.686666</td>\n",
       "      <td>-0.152447</td>\n",
       "      <td>-0.206250</td>\n",
       "      <td>-0.946203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.763118</td>\n",
       "      <td>-0.344353</td>\n",
       "      <td>-0.359078</td>\n",
       "      <td>-0.026088</td>\n",
       "      <td>0.564750</td>\n",
       "      <td>1.003991</td>\n",
       "      <td>-0.596669</td>\n",
       "      <td>0.102655</td>\n",
       "      <td>0.085838</td>\n",
       "      <td>-0.290042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-2.194468</td>\n",
       "      <td>-0.132089</td>\n",
       "      <td>0.536774</td>\n",
       "      <td>0.892406</td>\n",
       "      <td>0.988444</td>\n",
       "      <td>0.137109</td>\n",
       "      <td>-0.199647</td>\n",
       "      <td>0.679263</td>\n",
       "      <td>-0.050066</td>\n",
       "      <td>-0.531348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091432</td>\n",
       "      <td>0.141868</td>\n",
       "      <td>0.810808</td>\n",
       "      <td>-0.027440</td>\n",
       "      <td>1.058058</td>\n",
       "      <td>-0.593248</td>\n",
       "      <td>-0.591178</td>\n",
       "      <td>0.460742</td>\n",
       "      <td>0.488818</td>\n",
       "      <td>-0.220922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-2.194468</td>\n",
       "      <td>0.664270</td>\n",
       "      <td>-0.134145</td>\n",
       "      <td>0.558898</td>\n",
       "      <td>0.778981</td>\n",
       "      <td>-0.455631</td>\n",
       "      <td>0.401657</td>\n",
       "      <td>-0.567982</td>\n",
       "      <td>0.300443</td>\n",
       "      <td>0.590675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.287900</td>\n",
       "      <td>0.056405</td>\n",
       "      <td>0.445771</td>\n",
       "      <td>0.063169</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>0.434720</td>\n",
       "      <td>-0.830864</td>\n",
       "      <td>0.202478</td>\n",
       "      <td>0.070864</td>\n",
       "      <td>-0.302280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170856</th>\n",
       "      <td>2.130534</td>\n",
       "      <td>-0.725589</td>\n",
       "      <td>-0.637960</td>\n",
       "      <td>-0.927269</td>\n",
       "      <td>0.792830</td>\n",
       "      <td>0.933885</td>\n",
       "      <td>-0.574518</td>\n",
       "      <td>0.803646</td>\n",
       "      <td>-0.565971</td>\n",
       "      <td>0.125064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278358</td>\n",
       "      <td>0.019548</td>\n",
       "      <td>2.188841</td>\n",
       "      <td>1.295661</td>\n",
       "      <td>1.181945</td>\n",
       "      <td>-2.308025</td>\n",
       "      <td>2.068822</td>\n",
       "      <td>1.060838</td>\n",
       "      <td>1.328170</td>\n",
       "      <td>0.279989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170857</th>\n",
       "      <td>2.130534</td>\n",
       "      <td>-0.453298</td>\n",
       "      <td>-0.036663</td>\n",
       "      <td>0.424263</td>\n",
       "      <td>-2.530465</td>\n",
       "      <td>-0.240544</td>\n",
       "      <td>-0.042283</td>\n",
       "      <td>-0.209663</td>\n",
       "      <td>0.139325</td>\n",
       "      <td>-1.170108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100669</td>\n",
       "      <td>-0.412270</td>\n",
       "      <td>-0.513755</td>\n",
       "      <td>-0.641220</td>\n",
       "      <td>-0.005528</td>\n",
       "      <td>1.553586</td>\n",
       "      <td>-0.222828</td>\n",
       "      <td>1.204827</td>\n",
       "      <td>0.784807</td>\n",
       "      <td>-0.319316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170858</th>\n",
       "      <td>2.130570</td>\n",
       "      <td>1.238246</td>\n",
       "      <td>-0.554946</td>\n",
       "      <td>-1.062803</td>\n",
       "      <td>-0.381642</td>\n",
       "      <td>-0.410913</td>\n",
       "      <td>-0.321117</td>\n",
       "      <td>-0.562779</td>\n",
       "      <td>-0.002947</td>\n",
       "      <td>-0.024422</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.065078</td>\n",
       "      <td>-0.241632</td>\n",
       "      <td>0.135345</td>\n",
       "      <td>0.264122</td>\n",
       "      <td>-0.896942</td>\n",
       "      <td>-0.343982</td>\n",
       "      <td>-0.411077</td>\n",
       "      <td>0.054021</td>\n",
       "      <td>-0.213395</td>\n",
       "      <td>-0.351029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170859</th>\n",
       "      <td>2.130641</td>\n",
       "      <td>1.069291</td>\n",
       "      <td>-0.459799</td>\n",
       "      <td>-1.377172</td>\n",
       "      <td>-0.159404</td>\n",
       "      <td>0.490042</td>\n",
       "      <td>0.764991</td>\n",
       "      <td>-0.205551</td>\n",
       "      <td>0.288068</td>\n",
       "      <td>0.891419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.417930</td>\n",
       "      <td>-0.036725</td>\n",
       "      <td>0.112873</td>\n",
       "      <td>0.337942</td>\n",
       "      <td>-2.765981</td>\n",
       "      <td>-0.812682</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>-0.255658</td>\n",
       "      <td>-0.111145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170860</th>\n",
       "      <td>2.130641</td>\n",
       "      <td>1.106335</td>\n",
       "      <td>-0.199671</td>\n",
       "      <td>-1.058887</td>\n",
       "      <td>0.907119</td>\n",
       "      <td>0.340355</td>\n",
       "      <td>0.418715</td>\n",
       "      <td>-0.060740</td>\n",
       "      <td>0.103029</td>\n",
       "      <td>0.727976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305052</td>\n",
       "      <td>-0.353430</td>\n",
       "      <td>-0.735932</td>\n",
       "      <td>0.358235</td>\n",
       "      <td>0.420552</td>\n",
       "      <td>-0.038805</td>\n",
       "      <td>-1.753085</td>\n",
       "      <td>0.064368</td>\n",
       "      <td>-0.154476</td>\n",
       "      <td>-0.192462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170861</th>\n",
       "      <td>2.130677</td>\n",
       "      <td>-0.306929</td>\n",
       "      <td>-0.008348</td>\n",
       "      <td>0.033306</td>\n",
       "      <td>-1.980527</td>\n",
       "      <td>0.189729</td>\n",
       "      <td>0.436324</td>\n",
       "      <td>-0.241639</td>\n",
       "      <td>0.515749</td>\n",
       "      <td>-1.068486</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>0.637322</td>\n",
       "      <td>1.620498</td>\n",
       "      <td>-0.450894</td>\n",
       "      <td>-0.543863</td>\n",
       "      <td>0.104731</td>\n",
       "      <td>-0.370013</td>\n",
       "      <td>-0.054103</td>\n",
       "      <td>0.127070</td>\n",
       "      <td>-0.192665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170862</th>\n",
       "      <td>2.130677</td>\n",
       "      <td>1.069538</td>\n",
       "      <td>-0.279227</td>\n",
       "      <td>-0.335799</td>\n",
       "      <td>0.779018</td>\n",
       "      <td>-0.272348</td>\n",
       "      <td>0.352369</td>\n",
       "      <td>-0.633197</td>\n",
       "      <td>0.218378</td>\n",
       "      <td>0.742245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212393</td>\n",
       "      <td>0.214457</td>\n",
       "      <td>0.727440</td>\n",
       "      <td>0.509624</td>\n",
       "      <td>1.096442</td>\n",
       "      <td>-1.009333</td>\n",
       "      <td>-1.675969</td>\n",
       "      <td>0.164852</td>\n",
       "      <td>-0.060715</td>\n",
       "      <td>-0.172132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170863</th>\n",
       "      <td>2.130713</td>\n",
       "      <td>-0.061483</td>\n",
       "      <td>-0.118520</td>\n",
       "      <td>1.079451</td>\n",
       "      <td>0.243014</td>\n",
       "      <td>-0.195334</td>\n",
       "      <td>0.182594</td>\n",
       "      <td>0.492953</td>\n",
       "      <td>-0.245027</td>\n",
       "      <td>0.947530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220565</td>\n",
       "      <td>0.322963</td>\n",
       "      <td>1.854149</td>\n",
       "      <td>0.414726</td>\n",
       "      <td>-0.215890</td>\n",
       "      <td>-1.390446</td>\n",
       "      <td>-1.472529</td>\n",
       "      <td>-0.531092</td>\n",
       "      <td>-1.407212</td>\n",
       "      <td>0.085845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170864</th>\n",
       "      <td>2.130713</td>\n",
       "      <td>0.007110</td>\n",
       "      <td>0.285780</td>\n",
       "      <td>-0.570750</td>\n",
       "      <td>-1.712244</td>\n",
       "      <td>0.687576</td>\n",
       "      <td>-0.757864</td>\n",
       "      <td>0.690750</td>\n",
       "      <td>-0.140286</td>\n",
       "      <td>-1.344102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261848</td>\n",
       "      <td>0.046378</td>\n",
       "      <td>0.229616</td>\n",
       "      <td>-0.355845</td>\n",
       "      <td>-0.934388</td>\n",
       "      <td>0.336635</td>\n",
       "      <td>-0.755462</td>\n",
       "      <td>0.623754</td>\n",
       "      <td>0.270156</td>\n",
       "      <td>-0.294108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170865</th>\n",
       "      <td>2.130749</td>\n",
       "      <td>-0.062161</td>\n",
       "      <td>0.145307</td>\n",
       "      <td>0.635458</td>\n",
       "      <td>-0.453422</td>\n",
       "      <td>-0.224753</td>\n",
       "      <td>-0.343757</td>\n",
       "      <td>0.431561</td>\n",
       "      <td>0.016341</td>\n",
       "      <td>0.459640</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.143706</td>\n",
       "      <td>0.433281</td>\n",
       "      <td>1.421799</td>\n",
       "      <td>0.044040</td>\n",
       "      <td>0.104046</td>\n",
       "      <td>-1.729805</td>\n",
       "      <td>0.948354</td>\n",
       "      <td>0.358453</td>\n",
       "      <td>0.628696</td>\n",
       "      <td>-0.090856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170866</th>\n",
       "      <td>2.130749</td>\n",
       "      <td>0.169984</td>\n",
       "      <td>0.525979</td>\n",
       "      <td>-0.935405</td>\n",
       "      <td>-0.722426</td>\n",
       "      <td>1.212911</td>\n",
       "      <td>-0.036875</td>\n",
       "      <td>0.722529</td>\n",
       "      <td>0.077274</td>\n",
       "      <td>-0.164928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017720</td>\n",
       "      <td>-0.441275</td>\n",
       "      <td>-1.284715</td>\n",
       "      <td>-0.006779</td>\n",
       "      <td>-0.792800</td>\n",
       "      <td>-0.913498</td>\n",
       "      <td>0.294544</td>\n",
       "      <td>0.538382</td>\n",
       "      <td>0.200591</td>\n",
       "      <td>-0.344158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170867</th>\n",
       "      <td>2.130749</td>\n",
       "      <td>1.080954</td>\n",
       "      <td>-0.908328</td>\n",
       "      <td>-0.709151</td>\n",
       "      <td>-0.603368</td>\n",
       "      <td>-0.853701</td>\n",
       "      <td>-0.480012</td>\n",
       "      <td>-0.637515</td>\n",
       "      <td>-0.160923</td>\n",
       "      <td>-0.082649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497736</td>\n",
       "      <td>0.745519</td>\n",
       "      <td>1.936571</td>\n",
       "      <td>0.141922</td>\n",
       "      <td>2.020852</td>\n",
       "      <td>-0.753161</td>\n",
       "      <td>-0.322493</td>\n",
       "      <td>-0.037461</td>\n",
       "      <td>-0.018299</td>\n",
       "      <td>0.356427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170868</th>\n",
       "      <td>2.130749</td>\n",
       "      <td>1.172005</td>\n",
       "      <td>-0.434778</td>\n",
       "      <td>-1.077392</td>\n",
       "      <td>0.379868</td>\n",
       "      <td>-0.314627</td>\n",
       "      <td>-0.452275</td>\n",
       "      <td>-0.269562</td>\n",
       "      <td>-0.104019</td>\n",
       "      <td>-0.581675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.966787</td>\n",
       "      <td>0.073018</td>\n",
       "      <td>1.082179</td>\n",
       "      <td>0.029523</td>\n",
       "      <td>-0.042817</td>\n",
       "      <td>0.231318</td>\n",
       "      <td>-0.704749</td>\n",
       "      <td>0.067206</td>\n",
       "      <td>-0.180944</td>\n",
       "      <td>-0.196527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170869</th>\n",
       "      <td>2.130785</td>\n",
       "      <td>-0.207226</td>\n",
       "      <td>0.832508</td>\n",
       "      <td>1.365485</td>\n",
       "      <td>2.368066</td>\n",
       "      <td>0.676369</td>\n",
       "      <td>0.487377</td>\n",
       "      <td>0.847614</td>\n",
       "      <td>-0.099858</td>\n",
       "      <td>-1.211942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011823</td>\n",
       "      <td>0.085941</td>\n",
       "      <td>0.873083</td>\n",
       "      <td>-1.016878</td>\n",
       "      <td>-0.002933</td>\n",
       "      <td>1.460351</td>\n",
       "      <td>0.729254</td>\n",
       "      <td>-0.287987</td>\n",
       "      <td>-0.531362</td>\n",
       "      <td>-0.355095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170870</th>\n",
       "      <td>2.130785</td>\n",
       "      <td>-0.907790</td>\n",
       "      <td>-1.459532</td>\n",
       "      <td>0.351242</td>\n",
       "      <td>-0.190482</td>\n",
       "      <td>2.711966</td>\n",
       "      <td>-1.148733</td>\n",
       "      <td>-1.018419</td>\n",
       "      <td>-0.303633</td>\n",
       "      <td>1.160053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567071</td>\n",
       "      <td>0.165851</td>\n",
       "      <td>1.772521</td>\n",
       "      <td>-0.929157</td>\n",
       "      <td>0.360719</td>\n",
       "      <td>-2.625946</td>\n",
       "      <td>-0.969031</td>\n",
       "      <td>0.623764</td>\n",
       "      <td>-1.027161</td>\n",
       "      <td>-0.350338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170871</th>\n",
       "      <td>2.130785</td>\n",
       "      <td>-0.185992</td>\n",
       "      <td>0.125936</td>\n",
       "      <td>-2.556201</td>\n",
       "      <td>-0.525330</td>\n",
       "      <td>-0.017776</td>\n",
       "      <td>0.498301</td>\n",
       "      <td>2.381774</td>\n",
       "      <td>-0.071272</td>\n",
       "      <td>-0.717375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.364630</td>\n",
       "      <td>0.057257</td>\n",
       "      <td>0.181338</td>\n",
       "      <td>1.182864</td>\n",
       "      <td>-0.928375</td>\n",
       "      <td>-0.905287</td>\n",
       "      <td>0.735793</td>\n",
       "      <td>-0.110194</td>\n",
       "      <td>-0.719476</td>\n",
       "      <td>1.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170872</th>\n",
       "      <td>2.130821</td>\n",
       "      <td>1.079927</td>\n",
       "      <td>-0.375876</td>\n",
       "      <td>-0.891240</td>\n",
       "      <td>-0.203000</td>\n",
       "      <td>0.315152</td>\n",
       "      <td>0.878306</td>\n",
       "      <td>-0.507996</td>\n",
       "      <td>0.330178</td>\n",
       "      <td>0.489262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268207</td>\n",
       "      <td>-0.071624</td>\n",
       "      <td>-0.172407</td>\n",
       "      <td>0.733270</td>\n",
       "      <td>-2.754851</td>\n",
       "      <td>-2.014982</td>\n",
       "      <td>0.680467</td>\n",
       "      <td>-0.015380</td>\n",
       "      <td>-0.215121</td>\n",
       "      <td>-0.192462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170873</th>\n",
       "      <td>2.130821</td>\n",
       "      <td>0.993474</td>\n",
       "      <td>-0.351660</td>\n",
       "      <td>-0.547287</td>\n",
       "      <td>0.880781</td>\n",
       "      <td>-0.336940</td>\n",
       "      <td>-0.158977</td>\n",
       "      <td>-0.255672</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.454704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.531369</td>\n",
       "      <td>1.533597</td>\n",
       "      <td>0.090181</td>\n",
       "      <td>0.024125</td>\n",
       "      <td>-0.566052</td>\n",
       "      <td>-1.240210</td>\n",
       "      <td>0.089842</td>\n",
       "      <td>-0.064914</td>\n",
       "      <td>0.159234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170874</th>\n",
       "      <td>2.130857</td>\n",
       "      <td>-0.499622</td>\n",
       "      <td>-1.721934</td>\n",
       "      <td>-2.024784</td>\n",
       "      <td>-1.263136</td>\n",
       "      <td>-1.650302</td>\n",
       "      <td>-0.326792</td>\n",
       "      <td>3.342157</td>\n",
       "      <td>-0.760553</td>\n",
       "      <td>-2.668975</td>\n",
       "      <td>...</td>\n",
       "      <td>2.118511</td>\n",
       "      <td>1.127129</td>\n",
       "      <td>1.888571</td>\n",
       "      <td>3.280626</td>\n",
       "      <td>-0.069001</td>\n",
       "      <td>-0.131944</td>\n",
       "      <td>0.326897</td>\n",
       "      <td>-0.350385</td>\n",
       "      <td>0.899552</td>\n",
       "      <td>3.420037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170875</th>\n",
       "      <td>2.130893</td>\n",
       "      <td>-0.528998</td>\n",
       "      <td>0.564778</td>\n",
       "      <td>-2.391574</td>\n",
       "      <td>-1.628347</td>\n",
       "      <td>2.686066</td>\n",
       "      <td>1.884230</td>\n",
       "      <td>0.524605</td>\n",
       "      <td>0.832596</td>\n",
       "      <td>-0.281071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144069</td>\n",
       "      <td>0.330295</td>\n",
       "      <td>1.186213</td>\n",
       "      <td>-0.351342</td>\n",
       "      <td>1.253979</td>\n",
       "      <td>-0.554078</td>\n",
       "      <td>0.214101</td>\n",
       "      <td>1.334564</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>-0.317811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170876</th>\n",
       "      <td>2.130929</td>\n",
       "      <td>0.245901</td>\n",
       "      <td>-0.729108</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>-1.301359</td>\n",
       "      <td>-0.024792</td>\n",
       "      <td>-0.905928</td>\n",
       "      <td>-0.307063</td>\n",
       "      <td>-0.351711</td>\n",
       "      <td>-1.573611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173920</td>\n",
       "      <td>0.056676</td>\n",
       "      <td>1.043984</td>\n",
       "      <td>0.464343</td>\n",
       "      <td>-0.058898</td>\n",
       "      <td>-3.390892</td>\n",
       "      <td>-0.500523</td>\n",
       "      <td>0.361939</td>\n",
       "      <td>0.223116</td>\n",
       "      <td>-0.294108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170877</th>\n",
       "      <td>2.130929</td>\n",
       "      <td>-0.363060</td>\n",
       "      <td>0.284125</td>\n",
       "      <td>0.438775</td>\n",
       "      <td>-0.737123</td>\n",
       "      <td>-0.126813</td>\n",
       "      <td>-0.400851</td>\n",
       "      <td>-0.061410</td>\n",
       "      <td>0.488781</td>\n",
       "      <td>0.342831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.532202</td>\n",
       "      <td>0.565400</td>\n",
       "      <td>1.507504</td>\n",
       "      <td>-0.133294</td>\n",
       "      <td>1.818360</td>\n",
       "      <td>-1.082857</td>\n",
       "      <td>0.906043</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>0.255420</td>\n",
       "      <td>-0.314477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170878</th>\n",
       "      <td>2.130929</td>\n",
       "      <td>1.218632</td>\n",
       "      <td>0.070238</td>\n",
       "      <td>-1.757344</td>\n",
       "      <td>0.246773</td>\n",
       "      <td>0.473505</td>\n",
       "      <td>-1.279931</td>\n",
       "      <td>0.752186</td>\n",
       "      <td>-0.520029</td>\n",
       "      <td>0.215283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.334650</td>\n",
       "      <td>0.234458</td>\n",
       "      <td>1.136410</td>\n",
       "      <td>-0.119799</td>\n",
       "      <td>0.179005</td>\n",
       "      <td>1.045183</td>\n",
       "      <td>-0.177094</td>\n",
       "      <td>-0.132829</td>\n",
       "      <td>-0.239653</td>\n",
       "      <td>-0.301751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170879</th>\n",
       "      <td>2.130965</td>\n",
       "      <td>1.141009</td>\n",
       "      <td>-0.090937</td>\n",
       "      <td>-1.820458</td>\n",
       "      <td>-0.069788</td>\n",
       "      <td>1.071093</td>\n",
       "      <td>0.866264</td>\n",
       "      <td>-0.109044</td>\n",
       "      <td>0.304976</td>\n",
       "      <td>0.304247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410139</td>\n",
       "      <td>-0.332462</td>\n",
       "      <td>-0.850164</td>\n",
       "      <td>0.642599</td>\n",
       "      <td>-1.782708</td>\n",
       "      <td>-1.175293</td>\n",
       "      <td>0.549558</td>\n",
       "      <td>-0.061748</td>\n",
       "      <td>-0.197645</td>\n",
       "      <td>-0.347045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170880</th>\n",
       "      <td>2.130965</td>\n",
       "      <td>-0.007675</td>\n",
       "      <td>0.714847</td>\n",
       "      <td>-0.957236</td>\n",
       "      <td>-0.361955</td>\n",
       "      <td>0.802519</td>\n",
       "      <td>-0.426876</td>\n",
       "      <td>0.712796</td>\n",
       "      <td>-0.738035</td>\n",
       "      <td>-0.274384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527270</td>\n",
       "      <td>1.054006</td>\n",
       "      <td>-0.346645</td>\n",
       "      <td>0.421154</td>\n",
       "      <td>1.055302</td>\n",
       "      <td>-2.902983</td>\n",
       "      <td>0.339181</td>\n",
       "      <td>0.264789</td>\n",
       "      <td>0.876019</td>\n",
       "      <td>-0.283536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170881</th>\n",
       "      <td>2.130965</td>\n",
       "      <td>0.858128</td>\n",
       "      <td>-1.066176</td>\n",
       "      <td>-1.037773</td>\n",
       "      <td>0.450005</td>\n",
       "      <td>-0.552527</td>\n",
       "      <td>0.176118</td>\n",
       "      <td>-0.280974</td>\n",
       "      <td>0.031173</td>\n",
       "      <td>-0.428769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077221</td>\n",
       "      <td>-0.067074</td>\n",
       "      <td>-0.486858</td>\n",
       "      <td>0.078964</td>\n",
       "      <td>1.035264</td>\n",
       "      <td>-0.924205</td>\n",
       "      <td>-1.561799</td>\n",
       "      <td>-0.010988</td>\n",
       "      <td>0.060020</td>\n",
       "      <td>0.976874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170882</th>\n",
       "      <td>2.131001</td>\n",
       "      <td>-0.710221</td>\n",
       "      <td>0.274407</td>\n",
       "      <td>0.063900</td>\n",
       "      <td>-1.082013</td>\n",
       "      <td>1.145540</td>\n",
       "      <td>2.223947</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.703697</td>\n",
       "      <td>0.505197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035828</td>\n",
       "      <td>0.297671</td>\n",
       "      <td>1.978246</td>\n",
       "      <td>-0.093175</td>\n",
       "      <td>-2.736294</td>\n",
       "      <td>-0.410515</td>\n",
       "      <td>1.574034</td>\n",
       "      <td>1.462216</td>\n",
       "      <td>0.841686</td>\n",
       "      <td>-0.168473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>2.131001</td>\n",
       "      <td>-1.211031</td>\n",
       "      <td>-0.810190</td>\n",
       "      <td>-0.925721</td>\n",
       "      <td>-0.240239</td>\n",
       "      <td>0.983076</td>\n",
       "      <td>-1.612533</td>\n",
       "      <td>0.508466</td>\n",
       "      <td>-0.184965</td>\n",
       "      <td>-1.993121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.812551</td>\n",
       "      <td>-0.065113</td>\n",
       "      <td>0.207627</td>\n",
       "      <td>-2.089684</td>\n",
       "      <td>0.230718</td>\n",
       "      <td>1.894823</td>\n",
       "      <td>2.642878</td>\n",
       "      <td>0.208089</td>\n",
       "      <td>-1.996668</td>\n",
       "      <td>0.153053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170884</th>\n",
       "      <td>2.131001</td>\n",
       "      <td>-0.661798</td>\n",
       "      <td>0.151485</td>\n",
       "      <td>1.797362</td>\n",
       "      <td>0.178523</td>\n",
       "      <td>-0.872889</td>\n",
       "      <td>1.714594</td>\n",
       "      <td>-1.452554</td>\n",
       "      <td>-1.490775</td>\n",
       "      <td>0.443405</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.155561</td>\n",
       "      <td>2.653805</td>\n",
       "      <td>-0.683613</td>\n",
       "      <td>-0.725910</td>\n",
       "      <td>-0.885414</td>\n",
       "      <td>0.673259</td>\n",
       "      <td>-0.329846</td>\n",
       "      <td>1.165566</td>\n",
       "      <td>-0.240661</td>\n",
       "      <td>-0.151803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170885</th>\n",
       "      <td>2.131001</td>\n",
       "      <td>0.167648</td>\n",
       "      <td>0.589005</td>\n",
       "      <td>-0.722566</td>\n",
       "      <td>0.264687</td>\n",
       "      <td>1.183213</td>\n",
       "      <td>0.241984</td>\n",
       "      <td>0.738464</td>\n",
       "      <td>0.028907</td>\n",
       "      <td>-0.578969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123854</td>\n",
       "      <td>0.556855</td>\n",
       "      <td>2.077982</td>\n",
       "      <td>-0.264659</td>\n",
       "      <td>-0.336389</td>\n",
       "      <td>-1.754719</td>\n",
       "      <td>-0.908731</td>\n",
       "      <td>1.374783</td>\n",
       "      <td>1.045902</td>\n",
       "      <td>-0.319763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170886 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0      -2.195294 -0.643037 -0.070491  1.477187  0.918966 -0.121193  0.312054   \n",
       "1      -2.195294  0.735855  0.139913 -0.236081  0.241071  0.176384 -0.108559   \n",
       "2      -2.195258 -0.642251 -0.857264  0.925485  0.191231 -0.244364  1.345242   \n",
       "3      -2.195258 -0.430374 -0.140295  0.939788 -0.714867  0.123847  0.918029   \n",
       "4      -2.195222 -0.534108  0.519578  0.763192  0.208182 -0.172644  0.029097   \n",
       "5      -2.195222 -0.138399  0.570970  0.468516 -0.208239  0.446045 -0.067920   \n",
       "6      -2.195150  0.756282  0.062224 -0.323636  0.791010  0.274892  0.165598   \n",
       "7      -2.195043 -0.256368  0.854943  0.420275 -0.444371  0.840446  0.285594   \n",
       "8      -2.195043 -0.391474  0.152333 -0.438267 -0.283518  2.125862  2.828739   \n",
       "9      -2.194971 -0.091004  0.669719  0.398577 -0.247554  0.504594 -0.235497   \n",
       "10     -2.194935  0.874836 -0.755565  0.304228 -1.088347 -1.341166 -0.530750   \n",
       "11     -2.194935  0.299827  0.357163 -0.988501 -0.154129  2.316348  2.516190   \n",
       "12     -2.194935  0.767274 -0.783685 -0.078878 -0.985738 -0.978128 -0.626554   \n",
       "13     -2.194899  0.669667  0.153305  0.242600  1.891610 -0.001723  0.215659   \n",
       "14     -2.194863 -1.416900 -0.228785  0.830448  1.202747  0.029511  0.578598   \n",
       "15     -2.194863 -0.314809  0.189163  1.130882 -1.156119 -0.733825 -0.105076   \n",
       "16     -2.194863  0.687954 -0.050325  0.559767  0.854046 -0.418275  0.177458   \n",
       "17     -2.194827 -0.144310  0.545172  0.311986 -0.615681  0.815603 -0.143696   \n",
       "18     -2.194791 -2.826993 -3.408687  0.501189  1.179980  2.409371 -1.406534   \n",
       "19     -2.194755  0.898555 -0.664313 -0.027647 -1.133802 -1.030433 -0.601638   \n",
       "20     -2.194719  0.467297 -0.870708  0.387628  0.522437 -0.758339  0.965828   \n",
       "21     -2.194683  0.611911  0.178595 -0.480405  1.451842  0.975386  1.264585   \n",
       "22     -2.194647  0.722216  0.286400 -0.405090  1.562904  0.451885  0.024118   \n",
       "23     -2.194647  0.225530  0.147062  0.500587 -0.153097 -0.850364 -0.160875   \n",
       "24     -2.194504 -0.960093 -0.053183 -0.649638 -0.824034  2.329334  2.236701   \n",
       "25     -2.194504 -1.029138 -0.100724  0.599304  0.213265  0.352075 -0.785848   \n",
       "26     -2.194468  0.725819  0.194137 -0.151190  0.740679  0.002625 -0.752274   \n",
       "27     -2.194468  0.806565 -0.133352 -0.042279  0.334288 -0.493548 -0.686666   \n",
       "28     -2.194468 -0.132089  0.536774  0.892406  0.988444  0.137109 -0.199647   \n",
       "29     -2.194468  0.664270 -0.134145  0.558898  0.778981 -0.455631  0.401657   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "170856  2.130534 -0.725589 -0.637960 -0.927269  0.792830  0.933885 -0.574518   \n",
       "170857  2.130534 -0.453298 -0.036663  0.424263 -2.530465 -0.240544 -0.042283   \n",
       "170858  2.130570  1.238246 -0.554946 -1.062803 -0.381642 -0.410913 -0.321117   \n",
       "170859  2.130641  1.069291 -0.459799 -1.377172 -0.159404  0.490042  0.764991   \n",
       "170860  2.130641  1.106335 -0.199671 -1.058887  0.907119  0.340355  0.418715   \n",
       "170861  2.130677 -0.306929 -0.008348  0.033306 -1.980527  0.189729  0.436324   \n",
       "170862  2.130677  1.069538 -0.279227 -0.335799  0.779018 -0.272348  0.352369   \n",
       "170863  2.130713 -0.061483 -0.118520  1.079451  0.243014 -0.195334  0.182594   \n",
       "170864  2.130713  0.007110  0.285780 -0.570750 -1.712244  0.687576 -0.757864   \n",
       "170865  2.130749 -0.062161  0.145307  0.635458 -0.453422 -0.224753 -0.343757   \n",
       "170866  2.130749  0.169984  0.525979 -0.935405 -0.722426  1.212911 -0.036875   \n",
       "170867  2.130749  1.080954 -0.908328 -0.709151 -0.603368 -0.853701 -0.480012   \n",
       "170868  2.130749  1.172005 -0.434778 -1.077392  0.379868 -0.314627 -0.452275   \n",
       "170869  2.130785 -0.207226  0.832508  1.365485  2.368066  0.676369  0.487377   \n",
       "170870  2.130785 -0.907790 -1.459532  0.351242 -0.190482  2.711966 -1.148733   \n",
       "170871  2.130785 -0.185992  0.125936 -2.556201 -0.525330 -0.017776  0.498301   \n",
       "170872  2.130821  1.079927 -0.375876 -0.891240 -0.203000  0.315152  0.878306   \n",
       "170873  2.130821  0.993474 -0.351660 -0.547287  0.880781 -0.336940 -0.158977   \n",
       "170874  2.130857 -0.499622 -1.721934 -2.024784 -1.263136 -1.650302 -0.326792   \n",
       "170875  2.130893 -0.528998  0.564778 -2.391574 -1.628347  2.686066  1.884230   \n",
       "170876  2.130929  0.245901 -0.729108  0.002455 -1.301359 -0.024792 -0.905928   \n",
       "170877  2.130929 -0.363060  0.284125  0.438775 -0.737123 -0.126813 -0.400851   \n",
       "170878  2.130929  1.218632  0.070238 -1.757344  0.246773  0.473505 -1.279931   \n",
       "170879  2.130965  1.141009 -0.090937 -1.820458 -0.069788  1.071093  0.866264   \n",
       "170880  2.130965 -0.007675  0.714847 -0.957236 -0.361955  0.802519 -0.426876   \n",
       "170881  2.130965  0.858128 -1.066176 -1.037773  0.450005 -0.552527  0.176118   \n",
       "170882  2.131001 -0.710221  0.274407  0.063900 -1.082013  1.145540  2.223947   \n",
       "170883  2.131001 -1.211031 -0.810190 -0.925721 -0.240239  0.983076 -1.612533   \n",
       "170884  2.131001 -0.661798  0.151485  1.797362  0.178523 -0.872889  1.714594   \n",
       "170885  2.131001  0.167648  0.589005 -0.722566  0.264687  1.183213  0.241984   \n",
       "\n",
       "              V7        V8        V9    ...          V20       V21       V22  \\\n",
       "0       0.265010  0.054155  0.299331    ...     0.303747  0.013401  0.541832   \n",
       "1       0.001545  0.043080 -0.238046    ...    -0.137810 -0.265560 -0.831587   \n",
       "2       0.721656  0.175510 -1.330856    ...     0.680650  0.371472  1.281870   \n",
       "3       0.263364  0.281210 -1.220093    ...    -0.329252 -0.107604  0.133386   \n",
       "4       0.557388 -0.246613  0.693289    ...     0.520231  0.025335  1.321730   \n",
       "5       0.460790  0.185805 -0.509894    ...     0.074431 -0.242000 -0.713432   \n",
       "6       0.062483  0.039913  0.387133    ...    -0.345227 -0.187494 -0.280184   \n",
       "7       0.994032 -3.128060  0.517668    ...    -0.258580  2.651181 -1.396208   \n",
       "8       0.373033  0.667036 -0.356613    ...     0.030024 -0.060711 -0.276260   \n",
       "9       0.605912  0.030403 -0.655740    ...     0.238028 -0.293982 -0.824215   \n",
       "10     -1.110923  0.013229 -1.509418    ...    -0.576126  0.025508  0.595865   \n",
       "11      0.456035  0.412204 -0.501409    ...     0.130951  0.105143  0.482766   \n",
       "12     -0.503705 -0.211549 -1.833644    ...    -0.184202 -0.273673 -0.598735   \n",
       "13     -0.013278  0.068235 -0.208243    ...    -0.253696 -0.011567  0.236993   \n",
       "14     -0.283192 -1.579737  0.639460    ...    -2.222374  1.586531  0.458431   \n",
       "15     -0.436827 -0.023307 -0.394901    ...     0.320333  0.709807  2.153973   \n",
       "16     -0.418189  0.128023  0.662561    ...    -0.199569  0.004923  0.419199   \n",
       "17      0.652298  0.045410 -0.593727    ...    -0.107414 -0.223905 -0.882486   \n",
       "18     -1.223873  0.104777  1.053746    ...    -3.069302 -0.639121  1.600729   \n",
       "19     -0.827458 -0.069518 -1.733557    ...    -0.577068 -0.200851 -0.136870   \n",
       "20     -0.660245  0.336483 -0.403605    ...    -0.233219 -0.359422 -0.731609   \n",
       "21      0.155879  0.398564 -1.050246    ...    -0.413684  0.231633  0.728631   \n",
       "22      0.266291  0.086237 -0.874813    ...    -0.465828  0.063162  0.032616   \n",
       "23     -0.716330 -1.344183  1.323629    ...    -0.360865  2.256833  0.425871   \n",
       "24      0.014569  0.670671  0.026985    ...    -0.341207 -0.741209 -1.072187   \n",
       "25      0.516879 -0.111469  0.396422    ...    -0.575392 -0.504714 -0.215288   \n",
       "26      0.372106 -0.292822 -0.230432    ...    -0.004223  0.128108  0.466867   \n",
       "27     -0.152447 -0.206250 -0.946203    ...    -0.763118 -0.344353 -0.359078   \n",
       "28      0.679263 -0.050066 -0.531348    ...     0.091432  0.141868  0.810808   \n",
       "29     -0.567982  0.300443  0.590675    ...    -0.287900  0.056405  0.445771   \n",
       "...          ...       ...       ...    ...          ...       ...       ...   \n",
       "170856  0.803646 -0.565971  0.125064    ...    -0.278358  0.019548  2.188841   \n",
       "170857 -0.209663  0.139325 -1.170108    ...    -0.100669 -0.412270 -0.513755   \n",
       "170858 -0.562779 -0.002947 -0.024422    ...    -1.065078 -0.241632  0.135345   \n",
       "170859 -0.205551  0.288068  0.891419    ...    -0.417930 -0.036725  0.112873   \n",
       "170860 -0.060740  0.103029  0.727976    ...    -0.305052 -0.353430 -0.735932   \n",
       "170861 -0.241639  0.515749 -1.068486    ...     0.059448  0.637322  1.620498   \n",
       "170862 -0.633197  0.218378  0.742245    ...    -0.212393  0.214457  0.727440   \n",
       "170863  0.492953 -0.245027  0.947530    ...    -0.220565  0.322963  1.854149   \n",
       "170864  0.690750 -0.140286 -1.344102    ...     0.261848  0.046378  0.229616   \n",
       "170865  0.431561  0.016341  0.459640    ...    -0.143706  0.433281  1.421799   \n",
       "170866  0.722529  0.077274 -0.164928    ...     0.017720 -0.441275 -1.284715   \n",
       "170867 -0.637515 -0.160923 -0.082649    ...     0.497736  0.745519  1.936571   \n",
       "170868 -0.269562 -0.104019 -0.581675    ...    -0.966787  0.073018  1.082179   \n",
       "170869  0.847614 -0.099858 -1.211942    ...    -0.011823  0.085941  0.873083   \n",
       "170870 -1.018419 -0.303633  1.160053    ...    -0.567071  0.165851  1.772521   \n",
       "170871  2.381774 -0.071272 -0.717375    ...    -0.364630  0.057257  0.181338   \n",
       "170872 -0.507996  0.330178  0.489262    ...    -0.268207 -0.071624 -0.172407   \n",
       "170873 -0.255672  0.004881  0.454704    ...     0.000586  0.531369  1.533597   \n",
       "170874  3.342157 -0.760553 -2.668975    ...     2.118511  1.127129  1.888571   \n",
       "170875  0.524605  0.832596 -0.281071    ...     0.144069  0.330295  1.186213   \n",
       "170876 -0.307063 -0.351711 -1.573611    ...    -0.173920  0.056676  1.043984   \n",
       "170877 -0.061410  0.488781  0.342831    ...    -0.532202  0.565400  1.507504   \n",
       "170878  0.752186 -0.520029  0.215283    ...    -0.334650  0.234458  1.136410   \n",
       "170879 -0.109044  0.304976  0.304247    ...    -0.410139 -0.332462 -0.850164   \n",
       "170880  0.712796 -0.738035 -0.274384    ...    -0.527270  1.054006 -0.346645   \n",
       "170881 -0.280974  0.031173 -0.428769    ...    -0.077221 -0.067074 -0.486858   \n",
       "170882  0.047300  0.703697  0.505197    ...     0.035828  0.297671  1.978246   \n",
       "170883  0.508466 -0.184965 -1.993121    ...    -0.812551 -0.065113  0.207627   \n",
       "170884 -1.452554 -1.490775  0.443405    ...    -1.155561  2.653805 -0.683613   \n",
       "170885  0.738464  0.028907 -0.578969    ...     0.123854  0.556855  2.077982   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "0      -0.150576  0.096740  0.077910 -0.411119  0.335396 -0.076455  0.253236  \n",
       "1       0.211714 -0.582627  0.160897  0.230885 -0.028276  0.039963 -0.344158  \n",
       "2       1.594282 -1.166229 -0.902051 -0.309179 -0.146581 -0.202380  1.184476  \n",
       "3      -0.287180 -1.978405  1.192466 -0.477995  0.154671  0.192033  0.147036  \n",
       "4      -0.196741  0.220896 -0.640762  0.998002  0.554465  0.692154 -0.070527  \n",
       "5      -0.006735 -0.635370 -0.698300  0.190166  0.642287  0.255884 -0.340174  \n",
       "6      -0.225219 -1.317834  1.413216 -0.549954  0.082683  0.008867 -0.334807  \n",
       "7       0.136806 -1.100138 -1.090285 -0.130927 -3.084626 -3.539615 -0.189209  \n",
       "8      -0.310981  1.674454  0.603496 -0.808624  0.024615  0.455431  0.023841  \n",
       "9      -0.168232 -0.658123 -0.348015  0.166288  0.622833  0.262377 -0.340133  \n",
       "10      0.085886  0.820883  0.341767 -0.289576  0.103968  0.044939 -0.323382  \n",
       "11      0.054047  1.649600 -1.846549 -1.028837  0.103005 -0.184761 -0.314477  \n",
       "12      0.183280  0.641041  0.147931 -0.749180  0.062038  0.130092  0.138904  \n",
       "13     -0.083739  0.159898  0.979557  0.186455  0.049474  0.061339 -0.243285  \n",
       "14      1.784482  0.032254 -0.698198 -0.505770 -0.425761 -0.106068 -0.116024  \n",
       "15     -0.400528 -0.123737 -0.282262 -0.203180 -0.467143  0.413096 -0.290082  \n",
       "16      0.062039  0.158252  0.584362 -0.804759  0.231431  0.112613 -0.302280  \n",
       "17     -0.229930 -1.498761 -0.933782 -0.125612  0.197966  0.418399 -0.351477  \n",
       "18      4.244668  0.055306 -1.232847 -1.291875  0.994905  3.082007 -0.164814  \n",
       "19      0.106864  0.479010  0.516980 -0.474848  0.051534  0.016789 -0.334766  \n",
       "20     -0.048621 -0.523117 -0.043545 -0.886227  0.215471  0.198674  0.587001  \n",
       "21     -0.044562 -2.306237  0.641324  0.381842  0.036410 -0.055474 -0.216491  \n",
       "22     -0.139252 -0.633681  1.097569  0.195548 -0.108739 -0.045102 -0.345825  \n",
       "23     -0.278681  0.691550  1.564564 -0.489618  0.853513  0.807092 -0.262597  \n",
       "24      1.527368  1.627406  0.491783  0.279300  1.799766  0.039559 -0.351477  \n",
       "25      1.308611  0.650568  0.337137  0.533555  0.913048  0.783521 -0.247635  \n",
       "26     -0.219032  0.711545  1.358840 -0.712683  0.036405  0.089805 -0.184818  \n",
       "27     -0.026088  0.564750  1.003991 -0.596669  0.102655  0.085838 -0.290042  \n",
       "28     -0.027440  1.058058 -0.593248 -0.591178  0.460742  0.488818 -0.220922  \n",
       "29      0.063169 -0.010110  0.434720 -0.830864  0.202478  0.070864 -0.302280  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "170856  1.295661  1.181945 -2.308025  2.068822  1.060838  1.328170  0.279989  \n",
       "170857 -0.641220 -0.005528  1.553586 -0.222828  1.204827  0.784807 -0.319316  \n",
       "170858  0.264122 -0.896942 -0.343982 -0.411077  0.054021 -0.213395 -0.351029  \n",
       "170859  0.337942 -2.765981 -0.812682  0.018179  0.000829 -0.255658 -0.111145  \n",
       "170860  0.358235  0.420552 -0.038805 -1.753085  0.064368 -0.154476 -0.192462  \n",
       "170861 -0.450894 -0.543863  0.104731 -0.370013 -0.054103  0.127070 -0.192665  \n",
       "170862  0.509624  1.096442 -1.009333 -1.675969  0.164852 -0.060715 -0.172132  \n",
       "170863  0.414726 -0.215890 -1.390446 -1.472529 -0.531092 -1.407212  0.085845  \n",
       "170864 -0.355845 -0.934388  0.336635 -0.755462  0.623754  0.270156 -0.294108  \n",
       "170865  0.044040  0.104046 -1.729805  0.948354  0.358453  0.628696 -0.090856  \n",
       "170866 -0.006779 -0.792800 -0.913498  0.294544  0.538382  0.200591 -0.344158  \n",
       "170867  0.141922  2.020852 -0.753161 -0.322493 -0.037461 -0.018299  0.356427  \n",
       "170868  0.029523 -0.042817  0.231318 -0.704749  0.067206 -0.180944 -0.196527  \n",
       "170869 -1.016878 -0.002933  1.460351  0.729254 -0.287987 -0.531362 -0.355095  \n",
       "170870 -0.929157  0.360719 -2.625946 -0.969031  0.623764 -1.027161 -0.350338  \n",
       "170871  1.182864 -0.928375 -0.905287  0.735793 -0.110194 -0.719476  1.661765  \n",
       "170872  0.733270 -2.754851 -2.014982  0.680467 -0.015380 -0.215121 -0.192462  \n",
       "170873  0.090181  0.024125 -0.566052 -1.240210  0.089842 -0.064914  0.159234  \n",
       "170874  3.280626 -0.069001 -0.131944  0.326897 -0.350385  0.899552  3.420037  \n",
       "170875 -0.351342  1.253979 -0.554078  0.214101  1.334564  0.997530 -0.317811  \n",
       "170876  0.464343 -0.058898 -3.390892 -0.500523  0.361939  0.223116 -0.294108  \n",
       "170877 -0.133294  1.818360 -1.082857  0.906043 -0.059550  0.255420 -0.314477  \n",
       "170878 -0.119799  0.179005  1.045183 -0.177094 -0.132829 -0.239653 -0.301751  \n",
       "170879  0.642599 -1.782708 -1.175293  0.549558 -0.061748 -0.197645 -0.347045  \n",
       "170880  0.421154  1.055302 -2.902983  0.339181  0.264789  0.876019 -0.283536  \n",
       "170881  0.078964  1.035264 -0.924205 -1.561799 -0.010988  0.060020  0.976874  \n",
       "170882 -0.093175 -2.736294 -0.410515  1.574034  1.462216  0.841686 -0.168473  \n",
       "170883 -2.089684  0.230718  1.894823  2.642878  0.208089 -1.996668  0.153053  \n",
       "170884 -0.725910 -0.885414  0.673259 -0.329846  1.165566 -0.240661 -0.151803  \n",
       "170885 -0.264659 -0.336389 -1.754719 -0.908731  1.374783  1.045902 -0.319763  \n",
       "\n",
       "[170886 rows x 30 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XSc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.257784e-17</td>\n",
       "      <td>2.128892e-17</td>\n",
       "      <td>7.983346e-18</td>\n",
       "      <td>-6.386677e-17</td>\n",
       "      <td>-2.128892e-17</td>\n",
       "      <td>3.991673e-17</td>\n",
       "      <td>5.322231e-18</td>\n",
       "      <td>2.661115e-18</td>\n",
       "      <td>-1.064446e-17</td>\n",
       "      <td>4.224521e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>8.648625e-18</td>\n",
       "      <td>-3.991673e-18</td>\n",
       "      <td>1.064446e-17</td>\n",
       "      <td>4.656952e-18</td>\n",
       "      <td>1.896045e-17</td>\n",
       "      <td>-7.983346e-17</td>\n",
       "      <td>-4.656952e-18</td>\n",
       "      <td>-2.827435e-18</td>\n",
       "      <td>3.492714e-18</td>\n",
       "      <td>8.781681e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.195294e+00</td>\n",
       "      <td>-3.039022e+01</td>\n",
       "      <td>-4.516624e+01</td>\n",
       "      <td>-2.470572e+01</td>\n",
       "      <td>-4.109010e+00</td>\n",
       "      <td>-3.135488e+01</td>\n",
       "      <td>-2.024412e+01</td>\n",
       "      <td>-3.597523e+01</td>\n",
       "      <td>-5.966726e+01</td>\n",
       "      <td>-1.167500e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.150806e+01</td>\n",
       "      <td>-4.679459e+01</td>\n",
       "      <td>-1.625819e+01</td>\n",
       "      <td>-7.662024e+01</td>\n",
       "      <td>-4.752581e+00</td>\n",
       "      <td>-2.231462e+01</td>\n",
       "      <td>-5.333890e+00</td>\n",
       "      <td>-5.757814e+01</td>\n",
       "      <td>-3.811490e+01</td>\n",
       "      <td>-3.550952e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.142076e-01</td>\n",
       "      <td>-4.414013e-01</td>\n",
       "      <td>-3.600244e-01</td>\n",
       "      <td>-4.032511e-01</td>\n",
       "      <td>-6.275258e-01</td>\n",
       "      <td>-4.875802e-01</td>\n",
       "      <td>-5.786049e-01</td>\n",
       "      <td>-4.184043e-01</td>\n",
       "      <td>-1.587277e-01</td>\n",
       "      <td>-5.892283e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.955650e-01</td>\n",
       "      <td>-2.722068e-01</td>\n",
       "      <td>-6.938723e-01</td>\n",
       "      <td>-2.529335e-01</td>\n",
       "      <td>-5.702895e-01</td>\n",
       "      <td>-6.191203e-01</td>\n",
       "      <td>-6.989555e-01</td>\n",
       "      <td>-1.715110e-01</td>\n",
       "      <td>-9.598774e-02</td>\n",
       "      <td>-3.328144e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.137696e-02</td>\n",
       "      <td>-7.424534e-03</td>\n",
       "      <td>4.278288e-02</td>\n",
       "      <td>9.420951e-02</td>\n",
       "      <td>5.023245e-03</td>\n",
       "      <td>-3.745296e-02</td>\n",
       "      <td>-2.014165e-01</td>\n",
       "      <td>4.033029e-02</td>\n",
       "      <td>1.991464e-02</td>\n",
       "      <td>-8.490739e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.245452e-02</td>\n",
       "      <td>-3.521212e-02</td>\n",
       "      <td>2.541608e-02</td>\n",
       "      <td>-2.353039e-02</td>\n",
       "      <td>8.427964e-02</td>\n",
       "      <td>9.324221e-02</td>\n",
       "      <td>-1.458772e-01</td>\n",
       "      <td>1.682197e-02</td>\n",
       "      <td>6.087712e-02</td>\n",
       "      <td>-2.660736e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.299259e-01</td>\n",
       "      <td>7.318495e-01</td>\n",
       "      <td>4.739408e-01</td>\n",
       "      <td>5.814707e-01</td>\n",
       "      <td>5.978507e-01</td>\n",
       "      <td>4.113029e-01</td>\n",
       "      <td>3.018779e-01</td>\n",
       "      <td>4.495559e-01</td>\n",
       "      <td>2.596717e-01</td>\n",
       "      <td>5.402038e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.719836e-01</td>\n",
       "      <td>2.105796e-01</td>\n",
       "      <td>6.697075e-01</td>\n",
       "      <td>2.072875e-01</td>\n",
       "      <td>6.794951e-01</td>\n",
       "      <td>6.598947e-01</td>\n",
       "      <td>5.305713e-01</td>\n",
       "      <td>2.235738e-01</td>\n",
       "      <td>2.468473e-01</td>\n",
       "      <td>-4.316395e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.131001e+00</td>\n",
       "      <td>1.409910e+00</td>\n",
       "      <td>1.366783e+01</td>\n",
       "      <td>6.426577e+00</td>\n",
       "      <td>1.221516e+01</td>\n",
       "      <td>2.613000e+01</td>\n",
       "      <td>1.735045e+01</td>\n",
       "      <td>3.041582e+01</td>\n",
       "      <td>1.627127e+01</td>\n",
       "      <td>1.351758e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.426886e+01</td>\n",
       "      <td>3.661470e+01</td>\n",
       "      <td>1.586470e+01</td>\n",
       "      <td>3.254934e+01</td>\n",
       "      <td>6.703680e+00</td>\n",
       "      <td>1.595524e+01</td>\n",
       "      <td>7.142823e+00</td>\n",
       "      <td>3.099958e+01</td>\n",
       "      <td>1.101320e+02</td>\n",
       "      <td>7.956520e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean  -4.257784e-17  2.128892e-17  7.983346e-18 -6.386677e-17 -2.128892e-17   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -2.195294e+00 -3.039022e+01 -4.516624e+01 -2.470572e+01 -4.109010e+00   \n",
       "25%   -7.142076e-01 -4.414013e-01 -3.600244e-01 -4.032511e-01 -6.275258e-01   \n",
       "50%   -1.137696e-02 -7.424534e-03  4.278288e-02  9.420951e-02  5.023245e-03   \n",
       "75%    6.299259e-01  7.318495e-01  4.739408e-01  5.814707e-01  5.978507e-01   \n",
       "max    2.131001e+00  1.409910e+00  1.366783e+01  6.426577e+00  1.221516e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean   3.991673e-17  5.322231e-18  2.661115e-18 -1.064446e-17  4.224521e-17   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -3.135488e+01 -2.024412e+01 -3.597523e+01 -5.966726e+01 -1.167500e+01   \n",
       "25%   -4.875802e-01 -5.786049e-01 -4.184043e-01 -1.587277e-01 -5.892283e-01   \n",
       "50%   -3.745296e-02 -2.014165e-01  4.033029e-02  1.991464e-02 -8.490739e-02   \n",
       "75%    4.113029e-01  3.018779e-01  4.495559e-01  2.596717e-01  5.402038e-01   \n",
       "max    2.613000e+01  1.735045e+01  3.041582e+01  1.627127e+01  1.351758e+01   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "count      ...       1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean       ...       8.648625e-18 -3.991673e-18  1.064446e-17  4.656952e-18   \n",
       "std        ...       1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min        ...      -3.150806e+01 -4.679459e+01 -1.625819e+01 -7.662024e+01   \n",
       "25%        ...      -2.955650e-01 -2.722068e-01 -6.938723e-01 -2.529335e-01   \n",
       "50%        ...      -9.245452e-02 -3.521212e-02  2.541608e-02 -2.353039e-02   \n",
       "75%        ...       1.719836e-01  2.105796e-01  6.697075e-01  2.072875e-01   \n",
       "max        ...       5.426886e+01  3.661470e+01  1.586470e+01  3.254934e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean   1.896045e-17 -7.983346e-17 -4.656952e-18 -2.827435e-18  3.492714e-18   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -4.752581e+00 -2.231462e+01 -5.333890e+00 -5.757814e+01 -3.811490e+01   \n",
       "25%   -5.702895e-01 -6.191203e-01 -6.989555e-01 -1.715110e-01 -9.598774e-02   \n",
       "50%    8.427964e-02  9.324221e-02 -1.458772e-01  1.682197e-02  6.087712e-02   \n",
       "75%    6.794951e-01  6.598947e-01  5.305713e-01  2.235738e-01  2.468473e-01   \n",
       "max    6.703680e+00  1.595524e+01  7.142823e+00  3.099958e+01  1.101320e+02   \n",
       "\n",
       "             Amount  \n",
       "count  1.708860e+05  \n",
       "mean   8.781681e-17  \n",
       "std    1.000003e+00  \n",
       "min   -3.550952e-01  \n",
       "25%   -3.328144e-01  \n",
       "50%   -2.660736e-01  \n",
       "75%   -4.316395e-02  \n",
       "max    7.956520e+01  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XSc.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "5         0.0\n",
       "6         0.0\n",
       "7         0.0\n",
       "8         0.0\n",
       "9         0.0\n",
       "10        0.0\n",
       "11        0.0\n",
       "12        0.0\n",
       "13        0.0\n",
       "14        0.0\n",
       "15        0.0\n",
       "16        0.0\n",
       "17        0.0\n",
       "18        0.0\n",
       "19        0.0\n",
       "20        0.0\n",
       "21        0.0\n",
       "22        0.0\n",
       "23        0.0\n",
       "24        0.0\n",
       "25        0.0\n",
       "26        0.0\n",
       "27        0.0\n",
       "28        0.0\n",
       "29        0.0\n",
       "         ... \n",
       "170856    0.0\n",
       "170857    0.0\n",
       "170858    0.0\n",
       "170859    0.0\n",
       "170860    0.0\n",
       "170861    0.0\n",
       "170862    0.0\n",
       "170863    0.0\n",
       "170864    0.0\n",
       "170865    0.0\n",
       "170866    0.0\n",
       "170867    0.0\n",
       "170868    0.0\n",
       "170869    0.0\n",
       "170870    0.0\n",
       "170871    0.0\n",
       "170872    0.0\n",
       "170873    0.0\n",
       "170874    0.0\n",
       "170875    0.0\n",
       "170876    0.0\n",
       "170877    0.0\n",
       "170878    0.0\n",
       "170879    0.0\n",
       "170880    0.0\n",
       "170881    0.0\n",
       "170882    0.0\n",
       "170883    0.0\n",
       "170884    0.0\n",
       "170885    0.0\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJgAkCCYAJAgmACQIJgAkCCYAJPwfoJxgkNh1Ya0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f126c03d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAFYCAYAAAAx7qftAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11af44d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"Amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEYJJREFUeJzt3X1sVfX9wPFPeegqAwKiJPLX7JZlmaDLOrJEpXtmLlGZ\nodCOsSwRY+If7sFkm24G/ln2QLIlmvmwRIhLBnFAMsviw5zZFoUhi10yiwYXnAkMzbBAB7V0BXp+\nf/C7d7ftbf2UQm+rr1dCcu+5557zvd+c03d772mpK4qiCABgVNNqPQAAmAoEEwASBBMAEgQTABIE\nEwASBBMAEmaM9mBHR8dEjQMAJo2mpqZhy0YN5khPYriOjg5zdRGY1wvPnF4c5vXCq9WcjvTDordk\nASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTAB\nIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIGFGrQcAMFV9\n97vfjaNHj0ZPT0+cOXMm5s2bFxERCxYsiI0bN9Z4dFxogglwno4ePRpHjrxVvv/W8Z4oTp+q4Yi4\nmLwlCzAOdTMvKf+b/aGbo27mJbUeEheJYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJg\nAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmAC\nQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJA\ngmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCC\nYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJUsXnz5ti8efOU2zYXj2ACVLF79+7YvXv3lNs2F49g\nAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmAC\nQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJA\ngmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCC\nYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQMKMidpRZ2dnREQsWbJk\nonY5ZmMd41R4TRMpOx/V1uvs7Ix//vOf0djYWF7e2dkZr7/+ejQ1NQ1br6Ry/cz+Srd37doVERF3\n3HHHoO2+8cYbsWjRolixYsWYXk/l2KvtLyKGvb7KsVXuu/L5jY2Ng8Z7/fXXl7c7dFlJe3t7dHZ2\nxokTJyIi4sorr4xFixaVt3/o0KF46qmnYsmSJfHGG2/EX/7yl5g7d24sX748du/eHW+//XZERJw4\ncSLq6+vjyiuvjNdffz1OnDgRDQ0NUV9fHydOnIizZ89GRMTAwEDMmTMnrrjiijhw4ECcPn161Pki\n4siRIxERcdNNN03ofqdNmxbTp0+PiIj6+vqIiFiwYEEsXrx40DHS2NgYu3btiqNHj8bf/va3mD59\neqxfvz4iYtD5FxGDzpn29vby/ZKdO3dGQ0NDPPDAA8POjaHnTbVzpJrK86q0vYkwYcHcunVrRET8\n+Mc/nqhdjtlYxzgVXtNEys5HtfW2bt1aPllKy7du3RonT56MlpaWYeuVVK6f2V/p9iuvvBIR/wtm\nabt9fX3R0NAQK1asGNPrqRx7tf1FxLDXVzm2yn339vZGxLkvCqVglsZ78ODB8naHLqvcZmkbERGv\nvvpqNDQ0lLd/9uzZ+O9//xudnZ3R19cXAwMD0d3dPex5JaUv7hERfX19Veegu7s7uru7R50nam9g\nYCAGBgYiIsrf2Lz99tvxr3/9a9Ax0tjYGK+88sqgdSuP1UpDz5nS/ZLKY2rouTH0vKl2jlRTeV6V\ntjcRJiSYnZ2dsW/fvvLtyfgT2VjHOHT997rs/FVbr3LZvn37yvM52nolpfUz+2tvbx/2/Iceeiiu\nv/76Qct7e3vjoYceGvPr2bdv36B9VNtf5XirvZ7KLy69vb1Vnz90u5XbbG9vHxa9gYGB8rKh2x9p\n3/zPTTfdFL/73e8u6PYmm6HHyNDjLiKqLivp7e2NH/7wh1WPs5J169aVv/mqPIaHHtNjOacrl01E\nVybkM8zK7waGfmcwWYx1jFPhNU2k7HxUW2/o+lu3bk2td777q/T000+PuHys28/sr3L5+R431Z43\n3m0yunXr1lX919XVFcXZ/kHrFmf7o6ura8TnvFvt3bt31Mcr36kY7bypdv+dHpuo495FPwCQMCHB\nXLNmTdXbk8lYxzgVXtNEys5HtfWGrr9mzZrUeue7v0o33HDDiMvHuv3M/iqXn+9xU+15490mo9u0\naVPVf5dddlnUTa8ftG7d9Pq47LLLRnzOu9UnP/nJUR9fuHBh+fZo5021++/02EQd9xPyGeaSJUti\n8eLF5duT0VjHOHT9jo6Oizq+yS47f9XWKy0beoXc4sWL4+TJk1XXK3mnK+oq97dixYp44YUXImL4\nRT+l7ZYuWLjjjjvi4MGD6ddTGnvlPipvRwy/SrZybNUu+pk1a9awi34++tGPlrdbuay0zdKFF5Wf\nIU2bNq3qRT+zZs0qX/RT2p/PMYe7kJ9flrY32T7HHHqMDL3oJyIGHauVSs+59957o7W1dcSLfjZt\n2hT33HNPRPzv3Bh63mSukq08byqXTYQJu0p2KnznO9YxToXXNJGy8zHSd4ilk6Vy2auvvlp1vZLK\n9TP7K90u/UrG0O1WXhI/ltdTOfaRfsoc+voqHx/Lr5WUnjd0WeU23+nXSrq7u/1ayXvQeH6tpPJY\nrTT0nBnp10pKj5dUO2+qnSPV1Oprb11RFMVID3Z0dAz6HThGZq4uDvN64ZnTnNIFOqO9jbpu3bp4\n63hP+f7sD90cPQd2xuXzZ7/j895p29TuWB1pvy76AYAEwQSABMEEgATBBIAEwQSABMEEgATBBIAE\nwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSABMEEgATB\nBIAEwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSABMEE\ngATBBIAEwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSABMEEgATBBIAEwQSA\nBMEEgATBBIAEwQSABMEEgATBBICEGbUeAMBkdN11103JbXPxCCZAFbfeeuuU3DYXj7dkASBBMAEg\nQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBB\nMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEw\nASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTAB\nIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIGFGrQcAMJUV\np0+Vb/cc2Pn/92fXbkBcNIIJcJ4WLFgQERE9PT1x5syZmDdvdkTMLi/n3UUwAc7Txo0by7c7Ojqi\nqamphqPhYvMZJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQI\nJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgm\nACQIJgAk1BVFUYz0YEdHx0SOBQAmhaampmHLRg0mAHCOt2QBIEEwASBBMAEgQTABIEEwASBBMMdp\n06ZNsWLFili5cmW89NJLERGxf//+aGtri7a2ttiwYUONRzh1dXV1xdKlS2Pv3r0RYV7H48yZM/G9\n730vvvKVr8Tq1avjxRdfjAhzeiH86Ec/itbW1mhrayt/DeD8bNy4MVpbW2PlypXxzDPPxJtvvhlf\n+9rXYs2aNfHNb34z+vv7azvAgvP2j3/8o7jllluK06dPF/v27Svuu+++oiiKYu3atcXf//73oiiK\n4q677ir+/Oc/13KYU9Z3vvOd4pZbbileeOGFoijM63js2LGj2LBhQ1EU547blStXFkVhTsdr7969\nxe23314URVEcOHCgWL16dY1HNHXt2bOnuO2224qiKIpjx44Vn/rUp4q77767ePLJJ4uiKIqf/exn\nxZYtW2o5xMJPmOPwpz/9Kb70pS/FjBkz4qqrropvfOMb0d/fH4cPH46rr746IiI+85nPxJ49e2o8\n0qlnz5498f73vz8+/OEPR0SY13G6+eab45577omIiEsvvTS6u7vN6QWwZ8+e+PznPx8RER/84Afj\nP//5T/T09NR4VFPT0qVL47777ouIiLlz58apU6di79698bnPfS4iJsfxKZjjcPjw4XjzzTdj3bp1\n8fWvfz32798fx48fj7lz55bXWbBgQbz11ls1HOXU09/fHw888EB8+9vfLi8zr+Mzc+bMeN/73hcR\nEb/61a/ixhtvNKcXQFdXV8yfP798/9JLLzWH52n69Okxa9asiIjYsWNHNDc3x6lTp6K+vj4iJsfx\nOaOme59Ctm/fHtu3bx+0rKurK5YtWxaPPPJIdHR0xA9+8IN48MEHB61T+ENKo6o2r83NzbFq1apB\nX8yHMq8jqzand955Zyxbtiy2bNkSL7/8cjz88MNx7NixQeuY0/Ezh+P37LPPxo4dO2Lz5s2xfPny\n8vLJMLeCmbRq1apYtWrVoGX3339/NDY2Rl1dXXziE5+Iw4cPl9/uKvn3v/8dCxcunOjhThnV5rWt\nrS0GBgZiy5YtcfDgwXjppZfi5z//uXlNqjanEedC+sc//jEefPDBmDlzpmP1Ali4cGF0dXWV7x85\nciQuv/zyGo5oanv++efj4YcfjkceeSTmzJkTs2bNir6+vmhoaJgUx6e3ZMehubk5du3aFRERr732\nWlxxxRUxc+bMaGxsLF+F+Mwzz8SyZctqOcwp57HHHott27bFtm3b4tOf/nRs2LAhPvKRj5jXcTh0\n6FA89thj8Ytf/KL81qxjdfyuu+66+P3vfx8RES+//HIsXLgwZs+eXeNRTU0nT56MjRs3xi9/+cuY\nN29eRERce+215fmdDMennzDH4WMf+1g899xz0draGhER69evj4iI73//+7F+/foYGBiIa665Jq69\n9tpaDvNdw7yev+3bt0d3d3fcfvvt5WWbNm0yp+P08Y9/PK666qpoa2uLuro6v5ozDk8++WQcP348\nvvWtb5WX/eQnP4l77703fvOb38SiRYviy1/+cg1H6H8rAYAUb8kCQIJgAkCCYAJAgmACQIJgAkCC\nYEINffWrX41nn3120LK+vr5YunRp/PWvf43W1tZYu3ZtrF27Ng4dOlSjUQIRggk11dLSEo8//vig\nZX/4wx/immuuibvuuit++tOfxq9//etYvnz5sD+7CEwswYQauuGGG+LFF1+M48ePl5c9/vjj0dLS\nEk899VR84AMfiIhzf3i6ch1g4gkm1NAll1wSy5cvjyeeeCIizv0t0v3798dnP/vZmDNnTkSc+99b\nHn300Vi5cmUthwrveYIJNdbS0hK//e1vIyJi586dceONN5b/S6Oenp647bbborm5Ob7whS/Ucpjw\nnieYUGNXX3119Pf3x2uvvRbt7e3R0tISERG9vb1x6623xhe/+MW48847azxKwN+ShUng0Ucfjc7O\nzjh06FBs27YtIiLuvvvuWLx4caxdu7bGowMiBBMmhWPHjkVzc3OsX78+Vq9eXf7PyZuamqKuri4i\nIubPnx/3339/jUcK712CCQAJPsMEgATBBIAEwQSABMEEgATBBIAEwQSABMEEgATBBICE/wNd8cBu\n0cmkowAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f116e6a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIJgAkCCYAJAgmACQ8D9KOWS4kVLXHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1337ca50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEJdJREFUeJzt3F2MVAf9x+EvFBqKaGxXIRDfumq0CjWGaFQ0fbFp2ird\nC6nVVWoiNzaBGI3Shgtf0lgiaUxsTGpa22jSkNQ22i2a2OpFL0oqDdjEpfUlReRFanmpurJ0AWH/\nF/xnXJZd+mMte5bp89zAnDln5jdnd85nZvbsThseHh4OAHBa05seAADOBYIJAAWCCQAFggkABYIJ\nAAWCCQAFM0535ZYtWyZrDgCYMhYvXnzKstMGc7yNzrYtW7Y0cr+vRvb15LCfJ499PTk6eT+P92bR\nR7IAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAg\nmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQMKPpAfjf\nrV69OgcOHJjQtocPH87Ro0eTJHPmzJnQbXR1dWXdunUT2hbgXCGYHeDAgQPZu3dfps28YELbDx99\nKUny0tGJbwvQ6QSzQ0ybeUHmvOP6CW178LlHkmRC27e2Beh0foYJAAWCCQAFggkABYIJAAWCCQAF\nggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWC\nCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJ\nAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkA\nBYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYI5wn333Zf77ruv6TE4y3ydgYkQ\nzBE2btyYjRs3Nj0GZ5mvMzARggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkA\nBYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAF\nggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWC\nCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJAAWCCQAFggkABYIJ\nAAWCCQAFMybrjvr7+5MkixYtOmXZX/7ylyRJT09PkmT79u3ZvXt3Hnroofzzn/9MksyaNStz587N\nwMBAexlMxN69e5MkS5cubXiS8Z133nmZOXNmhoaGXna91772te3nxPTp0zM8PJzp06dn1qxZSZKZ\nM2dm/vz5GRwczGte85okyeDgYJJk4cKFWbBgQZKku7s7TzzxRA4cOJAkGRgYyOte97r287J13aJF\ni9LT05O77rormzdvzsUXX5yenp788Ic/zMDAQN71rnelq6srW7duTZJcffXVSZI9e/a0b7urqysL\nFizIxo0bMzg4mIULF+bAgQPt5f39/enq6spHP/rR9vFhLN3d3UlOHEO6u7vbx5fWsSVJ+vr6MjAw\nkCVLlmTPnj1Jkptvvjl9fX3Zs2dP+/G3bm/kMaqvr689y8j91DL6ePbEE09k+/btGRwczPz589PT\n05NFixaNefwbz8uteya31QlGP96Rlyd7X0xaMNevX58kWbt27SnLRgfz8ccfz759+3Lo0KH2ukND\nQ9m5c+dkjQuNOnbsWI4dO1Zab+QLyOPHj7eXt6KYZNwXmbt3726Htbu7O88++2z7Nlpat9O6rr+/\nPz09PfnVr36V48ePZ+/evRkcHGw/Pzdt2pTp06e3b6f1PB8aGmovawW99RzfvXt3jh8/ftLy6dOn\nZ+fOnWcUzNbxpXWfSdrh3rFjR/sFyM0335z169dnaGio/fhbtzf6GNWaZeR+ahm97sj9t3PnzgwO\nDmbt2rVjHv/G83LrnsltdYLRj3fk5cneF5MSzP7+/vY3bX9/f/uVQWtZS19fX7q7u7Njx47JGGtc\nS5cuzYYNGxqdgbNjKr+rbMLx48fb0Rr9fGwZvfzQoUNZvXr1SWEdvc7I60a+8B3rfkeuP3L58ePH\nx51prPvdunVr+vv7s3379jG3G3l/q1evbl8eubx1G4sWLUpfX99Js4y1n053PGut29fXd8rxbzxj\nHSvP5PpOM/rxJv/d/2eyX18pkxLMka/21q9ff9Irg9HrjXz11qQVK1Y0PULZ/v37M9zQj6OHjx3J\n/v37z6n9xf/uD3/4Q9MjjGn9+vX597///bLrnW7+0x2jJrLuWMe/ia57JrfVCUY/3tNdNxn7wkk/\nAFAwKe8we3t7s2bNmvb/Ry8buV53d/cpy5tw7733Nj1C2YoVK7LvHwcbue9p552fN1w455zZXz6S\nfWVccsklU/JdZm9vb/70pz/lJz/5yWnXO938I49RP/rRj172/lr/jnfcGnk7rfVPd3ujj5Vncn2n\nGevxjrxc3a+vlEkJ5qJFi7Jw4cL2/0cvG33Sz1vf+tZTTvqZTH5+2bk2bNggmiOMPpllrJN+Ws/T\n1nWzZ8/OunXr0tPT01534cKFJ/0Mb+RJP7Nnz05y+pN+WuuPPunnPe95zxmfJXvkyJH2zMl/f+Y1\ne/bs9kk/69aty4033jjmST+tY1RPT8/LnvQz+ng2ev8tXLgwPT09+e1vf3vS+uMZ61h5Jtd3mrEe\nb+vymezXV8qknSU73qulJKc8IS6//PLMnDnTr5XwqjXVf60kSa655pop92slLSOPN2P9WklrnbF+\nrWSk3t7e0/5ayeh1x/q1ktHzvJzKu9BXk9GPd+Tlyd4X04aHh4fHu3LLli1ZvHjxZM7T6P22Tlw5\nVz5ebGl9JDvnHddPaPuDzz2SJBPa/uBzj+SN59BHskkzX+emvqdfjezrydHJ+3m8x+akHwAoEEwA\nKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAo\nEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQ\nTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBM\nACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAomNH0AFPJkiVLmh6BSeDr\nDEyEYI7wxS9+sekRmAS+zsBE+EgWAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQT\nAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMA\nCgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAK\nBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoEEwAKBBMACgQTAAoE\nEwAKBBMACgQTAAoEEwAKBBMACmY0PQCvjOGjL+Xgc49MeNskE9r+xLZzJnS/AOcSwewAXV1dE972\n8OHDOXr0xP/nzJlI+Ob8T/cPcK4QzA6wbt26CW+7ZcuWLF68+BWcBqAz+RkmABQIJgAUCCYAFAgm\nABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYA\nFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABQIJgAUCCYAFAgmABRMGx4eHh7vyi1btkzmLAAw\nJSxevPiUZacNJgBwgo9kAaBAMAGgQDABoEAwAaBAMAGgYEoG82c/+1kuu+yyLF++PMuXL89dd93V\n9Egd5/bbb8+NN96Yz3zmM/n973/f9Dgda9OmTfnQhz7U/l6+7bbbmh6p4/z5z3/OVVddlfvvvz9J\n8vzzz2f58uXp7e3Nl7/85Rw5cqThCTvD6P186623ZunSpe3v7ccff7zZASfBjKYHGM91112XW265\npekxOtJTTz2VHTt25IEHHsi2bduyZs2aPPDAA02P1bE++MEP5s4772x6jI506NCh3Hbbbfnwhz/c\nXnbnnXemt7c31157bb73ve/loYceSm9vb4NTnvvG2s9J8tWvfjVXXHFFQ1NNvin5DpOz68knn8xV\nV12VJHn729+ef/3rXzl48GDDU8GZO//883PPPfdk7ty57WWbNm3Kxz/+8STJFVdckSeffLKp8TrG\nWPv51WjKBvOpp57KihUr8oUvfCHPPvts0+N0lP379+fCCy9sX77ooouyb9++BifqbM8991y+9KUv\n5bOf/Ww2btzY9DgdZcaMGZk1a9ZJy1566aWcf/75SZKuri7f26+AsfZzktx///256aab8pWvfCUv\nvvhiA5NNrsY/kn3wwQfz4IMPnrTsE5/4RFatWpXLL788Tz/9dG655ZZs2LChoQk7nz/2dPa87W1v\ny8qVK3Pttddm165duemmm/LYY4+1D+icXb63z56enp68/vWvzyWXXJK77747P/jBD/KNb3yj6bHO\nqsaDecMNN+SGG24Y9/r3v//9efHFF3Ps2LGcd955kzhZ55o7d27279/fvrx379688Y1vbHCizjVv\n3rxcd911SZK3vOUtecMb3pAXXnghb37zmxuerHPNnj07Q0NDmTVrVl544YVX/ceIZ8vIn2deeeWV\n+da3vtXcMJNkSn4ke8899+QXv/hFkhNnZl100UVi+QpasmRJHn300STJM888k7lz52bOnDkNT9WZ\nHnnkkdx7771Jkn379uXAgQOZN29ew1N1to985CPt7+/HHnssH/vYxxqeqDOtWrUqu3btSnLi58bv\nfOc7G57o7JuSf3z973//e77+9a9neHg4//nPf7JmzZpceumlTY/VUe64445s3rw506ZNyze/+c28\n+93vbnqkjnTw4MF87Wtfy8DAQI4ePZqVK1fmsssua3qsjrF169Z897vfzd/+9rfMmDEj8+bNyx13\n3JFbb701hw8fzoIFC7J27drMnDmz6VHPaWPt589//vO5++67c8EFF2T27NlZu3Zturq6mh71rJqS\nwQSAqWZKfiQLAFONYAJAgWACQIFgAkCBYAJAgWBCgz73uc/lN7/5zUnLhoaG8oEPfCDPP/98khOn\n9L/3ve/N7t27mxgR+H+CCQ1atmxZHn744ZOW/frXv8773ve+zJ8/P0eOHMl3vvOdXHzxxQ1NCLQI\nJjTommuuyebNm/OPf/yjvezhhx/OsmXLkiTf//73s2zZspP+WD7QDMGEBl1wwQW5+uqr88tf/jLJ\nib/r+8c//jFXXnllnn766Wzbti2f+tSnGp4SSAQTGrds2bL8/Oc/T3Lib89+8pOfzLFjx3L77bfn\n29/+dsPTAS2CCQ279NJLc+TIkWzbti19fX1ZtmxZfve732VgYCCrVq3Kpz/96TzzzDNZuXJl/vrX\nvzY9Lrxq+VuyMAX8+Mc/Tn9/f3bt2pWf/vSnp1y/fPnyrF27Nm9605samA5IvMOEKeH666/Po48+\n2j7ZB5h6vMMEgALvMAGgQDABoEAwAaBAMAGgQDABoEAwAaBAMAGgQDABoOD/AAuWfmIce3xKAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1205e1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11bdbbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V5\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11bdb2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V6\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1a947210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V6\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAFYCAYAAADa2RzuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngIT/A3Zlop+DxUSeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f131e4990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V7\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAaBAMAGgQDABoOD/APG2fY45h9odAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f129a6050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V20\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAAFYCAYAAADjvq21AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQIKAAkCCgAJAgoACQIKAAkCCgAJAwv8BB+20v6UQ+9UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f129a6f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V21\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conclusion on bloxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I discover that all the attribute has almost the same distribution there are some outlier but those can be considered a normat and they was treated in feature transformation and feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKOsucwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f161c14d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=XSc[\"V1\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11967410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V1\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I discovered that after feature scalling the outlier remain what to do??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us try yhe natural log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69314718055994529"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espy-mur/Documents/Machine-Learning/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log10\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQIFgAkCBYAJAgWACQIFgAkDB/wErp6xQa2vLuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f12b189d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=np.log10(X[\"V1\"]+0.00001))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAES9JREFUeJzt3G1slWf9wPFfGS1Q2RbowMgLk9WnRQvTkMUYdJvGLCRu\nIwuFVR0xE2PEZIma7IGZDF85s5i9mqvRQbKYkbEHXdEZN83ExIVBILoBcyxsBFRQ4AAbBZsCvf8v\nlnP+57Sn7a/b6AHO5/Nm9Drnus91rt3ju3P3bluKoigCABjTlEYvAAAuBIIJAAmCCQAJggkACYIJ\nAAmCCQAJYwZz+/btk7WO89auXbsavYTzjj0ZyZ6MZE9Gsie1LrT98AlzHAMDA41ewnnHnoxkT0ay\nJyPZk1oX2n4IJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQI\nJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgm\nACRMbfQCALh43XXXXVEqlWrG+vv7IyKitbU1pk2bNub8jo6OeOCBB87Z+iZCMAE4Z0qlUhw6dDha\nWmdUxorT/4uIiJbWiDh1etS55eedLwQTgHOqpXVGzPzozZWv+/dsjIioGaun/Lzzhe9hAkCCYAJA\ngmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCC\nYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJg\nAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmAC\nQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAjS5devW\nxbp16xq9jAmb7HULJkCTe/HFF+PFF19s9DImbLLXLZgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgA\nkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQ\nIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAg\nmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCY\nAJAgmACQIJgAkCCYAJAgmACQMHWyXmjHjh0RETF//vzJekkuIOXzo2wi50lfX19ERCxZsqTueVY9\nVv3ceo/X+3r48958882aY+zYsSP27t0bCxcuHPV97NixozLvwIEDMW/evOjs7Bzx3OHzIyJ+9atf\nRUTEihUr6r6H3t7eKJVKsWTJksox/vrXv0ZExLx58yqvWSqVoqOjIyIi9u7dG5dddlnMnz8/Ojs7\na+aVHysfr6+vr7Kujo6OmmNGRHz+85+vrPPkyZNxww03RETEc889Fxs2bIhFixZFZ2dnZU2lUqly\nrL1798bBgwejra0trrzyyjh48GC8/fbbERFx8uTJaGtriw9/+MOVvSiVSjF9+vTo6uqKnTt3xsDA\nQFx55ZUREZV5pVIpBgcHo62tLUqlUpw9ezZaWlri8ssvj7a2tnj77bfj9OnT0draGhERAwMDERHR\n0tISU6dOjTNnzkRRFCP+PcCkBXP9+vUREXH//fdP1ktyASmfH2UTOU/Kc5csWVL3PKseq35uvcfr\nfT38ecODuX79+jhx4kR0d3eP+j7Wr19fmTcwMBDTp08fEczq9VX7xz/+UTlGvffwhz/8IYaGhuLk\nyZOVx1999dWIiJg+fXrlNYeGhmLKlHcuKg0NDUXEOyHv7OysmVd+rPp4p06dioiIKVOm1BwzImL/\n/v0j1hkRlTn79u2Lzs7OyprKx58yZUrlzxERhw4dGvHeT58+XTlutX/961+VufXmDVcURRw/frxm\n7OzZsyOec/r06XGPRfOalGDu2LEjdu7cWfmzT5lUqz4/qscy50lfX1/lL+be3t4R51n1sXt7eyvP\n7evrq3wirZ4TEXXP1Xpr7Ovri87Ozsp4X19f3fdRfcyyU6dO1T3e8LFqO3fuHPEeDhw4UAnHzp07\nRxyj/Nyy6kBVr6Peaw9/vfL84ces997Ge6/11jIR72Uuo7vpppvit7/9baOXcd5qKca49rB9+/ZY\nuHDhe36R1atXV/6D6erquqA+Zb5fe3Axeb/3pPr8KMueJ7feemvNp5/yX6Tl+dXHrn68vb09NmzY\nMOLcjIi652q9Nba3t9cEs729fUQshh9zLPXmDzf8PZQ/OU7kGBN57eGfArn4zZ0793093pEjR2Io\npsSln+iujPXv2RgRETM/evOYc0/sfiqmxFBcccUVox57+vTpsWHDhvdvwWNw0w8AJEzKJdmvfe1r\nce+991b+DNWqz4/qsezcRx55JCIiFi9eHL///e9r5lcfe7zHy2P1ztXR1tjZ2Vnz/PJahr+P4XPH\ney+jGf4eDhw4UPk6e4yJvHb169Ec1q5d+74eb+XKlXH4WP+7mttySVtcMWvmqGtauXLle1nahE1K\nMOfPn1+5NOX7lwxXfX5Uj2VU3+izatWqyg0o5fnVx161alVs2rSpMm/44+U59c7V6ucNv+mnq6sr\nTpw4EUuWLImXXnqp7vvo6uoa96afevMjai8R13sP5Zt+urq6KsfI3vRTvqxcPa/6snb59ca66eeT\nn/xkzTrb29sj4v+/l1l+jfFu+pkIl4rPDd+/HNuk3SXrkyVjeS/nx/BPgu/l8bHWUh4vh696fPfu\n3ePOHe/HSkabX/6xkupPxdUWL15c+bGS8uMT/bGS6nnVP1ZSHn+3P1Yyc+ZMP1bCRWNSbvq5kNmD\nkezJSPZkJHsy0vm6J+VLm+/35djysQ8f66+5wSd700//no0xJ3FJ9lysux43/QBAgmACQIJgAkCC\nYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJg\nAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmAC\nQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJA\ngmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAwtRGLwCAxlq0aFGjl/CuTPa6BROg\nyX3zm99s9BLelclet0uyAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQ\nIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAg\nmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCY\nAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgA\nkCCYAJAgmACQIJgAkDC10QsA4OJWnP5f9O/ZWPN1RNSMjTYvYua5XNqECCYA50xHR8eIsf7+d/7Z\n2toa06ZNG2P2zLrzG0UwAThnHnjggVEf2759eyxcuHASV/Pe+B4mACQIJgAkCCYAJAgmACQIJgAk\nCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQI\nJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACS0FEVRjPbg9u3bJ3MtAHBeWLhw4Yix\nMYMJALzDJVkASBBMAEgQTABIEEwASBBMAEgQzDp+/etfx3XXXRcrVqyIFStWRG9vb0REvPbaa9HT\n0xM9PT2xZs2aBq+yMY4cORLXXHNNbNmyJSKae09KpVJ861vfihUrVkRPT0+8/PLLEdHce3LmzJm4\n++6746tf/WosX748tm3bFhHNvSdbt26Nz33uc/HnP/+5MtbM+1H24x//OG699dbo6emJV155pdHL\nySkY4emnny5+8pOfjBi/7bbbipdffrkoiqL4wQ9+UGzatGmyl9Zwd955Z3HLLbcUL730UlEUzb0n\n69atKzZu3FgURVFs2bKluP3224uiaO49eeqpp4o1a9YURVEUr7/+erF06dKiKJp3T/bt21d85zvf\nKb773e8WL7zwQmW8WfejbMuWLcW3v/3toiiKYs+ePcXy5csbvKIcnzCTBgcH49///ncsWLAgIiK+\n+MUvxubNmxu8qsm1efPm+MAHPhAf//jHI8Ke3H777XHTTTdFRMTBgwfjgx/8YNPvyc033xyrV6+O\niIjZs2fH8ePHm3pP5syZEw899FBceumllbFm3o+yzZs3x5e//OWIiPjIRz4Sb731VvT39zd4VeMT\nzFFs3bo1Vq5cGd/4xjfi1VdfjWPHjsVll11WebyjoyMOHz7cwBVOrsHBwfjZz34W3//+9ytjzb4n\nERGHDx+OpUuXRm9vb3zve99r+j1pbW2NadOmRUTEo48+GjfeeGNT78mMGTPikksuqRlr5v0oO3Lk\nSMyaNavy9ezZsy+IPZja6AU02pNPPhlPPvlkzdhXvvKVuOOOO+L666+Pv/3tb3H33XfHI488UvOc\n4iL+BUn19uTaa6+NZcuW1fyHPlyz7ckdd9wRX/jCF+Lpp5+Ov/zlL7F69eq4//77a57TrHvy2GOP\nxa5du+LnP/95HD16tOY5F+uejLUfY7lY92MiLpQ9aPpgLlu2LJYtWzbq45/5zGfi6NGjMWvWrDh+\n/Hhl/L///W/MnTt3MpY46ertSU9PTwwNDcVjjz0W+/fvj1deeSUefPDBpt6TrVu3xltvvRWXX355\nXHfddXHXXXdVLkOWNdueRLwTjhdeeCEefvjhaG1tbZo9Ge/vkrJm2Y+xzJ07N44cOVL5+tChQzFn\nzpwGrijHJdk6fvnLX8bvfve7iIh4/fXXY/bs2dHW1hadnZ2Vu/6ef/75cf/P8WLy+OOPxxNPPBFP\nPPFEXH/99bFmzZq46qqrmnpPnn/++fjNb34TERG7d++OD33oQ9Ha2trUe/LPf/4zHn/88XjooYcq\nl2abfU+Gsx8RixYtiueeey4iInbt2hVz586NmTNnNnhV4/PL1+v4z3/+E3feeWcURRFnzpyJe++9\nNxYsWBB79uyJ++67L4aGhuLqq6+u3NzQbO6555645ZZb4rOf/WxT78nRo0fjnnvuiZMnT8bg4GD8\n8Ic/jE9/+tNNvScPPvhgPPvsszFv3rzK2Nq1a2P//v1NuSebNm2KtWvXxptvvhmzZ8+OOXPmxLp1\n65r6HCn76U9/Gtu2bYuWlpbK/4Cf7wQTABJckgWABMEEgATBBIAEwQSABMEEgATBhAb6+te/Hn/6\n059qxgYGBuKaa66JgwcPxi9+8Yv41Kc+Ffv27WvQCoEywYQG6u7ujmeeeaZm7I9//GNcffXV0dfX\nF2fPnm263wID5yvBhAZavHhxbNu2LY4dO1YZe+aZZ6K7uztuu+22WLVqVbS0tDRwhUCZYEIDzZgx\nI2644YZ49tlnI+Kd36n52muvxZe+9KUL4leFQTMRTGiw7u7uyu+k3bhxY9x4443R1tbW4FUBwwkm\nNNiCBQticHAw3njjjejr64vu7u5GLwmoQzDhPLB06dJ4+OGHY8aMGfGxj32s0csB6vDL1+E8cPTo\n0bj22mvjvvvui+XLl0dExI9+9KN444034u9//3tcddVV0d7eHo8++miDVwrNSzABIMElWQBIEEwA\nSBBMAEgQTABIEEwASBBMAEgQTABIEEwASPg/8v5lXYnt/mgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f12b18690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V1\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see the natural log eliminate the outlier on the \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at this from sckit learn documentation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Scaling data with outliers\n",
    "\n",
    "If your data contains many outliers, scaling using the mean and variance of the data is likely to not work very well. In these cases, you can use robust_scale and RobustScaler as drop-in replacements instead. They use more robust estimates for the center and range of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amount'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(Dataset.groupby('Time').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ScalerRobust=RobustScaler(quantile_range=(50,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XScR=ScalerRobust.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XScRbs=pd.DataFrame(XScR,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUCCYAFDw//SySYngPFFhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f12b187d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=XScRbs[\"V1\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f12b4d350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V1\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let try this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale data\n",
    "standard_scaler = StandardScaler()\n",
    "Xtr_s = standard_scaler.fit_transform(X_train)\n",
    "Xte_s = standard_scaler.transform(X_test)\n",
    "\n",
    "robust_scaler = RobustScaler()\n",
    "Xtr_r = robust_scaler.fit_transform(X_train)\n",
    "Xte_r = robust_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_s = standard_scaler.fit_transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr_df=pd.DataFrame(Xtr_s,columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEYJJREFUeJzt3W9sVXf9wPFPGdS2gW3SwSIPSNZpWLYyNOgT8d8WXUjc\nxoOxmehmnCRmmCwmJoKwZMwHbmYxRs0yjA4SYra4bNOVOeKfZcFEMiE0ugA6FrYFVFCgsEGLlf45\nvwfk3t9tuS0fhPZQ7uv1qD33/Pl+OQfevaf3XpqKoigCABjXtLIHAABTgWACQIJgAkCCYAJAgmAC\nQIJgAkDCuMHs7u6e8AHs2bNnwo9xKTN/829k5t+485+Kcy/9GWZ/f3/ZQyiV+Zt/IzP/xp3/VJx7\n6cEEgKlAMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEg\nQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIGF62QMA\n4PK1atWq6OnpGbGst7c3BgcH4+qrrz7n9u3t7fH4449P1PDOi2ACMGF6enri8OEj0TSjtbqsGPhP\nREQcOd477raV9S4VggnAhGqa0RozP3hn9fvefZsjIkYsq6ey3qXC7zABIEEwASBBMAEgQTABIEEw\nASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTAB\nIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEg\nQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBB\nMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABGtzGjRtj48aNZQ/jvE32\nuAUToMFt27Yttm3bVvYwzttkj1swASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEw\nASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTAB\nIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEg\nQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBB\nMAEgQTABIGH6ZB1o165dERGxcOHCyTokU0jl+qg4n+ukq6srIiKWLVtW9zqrXVa7br3H630/er23\n3357xD5q1x9rHrt27apud/DgwZg3b150dHTEO++8E83NzWNuHxHx85//PCIi7rvvvrpzWL9+ffT0\n9MSyZcuq+/jjH/8YERHz5s2rHrOnpyfa29sjIuKdd96JK6+8MhYuXBgdHR0jtqs8VtlfV1dXdVzt\n7e0j9hkR8YlPfKI6zr6+vrjtttsiImLbtm0REbFkyZLo6Oiojqmnp6e6r127dsUPf/jDaG5ujuuu\nuy4OHToUJ06ciIiIvr6+aG5ujvnz51f/LHp6eqKlpSU6Oztj9+7d0d/fH9ddd11ERHW7np6eOH36\ndDQ3N0dPT08MDQ1FU1NTXHXVVdHc3BwnTpyIgYGBmDFjRkRE9Pf3R0REU1NTTJ8+PQYHB6MoirPO\nA0xaMJ955pmIiHjssccm65BMIZXro+J8rpPKtsuWLat7ndUuq1233uP1vh+93uhg1tv/6Hk888wz\n1e36+/ujpaUlOjo64uTJk9Hd3T3m9hERf/vb36r7qDeH3/zmNzE8PBx9fX3Vx//6179GRERLS0v1\nmMPDwzFt2pmbSsPDwxFxJuQdHR0jtqs8Vru/U6dORUTEtGnTRuwzIuLAgQNnjTMiqtvs378/Ojo6\nqmOq7H/atGnVryMiDh8+fNbcBwYGqvut9Y9//KO6bb3tRiuKIt59990Ry4aGhs5aZ2Bg4Jz7onFN\nSjB37doVu3fvrn7tWSa1aq+P2mWZ66Srq6v6D/P69evPus5q971+/frqul1dXdVnpLXbRETda7Xe\nGLu6uqKjo6O6vKurq+48avdZcerUqbr7G72s1u7du8+aw8GDB6vh2L1791n7qKxbURuo2nHUO/bo\n41W2H73PenM711zrjeV8XMi2jO2OO+6Il156qexhXLKainHuPXR3d8fixYsv+CBr1qyp/oXp7Owc\n8ZP7xTrGVGX+3fH888+f9Q/q6OtkLF/4whdGPPup/ENa2b722qt9vK2tLZ599tmzrs2IqHut1q5X\n0dbWNiKYbW1tZ8Vi9D7HU2/70UbPofLM8Xz2cT7HHv0skMvf3LlzL+r+jh49GsMxLWYtWF5d1rtv\nc0REzPzgneNue3Lv8zEthuOaa64Zc98tLS3x7LPPXrwBj8OLfgAgYVJuyX7xi1+MtWvXVr+GWrXX\nR+2y7LZPPfVUREQsXbo0tmzZMmL72n2f6/HKsnrX6lhj7OjoGLF+ZSyj5zF623PNZSyj53Dw4MHq\n99l9nM+xa49HY9iwYcNF3d+KFSviyPHe/2nbpiua45r3zxxzTCtWrLiQoZ23SQnmwoULq7em/P6S\n0Wqvj9plGbUv9Fm5cmX1BSiV7Wv3vXLlyti6dWt1u9GPV7apd63Wrjf6RT+V5cuWLYs//elPdefR\n2dk55ot+Zs2aNeb2ESNvEdebQ+VFP52dndV9ZF/0U7mtXLtd7W3tyvHGe9HPjTfeOGKcbW1tEfH/\nv8usHONcL/o5H24VTwy/vxzfpL1K1jNLxnMh18foZ4IX8vh4Y6ksr4Qvu//K8npvK9m7d28sWLBg\n3O0rbyupfVZca+nSpdW3lVQeP9+3ldRuV/u2ksryiXxbycmTJ72thClhUl70Mx4vejF/8zf/RnWp\nzL9ya/Ni346t7PvI8d4RL/DJvuind9/mmJO4JTsR467Hi34AIEEwASBBMAEgQTABIEEwASBBMAEg\nQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBB\nMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEw\nASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTAB\nIEEwASBBMAEgQTABIEEwASBBMAEgQTABIGF62QMAoFxLliwpewj/k8ket2ACNLivfvWrZQ/hfzLZ\n43ZLFgASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMA\nEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwAS\nBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIE\nEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQTABIEEwASBBMAEgQT\nABKmlz0AAC5vxcB/onff5hHfR8SIZWNtFzFzIod2XgQTgAnT3t5+1rLe3ojBwcG4+upzxXBm3e3L\nIpgATJjHH3+87vLu7u5YvHjxJI/mwvgdJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgm\nACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYA\nJAgmACQIJgAkCCYAJAgmACQIJgAkNBVFUYz1YHd392SOBQAuCYsXLz5r2bjBBADOcEsWABIEEwAS\nBBMAEgQTABIEEwASppdx0J6enli9enX897//jYGBgVizZk0sWrQo3njjjXjkkUciImLBggXxne98\np4zhTbjBwcF46KGH4sCBAzE0NBSrVq2Kj370o3HffffFqVOnoq2tLSIiVq9eHZ2dnSWP9uIba/6N\ncv4jInbs2BHf+MY34tFHH41bbrklIqJhzn9E/fk30vmPiPjlL38ZP/rRj2L+/PkREfHxj388Vq5c\nWfKoJsejjz4ar7/+ejQ1NcXatWvj5ptvLntIOUUJNm7cWGzevLkoiqLYvn17cf/99xdFURT33ntv\n8frrrxdFURTf/OY3i61bt5YxvAn3/PPPF+vWrSuKoijefPPN4q677iqK4sz89+7dW+LIJsd482+E\n879///7igQceKL7+9a8Xr776anV5o5z/8ebfCOe/4oUXXii+973vlT2MSbd9+/bia1/7WlEURbFv\n377innvuKXlEeaXckr3//vvjjjvuiIiIQ4cOxbXXXhunT5+Of/7zn9WfNG655ZZ47bXXyhjehLvz\nzjtjzZo1ERExe/bsePfdd0se0eSqN/9GOv9z5syJJ554ImbNmlX2UEpRb/6NdP4b3WuvvRaf/exn\nIyLi+uuvj/feey96e3tLHlVOKbdkIyKOHDkSDzzwQPT19cWmTZvi+PHjceWVV1Yfb29vjyNHjpQ1\nvAk1Y8aM6tebNm2K22+/vfr9j3/84zh+/Hhcf/31sXbt2mhpaSljiBOq3vwb6fy3traO+VgjnP96\n82+k819rx44dsWLFihgcHIzVq1fHjTfeWPaQJtzRo0fjpptuqn4/e/bsOHLkSMycObPEUeVMeDCf\ne+65eO6550Yse/DBB+OTn/xkvPDCC/GHP/wh1qxZE4899tiIdYrL5AOIxpv/008/HXv27Imf/OQn\nERHx5S9/ORYsWBDz58+PdevWxdNPPx0rVqwoY9gXTXb+x44dG7FOI5z/0Rrt/I/ncjn/FfX+HD7/\n+c/Hgw8+GJ/5zGfiz3/+c6xevTpeeumlkkZYnql0ric8mHfffXfcfffdI5bt2LEj3nvvvbjqqqvi\n05/+dKxateqsW5P//ve/Y+7cuRM9vAlXb/4RZ/4Cvfrqq/Hkk09Wn3F97nOfqz5+6623xpYtWyZt\nnBMlO/9GO//1NNL5H+1yPf8V5/pz+MhHPhLHjh2LoaGhuOKKKyZxZJNv7ty5cfTo0er3hw8fjjlz\n5pQ4orxSfof5u9/9Ln71q19FRMTevXvjAx/4QMyYMSM6Ojpi586d1XXO9VPoVPX3v/89fvGLX8QT\nTzwR73vf+yLizE9ZX/nKV+LEiRMREbF9+/b40Ic+VOYwJ0y9+TfS+a+nkc5/PY14/n/2s5/Fr3/9\n64iIePPNN2P27NmXfSwjIpYsWRK//e1vIyJiz549MXfu3ClxOzaipA9fP3bsWHz729+Ovr6+OH36\ndDz00EPx4Q9/OPbt2xcPP/xwDA8Px6JFi6ovDLnc/OAHP4iXX3455s2bV122YcOGeOWVV+Kpp56K\n1tbWuPbaa+O73/3uuL/vmqrGmv+BAwca4vxv3bo1NmzYEG+//XbMnj075syZExs3bowtW7Y0xPkf\na/6N8ve/4l//+ld861vfiqIoYnBwcGq9veICff/734+dO3dGU1NTrFu3Lm644Yayh5TifysBgASf\n9AMACYIJAAmCCQAJggkACYIJAAmCCSX60pe+FK+88sqIZf39/fGxj30sDh06FD/96U/jpptuiv37\n95c0QqBCMKFEy5cvjxdffHHEst///vexaNGi6OrqiqGhocvqE29gKhNMKNHSpUtj586dcfz48eqy\nF198MZYvXx733ntvrFy5MpqamkocIVAhmFCi1tbWuO222+Lll1+OiDOfq/nGG2/ErbfeOmU+Lgwa\nhWBCyZYvX179bOXNmzfH7bffHs3NzSWPChhNMKFkN998c5w+fTreeuut6OrqiuXLl5c9JKAOwYRL\nwF133RVPPvlktLa2NtT/UgJTiQ9fh0vAsWPH4lOf+lQ8/PDDcc8990RExCOPPBJvvfVW/OUvf4kb\nbrgh2traYtOmTSWPFBqXYAJAgluyAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQ8H9+i5dO\nKOsucwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11728650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_df[\"V1\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAES9JREFUeJzt3G1slWf9wPFfGS1Q2RbowMgLk9WnRQvTkMUYdJvGLCRu\nIwuFVR0xE2PEZIma7IGZDF85s5i9mqvRQbKYkbEHXdEZN83ExIVBILoBcyxsBFRQ4AAbBZsCvf8v\nlnP+57Sn7a/b6AHO5/Nm9Drnus91rt3ju3P3bluKoigCABjTlEYvAAAuBIIJAAmCCQAJggkACYIJ\nAAmCCQAJYwZz+/btk7WO89auXbsavYTzjj0ZyZ6MZE9Gsie1LrT98AlzHAMDA41ewnnHnoxkT0ay\nJyPZk1oX2n4IJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQI\nJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgm\nACRMbfQCALh43XXXXVEqlWrG+vv7IyKitbU1pk2bNub8jo6OeOCBB87Z+iZCMAE4Z0qlUhw6dDha\nWmdUxorT/4uIiJbWiDh1etS55eedLwQTgHOqpXVGzPzozZWv+/dsjIioGaun/Lzzhe9hAkCCYAJA\ngmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCC\nYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJg\nAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmAC\nQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAjS5devW\nxbp16xq9jAmb7HULJkCTe/HFF+PFF19s9DImbLLXLZgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgA\nkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQ\nIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAg\nmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCY\nAJAgmACQIJgAkCCYAJAgmACQMHWyXmjHjh0RETF//vzJekkuIOXzo2wi50lfX19ERCxZsqTueVY9\nVv3ceo/X+3r48958882aY+zYsSP27t0bCxcuHPV97NixozLvwIEDMW/evOjs7Bzx3OHzIyJ+9atf\nRUTEihUr6r6H3t7eKJVKsWTJksox/vrXv0ZExLx58yqvWSqVoqOjIyIi9u7dG5dddlnMnz8/Ojs7\na+aVHysfr6+vr7Kujo6OmmNGRHz+85+vrPPkyZNxww03RETEc889Fxs2bIhFixZFZ2dnZU2lUqly\nrL1798bBgwejra0trrzyyjh48GC8/fbbERFx8uTJaGtriw9/+MOVvSiVSjF9+vTo6uqKnTt3xsDA\nQFx55ZUREZV5pVIpBgcHo62tLUqlUpw9ezZaWlri8ssvj7a2tnj77bfj9OnT0draGhERAwMDERHR\n0tISU6dOjTNnzkRRFCP+PcCkBXP9+vUREXH//fdP1ktyASmfH2UTOU/Kc5csWVL3PKseq35uvcfr\nfT38ecODuX79+jhx4kR0d3eP+j7Wr19fmTcwMBDTp08fEczq9VX7xz/+UTlGvffwhz/8IYaGhuLk\nyZOVx1999dWIiJg+fXrlNYeGhmLKlHcuKg0NDUXEOyHv7OysmVd+rPp4p06dioiIKVOm1BwzImL/\n/v0j1hkRlTn79u2Lzs7OyprKx58yZUrlzxERhw4dGvHeT58+XTlutX/961+VufXmDVcURRw/frxm\n7OzZsyOec/r06XGPRfOalGDu2LEjdu7cWfmzT5lUqz4/qscy50lfX1/lL+be3t4R51n1sXt7eyvP\n7evrq3wirZ4TEXXP1Xpr7Ovri87Ozsp4X19f3fdRfcyyU6dO1T3e8LFqO3fuHPEeDhw4UAnHzp07\nRxyj/Nyy6kBVr6Peaw9/vfL84ces997Ge6/11jIR72Uuo7vpppvit7/9baOXcd5qKca49rB9+/ZY\nuHDhe36R1atXV/6D6erquqA+Zb5fe3Axeb/3pPr8KMueJ7feemvNp5/yX6Tl+dXHrn68vb09NmzY\nMOLcjIi652q9Nba3t9cEs729fUQshh9zLPXmDzf8PZQ/OU7kGBN57eGfArn4zZ0793093pEjR2Io\npsSln+iujPXv2RgRETM/evOYc0/sfiqmxFBcccUVox57+vTpsWHDhvdvwWNw0w8AJEzKJdmvfe1r\nce+991b+DNWqz4/qsezcRx55JCIiFi9eHL///e9r5lcfe7zHy2P1ztXR1tjZ2Vnz/PJahr+P4XPH\ney+jGf4eDhw4UPk6e4yJvHb169Ec1q5d+74eb+XKlXH4WP+7mttySVtcMWvmqGtauXLle1nahE1K\nMOfPn1+5NOX7lwxXfX5Uj2VU3+izatWqyg0o5fnVx161alVs2rSpMm/44+U59c7V6ucNv+mnq6sr\nTpw4EUuWLImXXnqp7vvo6uoa96afevMjai8R13sP5Zt+urq6KsfI3vRTvqxcPa/6snb59ca66eeT\nn/xkzTrb29sj4v+/l1l+jfFu+pkIl4rPDd+/HNuk3SXrkyVjeS/nx/BPgu/l8bHWUh4vh696fPfu\n3ePOHe/HSkabX/6xkupPxdUWL15c+bGS8uMT/bGS6nnVP1ZSHn+3P1Yyc+ZMP1bCRWNSbvq5kNmD\nkezJSPZkJHsy0vm6J+VLm+/35djysQ8f66+5wSd700//no0xJ3FJ9lysux43/QBAgmACQIJgAkCC\nYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJg\nAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmAC\nQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJA\ngmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAwtRGLwCAxlq0aFGjl/CuTPa6BROg\nyX3zm99s9BLelclet0uyAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQ\nIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAg\nmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCY\nAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgA\nkCCYAJAgmACQIJgAkDC10QsA4OJWnP5f9O/ZWPN1RNSMjTYvYua5XNqECCYA50xHR8eIsf7+d/7Z\n2toa06ZNG2P2zLrzG0UwAThnHnjggVEf2759eyxcuHASV/Pe+B4mACQIJgAkCCYAJAgmACQIJgAk\nCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACQI\nJgAkCCYAJAgmACQIJgAkCCYAJAgmACQIJgAkCCYAJAgmACS0FEVRjPbg9u3bJ3MtAHBeWLhw4Yix\nMYMJALzDJVkASBBMAEgQTABIEEwASBBMAEgQzDp+/etfx3XXXRcrVqyIFStWRG9vb0REvPbaa9HT\n0xM9PT2xZs2aBq+yMY4cORLXXHNNbNmyJSKae09KpVJ861vfihUrVkRPT0+8/PLLEdHce3LmzJm4\n++6746tf/WosX748tm3bFhHNvSdbt26Nz33uc/HnP/+5MtbM+1H24x//OG699dbo6emJV155pdHL\nySkY4emnny5+8pOfjBi/7bbbipdffrkoiqL4wQ9+UGzatGmyl9Zwd955Z3HLLbcUL730UlEUzb0n\n69atKzZu3FgURVFs2bKluP3224uiaO49eeqpp4o1a9YURVEUr7/+erF06dKiKJp3T/bt21d85zvf\nKb773e8WL7zwQmW8WfejbMuWLcW3v/3toiiKYs+ePcXy5csbvKIcnzCTBgcH49///ncsWLAgIiK+\n+MUvxubNmxu8qsm1efPm+MAHPhAf//jHI8Ke3H777XHTTTdFRMTBgwfjgx/8YNPvyc033xyrV6+O\niIjZs2fH8ePHm3pP5syZEw899FBceumllbFm3o+yzZs3x5e//OWIiPjIRz4Sb731VvT39zd4VeMT\nzFFs3bo1Vq5cGd/4xjfi1VdfjWPHjsVll11WebyjoyMOHz7cwBVOrsHBwfjZz34W3//+9ytjzb4n\nERGHDx+OpUuXRm9vb3zve99r+j1pbW2NadOmRUTEo48+GjfeeGNT78mMGTPikksuqRlr5v0oO3Lk\nSMyaNavy9ezZsy+IPZja6AU02pNPPhlPPvlkzdhXvvKVuOOOO+L666+Pv/3tb3H33XfHI488UvOc\n4iL+BUn19uTaa6+NZcuW1fyHPlyz7ckdd9wRX/jCF+Lpp5+Ov/zlL7F69eq4//77a57TrHvy2GOP\nxa5du+LnP/95HD16tOY5F+uejLUfY7lY92MiLpQ9aPpgLlu2LJYtWzbq45/5zGfi6NGjMWvWrDh+\n/Hhl/L///W/MnTt3MpY46ertSU9PTwwNDcVjjz0W+/fvj1deeSUefPDBpt6TrVu3xltvvRWXX355\nXHfddXHXXXdVLkOWNdueRLwTjhdeeCEefvjhaG1tbZo9Ge/vkrJm2Y+xzJ07N44cOVL5+tChQzFn\nzpwGrijHJdk6fvnLX8bvfve7iIh4/fXXY/bs2dHW1hadnZ2Vu/6ef/75cf/P8WLy+OOPxxNPPBFP\nPPFEXH/99bFmzZq46qqrmnpPnn/++fjNb34TERG7d++OD33oQ9Ha2trUe/LPf/4zHn/88XjooYcq\nl2abfU+Gsx8RixYtiueeey4iInbt2hVz586NmTNnNnhV4/PL1+v4z3/+E3feeWcURRFnzpyJe++9\nNxYsWBB79uyJ++67L4aGhuLqq6+u3NzQbO6555645ZZb4rOf/WxT78nRo0fjnnvuiZMnT8bg4GD8\n8Ic/jE9/+tNNvScPPvhgPPvsszFv3rzK2Nq1a2P//v1NuSebNm2KtWvXxptvvhmzZ8+OOXPmxLp1\n65r6HCn76U9/Gtu2bYuWlpbK/4Cf7wQTABJckgWABMEEgATBBIAEwQSABMEEgATBhAb6+te/Hn/6\n059qxgYGBuKaa66JgwcPxi9+8Yv41Kc+Ffv27WvQCoEywYQG6u7ujmeeeaZm7I9//GNcffXV0dfX\nF2fPnm263wID5yvBhAZavHhxbNu2LY4dO1YZe+aZZ6K7uztuu+22WLVqVbS0tDRwhUCZYEIDzZgx\nI2644YZ49tlnI+Kd36n52muvxZe+9KUL4leFQTMRTGiw7u7uyu+k3bhxY9x4443R1tbW4FUBwwkm\nNNiCBQticHAw3njjjejr64vu7u5GLwmoQzDhPLB06dJ4+OGHY8aMGfGxj32s0csB6vDL1+E8cPTo\n0bj22mvjvvvui+XLl0dExI9+9KN444034u9//3tcddVV0d7eHo8++miDVwrNSzABIMElWQBIEEwA\nSBBMAEgQTABIEEwASBBMAEgQTABIEEwASPg/8v5lXYnt/mgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11f0b790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Dataset[\"V1\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0CpxdTMFpb0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11f0b090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Dataset[\"V2\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "affter applying all scaller the outlier persit so we will try to remove it directlly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>39954.0</td>\n",
       "      <td>-56.40751</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-6.605265</td>\n",
       "      <td>16.491217</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-19.399981</td>\n",
       "      <td>-1.5013</td>\n",
       "      <td>6.967698</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.266878</td>\n",
       "      <td>-1.272167</td>\n",
       "      <td>7.893082</td>\n",
       "      <td>0.767805</td>\n",
       "      <td>5.376595</td>\n",
       "      <td>0.163672</td>\n",
       "      <td>-8.358317</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>1201.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time        V1         V2        V3         V4         V5  \\\n",
       "39769  39954.0 -56.40751 -72.715728 -6.605265  16.491217  34.801666   \n",
       "\n",
       "              V6         V7      V8        V9  ...         V21       V22  \\\n",
       "39769 -26.160506 -19.399981 -1.5013  6.967698  ...   -6.266878 -1.272167   \n",
       "\n",
       "            V23       V24       V25       V26       V27        V28   Amount  \\\n",
       "39769  7.893082  0.767805  5.376595  0.163672 -8.358317  33.847808  1201.83   \n",
       "\n",
       "       Class  \n",
       "39769    0.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[Dataset['V1'] < -40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>39954.0</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-6.605265</td>\n",
       "      <td>16.491217</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-19.399981</td>\n",
       "      <td>-1.501300</td>\n",
       "      <td>6.967698</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.266878</td>\n",
       "      <td>-1.272167</td>\n",
       "      <td>7.893082</td>\n",
       "      <td>0.767805</td>\n",
       "      <td>5.376595</td>\n",
       "      <td>0.163672</td>\n",
       "      <td>-8.358317</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>1201.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58465</th>\n",
       "      <td>48401.0</td>\n",
       "      <td>-36.802320</td>\n",
       "      <td>-63.344698</td>\n",
       "      <td>-20.645794</td>\n",
       "      <td>16.715537</td>\n",
       "      <td>-20.672064</td>\n",
       "      <td>7.694002</td>\n",
       "      <td>24.956587</td>\n",
       "      <td>-4.730111</td>\n",
       "      <td>-2.687312</td>\n",
       "      <td>...</td>\n",
       "      <td>11.455313</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-17.173665</td>\n",
       "      <td>1.180700</td>\n",
       "      <td>-7.025783</td>\n",
       "      <td>-2.534330</td>\n",
       "      <td>-3.602479</td>\n",
       "      <td>3.450224</td>\n",
       "      <td>19656.53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151296</th>\n",
       "      <td>95286.0</td>\n",
       "      <td>-34.549296</td>\n",
       "      <td>-60.464618</td>\n",
       "      <td>-21.340854</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>-19.229075</td>\n",
       "      <td>6.335259</td>\n",
       "      <td>24.422716</td>\n",
       "      <td>-4.964566</td>\n",
       "      <td>0.188912</td>\n",
       "      <td>...</td>\n",
       "      <td>11.502580</td>\n",
       "      <td>-9.499423</td>\n",
       "      <td>-16.513186</td>\n",
       "      <td>0.744341</td>\n",
       "      <td>-7.081325</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-3.550963</td>\n",
       "      <td>3.250802</td>\n",
       "      <td>18910.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time         V1         V2         V3         V4         V5  \\\n",
       "39769   39954.0 -56.407510 -72.715728  -6.605265  16.491217  34.801666   \n",
       "58465   48401.0 -36.802320 -63.344698 -20.645794  16.715537 -20.672064   \n",
       "151296  95286.0 -34.549296 -60.464618 -21.340854  16.875344 -19.229075   \n",
       "\n",
       "               V6         V7        V8        V9  ...          V21        V22  \\\n",
       "39769  -26.160506 -19.399981 -1.501300  6.967698  ...    -6.266878  -1.272167   \n",
       "58465    7.694002  24.956587 -4.730111 -2.687312  ...    11.455313 -10.933144   \n",
       "151296   6.335259  24.422716 -4.964566  0.188912  ...    11.502580  -9.499423   \n",
       "\n",
       "              V23       V24       V25       V26       V27        V28  \\\n",
       "39769    7.893082  0.767805  5.376595  0.163672 -8.358317  33.847808   \n",
       "58465  -17.173665  1.180700 -7.025783 -2.534330 -3.602479   3.450224   \n",
       "151296 -16.513186  0.744341 -7.081325 -2.604551 -3.550963   3.250802   \n",
       "\n",
       "          Amount  Class  \n",
       "39769    1201.83    0.0  \n",
       "58465   19656.53    0.0  \n",
       "151296  18910.00    0.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[Dataset['V2'] < -60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61092.608212</td>\n",
       "      <td>-0.169856</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>0.493038</td>\n",
       "      <td>0.117430</td>\n",
       "      <td>-0.176091</td>\n",
       "      <td>0.058238</td>\n",
       "      <td>-0.080670</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028273</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.022461</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>87.336246</td>\n",
       "      <td>0.002107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27828.974490</td>\n",
       "      <td>1.850523</td>\n",
       "      <td>1.610865</td>\n",
       "      <td>1.383248</td>\n",
       "      <td>1.371899</td>\n",
       "      <td>1.338609</td>\n",
       "      <td>1.295132</td>\n",
       "      <td>1.208518</td>\n",
       "      <td>1.227627</td>\n",
       "      <td>1.152289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743723</td>\n",
       "      <td>0.667322</td>\n",
       "      <td>0.584511</td>\n",
       "      <td>0.598757</td>\n",
       "      <td>0.465511</td>\n",
       "      <td>0.490667</td>\n",
       "      <td>0.391952</td>\n",
       "      <td>0.307317</td>\n",
       "      <td>245.952377</td>\n",
       "      <td>0.045850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-11.710896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41217.000000</td>\n",
       "      <td>-0.986678</td>\n",
       "      <td>-0.539179</td>\n",
       "      <td>-0.064757</td>\n",
       "      <td>-0.743469</td>\n",
       "      <td>-0.828769</td>\n",
       "      <td>-0.691130</td>\n",
       "      <td>-0.586318</td>\n",
       "      <td>-0.162642</td>\n",
       "      <td>-0.660087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230719</td>\n",
       "      <td>-0.546772</td>\n",
       "      <td>-0.170303</td>\n",
       "      <td>-0.332459</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.330347</td>\n",
       "      <td>-0.065124</td>\n",
       "      <td>-0.027056</td>\n",
       "      <td>5.480000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60776.000000</td>\n",
       "      <td>-0.183596</td>\n",
       "      <td>0.109687</td>\n",
       "      <td>0.623352</td>\n",
       "      <td>0.124322</td>\n",
       "      <td>-0.226226</td>\n",
       "      <td>-0.202623</td>\n",
       "      <td>-0.031930</td>\n",
       "      <td>0.056663</td>\n",
       "      <td>-0.078965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054461</td>\n",
       "      <td>-0.066777</td>\n",
       "      <td>-0.036215</td>\n",
       "      <td>0.059467</td>\n",
       "      <td>0.135677</td>\n",
       "      <td>-0.058970</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>21.895000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78622.750000</td>\n",
       "      <td>1.184444</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>1.297353</td>\n",
       "      <td>0.937619</td>\n",
       "      <td>0.374481</td>\n",
       "      <td>0.449208</td>\n",
       "      <td>0.462624</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128339</td>\n",
       "      <td>0.363171</td>\n",
       "      <td>0.098701</td>\n",
       "      <td>0.415855</td>\n",
       "      <td>0.399459</td>\n",
       "      <td>0.272940</td>\n",
       "      <td>0.089729</td>\n",
       "      <td>0.078303</td>\n",
       "      <td>76.720000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120396.000000</td>\n",
       "      <td>2.439207</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>19.002942</td>\n",
       "      <td>4.022866</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>19656.530000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean    61092.608212      -0.169856       0.040770       0.493038   \n",
       "std     27828.974490       1.850523       1.610865       1.383248   \n",
       "min         0.000000     -56.407510     -72.715728     -33.680984   \n",
       "25%     41217.000000      -0.986678      -0.539179      -0.064757   \n",
       "50%     60776.000000      -0.183596       0.109687       0.623352   \n",
       "75%     78622.750000       1.184444       0.804222       1.297353   \n",
       "max    120396.000000       2.439207      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean        0.117430      -0.176091       0.058238      -0.080670   \n",
       "std         1.371899       1.338609       1.295132       1.208518   \n",
       "min        -5.519697     -42.147898     -26.160506     -43.557242   \n",
       "25%        -0.743469      -0.828769      -0.691130      -0.586318   \n",
       "50%         0.124322      -0.226226      -0.202623      -0.031930   \n",
       "75%         0.937619       0.374481       0.449208       0.462624   \n",
       "max        16.875344      34.801666      22.529298      36.677268   \n",
       "\n",
       "                  V8             V9      ...                  V21  \\\n",
       "count  170886.000000  170886.000000      ...        170886.000000   \n",
       "mean        0.032215       0.018873      ...            -0.028273   \n",
       "std         1.227627       1.152289      ...             0.743723   \n",
       "min       -73.216718     -13.434066      ...           -34.830382   \n",
       "25%        -0.162642      -0.660087      ...            -0.230719   \n",
       "50%         0.056663      -0.078965      ...            -0.054461   \n",
       "75%         0.350995       0.641342      ...             0.128339   \n",
       "max        20.007208      15.594995      ...            27.202839   \n",
       "\n",
       "                 V22            V23            V24            V25  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean       -0.083738      -0.022461       0.009004       0.092271   \n",
       "std         0.667322       0.584511       0.598757       0.465511   \n",
       "min       -10.933144     -44.807735      -2.836627     -10.295397   \n",
       "25%        -0.546772      -0.170303      -0.332459      -0.195935   \n",
       "50%        -0.066777      -0.036215       0.059467       0.135677   \n",
       "75%         0.363171       0.098701       0.415855       0.399459   \n",
       "max        10.503090      19.002942       4.022866       7.519589   \n",
       "\n",
       "                 V26            V27            V28         Amount  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean        0.012607       0.002100       0.002443      87.336246   \n",
       "std         0.490667       0.391952       0.307317     245.952377   \n",
       "min        -2.604551     -22.565679     -11.710896       0.000000   \n",
       "25%        -0.330347      -0.065124      -0.027056       5.480000   \n",
       "50%        -0.058970       0.008693       0.021151      21.895000   \n",
       "75%         0.272940       0.089729       0.078303      76.720000   \n",
       "max         3.517346      12.152401      33.847808   19656.530000   \n",
       "\n",
       "               Class  \n",
       "count  170886.000000  \n",
       "mean        0.002107  \n",
       "std         0.045850  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTABI+H8XeoiaGuv3/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11a764d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Dataset[\"V3\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f120cc890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_df[\"V3\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those outlier persisit even after robust scalling what to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let try a log transofrmer again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " transformer = FunctionTransformer(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/sklearn/preprocessing/_function_transformer.py:94: RuntimeWarning: invalid value encountered in log1p\n",
      "  **(kw_args if kw_args else {}))\n"
     ]
    }
   ],
   "source": [
    "X_trLog=transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yeah log must return invalid for negative number so let customize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Mylog(x):\n",
    "    if x ==0:\n",
    "        return x\n",
    "    if x < 0:\n",
    "        return -np.log1p(abs(x))\n",
    "    else:\n",
    "        return np.log1p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " transformer = FunctionTransformer(Mylog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda x: 0 if x==0 else np.log1p(abs(x)) if x<0 else np.log1p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XLog=X['V1'].apply(lambda x: 0 if operator.eq(x,0) else - np.log1p(abs(x)) if operator.lt(x,0) else np.log1p(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -0.858580\n",
       "1         0.784749\n",
       "2        -0.857964\n",
       "3        -0.676139\n",
       "4        -0.769290\n",
       "5        -0.354849\n",
       "6         0.801848\n",
       "7        -0.497296\n",
       "8        -0.638842\n",
       "9        -0.291372\n",
       "10        0.895698\n",
       "11        0.325684\n",
       "12        0.810930\n",
       "13        0.727246\n",
       "14       -1.332855\n",
       "15       -0.560996\n",
       "16        0.743467\n",
       "17       -0.362492\n",
       "18       -1.856494\n",
       "19        0.913461\n",
       "20        0.527615\n",
       "21        0.674217\n",
       "22        0.773167\n",
       "23        0.221134\n",
       "24       -1.080627\n",
       "25       -1.123076\n",
       "26        0.776240\n",
       "27        0.842733\n",
       "28       -0.346627\n",
       "29        0.722408\n",
       "            ...   \n",
       "170856   -0.921307\n",
       "170857   -0.697485\n",
       "170858    1.138327\n",
       "170859    1.032788\n",
       "170860    1.056900\n",
       "170861   -0.552640\n",
       "170862    1.032950\n",
       "170863   -0.249694\n",
       "170864   -0.145571\n",
       "170865   -0.250670\n",
       "170866    0.135145\n",
       "170867    1.040442\n",
       "170868    1.098266\n",
       "170869   -0.440402\n",
       "170870   -1.047227\n",
       "170871   -0.414781\n",
       "170872    1.039771\n",
       "170873    0.981548\n",
       "170874   -0.739274\n",
       "170875   -0.764899\n",
       "170876    0.250905\n",
       "170877   -0.610692\n",
       "170878    1.126631\n",
       "170879    1.078954\n",
       "170880   -0.168949\n",
       "170881    0.882993\n",
       "170882   -0.909924\n",
       "170883   -1.226974\n",
       "170884   -0.873185\n",
       "170885    0.131360\n",
       "Name: V1, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11b5aa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X[\"V1\"])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f11c0d590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=XLog)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "even a log transformer cannot delete it so let drop them or keep them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let keep the result of RObust scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.405438</td>\n",
       "      <td>-0.859779</td>\n",
       "      <td>-0.262720</td>\n",
       "      <td>2.838267</td>\n",
       "      <td>1.541668</td>\n",
       "      <td>-0.186604</td>\n",
       "      <td>1.020219</td>\n",
       "      <td>0.549037</td>\n",
       "      <td>0.142815</td>\n",
       "      <td>0.614671</td>\n",
       "      <td>...</td>\n",
       "      <td>1.498278</td>\n",
       "      <td>0.197780</td>\n",
       "      <td>0.801526</td>\n",
       "      <td>-0.550413</td>\n",
       "      <td>0.020935</td>\n",
       "      <td>-0.027057</td>\n",
       "      <td>-0.392109</td>\n",
       "      <td>1.540854</td>\n",
       "      <td>-0.738462</td>\n",
       "      <td>2.329685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.405438</td>\n",
       "      <td>1.005419</td>\n",
       "      <td>0.225278</td>\n",
       "      <td>-0.677851</td>\n",
       "      <td>0.398172</td>\n",
       "      <td>0.476512</td>\n",
       "      <td>0.184499</td>\n",
       "      <td>-0.094777</td>\n",
       "      <td>0.096621</td>\n",
       "      <td>-0.244979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171515</td>\n",
       "      <td>-0.937165</td>\n",
       "      <td>-1.330148</td>\n",
       "      <td>1.019179</td>\n",
       "      <td>-1.120446</td>\n",
       "      <td>0.119393</td>\n",
       "      <td>0.556972</td>\n",
       "      <td>-0.218125</td>\n",
       "      <td>-0.112457</td>\n",
       "      <td>-0.350296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.405382</td>\n",
       "      <td>-0.858716</td>\n",
       "      <td>-2.087512</td>\n",
       "      <td>1.706017</td>\n",
       "      <td>0.314102</td>\n",
       "      <td>-0.461077</td>\n",
       "      <td>3.073069</td>\n",
       "      <td>1.664914</td>\n",
       "      <td>0.648971</td>\n",
       "      <td>-1.993163</td>\n",
       "      <td>...</td>\n",
       "      <td>2.923576</td>\n",
       "      <td>1.654587</td>\n",
       "      <td>1.950133</td>\n",
       "      <td>7.009043</td>\n",
       "      <td>-2.100934</td>\n",
       "      <td>-1.756443</td>\n",
       "      <td>-0.241410</td>\n",
       "      <td>-0.790333</td>\n",
       "      <td>-1.415586</td>\n",
       "      <td>6.507342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.405382</td>\n",
       "      <td>-0.572115</td>\n",
       "      <td>-0.424620</td>\n",
       "      <td>1.735370</td>\n",
       "      <td>-1.214333</td>\n",
       "      <td>0.359439</td>\n",
       "      <td>2.224236</td>\n",
       "      <td>0.545014</td>\n",
       "      <td>1.089835</td>\n",
       "      <td>-1.815974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.895474</td>\n",
       "      <td>-0.294526</td>\n",
       "      <td>0.167580</td>\n",
       "      <td>-1.142241</td>\n",
       "      <td>-3.465441</td>\n",
       "      <td>1.939856</td>\n",
       "      <td>-0.490973</td>\n",
       "      <td>0.666735</td>\n",
       "      <td>0.705252</td>\n",
       "      <td>1.853260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.405326</td>\n",
       "      <td>-0.712433</td>\n",
       "      <td>1.105847</td>\n",
       "      <td>1.372944</td>\n",
       "      <td>0.342694</td>\n",
       "      <td>-0.301257</td>\n",
       "      <td>0.458009</td>\n",
       "      <td>1.263502</td>\n",
       "      <td>-1.111657</td>\n",
       "      <td>1.244892</td>\n",
       "      <td>...</td>\n",
       "      <td>2.316933</td>\n",
       "      <td>0.246336</td>\n",
       "      <td>2.011999</td>\n",
       "      <td>-0.750421</td>\n",
       "      <td>0.229525</td>\n",
       "      <td>-1.295334</td>\n",
       "      <td>1.691007</td>\n",
       "      <td>2.600424</td>\n",
       "      <td>3.394507</td>\n",
       "      <td>0.877246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-3.405326</td>\n",
       "      <td>-0.177166</td>\n",
       "      <td>1.225044</td>\n",
       "      <td>0.768184</td>\n",
       "      <td>-0.359738</td>\n",
       "      <td>1.077419</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>1.027452</td>\n",
       "      <td>0.691911</td>\n",
       "      <td>-0.679858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.631096</td>\n",
       "      <td>-0.841314</td>\n",
       "      <td>-1.146760</td>\n",
       "      <td>0.072765</td>\n",
       "      <td>-1.209057</td>\n",
       "      <td>-1.396874</td>\n",
       "      <td>0.496775</td>\n",
       "      <td>3.025196</td>\n",
       "      <td>1.048595</td>\n",
       "      <td>-0.332421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-3.405214</td>\n",
       "      <td>1.033050</td>\n",
       "      <td>0.045090</td>\n",
       "      <td>-0.857538</td>\n",
       "      <td>1.325827</td>\n",
       "      <td>0.696025</td>\n",
       "      <td>0.729224</td>\n",
       "      <td>0.054132</td>\n",
       "      <td>0.083409</td>\n",
       "      <td>0.755130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.955884</td>\n",
       "      <td>-0.619557</td>\n",
       "      <td>-0.474319</td>\n",
       "      <td>-0.873800</td>\n",
       "      <td>-2.355641</td>\n",
       "      <td>2.329423</td>\n",
       "      <td>-0.597351</td>\n",
       "      <td>0.318553</td>\n",
       "      <td>-0.279668</td>\n",
       "      <td>-0.308345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.405046</td>\n",
       "      <td>-0.336740</td>\n",
       "      <td>1.883672</td>\n",
       "      <td>0.669180</td>\n",
       "      <td>-0.758052</td>\n",
       "      <td>1.956295</td>\n",
       "      <td>0.967645</td>\n",
       "      <td>2.330503</td>\n",
       "      <td>-13.129848</td>\n",
       "      <td>0.963950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.628221</td>\n",
       "      <td>10.929553</td>\n",
       "      <td>-2.206492</td>\n",
       "      <td>0.694645</td>\n",
       "      <td>-1.989898</td>\n",
       "      <td>-2.088629</td>\n",
       "      <td>0.022102</td>\n",
       "      <td>-15.000822</td>\n",
       "      <td>-19.360587</td>\n",
       "      <td>0.344824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-3.405046</td>\n",
       "      <td>-0.519495</td>\n",
       "      <td>0.254084</td>\n",
       "      <td>-1.092795</td>\n",
       "      <td>-0.486720</td>\n",
       "      <td>4.820695</td>\n",
       "      <td>6.020641</td>\n",
       "      <td>0.813005</td>\n",
       "      <td>2.699071</td>\n",
       "      <td>-0.434651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463166</td>\n",
       "      <td>-0.103742</td>\n",
       "      <td>-0.468230</td>\n",
       "      <td>-1.245359</td>\n",
       "      <td>2.671594</td>\n",
       "      <td>0.900470</td>\n",
       "      <td>-0.979745</td>\n",
       "      <td>0.037691</td>\n",
       "      <td>2.121600</td>\n",
       "      <td>1.300593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-3.404934</td>\n",
       "      <td>-0.113057</td>\n",
       "      <td>1.454075</td>\n",
       "      <td>0.624649</td>\n",
       "      <td>-0.426055</td>\n",
       "      <td>1.207888</td>\n",
       "      <td>-0.067714</td>\n",
       "      <td>1.382078</td>\n",
       "      <td>0.043745</td>\n",
       "      <td>-0.913169</td>\n",
       "      <td>...</td>\n",
       "      <td>1.249755</td>\n",
       "      <td>-1.052803</td>\n",
       "      <td>-1.318706</td>\n",
       "      <td>-0.626907</td>\n",
       "      <td>-1.247283</td>\n",
       "      <td>-0.778709</td>\n",
       "      <td>0.461477</td>\n",
       "      <td>2.931103</td>\n",
       "      <td>1.083509</td>\n",
       "      <td>-0.332239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-3.404878</td>\n",
       "      <td>1.193415</td>\n",
       "      <td>-1.851636</td>\n",
       "      <td>0.431019</td>\n",
       "      <td>-1.844331</td>\n",
       "      <td>-2.905172</td>\n",
       "      <td>-0.654356</td>\n",
       "      <td>-2.813247</td>\n",
       "      <td>-0.027884</td>\n",
       "      <td>-2.278811</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.829055</td>\n",
       "      <td>0.247041</td>\n",
       "      <td>0.885389</td>\n",
       "      <td>0.474038</td>\n",
       "      <td>1.237541</td>\n",
       "      <td>0.438584</td>\n",
       "      <td>-0.212431</td>\n",
       "      <td>0.421500</td>\n",
       "      <td>-0.085702</td>\n",
       "      <td>-0.257091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-3.404878</td>\n",
       "      <td>0.415612</td>\n",
       "      <td>0.729153</td>\n",
       "      <td>-2.222033</td>\n",
       "      <td>-0.268463</td>\n",
       "      <td>5.245171</td>\n",
       "      <td>5.399635</td>\n",
       "      <td>1.015833</td>\n",
       "      <td>1.636197</td>\n",
       "      <td>-0.666285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844832</td>\n",
       "      <td>0.571031</td>\n",
       "      <td>0.709850</td>\n",
       "      <td>0.336097</td>\n",
       "      <td>2.629837</td>\n",
       "      <td>-3.423246</td>\n",
       "      <td>-1.305288</td>\n",
       "      <td>0.416843</td>\n",
       "      <td>-1.320847</td>\n",
       "      <td>-0.217145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-3.404878</td>\n",
       "      <td>1.047919</td>\n",
       "      <td>-1.916856</td>\n",
       "      <td>-0.355226</td>\n",
       "      <td>-1.671248</td>\n",
       "      <td>-2.096185</td>\n",
       "      <td>-0.844709</td>\n",
       "      <td>-1.329427</td>\n",
       "      <td>-0.965409</td>\n",
       "      <td>-2.797482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346952</td>\n",
       "      <td>-0.970174</td>\n",
       "      <td>-0.968740</td>\n",
       "      <td>0.895988</td>\n",
       "      <td>0.935395</td>\n",
       "      <td>0.096511</td>\n",
       "      <td>-0.891868</td>\n",
       "      <td>0.218699</td>\n",
       "      <td>0.372181</td>\n",
       "      <td>1.816781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-3.404822</td>\n",
       "      <td>0.915886</td>\n",
       "      <td>0.256337</td>\n",
       "      <td>0.304540</td>\n",
       "      <td>3.182355</td>\n",
       "      <td>0.079620</td>\n",
       "      <td>0.828691</td>\n",
       "      <td>-0.131000</td>\n",
       "      <td>0.201537</td>\n",
       "      <td>-0.197301</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.609753</td>\n",
       "      <td>0.096201</td>\n",
       "      <td>0.328387</td>\n",
       "      <td>-0.260850</td>\n",
       "      <td>0.127043</td>\n",
       "      <td>1.564124</td>\n",
       "      <td>0.491290</td>\n",
       "      <td>0.157930</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.102234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-3.404766</td>\n",
       "      <td>-1.906566</td>\n",
       "      <td>-0.629857</td>\n",
       "      <td>1.510974</td>\n",
       "      <td>2.020358</td>\n",
       "      <td>0.149220</td>\n",
       "      <td>1.549817</td>\n",
       "      <td>-0.790571</td>\n",
       "      <td>-6.671970</td>\n",
       "      <td>1.158781</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.054508</td>\n",
       "      <td>6.598039</td>\n",
       "      <td>0.672079</td>\n",
       "      <td>7.833071</td>\n",
       "      <td>-0.087406</td>\n",
       "      <td>-1.396694</td>\n",
       "      <td>-0.532033</td>\n",
       "      <td>-2.140647</td>\n",
       "      <td>-0.897697</td>\n",
       "      <td>0.673142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-3.404766</td>\n",
       "      <td>-0.415793</td>\n",
       "      <td>0.339505</td>\n",
       "      <td>2.127550</td>\n",
       "      <td>-1.958652</td>\n",
       "      <td>-1.551784</td>\n",
       "      <td>0.191419</td>\n",
       "      <td>-1.166000</td>\n",
       "      <td>-0.180272</td>\n",
       "      <td>-0.495902</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>3.031099</td>\n",
       "      <td>3.303717</td>\n",
       "      <td>-1.633310</td>\n",
       "      <td>-0.349481</td>\n",
       "      <td>-0.662671</td>\n",
       "      <td>-0.084711</td>\n",
       "      <td>-2.340803</td>\n",
       "      <td>1.893955</td>\n",
       "      <td>-0.107706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-3.404766</td>\n",
       "      <td>0.940624</td>\n",
       "      <td>-0.215948</td>\n",
       "      <td>0.955458</td>\n",
       "      <td>1.432158</td>\n",
       "      <td>-0.848618</td>\n",
       "      <td>0.752790</td>\n",
       "      <td>-1.120455</td>\n",
       "      <td>0.450909</td>\n",
       "      <td>1.195737</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.405066</td>\n",
       "      <td>0.163288</td>\n",
       "      <td>0.611188</td>\n",
       "      <td>0.370725</td>\n",
       "      <td>0.124278</td>\n",
       "      <td>0.866703</td>\n",
       "      <td>-0.974030</td>\n",
       "      <td>1.038004</td>\n",
       "      <td>0.278193</td>\n",
       "      <td>-0.162426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-3.404710</td>\n",
       "      <td>-0.185162</td>\n",
       "      <td>1.165210</td>\n",
       "      <td>0.446941</td>\n",
       "      <td>-1.047024</td>\n",
       "      <td>1.900935</td>\n",
       "      <td>0.114685</td>\n",
       "      <td>1.495430</td>\n",
       "      <td>0.106340</td>\n",
       "      <td>-0.813967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056572</td>\n",
       "      <td>-0.767694</td>\n",
       "      <td>-1.409148</td>\n",
       "      <td>-0.894211</td>\n",
       "      <td>-2.659609</td>\n",
       "      <td>-1.812441</td>\n",
       "      <td>0.029958</td>\n",
       "      <td>0.876141</td>\n",
       "      <td>1.922471</td>\n",
       "      <td>-0.383128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-3.404654</td>\n",
       "      <td>-3.813969</td>\n",
       "      <td>-8.005118</td>\n",
       "      <td>0.835239</td>\n",
       "      <td>1.981954</td>\n",
       "      <td>5.452462</td>\n",
       "      <td>-2.394459</td>\n",
       "      <td>-3.089257</td>\n",
       "      <td>0.353950</td>\n",
       "      <td>1.821522</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.257254</td>\n",
       "      <td>-2.456993</td>\n",
       "      <td>2.445031</td>\n",
       "      <td>18.491629</td>\n",
       "      <td>-0.048678</td>\n",
       "      <td>-2.340216</td>\n",
       "      <td>-1.694139</td>\n",
       "      <td>4.730712</td>\n",
       "      <td>16.245237</td>\n",
       "      <td>0.454264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-3.404597</td>\n",
       "      <td>1.225499</td>\n",
       "      <td>-1.639993</td>\n",
       "      <td>-0.250085</td>\n",
       "      <td>-1.921006</td>\n",
       "      <td>-2.212739</td>\n",
       "      <td>-0.795204</td>\n",
       "      <td>-2.120561</td>\n",
       "      <td>-0.373016</td>\n",
       "      <td>-2.637371</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.832617</td>\n",
       "      <td>-0.673898</td>\n",
       "      <td>-0.251883</td>\n",
       "      <td>0.564925</td>\n",
       "      <td>0.663172</td>\n",
       "      <td>0.747791</td>\n",
       "      <td>-0.486321</td>\n",
       "      <td>0.167893</td>\n",
       "      <td>-0.237071</td>\n",
       "      <td>-0.308162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-3.404541</td>\n",
       "      <td>0.642145</td>\n",
       "      <td>-2.118693</td>\n",
       "      <td>0.602178</td>\n",
       "      <td>0.872790</td>\n",
       "      <td>-1.606411</td>\n",
       "      <td>2.319208</td>\n",
       "      <td>-1.711955</td>\n",
       "      <td>1.320372</td>\n",
       "      <td>-0.509825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.532315</td>\n",
       "      <td>-1.319045</td>\n",
       "      <td>-1.174974</td>\n",
       "      <td>-0.108705</td>\n",
       "      <td>-1.020465</td>\n",
       "      <td>-0.241395</td>\n",
       "      <td>-1.094466</td>\n",
       "      <td>0.960807</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>3.826995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-3.404485</td>\n",
       "      <td>0.837762</td>\n",
       "      <td>0.314993</td>\n",
       "      <td>-1.179274</td>\n",
       "      <td>2.440539</td>\n",
       "      <td>2.256994</td>\n",
       "      <td>2.912810</td>\n",
       "      <td>0.282359</td>\n",
       "      <td>1.579305</td>\n",
       "      <td>-1.544267</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.214762</td>\n",
       "      <td>1.085657</td>\n",
       "      <td>1.091454</td>\n",
       "      <td>-0.091120</td>\n",
       "      <td>-4.016220</td>\n",
       "      <td>0.967227</td>\n",
       "      <td>0.780132</td>\n",
       "      <td>0.094743</td>\n",
       "      <td>-0.625644</td>\n",
       "      <td>0.222435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-3.404429</td>\n",
       "      <td>0.986968</td>\n",
       "      <td>0.565030</td>\n",
       "      <td>-1.024706</td>\n",
       "      <td>2.627881</td>\n",
       "      <td>1.090433</td>\n",
       "      <td>0.448117</td>\n",
       "      <td>0.552167</td>\n",
       "      <td>0.276622</td>\n",
       "      <td>-1.263624</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.411949</td>\n",
       "      <td>0.400234</td>\n",
       "      <td>0.011175</td>\n",
       "      <td>-0.501353</td>\n",
       "      <td>-1.206219</td>\n",
       "      <td>1.772385</td>\n",
       "      <td>0.504733</td>\n",
       "      <td>-0.607303</td>\n",
       "      <td>-0.569871</td>\n",
       "      <td>-0.357775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-3.404429</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.241857</td>\n",
       "      <td>0.834002</td>\n",
       "      <td>-0.266722</td>\n",
       "      <td>-1.811478</td>\n",
       "      <td>0.080553</td>\n",
       "      <td>-1.849005</td>\n",
       "      <td>-5.689498</td>\n",
       "      <td>2.253257</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.015021</td>\n",
       "      <td>9.325153</td>\n",
       "      <td>0.621543</td>\n",
       "      <td>-1.105418</td>\n",
       "      <td>1.020253</td>\n",
       "      <td>2.596516</td>\n",
       "      <td>-0.508155</td>\n",
       "      <td>4.046837</td>\n",
       "      <td>4.012550</td>\n",
       "      <td>0.015595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-3.404205</td>\n",
       "      <td>-1.288653</td>\n",
       "      <td>-0.222577</td>\n",
       "      <td>-1.526589</td>\n",
       "      <td>-1.398480</td>\n",
       "      <td>5.274109</td>\n",
       "      <td>4.844317</td>\n",
       "      <td>-0.062951</td>\n",
       "      <td>2.714230</td>\n",
       "      <td>0.178996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.940684</td>\n",
       "      <td>-2.872340</td>\n",
       "      <td>-1.703581</td>\n",
       "      <td>6.719142</td>\n",
       "      <td>2.592550</td>\n",
       "      <td>0.703325</td>\n",
       "      <td>0.628543</td>\n",
       "      <td>8.623594</td>\n",
       "      <td>-0.114634</td>\n",
       "      <td>-0.383128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-3.404205</td>\n",
       "      <td>-1.382050</td>\n",
       "      <td>-0.332840</td>\n",
       "      <td>1.036598</td>\n",
       "      <td>0.351269</td>\n",
       "      <td>0.868017</td>\n",
       "      <td>-1.161213</td>\n",
       "      <td>1.164514</td>\n",
       "      <td>-0.547987</td>\n",
       "      <td>0.769990</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.826278</td>\n",
       "      <td>-1.910163</td>\n",
       "      <td>-0.373596</td>\n",
       "      <td>5.771397</td>\n",
       "      <td>0.951400</td>\n",
       "      <td>0.430414</td>\n",
       "      <td>1.004411</td>\n",
       "      <td>4.334792</td>\n",
       "      <td>3.885805</td>\n",
       "      <td>0.082718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-3.404149</td>\n",
       "      <td>0.991843</td>\n",
       "      <td>0.351042</td>\n",
       "      <td>-0.503630</td>\n",
       "      <td>1.240927</td>\n",
       "      <td>0.089310</td>\n",
       "      <td>-1.094503</td>\n",
       "      <td>0.810740</td>\n",
       "      <td>-1.304391</td>\n",
       "      <td>-0.232798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333656</td>\n",
       "      <td>0.664465</td>\n",
       "      <td>0.685173</td>\n",
       "      <td>-0.846994</td>\n",
       "      <td>1.053845</td>\n",
       "      <td>2.233464</td>\n",
       "      <td>-0.837914</td>\n",
       "      <td>0.094715</td>\n",
       "      <td>0.155549</td>\n",
       "      <td>0.364523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-3.404149</td>\n",
       "      <td>1.101066</td>\n",
       "      <td>-0.408515</td>\n",
       "      <td>-0.280115</td>\n",
       "      <td>0.555413</td>\n",
       "      <td>-1.016355</td>\n",
       "      <td>-0.964146</td>\n",
       "      <td>-0.471079</td>\n",
       "      <td>-0.943307</td>\n",
       "      <td>-1.377829</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.536184</td>\n",
       "      <td>-1.257735</td>\n",
       "      <td>-0.596770</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>1.607245</td>\n",
       "      <td>-0.666410</td>\n",
       "      <td>0.415150</td>\n",
       "      <td>0.134222</td>\n",
       "      <td>-0.107524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-3.404149</td>\n",
       "      <td>-0.168630</td>\n",
       "      <td>1.145731</td>\n",
       "      <td>1.638129</td>\n",
       "      <td>1.658865</td>\n",
       "      <td>0.388990</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>1.561321</td>\n",
       "      <td>-0.291883</td>\n",
       "      <td>-0.714177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695387</td>\n",
       "      <td>0.720450</td>\n",
       "      <td>1.219002</td>\n",
       "      <td>-0.016936</td>\n",
       "      <td>1.636010</td>\n",
       "      <td>-1.211484</td>\n",
       "      <td>-0.658293</td>\n",
       "      <td>2.147113</td>\n",
       "      <td>2.301128</td>\n",
       "      <td>0.202554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-3.404149</td>\n",
       "      <td>0.908587</td>\n",
       "      <td>-0.410356</td>\n",
       "      <td>0.953674</td>\n",
       "      <td>1.305536</td>\n",
       "      <td>-0.931861</td>\n",
       "      <td>1.198252</td>\n",
       "      <td>-1.486496</td>\n",
       "      <td>1.170052</td>\n",
       "      <td>1.080740</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.739098</td>\n",
       "      <td>0.372742</td>\n",
       "      <td>0.652429</td>\n",
       "      <td>0.375618</td>\n",
       "      <td>-0.158581</td>\n",
       "      <td>0.602624</td>\n",
       "      <td>-1.012622</td>\n",
       "      <td>0.897967</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>-0.162426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170856</th>\n",
       "      <td>3.339936</td>\n",
       "      <td>-0.971445</td>\n",
       "      <td>-1.578872</td>\n",
       "      <td>-2.096367</td>\n",
       "      <td>1.328897</td>\n",
       "      <td>2.164513</td>\n",
       "      <td>-0.741318</td>\n",
       "      <td>1.865269</td>\n",
       "      <td>-2.443662</td>\n",
       "      <td>0.335894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.703014</td>\n",
       "      <td>0.222789</td>\n",
       "      <td>3.357835</td>\n",
       "      <td>5.715292</td>\n",
       "      <td>1.844148</td>\n",
       "      <td>-4.237637</td>\n",
       "      <td>3.274010</td>\n",
       "      <td>5.049608</td>\n",
       "      <td>6.814495</td>\n",
       "      <td>2.449704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170857</th>\n",
       "      <td>3.339936</td>\n",
       "      <td>-0.603124</td>\n",
       "      <td>-0.184261</td>\n",
       "      <td>0.677364</td>\n",
       "      <td>-4.276941</td>\n",
       "      <td>-0.452565</td>\n",
       "      <td>0.316184</td>\n",
       "      <td>-0.610894</td>\n",
       "      <td>0.498048</td>\n",
       "      <td>-1.736013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031065</td>\n",
       "      <td>-1.534053</td>\n",
       "      <td>-0.836844</td>\n",
       "      <td>-2.676091</td>\n",
       "      <td>-0.150882</td>\n",
       "      <td>2.577141</td>\n",
       "      <td>-0.113756</td>\n",
       "      <td>5.746045</td>\n",
       "      <td>3.892722</td>\n",
       "      <td>-0.238851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170858</th>\n",
       "      <td>3.339992</td>\n",
       "      <td>1.684992</td>\n",
       "      <td>-1.386334</td>\n",
       "      <td>-2.374522</td>\n",
       "      <td>-0.652239</td>\n",
       "      <td>-0.832211</td>\n",
       "      <td>-0.237834</td>\n",
       "      <td>-1.473783</td>\n",
       "      <td>-0.095354</td>\n",
       "      <td>0.096759</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.678077</td>\n",
       "      <td>-0.839815</td>\n",
       "      <td>0.170620</td>\n",
       "      <td>1.246231</td>\n",
       "      <td>-1.648516</td>\n",
       "      <td>-0.771591</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>0.179923</td>\n",
       "      <td>-1.474815</td>\n",
       "      <td>-0.381122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170859</th>\n",
       "      <td>3.340104</td>\n",
       "      <td>1.456450</td>\n",
       "      <td>-1.165656</td>\n",
       "      <td>-3.019698</td>\n",
       "      <td>-0.277362</td>\n",
       "      <td>1.175461</td>\n",
       "      <td>1.920164</td>\n",
       "      <td>-0.600845</td>\n",
       "      <td>1.118438</td>\n",
       "      <td>1.561844</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.230820</td>\n",
       "      <td>-0.006157</td>\n",
       "      <td>0.135741</td>\n",
       "      <td>1.566048</td>\n",
       "      <td>-4.788620</td>\n",
       "      <td>-1.598730</td>\n",
       "      <td>0.242526</td>\n",
       "      <td>-0.077352</td>\n",
       "      <td>-1.702074</td>\n",
       "      <td>0.695030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170860</th>\n",
       "      <td>3.340104</td>\n",
       "      <td>1.506559</td>\n",
       "      <td>-0.562331</td>\n",
       "      <td>-2.366486</td>\n",
       "      <td>1.521683</td>\n",
       "      <td>0.841901</td>\n",
       "      <td>1.232145</td>\n",
       "      <td>-0.246978</td>\n",
       "      <td>0.346662</td>\n",
       "      <td>1.300382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.803960</td>\n",
       "      <td>-1.294664</td>\n",
       "      <td>-1.181682</td>\n",
       "      <td>1.653968</td>\n",
       "      <td>0.564959</td>\n",
       "      <td>-0.233030</td>\n",
       "      <td>-2.375950</td>\n",
       "      <td>0.229965</td>\n",
       "      <td>-1.158000</td>\n",
       "      <td>0.330233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170861</th>\n",
       "      <td>3.340160</td>\n",
       "      <td>-0.405134</td>\n",
       "      <td>-0.118589</td>\n",
       "      <td>-0.124992</td>\n",
       "      <td>-3.349288</td>\n",
       "      <td>0.506248</td>\n",
       "      <td>1.267132</td>\n",
       "      <td>-0.689031</td>\n",
       "      <td>2.068070</td>\n",
       "      <td>-1.573445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.574437</td>\n",
       "      <td>2.736196</td>\n",
       "      <td>2.475715</td>\n",
       "      <td>-1.851518</td>\n",
       "      <td>-1.055320</td>\n",
       "      <td>0.020275</td>\n",
       "      <td>-0.331342</td>\n",
       "      <td>-0.343042</td>\n",
       "      <td>0.355933</td>\n",
       "      <td>0.329321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170862</th>\n",
       "      <td>3.340160</td>\n",
       "      <td>1.456783</td>\n",
       "      <td>-0.746849</td>\n",
       "      <td>-0.882501</td>\n",
       "      <td>1.305599</td>\n",
       "      <td>-0.523437</td>\n",
       "      <td>1.100321</td>\n",
       "      <td>-1.645858</td>\n",
       "      <td>0.827768</td>\n",
       "      <td>1.323208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.453560</td>\n",
       "      <td>1.015777</td>\n",
       "      <td>1.089607</td>\n",
       "      <td>2.309848</td>\n",
       "      <td>1.700498</td>\n",
       "      <td>-1.945770</td>\n",
       "      <td>-2.261948</td>\n",
       "      <td>0.715977</td>\n",
       "      <td>-0.653825</td>\n",
       "      <td>0.421432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170863</th>\n",
       "      <td>3.340216</td>\n",
       "      <td>-0.073124</td>\n",
       "      <td>-0.374115</td>\n",
       "      <td>2.021998</td>\n",
       "      <td>0.401450</td>\n",
       "      <td>-0.351819</td>\n",
       "      <td>0.762994</td>\n",
       "      <td>1.106046</td>\n",
       "      <td>-1.105040</td>\n",
       "      <td>1.651606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.484463</td>\n",
       "      <td>1.457228</td>\n",
       "      <td>2.838362</td>\n",
       "      <td>1.898710</td>\n",
       "      <td>-0.504305</td>\n",
       "      <td>-2.618338</td>\n",
       "      <td>-1.961201</td>\n",
       "      <td>-2.650102</td>\n",
       "      <td>-7.894216</td>\n",
       "      <td>1.578751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170864</th>\n",
       "      <td>3.340216</td>\n",
       "      <td>0.019660</td>\n",
       "      <td>0.563593</td>\n",
       "      <td>-1.364687</td>\n",
       "      <td>-2.896740</td>\n",
       "      <td>1.615641</td>\n",
       "      <td>-1.105609</td>\n",
       "      <td>1.589391</td>\n",
       "      <td>-0.668181</td>\n",
       "      <td>-2.014353</td>\n",
       "      <td>...</td>\n",
       "      <td>1.339830</td>\n",
       "      <td>0.331949</td>\n",
       "      <td>0.316937</td>\n",
       "      <td>-1.439725</td>\n",
       "      <td>-1.711427</td>\n",
       "      <td>0.429527</td>\n",
       "      <td>-0.901154</td>\n",
       "      <td>2.935558</td>\n",
       "      <td>1.125338</td>\n",
       "      <td>-0.125764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170865</th>\n",
       "      <td>3.340272</td>\n",
       "      <td>-0.074041</td>\n",
       "      <td>0.237787</td>\n",
       "      <td>1.110798</td>\n",
       "      <td>-0.773319</td>\n",
       "      <td>-0.417376</td>\n",
       "      <td>-0.282818</td>\n",
       "      <td>0.956026</td>\n",
       "      <td>-0.014904</td>\n",
       "      <td>0.871121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193814</td>\n",
       "      <td>1.906059</td>\n",
       "      <td>2.167316</td>\n",
       "      <td>0.292742</td>\n",
       "      <td>0.033209</td>\n",
       "      <td>-3.217222</td>\n",
       "      <td>1.617612</td>\n",
       "      <td>1.652370</td>\n",
       "      <td>3.053282</td>\n",
       "      <td>0.786047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170866</th>\n",
       "      <td>3.340272</td>\n",
       "      <td>0.239977</td>\n",
       "      <td>1.120695</td>\n",
       "      <td>-2.113065</td>\n",
       "      <td>-1.227085</td>\n",
       "      <td>2.786290</td>\n",
       "      <td>0.326929</td>\n",
       "      <td>1.667047</td>\n",
       "      <td>0.239240</td>\n",
       "      <td>-0.128010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416636</td>\n",
       "      <td>-1.652060</td>\n",
       "      <td>-2.033444</td>\n",
       "      <td>0.072574</td>\n",
       "      <td>-1.473550</td>\n",
       "      <td>-1.776645</td>\n",
       "      <td>0.651079</td>\n",
       "      <td>2.522636</td>\n",
       "      <td>0.751273</td>\n",
       "      <td>-0.350296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170867</th>\n",
       "      <td>3.340272</td>\n",
       "      <td>1.472226</td>\n",
       "      <td>-2.205945</td>\n",
       "      <td>-1.648726</td>\n",
       "      <td>-1.026254</td>\n",
       "      <td>-1.818913</td>\n",
       "      <td>-0.553544</td>\n",
       "      <td>-1.656410</td>\n",
       "      <td>-0.754255</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>...</td>\n",
       "      <td>2.231866</td>\n",
       "      <td>3.176394</td>\n",
       "      <td>2.966289</td>\n",
       "      <td>0.716807</td>\n",
       "      <td>3.253566</td>\n",
       "      <td>-1.493689</td>\n",
       "      <td>-0.261093</td>\n",
       "      <td>-0.262552</td>\n",
       "      <td>-0.425744</td>\n",
       "      <td>2.792613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170868</th>\n",
       "      <td>3.340272</td>\n",
       "      <td>1.595389</td>\n",
       "      <td>-1.107625</td>\n",
       "      <td>-2.404462</td>\n",
       "      <td>0.632300</td>\n",
       "      <td>-0.617649</td>\n",
       "      <td>-0.498434</td>\n",
       "      <td>-0.757265</td>\n",
       "      <td>-0.516912</td>\n",
       "      <td>-0.794687</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.306379</td>\n",
       "      <td>0.440334</td>\n",
       "      <td>1.640195</td>\n",
       "      <td>0.229850</td>\n",
       "      <td>-0.213531</td>\n",
       "      <td>0.243669</td>\n",
       "      <td>-0.826185</td>\n",
       "      <td>0.243694</td>\n",
       "      <td>-1.300321</td>\n",
       "      <td>0.311993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170869</th>\n",
       "      <td>3.340328</td>\n",
       "      <td>-0.270267</td>\n",
       "      <td>1.831638</td>\n",
       "      <td>2.609023</td>\n",
       "      <td>3.986054</td>\n",
       "      <td>1.590668</td>\n",
       "      <td>1.368569</td>\n",
       "      <td>1.972712</td>\n",
       "      <td>-0.499558</td>\n",
       "      <td>-1.802934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304917</td>\n",
       "      <td>0.492911</td>\n",
       "      <td>1.315658</td>\n",
       "      <td>-4.303601</td>\n",
       "      <td>-0.146523</td>\n",
       "      <td>2.412606</td>\n",
       "      <td>1.293715</td>\n",
       "      <td>-1.474274</td>\n",
       "      <td>-3.184593</td>\n",
       "      <td>-0.399362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170870</th>\n",
       "      <td>3.340328</td>\n",
       "      <td>-1.217905</td>\n",
       "      <td>-3.484372</td>\n",
       "      <td>0.527504</td>\n",
       "      <td>-0.329785</td>\n",
       "      <td>6.126759</td>\n",
       "      <td>-1.882230</td>\n",
       "      <td>-2.587201</td>\n",
       "      <td>-1.349480</td>\n",
       "      <td>1.991582</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.794811</td>\n",
       "      <td>0.818023</td>\n",
       "      <td>2.711669</td>\n",
       "      <td>-3.923554</td>\n",
       "      <td>0.464436</td>\n",
       "      <td>-4.798686</td>\n",
       "      <td>-1.216875</td>\n",
       "      <td>2.935604</td>\n",
       "      <td>-5.850604</td>\n",
       "      <td>-0.378021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170871</th>\n",
       "      <td>3.340328</td>\n",
       "      <td>-0.241545</td>\n",
       "      <td>0.192860</td>\n",
       "      <td>-5.439403</td>\n",
       "      <td>-0.894617</td>\n",
       "      <td>0.043849</td>\n",
       "      <td>1.390274</td>\n",
       "      <td>5.721644</td>\n",
       "      <td>-0.380329</td>\n",
       "      <td>-1.011768</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.029258</td>\n",
       "      <td>0.376209</td>\n",
       "      <td>0.242005</td>\n",
       "      <td>5.226609</td>\n",
       "      <td>-1.701324</td>\n",
       "      <td>-1.762154</td>\n",
       "      <td>1.303382</td>\n",
       "      <td>-0.614339</td>\n",
       "      <td>-4.196120</td>\n",
       "      <td>8.648518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170872</th>\n",
       "      <td>3.340384</td>\n",
       "      <td>1.470838</td>\n",
       "      <td>-0.971010</td>\n",
       "      <td>-2.022426</td>\n",
       "      <td>-0.350901</td>\n",
       "      <td>0.785738</td>\n",
       "      <td>2.145310</td>\n",
       "      <td>-1.339913</td>\n",
       "      <td>1.294075</td>\n",
       "      <td>0.918508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.664624</td>\n",
       "      <td>-0.148141</td>\n",
       "      <td>-0.307040</td>\n",
       "      <td>3.278778</td>\n",
       "      <td>-4.769920</td>\n",
       "      <td>-3.720488</td>\n",
       "      <td>1.221592</td>\n",
       "      <td>-0.155753</td>\n",
       "      <td>-1.484099</td>\n",
       "      <td>0.330233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170873</th>\n",
       "      <td>3.340384</td>\n",
       "      <td>1.353894</td>\n",
       "      <td>-0.914846</td>\n",
       "      <td>-1.316536</td>\n",
       "      <td>1.477256</td>\n",
       "      <td>-0.667373</td>\n",
       "      <td>0.084323</td>\n",
       "      <td>-0.723324</td>\n",
       "      <td>-0.062704</td>\n",
       "      <td>0.863224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351844</td>\n",
       "      <td>2.305128</td>\n",
       "      <td>2.340837</td>\n",
       "      <td>0.492647</td>\n",
       "      <td>-0.101064</td>\n",
       "      <td>-1.163489</td>\n",
       "      <td>-1.617762</td>\n",
       "      <td>0.353179</td>\n",
       "      <td>-0.676404</td>\n",
       "      <td>1.907980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170874</th>\n",
       "      <td>3.340440</td>\n",
       "      <td>-0.665784</td>\n",
       "      <td>-4.092970</td>\n",
       "      <td>-4.348783</td>\n",
       "      <td>-2.139170</td>\n",
       "      <td>-3.594047</td>\n",
       "      <td>-0.249110</td>\n",
       "      <td>8.068475</td>\n",
       "      <td>-3.255244</td>\n",
       "      <td>-4.133772</td>\n",
       "      <td>...</td>\n",
       "      <td>8.360994</td>\n",
       "      <td>4.728967</td>\n",
       "      <td>2.891788</td>\n",
       "      <td>14.314992</td>\n",
       "      <td>-0.257521</td>\n",
       "      <td>-0.397397</td>\n",
       "      <td>0.698906</td>\n",
       "      <td>-1.776074</td>\n",
       "      <td>4.509729</td>\n",
       "      <td>16.536343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170875</th>\n",
       "      <td>3.340496</td>\n",
       "      <td>-0.705521</td>\n",
       "      <td>1.210682</td>\n",
       "      <td>-5.101541</td>\n",
       "      <td>-2.755221</td>\n",
       "      <td>6.069044</td>\n",
       "      <td>4.143988</td>\n",
       "      <td>1.183394</td>\n",
       "      <td>3.389602</td>\n",
       "      <td>-0.313806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894440</td>\n",
       "      <td>1.487062</td>\n",
       "      <td>1.801665</td>\n",
       "      <td>-1.420219</td>\n",
       "      <td>1.965170</td>\n",
       "      <td>-1.142359</td>\n",
       "      <td>0.532159</td>\n",
       "      <td>6.373543</td>\n",
       "      <td>5.036578</td>\n",
       "      <td>-0.232102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170876</th>\n",
       "      <td>3.340552</td>\n",
       "      <td>0.342668</td>\n",
       "      <td>-1.790273</td>\n",
       "      <td>-0.188306</td>\n",
       "      <td>-2.203647</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>-1.399799</td>\n",
       "      <td>-0.848904</td>\n",
       "      <td>-1.550011</td>\n",
       "      <td>-2.381502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.308071</td>\n",
       "      <td>0.373847</td>\n",
       "      <td>1.580912</td>\n",
       "      <td>2.113673</td>\n",
       "      <td>-0.240547</td>\n",
       "      <td>-6.148626</td>\n",
       "      <td>-0.524276</td>\n",
       "      <td>1.669234</td>\n",
       "      <td>0.872391</td>\n",
       "      <td>-0.125764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170877</th>\n",
       "      <td>3.340552</td>\n",
       "      <td>-0.481061</td>\n",
       "      <td>0.559754</td>\n",
       "      <td>0.707148</td>\n",
       "      <td>-1.251876</td>\n",
       "      <td>-0.199128</td>\n",
       "      <td>-0.396257</td>\n",
       "      <td>-0.248615</td>\n",
       "      <td>1.955590</td>\n",
       "      <td>0.684260</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.662952</td>\n",
       "      <td>2.443582</td>\n",
       "      <td>2.300337</td>\n",
       "      <td>-0.475543</td>\n",
       "      <td>2.913365</td>\n",
       "      <td>-2.075521</td>\n",
       "      <td>1.555064</td>\n",
       "      <td>-0.369388</td>\n",
       "      <td>1.046098</td>\n",
       "      <td>-0.217145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170878</th>\n",
       "      <td>3.340552</td>\n",
       "      <td>1.658460</td>\n",
       "      <td>0.063678</td>\n",
       "      <td>-3.799920</td>\n",
       "      <td>0.407792</td>\n",
       "      <td>1.138609</td>\n",
       "      <td>-2.142910</td>\n",
       "      <td>1.739518</td>\n",
       "      <td>-2.252044</td>\n",
       "      <td>0.480220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.915886</td>\n",
       "      <td>1.097150</td>\n",
       "      <td>1.724365</td>\n",
       "      <td>-0.417077</td>\n",
       "      <td>0.159145</td>\n",
       "      <td>1.679937</td>\n",
       "      <td>-0.046148</td>\n",
       "      <td>-0.723819</td>\n",
       "      <td>-1.616011</td>\n",
       "      <td>-0.160055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170879</th>\n",
       "      <td>3.340608</td>\n",
       "      <td>1.553461</td>\n",
       "      <td>-0.310142</td>\n",
       "      <td>-3.929448</td>\n",
       "      <td>-0.126194</td>\n",
       "      <td>2.470265</td>\n",
       "      <td>2.121383</td>\n",
       "      <td>-0.365016</td>\n",
       "      <td>1.188959</td>\n",
       "      <td>0.622537</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.201358</td>\n",
       "      <td>-1.209356</td>\n",
       "      <td>-1.358982</td>\n",
       "      <td>2.885951</td>\n",
       "      <td>-3.136657</td>\n",
       "      <td>-2.238647</td>\n",
       "      <td>1.028068</td>\n",
       "      <td>-0.380023</td>\n",
       "      <td>-1.390128</td>\n",
       "      <td>-0.363247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170880</th>\n",
       "      <td>3.340608</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>1.558742</td>\n",
       "      <td>-2.157869</td>\n",
       "      <td>-0.619031</td>\n",
       "      <td>1.871780</td>\n",
       "      <td>-0.447968</td>\n",
       "      <td>1.643263</td>\n",
       "      <td>-3.161325</td>\n",
       "      <td>-0.303108</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.644298</td>\n",
       "      <td>4.431467</td>\n",
       "      <td>-0.577473</td>\n",
       "      <td>1.926558</td>\n",
       "      <td>1.631380</td>\n",
       "      <td>-5.287589</td>\n",
       "      <td>0.717066</td>\n",
       "      <td>1.199344</td>\n",
       "      <td>4.383185</td>\n",
       "      <td>-0.078340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170881</th>\n",
       "      <td>3.340608</td>\n",
       "      <td>1.170815</td>\n",
       "      <td>-2.572047</td>\n",
       "      <td>-2.323154</td>\n",
       "      <td>0.750609</td>\n",
       "      <td>-1.147782</td>\n",
       "      <td>0.750127</td>\n",
       "      <td>-0.785153</td>\n",
       "      <td>0.046956</td>\n",
       "      <td>-0.550081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057606</td>\n",
       "      <td>-0.129630</td>\n",
       "      <td>-0.795097</td>\n",
       "      <td>0.444050</td>\n",
       "      <td>1.597715</td>\n",
       "      <td>-1.795539</td>\n",
       "      <td>-2.093171</td>\n",
       "      <td>-0.134508</td>\n",
       "      <td>-0.004610</td>\n",
       "      <td>5.576015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170882</th>\n",
       "      <td>3.340664</td>\n",
       "      <td>-0.950658</td>\n",
       "      <td>0.537214</td>\n",
       "      <td>-0.062205</td>\n",
       "      <td>-1.833647</td>\n",
       "      <td>2.636162</td>\n",
       "      <td>4.818975</td>\n",
       "      <td>0.017031</td>\n",
       "      <td>2.851981</td>\n",
       "      <td>0.943999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485113</td>\n",
       "      <td>1.354329</td>\n",
       "      <td>3.030973</td>\n",
       "      <td>-0.301732</td>\n",
       "      <td>-4.738743</td>\n",
       "      <td>-0.889005</td>\n",
       "      <td>2.542561</td>\n",
       "      <td>6.990960</td>\n",
       "      <td>4.198570</td>\n",
       "      <td>0.437848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>3.340664</td>\n",
       "      <td>-1.628093</td>\n",
       "      <td>-1.978331</td>\n",
       "      <td>-2.093190</td>\n",
       "      <td>-0.413716</td>\n",
       "      <td>2.274130</td>\n",
       "      <td>-2.803760</td>\n",
       "      <td>1.143955</td>\n",
       "      <td>-0.854531</td>\n",
       "      <td>-3.052599</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.723119</td>\n",
       "      <td>-0.121651</td>\n",
       "      <td>0.282808</td>\n",
       "      <td>-8.951445</td>\n",
       "      <td>0.246026</td>\n",
       "      <td>3.179339</td>\n",
       "      <td>4.122642</td>\n",
       "      <td>0.925105</td>\n",
       "      <td>-11.063847</td>\n",
       "      <td>1.880255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170884</th>\n",
       "      <td>3.340664</td>\n",
       "      <td>-0.885157</td>\n",
       "      <td>0.252116</td>\n",
       "      <td>3.495357</td>\n",
       "      <td>0.292664</td>\n",
       "      <td>-1.861672</td>\n",
       "      <td>3.806938</td>\n",
       "      <td>-3.648070</td>\n",
       "      <td>-6.300918</td>\n",
       "      <td>0.845149</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.020248</td>\n",
       "      <td>10.940226</td>\n",
       "      <td>-1.100478</td>\n",
       "      <td>-3.043004</td>\n",
       "      <td>-1.629147</td>\n",
       "      <td>1.023584</td>\n",
       "      <td>-0.271963</td>\n",
       "      <td>5.556148</td>\n",
       "      <td>-1.621430</td>\n",
       "      <td>0.512631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170885</th>\n",
       "      <td>3.340664</td>\n",
       "      <td>0.236816</td>\n",
       "      <td>1.266872</td>\n",
       "      <td>-1.676258</td>\n",
       "      <td>0.438009</td>\n",
       "      <td>2.720111</td>\n",
       "      <td>0.880995</td>\n",
       "      <td>1.705988</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>-0.790359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817994</td>\n",
       "      <td>2.408818</td>\n",
       "      <td>3.185773</td>\n",
       "      <td>-1.044671</td>\n",
       "      <td>-0.706749</td>\n",
       "      <td>-3.261189</td>\n",
       "      <td>-1.127734</td>\n",
       "      <td>6.568073</td>\n",
       "      <td>5.296681</td>\n",
       "      <td>-0.240857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170886 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0      -3.405438 -0.859779 -0.262720  2.838267  1.541668 -0.186604  1.020219   \n",
       "1      -3.405438  1.005419  0.225278 -0.677851  0.398172  0.476512  0.184499   \n",
       "2      -3.405382 -0.858716 -2.087512  1.706017  0.314102 -0.461077  3.073069   \n",
       "3      -3.405382 -0.572115 -0.424620  1.735370 -1.214333  0.359439  2.224236   \n",
       "4      -3.405326 -0.712433  1.105847  1.372944  0.342694 -0.301257  0.458009   \n",
       "5      -3.405326 -0.177166  1.225044  0.768184 -0.359738  1.077419  0.265245   \n",
       "6      -3.405214  1.033050  0.045090 -0.857538  1.325827  0.696025  0.729224   \n",
       "7      -3.405046 -0.336740  1.883672  0.669180 -0.758052  1.956295  0.967645   \n",
       "8      -3.405046 -0.519495  0.254084 -1.092795 -0.486720  4.820695  6.020641   \n",
       "9      -3.404934 -0.113057  1.454075  0.624649 -0.426055  1.207888 -0.067714   \n",
       "10     -3.404878  1.193415 -1.851636  0.431019 -1.844331 -2.905172 -0.654356   \n",
       "11     -3.404878  0.415612  0.729153 -2.222033 -0.268463  5.245171  5.399635   \n",
       "12     -3.404878  1.047919 -1.916856 -0.355226 -1.671248 -2.096185 -0.844709   \n",
       "13     -3.404822  0.915886  0.256337  0.304540  3.182355  0.079620  0.828691   \n",
       "14     -3.404766 -1.906566 -0.629857  1.510974  2.020358  0.149220  1.549817   \n",
       "15     -3.404766 -0.415793  0.339505  2.127550 -1.958652 -1.551784  0.191419   \n",
       "16     -3.404766  0.940624 -0.215948  0.955458  1.432158 -0.848618  0.752790   \n",
       "17     -3.404710 -0.185162  1.165210  0.446941 -1.047024  1.900935  0.114685   \n",
       "18     -3.404654 -3.813969 -8.005118  0.835239  1.981954  5.452462 -2.394459   \n",
       "19     -3.404597  1.225499 -1.639993 -0.250085 -1.921006 -2.212739 -0.795204   \n",
       "20     -3.404541  0.642145 -2.118693  0.602178  0.872790 -1.606411  2.319208   \n",
       "21     -3.404485  0.837762  0.314993 -1.179274  2.440539  2.256994  2.912810   \n",
       "22     -3.404429  0.986968  0.565030 -1.024706  2.627881  1.090433  0.448117   \n",
       "23     -3.404429  0.315113  0.241857  0.834002 -0.266722 -1.811478  0.080553   \n",
       "24     -3.404205 -1.288653 -0.222577 -1.526589 -1.398480  5.274109  4.844317   \n",
       "25     -3.404205 -1.382050 -0.332840  1.036598  0.351269  0.868017 -1.161213   \n",
       "26     -3.404149  0.991843  0.351042 -0.503630  1.240927  0.089310 -1.094503   \n",
       "27     -3.404149  1.101066 -0.408515 -0.280115  0.555413 -1.016355 -0.964146   \n",
       "28     -3.404149 -0.168630  1.145731  1.638129  1.658865  0.388990  0.003516   \n",
       "29     -3.404149  0.908587 -0.410356  0.953674  1.305536 -0.931861  1.198252   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "170856  3.339936 -0.971445 -1.578872 -2.096367  1.328897  2.164513 -0.741318   \n",
       "170857  3.339936 -0.603124 -0.184261  0.677364 -4.276941 -0.452565  0.316184   \n",
       "170858  3.339992  1.684992 -1.386334 -2.374522 -0.652239 -0.832211 -0.237834   \n",
       "170859  3.340104  1.456450 -1.165656 -3.019698 -0.277362  1.175461  1.920164   \n",
       "170860  3.340104  1.506559 -0.562331 -2.366486  1.521683  0.841901  1.232145   \n",
       "170861  3.340160 -0.405134 -0.118589 -0.124992 -3.349288  0.506248  1.267132   \n",
       "170862  3.340160  1.456783 -0.746849 -0.882501  1.305599 -0.523437  1.100321   \n",
       "170863  3.340216 -0.073124 -0.374115  2.021998  0.401450 -0.351819  0.762994   \n",
       "170864  3.340216  0.019660  0.563593 -1.364687 -2.896740  1.615641 -1.105609   \n",
       "170865  3.340272 -0.074041  0.237787  1.110798 -0.773319 -0.417376 -0.282818   \n",
       "170866  3.340272  0.239977  1.120695 -2.113065 -1.227085  2.786290  0.326929   \n",
       "170867  3.340272  1.472226 -2.205945 -1.648726 -1.026254 -1.818913 -0.553544   \n",
       "170868  3.340272  1.595389 -1.107625 -2.404462  0.632300 -0.617649 -0.498434   \n",
       "170869  3.340328 -0.270267  1.831638  2.609023  3.986054  1.590668  1.368569   \n",
       "170870  3.340328 -1.217905 -3.484372  0.527504 -0.329785  6.126759 -1.882230   \n",
       "170871  3.340328 -0.241545  0.192860 -5.439403 -0.894617  0.043849  1.390274   \n",
       "170872  3.340384  1.470838 -0.971010 -2.022426 -0.350901  0.785738  2.145310   \n",
       "170873  3.340384  1.353894 -0.914846 -1.316536  1.477256 -0.667373  0.084323   \n",
       "170874  3.340440 -0.665784 -4.092970 -4.348783 -2.139170 -3.594047 -0.249110   \n",
       "170875  3.340496 -0.705521  1.210682 -5.101541 -2.755221  6.069044  4.143988   \n",
       "170876  3.340552  0.342668 -1.790273 -0.188306 -2.203647  0.028213 -1.399799   \n",
       "170877  3.340552 -0.481061  0.559754  0.707148 -1.251876 -0.199128 -0.396257   \n",
       "170878  3.340552  1.658460  0.063678 -3.799920  0.407792  1.138609 -2.142910   \n",
       "170879  3.340608  1.553461 -0.310142 -3.929448 -0.126194  2.470265  2.121383   \n",
       "170880  3.340608 -0.000339  1.558742 -2.157869 -0.619031  1.871780 -0.447968   \n",
       "170881  3.340608  1.170815 -2.572047 -2.323154  0.750609 -1.147782  0.750127   \n",
       "170882  3.340664 -0.950658  0.537214 -0.062205 -1.833647  2.636162  4.818975   \n",
       "170883  3.340664 -1.628093 -1.978331 -2.093190 -0.413716  2.274130 -2.803760   \n",
       "170884  3.340664 -0.885157  0.252116  3.495357  0.292664 -1.861672  3.806938   \n",
       "170885  3.340664  0.236816  1.266872 -1.676258  0.438009  2.720111  0.880995   \n",
       "\n",
       "              V7         V8        V9    ...            V20        V21  \\\n",
       "0       0.549037   0.142815  0.614671    ...       1.498278   0.197780   \n",
       "1      -0.094777   0.096621 -0.244979    ...      -0.171515  -0.937165   \n",
       "2       1.664914   0.648971 -1.993163    ...       2.923576   1.654587   \n",
       "3       0.545014   1.089835 -1.815974    ...      -0.895474  -0.294526   \n",
       "4       1.263502  -1.111657  1.244892    ...       2.316933   0.246336   \n",
       "5       1.027452   0.691911 -0.679858    ...       0.631096  -0.841314   \n",
       "6       0.054132   0.083409  0.755130    ...      -0.955884  -0.619557   \n",
       "7       2.330503 -13.129848  0.963950    ...      -0.628221  10.929553   \n",
       "8       0.813005   2.699071 -0.434651    ...       0.463166  -0.103742   \n",
       "9       1.382078   0.043745 -0.913169    ...       1.249755  -1.052803   \n",
       "10     -2.813247  -0.027884 -2.278811    ...      -1.829055   0.247041   \n",
       "11      1.015833   1.636197 -0.666285    ...       0.844832   0.571031   \n",
       "12     -1.329427  -0.965409 -2.797482    ...      -0.346952  -0.970174   \n",
       "13     -0.131000   0.201537 -0.197301    ...      -0.609753   0.096201   \n",
       "14     -0.790571  -6.671970  1.158781    ...      -8.054508   6.598039   \n",
       "15     -1.166000  -0.180272 -0.495902    ...       1.561000   3.031099   \n",
       "16     -1.120455   0.450909  1.195737    ...      -0.405066   0.163288   \n",
       "17      1.495430   0.106340 -0.813967    ...      -0.056572  -0.767694   \n",
       "18     -3.089257   0.353950  1.821522    ...     -11.257254  -2.456993   \n",
       "19     -2.120561  -0.373016 -2.637371    ...      -1.832617  -0.673898   \n",
       "20     -1.711955   1.320372 -0.509825    ...      -0.532315  -1.319045   \n",
       "21      0.282359   1.579305 -1.544267    ...      -1.214762   1.085657   \n",
       "22      0.552167   0.276622 -1.263624    ...      -1.411949   0.400234   \n",
       "23     -1.849005  -5.689498  2.253257    ...      -1.015021   9.325153   \n",
       "24     -0.062951   2.714230  0.178996    ...      -0.940684  -2.872340   \n",
       "25      1.164514  -0.547987  0.769990    ...      -1.826278  -1.910163   \n",
       "26      0.810740  -1.304391 -0.232798    ...       0.333656   0.664465   \n",
       "27     -0.471079  -0.943307 -1.377829    ...      -2.536184  -1.257735   \n",
       "28      1.561321  -0.291883 -0.714177    ...       0.695387   0.720450   \n",
       "29     -1.486496   1.170052  1.080740    ...      -0.739098   0.372742   \n",
       "...          ...        ...       ...    ...            ...        ...   \n",
       "170856  1.865269  -2.443662  0.335894    ...      -0.703014   0.222789   \n",
       "170857 -0.610894   0.498048 -1.736013    ...      -0.031065  -1.534053   \n",
       "170858 -1.473783  -0.095354  0.096759    ...      -3.678077  -0.839815   \n",
       "170859 -0.600845   1.118438  1.561844    ...      -1.230820  -0.006157   \n",
       "170860 -0.246978   0.346662  1.300382    ...      -0.803960  -1.294664   \n",
       "170861 -0.689031   2.068070 -1.573445    ...       0.574437   2.736196   \n",
       "170862 -1.645858   0.827768  1.323208    ...      -0.453560   1.015777   \n",
       "170863  1.106046  -1.105040  1.651606    ...      -0.484463   1.457228   \n",
       "170864  1.589391  -0.668181 -2.014353    ...       1.339830   0.331949   \n",
       "170865  0.956026  -0.014904  0.871121    ...      -0.193814   1.906059   \n",
       "170866  1.667047   0.239240 -0.128010    ...       0.416636  -1.652060   \n",
       "170867 -1.656410  -0.754255  0.003613    ...       2.231866   3.176394   \n",
       "170868 -0.757265  -0.516912 -0.794687    ...      -3.306379   0.440334   \n",
       "170869  1.972712  -0.499558 -1.802934    ...       0.304917   0.492911   \n",
       "170870 -2.587201  -1.349480  1.991582    ...      -1.794811   0.818023   \n",
       "170871  5.721644  -0.380329 -1.011768    ...      -1.029258   0.376209   \n",
       "170872 -1.339913   1.294075  0.918508    ...      -0.664624  -0.148141   \n",
       "170873 -0.723324  -0.062704  0.863224    ...       0.351844   2.305128   \n",
       "170874  8.068475  -3.255244 -4.133772    ...       8.360994   4.728967   \n",
       "170875  1.183394   3.389602 -0.313806    ...       0.894440   1.487062   \n",
       "170876 -0.848904  -1.550011 -2.381502    ...      -0.308071   0.373847   \n",
       "170877 -0.248615   1.955590  0.684260    ...      -1.662952   2.443582   \n",
       "170878  1.739518  -2.252044  0.480220    ...      -0.915886   1.097150   \n",
       "170879 -0.365016   1.188959  0.622537    ...      -1.201358  -1.209356   \n",
       "170880  1.643263  -3.161325 -0.303108    ...      -1.644298   4.431467   \n",
       "170881 -0.785153   0.046956 -0.550081    ...       0.057606  -0.129630   \n",
       "170882  0.017031   2.851981  0.943999    ...       0.485113   1.354329   \n",
       "170883  1.143955  -0.854531 -3.052599    ...      -2.723119  -0.121651   \n",
       "170884 -3.648070  -6.300918  0.845149    ...      -4.020248  10.940226   \n",
       "170885  1.705988   0.037505 -0.790359    ...       0.817994   2.408818   \n",
       "\n",
       "             V22        V23       V24       V25       V26        V27  \\\n",
       "0       0.801526  -0.550413  0.020935 -0.027057 -0.392109   1.540854   \n",
       "1      -1.330148   1.019179 -1.120446  0.119393  0.556972  -0.218125   \n",
       "2       1.950133   7.009043 -2.100934 -1.756443 -0.241410  -0.790333   \n",
       "3       0.167580  -1.142241 -3.465441  1.939856 -0.490973   0.666735   \n",
       "4       2.011999  -0.750421  0.229525 -1.295334  1.691007   2.600424   \n",
       "5      -1.146760   0.072765 -1.209057 -1.396874  0.496775   3.025196   \n",
       "6      -0.474319  -0.873800 -2.355641  2.329423 -0.597351   0.318553   \n",
       "7      -2.206492   0.694645 -1.989898 -2.088629  0.022102 -15.000822   \n",
       "8      -0.468230  -1.245359  2.671594  0.900470 -0.979745   0.037691   \n",
       "9      -1.318706  -0.626907 -1.247283 -0.778709  0.461477   2.931103   \n",
       "10      0.885389   0.474038  1.237541  0.438584 -0.212431   0.421500   \n",
       "11      0.709850   0.336097  2.629837 -3.423246 -1.305288   0.416843   \n",
       "12     -0.968740   0.895988  0.935395  0.096511 -0.891868   0.218699   \n",
       "13      0.328387  -0.260850  0.127043  1.564124  0.491290   0.157930   \n",
       "14      0.672079   7.833071 -0.087406 -1.396694 -0.532033  -2.140647   \n",
       "15      3.303717  -1.633310 -0.349481 -0.662671 -0.084711  -2.340803   \n",
       "16      0.611188   0.370725  0.124278  0.866703 -0.974030   1.038004   \n",
       "17     -1.409148  -0.894211 -2.659609 -1.812441  0.029958   0.876141   \n",
       "18      2.445031  18.491629 -0.048678 -2.340216 -1.694139   4.730712   \n",
       "19     -0.251883   0.564925  0.663172  0.747791 -0.486321   0.167893   \n",
       "20     -1.174974  -0.108705 -1.020465 -0.241395 -1.094466   0.960807   \n",
       "21      1.091454  -0.091120 -4.016220  0.967227  0.780132   0.094743   \n",
       "22      0.011175  -0.501353 -1.206219  1.772385  0.504733  -0.607303   \n",
       "23      0.621543  -1.105418  1.020253  2.596516 -0.508155   4.046837   \n",
       "24     -1.703581   6.719142  2.592550  0.703325  0.628543   8.623594   \n",
       "25     -0.373596   5.771397  0.951400  0.430414  1.004411   4.334792   \n",
       "26      0.685173  -0.846994  1.053845  2.233464 -0.837914   0.094715   \n",
       "27     -0.596770  -0.011082  0.807220  1.607245 -0.666410   0.415150   \n",
       "28      1.219002  -0.016936  1.636010 -1.211484 -0.658293   2.147113   \n",
       "29      0.652429   0.375618 -0.158581  0.602624 -1.012622   0.897967   \n",
       "...          ...        ...       ...       ...       ...        ...   \n",
       "170856  3.357835   5.715292  1.844148 -4.237637  3.274010   5.049608   \n",
       "170857 -0.836844  -2.676091 -0.150882  2.577141 -0.113756   5.746045   \n",
       "170858  0.170620   1.246231 -1.648516 -0.771591 -0.392048   0.179923   \n",
       "170859  0.135741   1.566048 -4.788620 -1.598730  0.242526  -0.077352   \n",
       "170860 -1.181682   1.653968  0.564959 -0.233030 -2.375950   0.229965   \n",
       "170861  2.475715  -1.851518 -1.055320  0.020275 -0.331342  -0.343042   \n",
       "170862  1.089607   2.309848  1.700498 -1.945770 -2.261948   0.715977   \n",
       "170863  2.838362   1.898710 -0.504305 -2.618338 -1.961201  -2.650102   \n",
       "170864  0.316937  -1.439725 -1.711427  0.429527 -0.901154   2.935558   \n",
       "170865  2.167316   0.292742  0.033209 -3.217222  1.617612   1.652370   \n",
       "170866 -2.033444   0.072574 -1.473550 -1.776645  0.651079   2.522636   \n",
       "170867  2.966289   0.716807  3.253566 -1.493689 -0.261093  -0.262552   \n",
       "170868  1.640195   0.229850 -0.213531  0.243669 -0.826185   0.243694   \n",
       "170869  1.315658  -4.303601 -0.146523  2.412606  1.293715  -1.474274   \n",
       "170870  2.711669  -3.923554  0.464436 -4.798686 -1.216875   2.935604   \n",
       "170871  0.242005   5.226609 -1.701324 -1.762154  1.303382  -0.614339   \n",
       "170872 -0.307040   3.278778 -4.769920 -3.720488  1.221592  -0.155753   \n",
       "170873  2.340837   0.492647 -0.101064 -1.163489 -1.617762   0.353179   \n",
       "170874  2.891788  14.314992 -0.257521 -0.397397  0.698906  -1.776074   \n",
       "170875  1.801665  -1.420219  1.965170 -1.142359  0.532159   6.373543   \n",
       "170876  1.580912   2.113673 -0.240547 -6.148626 -0.524276   1.669234   \n",
       "170877  2.300337  -0.475543  2.913365 -2.075521  1.555064  -0.369388   \n",
       "170878  1.724365  -0.417077  0.159145  1.679937 -0.046148  -0.723819   \n",
       "170879 -1.358982   2.885951 -3.136657 -2.238647  1.028068  -0.380023   \n",
       "170880 -0.577473   1.926558  1.631380 -5.287589  0.717066   1.199344   \n",
       "170881 -0.795097   0.444050  1.597715 -1.795539 -2.093171  -0.134508   \n",
       "170882  3.030973  -0.301732 -4.738743 -0.889005  2.542561   6.990960   \n",
       "170883  0.282808  -8.951445  0.246026  3.179339  4.122642   0.925105   \n",
       "170884 -1.100478  -3.043004 -1.629147  1.023584 -0.271963   5.556148   \n",
       "170885  3.185773  -1.044671 -0.706749 -3.261189 -1.127734   6.568073   \n",
       "\n",
       "              V28     Amount  \n",
       "0       -0.738462   2.329685  \n",
       "1       -0.112457  -0.350296  \n",
       "2       -1.415586   6.507342  \n",
       "3        0.705252   1.853260  \n",
       "4        3.394507   0.877246  \n",
       "5        1.048595  -0.332421  \n",
       "6       -0.279668  -0.308345  \n",
       "7      -19.360587   0.344824  \n",
       "8        2.121600   1.300593  \n",
       "9        1.083509  -0.332239  \n",
       "10      -0.085702  -0.257091  \n",
       "11      -1.320847  -0.217145  \n",
       "12       0.372181   1.816781  \n",
       "13       0.002485   0.102234  \n",
       "14      -0.897697   0.673142  \n",
       "15       1.893955  -0.107706  \n",
       "16       0.278193  -0.162426  \n",
       "17       1.922471  -0.383128  \n",
       "18      16.245237   0.454264  \n",
       "19      -0.237071  -0.308162  \n",
       "20       0.740964   3.826995  \n",
       "21      -0.625644   0.222435  \n",
       "22      -0.569871  -0.357775  \n",
       "23       4.012550   0.015595  \n",
       "24      -0.114634  -0.383128  \n",
       "25       3.885805   0.082718  \n",
       "26       0.155549   0.364523  \n",
       "27       0.134222  -0.107524  \n",
       "28       2.301128   0.202554  \n",
       "29       0.053700  -0.162426  \n",
       "...           ...        ...  \n",
       "170856   6.814495   2.449704  \n",
       "170857   3.892722  -0.238851  \n",
       "170858  -1.474815  -0.381122  \n",
       "170859  -1.702074   0.695030  \n",
       "170860  -1.158000   0.330233  \n",
       "170861   0.355933   0.329321  \n",
       "170862  -0.653825   0.421432  \n",
       "170863  -7.894216   1.578751  \n",
       "170864   1.125338  -0.125764  \n",
       "170865   3.053282   0.786047  \n",
       "170866   0.751273  -0.350296  \n",
       "170867  -0.425744   2.792613  \n",
       "170868  -1.300321   0.311993  \n",
       "170869  -3.184593  -0.399362  \n",
       "170870  -5.850604  -0.378021  \n",
       "170871  -4.196120   8.648518  \n",
       "170872  -1.484099   0.330233  \n",
       "170873  -0.676404   1.907980  \n",
       "170874   4.509729  16.536343  \n",
       "170875   5.036578  -0.232102  \n",
       "170876   0.872391  -0.125764  \n",
       "170877   1.046098  -0.217145  \n",
       "170878  -1.616011  -0.160055  \n",
       "170879  -1.390128  -0.363247  \n",
       "170880   4.383185  -0.078340  \n",
       "170881  -0.004610   5.576015  \n",
       "170882   4.198570   0.437848  \n",
       "170883 -11.063847   1.880255  \n",
       "170884  -1.621430   0.512631  \n",
       "170885   5.296681  -0.240857  \n",
       "\n",
       "[170886 rows x 30 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XScRbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>39954.0</td>\n",
       "      <td>-56.40751</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-6.605265</td>\n",
       "      <td>16.491217</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-19.399981</td>\n",
       "      <td>-1.5013</td>\n",
       "      <td>6.967698</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.266878</td>\n",
       "      <td>-1.272167</td>\n",
       "      <td>7.893082</td>\n",
       "      <td>0.767805</td>\n",
       "      <td>5.376595</td>\n",
       "      <td>0.163672</td>\n",
       "      <td>-8.358317</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>1201.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Time        V1         V2        V3         V4         V5  \\\n",
       "39769  39954.0 -56.40751 -72.715728 -6.605265  16.491217  34.801666   \n",
       "\n",
       "              V6         V7      V8        V9  ...         V21       V22  \\\n",
       "39769 -26.160506 -19.399981 -1.5013  6.967698  ...   -6.266878 -1.272167   \n",
       "\n",
       "            V23       V24       V25       V26       V27        V28   Amount  \\\n",
       "39769  7.893082  0.767805  5.376595  0.163672 -8.358317  33.847808  1201.83   \n",
       "\n",
       "       Class  \n",
       "39769    0.0  \n",
       "\n",
       "[1 rows x 31 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[Dataset['V1'] < -40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>39954.0</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-6.605265</td>\n",
       "      <td>16.491217</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-19.399981</td>\n",
       "      <td>-1.501300</td>\n",
       "      <td>6.967698</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.266878</td>\n",
       "      <td>-1.272167</td>\n",
       "      <td>7.893082</td>\n",
       "      <td>0.767805</td>\n",
       "      <td>5.376595</td>\n",
       "      <td>0.163672</td>\n",
       "      <td>-8.358317</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>1201.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58465</th>\n",
       "      <td>48401.0</td>\n",
       "      <td>-36.802320</td>\n",
       "      <td>-63.344698</td>\n",
       "      <td>-20.645794</td>\n",
       "      <td>16.715537</td>\n",
       "      <td>-20.672064</td>\n",
       "      <td>7.694002</td>\n",
       "      <td>24.956587</td>\n",
       "      <td>-4.730111</td>\n",
       "      <td>-2.687312</td>\n",
       "      <td>...</td>\n",
       "      <td>11.455313</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-17.173665</td>\n",
       "      <td>1.180700</td>\n",
       "      <td>-7.025783</td>\n",
       "      <td>-2.534330</td>\n",
       "      <td>-3.602479</td>\n",
       "      <td>3.450224</td>\n",
       "      <td>19656.53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151296</th>\n",
       "      <td>95286.0</td>\n",
       "      <td>-34.549296</td>\n",
       "      <td>-60.464618</td>\n",
       "      <td>-21.340854</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>-19.229075</td>\n",
       "      <td>6.335259</td>\n",
       "      <td>24.422716</td>\n",
       "      <td>-4.964566</td>\n",
       "      <td>0.188912</td>\n",
       "      <td>...</td>\n",
       "      <td>11.502580</td>\n",
       "      <td>-9.499423</td>\n",
       "      <td>-16.513186</td>\n",
       "      <td>0.744341</td>\n",
       "      <td>-7.081325</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-3.550963</td>\n",
       "      <td>3.250802</td>\n",
       "      <td>18910.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time         V1         V2         V3         V4         V5  \\\n",
       "39769   39954.0 -56.407510 -72.715728  -6.605265  16.491217  34.801666   \n",
       "58465   48401.0 -36.802320 -63.344698 -20.645794  16.715537 -20.672064   \n",
       "151296  95286.0 -34.549296 -60.464618 -21.340854  16.875344 -19.229075   \n",
       "\n",
       "               V6         V7        V8        V9  ...          V21        V22  \\\n",
       "39769  -26.160506 -19.399981 -1.501300  6.967698  ...    -6.266878  -1.272167   \n",
       "58465    7.694002  24.956587 -4.730111 -2.687312  ...    11.455313 -10.933144   \n",
       "151296   6.335259  24.422716 -4.964566  0.188912  ...    11.502580  -9.499423   \n",
       "\n",
       "              V23       V24       V25       V26       V27        V28  \\\n",
       "39769    7.893082  0.767805  5.376595  0.163672 -8.358317  33.847808   \n",
       "58465  -17.173665  1.180700 -7.025783 -2.534330 -3.602479   3.450224   \n",
       "151296 -16.513186  0.744341 -7.081325 -2.604551 -3.550963   3.250802   \n",
       "\n",
       "          Amount  Class  \n",
       "39769    1201.83    0.0  \n",
       "58465   19656.53    0.0  \n",
       "151296  18910.00    0.0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[Dataset['V2'] < -60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTABIEEwASPg/et4VJ7/qgy4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f12b45c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=XScRbs['V3'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0CpxdTMFpb0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f12b45750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X['V2'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1346b610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_df['V2'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finaly i will keep the transformation with scalar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-1744dc52d1db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXtr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXtr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'V2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2738\u001b[0m         if (name in self._internal_names_set or name in self._metadata or\n\u001b[1;32m   2739\u001b[0m                 name in self._accessors):\n\u001b[0;32m-> 2740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2741\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "Xtr_df[Xtr_df['V2'] < -30].labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtr_dfWO=Xtr_df[Xtr_df['V2'] > -30]  #the dataset without some outlier where outlier was dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f126eef10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_df['V2'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f120c8550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_dfWO['V2'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKOsucwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1122ecd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_df['V1'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEwAS/h/S5kf7GqVhPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1122e890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_dfWO['V1'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f116cdf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_df['V3'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZCBmmwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f115fd850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_dfWO['V3'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f12fb6450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_dfWO['V20'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THOSE OUTLIER WILL nOT DISAPEAR IT LOOKS LIKE THAT IS WHAT i'M LOOKING FOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.257784e-17</td>\n",
       "      <td>2.128892e-17</td>\n",
       "      <td>7.983346e-18</td>\n",
       "      <td>-6.386677e-17</td>\n",
       "      <td>-2.128892e-17</td>\n",
       "      <td>3.991673e-17</td>\n",
       "      <td>5.322231e-18</td>\n",
       "      <td>2.661115e-18</td>\n",
       "      <td>-1.064446e-17</td>\n",
       "      <td>4.224521e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>8.648625e-18</td>\n",
       "      <td>-3.991673e-18</td>\n",
       "      <td>1.064446e-17</td>\n",
       "      <td>4.656952e-18</td>\n",
       "      <td>1.896045e-17</td>\n",
       "      <td>-7.983346e-17</td>\n",
       "      <td>-4.656952e-18</td>\n",
       "      <td>-2.827435e-18</td>\n",
       "      <td>3.492714e-18</td>\n",
       "      <td>8.781681e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.195294e+00</td>\n",
       "      <td>-3.039022e+01</td>\n",
       "      <td>-4.516624e+01</td>\n",
       "      <td>-2.470572e+01</td>\n",
       "      <td>-4.109010e+00</td>\n",
       "      <td>-3.135488e+01</td>\n",
       "      <td>-2.024412e+01</td>\n",
       "      <td>-3.597523e+01</td>\n",
       "      <td>-5.966726e+01</td>\n",
       "      <td>-1.167500e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.150806e+01</td>\n",
       "      <td>-4.679459e+01</td>\n",
       "      <td>-1.625819e+01</td>\n",
       "      <td>-7.662024e+01</td>\n",
       "      <td>-4.752581e+00</td>\n",
       "      <td>-2.231462e+01</td>\n",
       "      <td>-5.333890e+00</td>\n",
       "      <td>-5.757814e+01</td>\n",
       "      <td>-3.811490e+01</td>\n",
       "      <td>-3.550952e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.142076e-01</td>\n",
       "      <td>-4.414013e-01</td>\n",
       "      <td>-3.600244e-01</td>\n",
       "      <td>-4.032511e-01</td>\n",
       "      <td>-6.275258e-01</td>\n",
       "      <td>-4.875802e-01</td>\n",
       "      <td>-5.786049e-01</td>\n",
       "      <td>-4.184043e-01</td>\n",
       "      <td>-1.587277e-01</td>\n",
       "      <td>-5.892283e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.955650e-01</td>\n",
       "      <td>-2.722068e-01</td>\n",
       "      <td>-6.938723e-01</td>\n",
       "      <td>-2.529335e-01</td>\n",
       "      <td>-5.702895e-01</td>\n",
       "      <td>-6.191203e-01</td>\n",
       "      <td>-6.989555e-01</td>\n",
       "      <td>-1.715110e-01</td>\n",
       "      <td>-9.598774e-02</td>\n",
       "      <td>-3.328144e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.137696e-02</td>\n",
       "      <td>-7.424534e-03</td>\n",
       "      <td>4.278288e-02</td>\n",
       "      <td>9.420951e-02</td>\n",
       "      <td>5.023245e-03</td>\n",
       "      <td>-3.745296e-02</td>\n",
       "      <td>-2.014165e-01</td>\n",
       "      <td>4.033029e-02</td>\n",
       "      <td>1.991464e-02</td>\n",
       "      <td>-8.490739e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.245452e-02</td>\n",
       "      <td>-3.521212e-02</td>\n",
       "      <td>2.541608e-02</td>\n",
       "      <td>-2.353039e-02</td>\n",
       "      <td>8.427964e-02</td>\n",
       "      <td>9.324221e-02</td>\n",
       "      <td>-1.458772e-01</td>\n",
       "      <td>1.682197e-02</td>\n",
       "      <td>6.087712e-02</td>\n",
       "      <td>-2.660736e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.299259e-01</td>\n",
       "      <td>7.318495e-01</td>\n",
       "      <td>4.739408e-01</td>\n",
       "      <td>5.814707e-01</td>\n",
       "      <td>5.978507e-01</td>\n",
       "      <td>4.113029e-01</td>\n",
       "      <td>3.018779e-01</td>\n",
       "      <td>4.495559e-01</td>\n",
       "      <td>2.596717e-01</td>\n",
       "      <td>5.402038e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.719836e-01</td>\n",
       "      <td>2.105796e-01</td>\n",
       "      <td>6.697075e-01</td>\n",
       "      <td>2.072875e-01</td>\n",
       "      <td>6.794951e-01</td>\n",
       "      <td>6.598947e-01</td>\n",
       "      <td>5.305713e-01</td>\n",
       "      <td>2.235738e-01</td>\n",
       "      <td>2.468473e-01</td>\n",
       "      <td>-4.316395e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.131001e+00</td>\n",
       "      <td>1.409910e+00</td>\n",
       "      <td>1.366783e+01</td>\n",
       "      <td>6.426577e+00</td>\n",
       "      <td>1.221516e+01</td>\n",
       "      <td>2.613000e+01</td>\n",
       "      <td>1.735045e+01</td>\n",
       "      <td>3.041582e+01</td>\n",
       "      <td>1.627127e+01</td>\n",
       "      <td>1.351758e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.426886e+01</td>\n",
       "      <td>3.661470e+01</td>\n",
       "      <td>1.586470e+01</td>\n",
       "      <td>3.254934e+01</td>\n",
       "      <td>6.703680e+00</td>\n",
       "      <td>1.595524e+01</td>\n",
       "      <td>7.142823e+00</td>\n",
       "      <td>3.099958e+01</td>\n",
       "      <td>1.101320e+02</td>\n",
       "      <td>7.956520e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean  -4.257784e-17  2.128892e-17  7.983346e-18 -6.386677e-17 -2.128892e-17   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -2.195294e+00 -3.039022e+01 -4.516624e+01 -2.470572e+01 -4.109010e+00   \n",
       "25%   -7.142076e-01 -4.414013e-01 -3.600244e-01 -4.032511e-01 -6.275258e-01   \n",
       "50%   -1.137696e-02 -7.424534e-03  4.278288e-02  9.420951e-02  5.023245e-03   \n",
       "75%    6.299259e-01  7.318495e-01  4.739408e-01  5.814707e-01  5.978507e-01   \n",
       "max    2.131001e+00  1.409910e+00  1.366783e+01  6.426577e+00  1.221516e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean   3.991673e-17  5.322231e-18  2.661115e-18 -1.064446e-17  4.224521e-17   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -3.135488e+01 -2.024412e+01 -3.597523e+01 -5.966726e+01 -1.167500e+01   \n",
       "25%   -4.875802e-01 -5.786049e-01 -4.184043e-01 -1.587277e-01 -5.892283e-01   \n",
       "50%   -3.745296e-02 -2.014165e-01  4.033029e-02  1.991464e-02 -8.490739e-02   \n",
       "75%    4.113029e-01  3.018779e-01  4.495559e-01  2.596717e-01  5.402038e-01   \n",
       "max    2.613000e+01  1.735045e+01  3.041582e+01  1.627127e+01  1.351758e+01   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "count      ...       1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean       ...       8.648625e-18 -3.991673e-18  1.064446e-17  4.656952e-18   \n",
       "std        ...       1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min        ...      -3.150806e+01 -4.679459e+01 -1.625819e+01 -7.662024e+01   \n",
       "25%        ...      -2.955650e-01 -2.722068e-01 -6.938723e-01 -2.529335e-01   \n",
       "50%        ...      -9.245452e-02 -3.521212e-02  2.541608e-02 -2.353039e-02   \n",
       "75%        ...       1.719836e-01  2.105796e-01  6.697075e-01  2.072875e-01   \n",
       "max        ...       5.426886e+01  3.661470e+01  1.586470e+01  3.254934e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean   1.896045e-17 -7.983346e-17 -4.656952e-18 -2.827435e-18  3.492714e-18   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -4.752581e+00 -2.231462e+01 -5.333890e+00 -5.757814e+01 -3.811490e+01   \n",
       "25%   -5.702895e-01 -6.191203e-01 -6.989555e-01 -1.715110e-01 -9.598774e-02   \n",
       "50%    8.427964e-02  9.324221e-02 -1.458772e-01  1.682197e-02  6.087712e-02   \n",
       "75%    6.794951e-01  6.598947e-01  5.305713e-01  2.235738e-01  2.468473e-01   \n",
       "max    6.703680e+00  1.595524e+01  7.142823e+00  3.099958e+01  1.101320e+02   \n",
       "\n",
       "             Amount  \n",
       "count  1.708860e+05  \n",
       "mean   8.781681e-17  \n",
       "std    1.000003e+00  \n",
       "min   -3.550952e-01  \n",
       "25%   -3.328144e-01  \n",
       "50%   -2.660736e-01  \n",
       "75%   -4.316395e-02  \n",
       "max    7.956520e+01  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTABIEEwASBBMAEj4P1h1eDfT0GOyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f12fb6c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Xtr_df['Amount'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>-2.149874</td>\n",
       "      <td>-5.928529</td>\n",
       "      <td>-5.992759</td>\n",
       "      <td>-9.313315</td>\n",
       "      <td>4.297645</td>\n",
       "      <td>-23.842752</td>\n",
       "      <td>16.473136</td>\n",
       "      <td>28.451344</td>\n",
       "      <td>-6.152537</td>\n",
       "      <td>-1.687605</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.229190</td>\n",
       "      <td>-6.294976</td>\n",
       "      <td>2.172644</td>\n",
       "      <td>-4.967286</td>\n",
       "      <td>1.393803</td>\n",
       "      <td>1.404903</td>\n",
       "      <td>1.607571</td>\n",
       "      <td>9.822532</td>\n",
       "      <td>13.521861</td>\n",
       "      <td>31.002408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19760</th>\n",
       "      <td>-1.097981</td>\n",
       "      <td>-7.577325</td>\n",
       "      <td>-15.739432</td>\n",
       "      <td>-5.835429</td>\n",
       "      <td>5.549562</td>\n",
       "      <td>-6.058037</td>\n",
       "      <td>3.039262</td>\n",
       "      <td>8.057352</td>\n",
       "      <td>-1.250159</td>\n",
       "      <td>-0.216972</td>\n",
       "      <td>...</td>\n",
       "      <td>21.746289</td>\n",
       "      <td>6.352248</td>\n",
       "      <td>-5.969954</td>\n",
       "      <td>-11.714075</td>\n",
       "      <td>0.164546</td>\n",
       "      <td>-5.870206</td>\n",
       "      <td>-2.547977</td>\n",
       "      <td>-3.544438</td>\n",
       "      <td>4.513016</td>\n",
       "      <td>31.681363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23128</th>\n",
       "      <td>-1.023670</td>\n",
       "      <td>-12.544202</td>\n",
       "      <td>-11.260801</td>\n",
       "      <td>-14.956445</td>\n",
       "      <td>3.011656</td>\n",
       "      <td>-31.354875</td>\n",
       "      <td>17.350446</td>\n",
       "      <td>30.415816</td>\n",
       "      <td>-3.987391</td>\n",
       "      <td>1.411755</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.910114</td>\n",
       "      <td>-7.885966</td>\n",
       "      <td>-0.083938</td>\n",
       "      <td>-10.374014</td>\n",
       "      <td>3.199921</td>\n",
       "      <td>1.240399</td>\n",
       "      <td>0.890981</td>\n",
       "      <td>28.405732</td>\n",
       "      <td>-31.304400</td>\n",
       "      <td>29.850637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46841</th>\n",
       "      <td>-0.651898</td>\n",
       "      <td>-12.722374</td>\n",
       "      <td>-26.205541</td>\n",
       "      <td>-9.986573</td>\n",
       "      <td>7.148938</td>\n",
       "      <td>-10.286411</td>\n",
       "      <td>4.251820</td>\n",
       "      <td>13.066720</td>\n",
       "      <td>-2.343119</td>\n",
       "      <td>-1.388195</td>\n",
       "      <td>...</td>\n",
       "      <td>36.105492</td>\n",
       "      <td>10.689326</td>\n",
       "      <td>-9.346304</td>\n",
       "      <td>-19.311701</td>\n",
       "      <td>0.659988</td>\n",
       "      <td>-9.966603</td>\n",
       "      <td>-3.239935</td>\n",
       "      <td>-6.019853</td>\n",
       "      <td>7.325410</td>\n",
       "      <td>52.138676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54018</th>\n",
       "      <td>-0.533245</td>\n",
       "      <td>-11.678248</td>\n",
       "      <td>-23.804725</td>\n",
       "      <td>-9.120236</td>\n",
       "      <td>7.023398</td>\n",
       "      <td>-9.490999</td>\n",
       "      <td>3.241206</td>\n",
       "      <td>12.300827</td>\n",
       "      <td>-2.321940</td>\n",
       "      <td>-0.595521</td>\n",
       "      <td>...</td>\n",
       "      <td>33.207435</td>\n",
       "      <td>10.038380</td>\n",
       "      <td>-8.295427</td>\n",
       "      <td>-18.005822</td>\n",
       "      <td>1.075974</td>\n",
       "      <td>-9.290206</td>\n",
       "      <td>-1.004892</td>\n",
       "      <td>-5.766067</td>\n",
       "      <td>6.768414</td>\n",
       "      <td>48.020631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57209</th>\n",
       "      <td>-0.477403</td>\n",
       "      <td>-7.223709</td>\n",
       "      <td>-15.189174</td>\n",
       "      <td>-5.674331</td>\n",
       "      <td>4.941382</td>\n",
       "      <td>-6.230242</td>\n",
       "      <td>1.773198</td>\n",
       "      <td>7.984501</td>\n",
       "      <td>-1.660704</td>\n",
       "      <td>-0.221403</td>\n",
       "      <td>...</td>\n",
       "      <td>21.339135</td>\n",
       "      <td>6.395042</td>\n",
       "      <td>-5.125423</td>\n",
       "      <td>-11.579791</td>\n",
       "      <td>1.428292</td>\n",
       "      <td>-5.426499</td>\n",
       "      <td>-0.523143</td>\n",
       "      <td>-3.650539</td>\n",
       "      <td>4.398674</td>\n",
       "      <td>30.692876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58465</th>\n",
       "      <td>-0.456059</td>\n",
       "      <td>-19.795788</td>\n",
       "      <td>-39.348837</td>\n",
       "      <td>-15.282076</td>\n",
       "      <td>12.098676</td>\n",
       "      <td>-15.311437</td>\n",
       "      <td>5.895757</td>\n",
       "      <td>20.717392</td>\n",
       "      <td>-3.879305</td>\n",
       "      <td>-2.348535</td>\n",
       "      <td>...</td>\n",
       "      <td>54.268855</td>\n",
       "      <td>15.440724</td>\n",
       "      <td>-16.258186</td>\n",
       "      <td>-29.342891</td>\n",
       "      <td>1.956887</td>\n",
       "      <td>-15.290886</td>\n",
       "      <td>-5.190777</td>\n",
       "      <td>-9.196517</td>\n",
       "      <td>11.218994</td>\n",
       "      <td>79.565204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74699</th>\n",
       "      <td>-0.193454</td>\n",
       "      <td>-9.067843</td>\n",
       "      <td>-10.217005</td>\n",
       "      <td>-9.410070</td>\n",
       "      <td>4.692932</td>\n",
       "      <td>-20.601195</td>\n",
       "      <td>13.908883</td>\n",
       "      <td>23.652797</td>\n",
       "      <td>-8.296057</td>\n",
       "      <td>1.827498</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.463118</td>\n",
       "      <td>-7.938895</td>\n",
       "      <td>0.200556</td>\n",
       "      <td>-18.534317</td>\n",
       "      <td>2.574347</td>\n",
       "      <td>-1.276974</td>\n",
       "      <td>1.648998</td>\n",
       "      <td>30.999583</td>\n",
       "      <td>-13.055862</td>\n",
       "      <td>35.384692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151296</th>\n",
       "      <td>1.228701</td>\n",
       "      <td>-18.578279</td>\n",
       "      <td>-37.560922</td>\n",
       "      <td>-15.784561</td>\n",
       "      <td>12.215162</td>\n",
       "      <td>-14.233458</td>\n",
       "      <td>4.846639</td>\n",
       "      <td>20.275633</td>\n",
       "      <td>-4.070288</td>\n",
       "      <td>0.147567</td>\n",
       "      <td>...</td>\n",
       "      <td>52.472711</td>\n",
       "      <td>15.504279</td>\n",
       "      <td>-14.109709</td>\n",
       "      <td>-28.212920</td>\n",
       "      <td>1.228110</td>\n",
       "      <td>-15.410200</td>\n",
       "      <td>-5.333890</td>\n",
       "      <td>-9.065081</td>\n",
       "      <td>10.570079</td>\n",
       "      <td>76.529933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169457</th>\n",
       "      <td>2.106458</td>\n",
       "      <td>-11.215800</td>\n",
       "      <td>-23.580089</td>\n",
       "      <td>-10.521155</td>\n",
       "      <td>7.548376</td>\n",
       "      <td>-7.986332</td>\n",
       "      <td>4.785947</td>\n",
       "      <td>12.446022</td>\n",
       "      <td>-1.974849</td>\n",
       "      <td>-0.534544</td>\n",
       "      <td>...</td>\n",
       "      <td>32.539510</td>\n",
       "      <td>9.221315</td>\n",
       "      <td>-10.253881</td>\n",
       "      <td>-16.947873</td>\n",
       "      <td>-0.761727</td>\n",
       "      <td>-10.612932</td>\n",
       "      <td>-4.594221</td>\n",
       "      <td>-5.467076</td>\n",
       "      <td>6.504856</td>\n",
       "      <td>47.580504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2         V3         V4         V5  \\\n",
       "1632   -2.149874  -5.928529  -5.992759  -9.313315   4.297645 -23.842752   \n",
       "19760  -1.097981  -7.577325 -15.739432  -5.835429   5.549562  -6.058037   \n",
       "23128  -1.023670 -12.544202 -11.260801 -14.956445   3.011656 -31.354875   \n",
       "46841  -0.651898 -12.722374 -26.205541  -9.986573   7.148938 -10.286411   \n",
       "54018  -0.533245 -11.678248 -23.804725  -9.120236   7.023398  -9.490999   \n",
       "57209  -0.477403  -7.223709 -15.189174  -5.674331   4.941382  -6.230242   \n",
       "58465  -0.456059 -19.795788 -39.348837 -15.282076  12.098676 -15.311437   \n",
       "74699  -0.193454  -9.067843 -10.217005  -9.410070   4.692932 -20.601195   \n",
       "151296  1.228701 -18.578279 -37.560922 -15.784561  12.215162 -14.233458   \n",
       "169457  2.106458 -11.215800 -23.580089 -10.521155   7.548376  -7.986332   \n",
       "\n",
       "               V6         V7        V8        V9    ...            V20  \\\n",
       "1632    16.473136  28.451344 -6.152537 -1.687605    ...     -16.229190   \n",
       "19760    3.039262   8.057352 -1.250159 -0.216972    ...      21.746289   \n",
       "23128   17.350446  30.415816 -3.987391  1.411755    ...     -18.910114   \n",
       "46841    4.251820  13.066720 -2.343119 -1.388195    ...      36.105492   \n",
       "54018    3.241206  12.300827 -2.321940 -0.595521    ...      33.207435   \n",
       "57209    1.773198   7.984501 -1.660704 -0.221403    ...      21.339135   \n",
       "58465    5.895757  20.717392 -3.879305 -2.348535    ...      54.268855   \n",
       "74699   13.908883  23.652797 -8.296057  1.827498    ...     -27.463118   \n",
       "151296   4.846639  20.275633 -4.070288  0.147567    ...      52.472711   \n",
       "169457   4.785947  12.446022 -1.974849 -0.534544    ...      32.539510   \n",
       "\n",
       "              V21        V22        V23       V24        V25       V26  \\\n",
       "1632    -6.294976   2.172644  -4.967286  1.393803   1.404903  1.607571   \n",
       "19760    6.352248  -5.969954 -11.714075  0.164546  -5.870206 -2.547977   \n",
       "23128   -7.885966  -0.083938 -10.374014  3.199921   1.240399  0.890981   \n",
       "46841   10.689326  -9.346304 -19.311701  0.659988  -9.966603 -3.239935   \n",
       "54018   10.038380  -8.295427 -18.005822  1.075974  -9.290206 -1.004892   \n",
       "57209    6.395042  -5.125423 -11.579791  1.428292  -5.426499 -0.523143   \n",
       "58465   15.440724 -16.258186 -29.342891  1.956887 -15.290886 -5.190777   \n",
       "74699   -7.938895   0.200556 -18.534317  2.574347  -1.276974  1.648998   \n",
       "151296  15.504279 -14.109709 -28.212920  1.228110 -15.410200 -5.333890   \n",
       "169457   9.221315 -10.253881 -16.947873 -0.761727 -10.612932 -4.594221   \n",
       "\n",
       "              V27        V28     Amount  \n",
       "1632     9.822532  13.521861  31.002408  \n",
       "19760   -3.544438   4.513016  31.681363  \n",
       "23128   28.405732 -31.304400  29.850637  \n",
       "46841   -6.019853   7.325410  52.138676  \n",
       "54018   -5.766067   6.768414  48.020631  \n",
       "57209   -3.650539   4.398674  30.692876  \n",
       "58465   -9.196517  11.218994  79.565204  \n",
       "74699   30.999583 -13.055862  35.384692  \n",
       "151296  -9.065081  10.570079  76.529933  \n",
       "169457  -5.467076   6.504856  47.580504  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_df[Xtr_df['Amount']>28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>1264.0</td>\n",
       "      <td>-11.140706</td>\n",
       "      <td>-9.612726</td>\n",
       "      <td>-12.389545</td>\n",
       "      <td>6.013346</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>-7.520784</td>\n",
       "      <td>-1.925732</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.709977</td>\n",
       "      <td>1.366110</td>\n",
       "      <td>-2.925888</td>\n",
       "      <td>0.843551</td>\n",
       "      <td>0.746267</td>\n",
       "      <td>0.801387</td>\n",
       "      <td>3.852046</td>\n",
       "      <td>4.157934</td>\n",
       "      <td>7712.43</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19760</th>\n",
       "      <td>30537.0</td>\n",
       "      <td>-14.191832</td>\n",
       "      <td>-25.313252</td>\n",
       "      <td>-7.578781</td>\n",
       "      <td>7.730844</td>\n",
       "      <td>-8.285413</td>\n",
       "      <td>3.994474</td>\n",
       "      <td>9.656752</td>\n",
       "      <td>-1.502509</td>\n",
       "      <td>-0.231141</td>\n",
       "      <td>...</td>\n",
       "      <td>4.696025</td>\n",
       "      <td>-4.067605</td>\n",
       "      <td>-6.869451</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>-2.640366</td>\n",
       "      <td>-1.237598</td>\n",
       "      <td>-1.387145</td>\n",
       "      <td>1.389367</td>\n",
       "      <td>7879.42</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46841</th>\n",
       "      <td>42951.0</td>\n",
       "      <td>-23.712839</td>\n",
       "      <td>-42.172688</td>\n",
       "      <td>-13.320825</td>\n",
       "      <td>9.925019</td>\n",
       "      <td>-13.945538</td>\n",
       "      <td>5.564891</td>\n",
       "      <td>15.710644</td>\n",
       "      <td>-2.844253</td>\n",
       "      <td>-1.580725</td>\n",
       "      <td>...</td>\n",
       "      <td>7.921600</td>\n",
       "      <td>-6.320710</td>\n",
       "      <td>-11.310338</td>\n",
       "      <td>0.404175</td>\n",
       "      <td>-4.547278</td>\n",
       "      <td>-1.577118</td>\n",
       "      <td>-2.357385</td>\n",
       "      <td>2.253662</td>\n",
       "      <td>12910.93</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54018</th>\n",
       "      <td>46253.0</td>\n",
       "      <td>-21.780665</td>\n",
       "      <td>-38.305310</td>\n",
       "      <td>-12.122469</td>\n",
       "      <td>9.752791</td>\n",
       "      <td>-12.880794</td>\n",
       "      <td>4.256017</td>\n",
       "      <td>14.785051</td>\n",
       "      <td>-2.818253</td>\n",
       "      <td>-0.667338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.437478</td>\n",
       "      <td>-5.619439</td>\n",
       "      <td>-10.547038</td>\n",
       "      <td>0.653249</td>\n",
       "      <td>-4.232409</td>\n",
       "      <td>-0.480459</td>\n",
       "      <td>-2.257913</td>\n",
       "      <td>2.082488</td>\n",
       "      <td>11898.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57209</th>\n",
       "      <td>47807.0</td>\n",
       "      <td>-13.537461</td>\n",
       "      <td>-24.426864</td>\n",
       "      <td>-7.355943</td>\n",
       "      <td>6.896486</td>\n",
       "      <td>-8.515928</td>\n",
       "      <td>2.354758</td>\n",
       "      <td>9.568711</td>\n",
       "      <td>-2.006504</td>\n",
       "      <td>-0.236247</td>\n",
       "      <td>...</td>\n",
       "      <td>4.727852</td>\n",
       "      <td>-3.504033</td>\n",
       "      <td>-6.790961</td>\n",
       "      <td>0.864201</td>\n",
       "      <td>-2.433816</td>\n",
       "      <td>-0.244081</td>\n",
       "      <td>-1.428731</td>\n",
       "      <td>1.354228</td>\n",
       "      <td>7636.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58465</th>\n",
       "      <td>48401.0</td>\n",
       "      <td>-36.802320</td>\n",
       "      <td>-63.344698</td>\n",
       "      <td>-20.645794</td>\n",
       "      <td>16.715537</td>\n",
       "      <td>-20.672064</td>\n",
       "      <td>7.694002</td>\n",
       "      <td>24.956587</td>\n",
       "      <td>-4.730111</td>\n",
       "      <td>-2.687312</td>\n",
       "      <td>...</td>\n",
       "      <td>11.455313</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-17.173665</td>\n",
       "      <td>1.180700</td>\n",
       "      <td>-7.025783</td>\n",
       "      <td>-2.534330</td>\n",
       "      <td>-3.602479</td>\n",
       "      <td>3.450224</td>\n",
       "      <td>19656.53</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74699</th>\n",
       "      <td>55709.0</td>\n",
       "      <td>-16.950064</td>\n",
       "      <td>-16.417395</td>\n",
       "      <td>-12.523381</td>\n",
       "      <td>6.555638</td>\n",
       "      <td>-27.752964</td>\n",
       "      <td>18.072031</td>\n",
       "      <td>28.504065</td>\n",
       "      <td>-10.152220</td>\n",
       "      <td>2.124673</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.932594</td>\n",
       "      <td>0.050097</td>\n",
       "      <td>-10.855949</td>\n",
       "      <td>1.550407</td>\n",
       "      <td>-0.502172</td>\n",
       "      <td>0.821714</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>-4.009839</td>\n",
       "      <td>8790.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151296</th>\n",
       "      <td>95286.0</td>\n",
       "      <td>-34.549296</td>\n",
       "      <td>-60.464618</td>\n",
       "      <td>-21.340854</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>-19.229075</td>\n",
       "      <td>6.335259</td>\n",
       "      <td>24.422716</td>\n",
       "      <td>-4.964566</td>\n",
       "      <td>0.188912</td>\n",
       "      <td>...</td>\n",
       "      <td>11.502580</td>\n",
       "      <td>-9.499423</td>\n",
       "      <td>-16.513186</td>\n",
       "      <td>0.744341</td>\n",
       "      <td>-7.081325</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-3.550963</td>\n",
       "      <td>3.250802</td>\n",
       "      <td>18910.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169457</th>\n",
       "      <td>119713.0</td>\n",
       "      <td>-20.924897</td>\n",
       "      <td>-37.943452</td>\n",
       "      <td>-14.060281</td>\n",
       "      <td>10.473005</td>\n",
       "      <td>-10.866639</td>\n",
       "      <td>6.256654</td>\n",
       "      <td>14.960521</td>\n",
       "      <td>-2.392155</td>\n",
       "      <td>-0.597076</td>\n",
       "      <td>...</td>\n",
       "      <td>6.829810</td>\n",
       "      <td>-6.926353</td>\n",
       "      <td>-9.928657</td>\n",
       "      <td>-0.447084</td>\n",
       "      <td>-4.848151</td>\n",
       "      <td>-2.241620</td>\n",
       "      <td>-2.140723</td>\n",
       "      <td>2.001492</td>\n",
       "      <td>11789.84</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2         V3         V4         V5  \\\n",
       "1632      1264.0 -11.140706  -9.612726 -12.389545   6.013346 -32.092129   \n",
       "19760    30537.0 -14.191832 -25.313252  -7.578781   7.730844  -8.285413   \n",
       "46841    42951.0 -23.712839 -42.172688 -13.320825   9.925019 -13.945538   \n",
       "54018    46253.0 -21.780665 -38.305310 -12.122469   9.752791 -12.880794   \n",
       "57209    47807.0 -13.537461 -24.426864  -7.355943   6.896486  -8.515928   \n",
       "58465    48401.0 -36.802320 -63.344698 -20.645794  16.715537 -20.672064   \n",
       "74699    55709.0 -16.950064 -16.417395 -12.523381   6.555638 -27.752964   \n",
       "151296   95286.0 -34.549296 -60.464618 -21.340854  16.875344 -19.229075   \n",
       "169457  119713.0 -20.924897 -37.943452 -14.060281  10.473005 -10.866639   \n",
       "\n",
       "               V6         V7         V8        V9  ...          V21  \\\n",
       "1632    21.393069  34.303177  -7.520784 -1.925732  ...    -4.709977   \n",
       "19760    3.994474   9.656752  -1.502509 -0.231141  ...     4.696025   \n",
       "46841    5.564891  15.710644  -2.844253 -1.580725  ...     7.921600   \n",
       "54018    4.256017  14.785051  -2.818253 -0.667338  ...     7.437478   \n",
       "57209    2.354758   9.568711  -2.006504 -0.236247  ...     4.727852   \n",
       "58465    7.694002  24.956587  -4.730111 -2.687312  ...    11.455313   \n",
       "74699   18.072031  28.504065 -10.152220  2.124673  ...    -5.932594   \n",
       "151296   6.335259  24.422716  -4.964566  0.188912  ...    11.502580   \n",
       "169457   6.256654  14.960521  -2.392155 -0.597076  ...     6.829810   \n",
       "\n",
       "              V22        V23       V24       V25       V26        V27  \\\n",
       "1632     1.366110  -2.925888  0.843551  0.746267  0.801387   3.852046   \n",
       "19760   -4.067605  -6.869451  0.107527 -2.640366 -1.237598  -1.387145   \n",
       "46841   -6.320710 -11.310338  0.404175 -4.547278 -1.577118  -2.357385   \n",
       "54018   -5.619439 -10.547038  0.653249 -4.232409 -0.480459  -2.257913   \n",
       "57209   -3.504033  -6.790961  0.864201 -2.433816 -0.244081  -1.428731   \n",
       "58465  -10.933144 -17.173665  1.180700 -7.025783 -2.534330  -3.602479   \n",
       "74699    0.050097 -10.855949  1.550407 -0.502172  0.821714  12.152401   \n",
       "151296  -9.499423 -16.513186  0.744341 -7.081325 -2.604551  -3.550963   \n",
       "169457  -6.926353  -9.928657 -0.447084 -4.848151 -2.241620  -2.140723   \n",
       "\n",
       "             V28    Amount  Class  \n",
       "1632    4.157934   7712.43    0.0  \n",
       "19760   1.389367   7879.42    0.0  \n",
       "46841   2.253662  12910.93    0.0  \n",
       "54018   2.082488  11898.09    0.0  \n",
       "57209   1.354228   7636.30    0.0  \n",
       "58465   3.450224  19656.53    0.0  \n",
       "74699  -4.009839   8790.26    0.0  \n",
       "151296  3.250802  18910.00    0.0  \n",
       "169457  2.001492  11789.84    0.0  \n",
       "\n",
       "[9 rows x 31 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset[Dataset['Amount']>7500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAAFYCAYAAAAx7qftAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f125da150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=Dataset['Amount'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "      <td>170886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61092.608212</td>\n",
       "      <td>-0.169856</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>0.493038</td>\n",
       "      <td>0.117430</td>\n",
       "      <td>-0.176091</td>\n",
       "      <td>0.058238</td>\n",
       "      <td>-0.080670</td>\n",
       "      <td>0.032215</td>\n",
       "      <td>0.018873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030943</td>\n",
       "      <td>-0.028273</td>\n",
       "      <td>-0.083738</td>\n",
       "      <td>-0.022461</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.092271</td>\n",
       "      <td>0.012607</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>87.336246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27828.974490</td>\n",
       "      <td>1.850523</td>\n",
       "      <td>1.610865</td>\n",
       "      <td>1.383248</td>\n",
       "      <td>1.371899</td>\n",
       "      <td>1.338609</td>\n",
       "      <td>1.295132</td>\n",
       "      <td>1.208518</td>\n",
       "      <td>1.227627</td>\n",
       "      <td>1.152289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725832</td>\n",
       "      <td>0.743723</td>\n",
       "      <td>0.667322</td>\n",
       "      <td>0.584511</td>\n",
       "      <td>0.598757</td>\n",
       "      <td>0.465511</td>\n",
       "      <td>0.490667</td>\n",
       "      <td>0.391952</td>\n",
       "      <td>0.307317</td>\n",
       "      <td>245.952377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-33.680984</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.838548</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-11.710896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41217.000000</td>\n",
       "      <td>-0.986678</td>\n",
       "      <td>-0.539179</td>\n",
       "      <td>-0.064757</td>\n",
       "      <td>-0.743469</td>\n",
       "      <td>-0.828769</td>\n",
       "      <td>-0.691130</td>\n",
       "      <td>-0.586318</td>\n",
       "      <td>-0.162642</td>\n",
       "      <td>-0.660087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183587</td>\n",
       "      <td>-0.230719</td>\n",
       "      <td>-0.546772</td>\n",
       "      <td>-0.170303</td>\n",
       "      <td>-0.332459</td>\n",
       "      <td>-0.195935</td>\n",
       "      <td>-0.330347</td>\n",
       "      <td>-0.065124</td>\n",
       "      <td>-0.027056</td>\n",
       "      <td>5.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60776.000000</td>\n",
       "      <td>-0.183596</td>\n",
       "      <td>0.109687</td>\n",
       "      <td>0.623352</td>\n",
       "      <td>0.124322</td>\n",
       "      <td>-0.226226</td>\n",
       "      <td>-0.202623</td>\n",
       "      <td>-0.031930</td>\n",
       "      <td>0.056663</td>\n",
       "      <td>-0.078965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036163</td>\n",
       "      <td>-0.054461</td>\n",
       "      <td>-0.066777</td>\n",
       "      <td>-0.036215</td>\n",
       "      <td>0.059467</td>\n",
       "      <td>0.135677</td>\n",
       "      <td>-0.058970</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>21.895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78622.750000</td>\n",
       "      <td>1.184444</td>\n",
       "      <td>0.804222</td>\n",
       "      <td>1.297353</td>\n",
       "      <td>0.937619</td>\n",
       "      <td>0.374481</td>\n",
       "      <td>0.449208</td>\n",
       "      <td>0.462624</td>\n",
       "      <td>0.350995</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155774</td>\n",
       "      <td>0.128339</td>\n",
       "      <td>0.363171</td>\n",
       "      <td>0.098701</td>\n",
       "      <td>0.415855</td>\n",
       "      <td>0.399459</td>\n",
       "      <td>0.272940</td>\n",
       "      <td>0.089729</td>\n",
       "      <td>0.078303</td>\n",
       "      <td>76.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120396.000000</td>\n",
       "      <td>2.439207</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>19.002942</td>\n",
       "      <td>4.022866</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>19656.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean    61092.608212      -0.169856       0.040770       0.493038   \n",
       "std     27828.974490       1.850523       1.610865       1.383248   \n",
       "min         0.000000     -56.407510     -72.715728     -33.680984   \n",
       "25%     41217.000000      -0.986678      -0.539179      -0.064757   \n",
       "50%     60776.000000      -0.183596       0.109687       0.623352   \n",
       "75%     78622.750000       1.184444       0.804222       1.297353   \n",
       "max    120396.000000       2.439207      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean        0.117430      -0.176091       0.058238      -0.080670   \n",
       "std         1.371899       1.338609       1.295132       1.208518   \n",
       "min        -5.519697     -42.147898     -26.160506     -43.557242   \n",
       "25%        -0.743469      -0.828769      -0.691130      -0.586318   \n",
       "50%         0.124322      -0.226226      -0.202623      -0.031930   \n",
       "75%         0.937619       0.374481       0.449208       0.462624   \n",
       "max        16.875344      34.801666      22.529298      36.677268   \n",
       "\n",
       "                  V8             V9      ...                  V20  \\\n",
       "count  170886.000000  170886.000000      ...        170886.000000   \n",
       "mean        0.032215       0.018873      ...             0.030943   \n",
       "std         1.227627       1.152289      ...             0.725832   \n",
       "min       -73.216718     -13.434066      ...           -22.838548   \n",
       "25%        -0.162642      -0.660087      ...            -0.183587   \n",
       "50%         0.056663      -0.078965      ...            -0.036163   \n",
       "75%         0.350995       0.641342      ...             0.155774   \n",
       "max        20.007208      15.594995      ...            39.420904   \n",
       "\n",
       "                 V21            V22            V23            V24  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean       -0.028273      -0.083738      -0.022461       0.009004   \n",
       "std         0.743723       0.667322       0.584511       0.598757   \n",
       "min       -34.830382     -10.933144     -44.807735      -2.836627   \n",
       "25%        -0.230719      -0.546772      -0.170303      -0.332459   \n",
       "50%        -0.054461      -0.066777      -0.036215       0.059467   \n",
       "75%         0.128339       0.363171       0.098701       0.415855   \n",
       "max        27.202839      10.503090      19.002942       4.022866   \n",
       "\n",
       "                 V25            V26            V27            V28  \\\n",
       "count  170886.000000  170886.000000  170886.000000  170886.000000   \n",
       "mean        0.092271       0.012607       0.002100       0.002443   \n",
       "std         0.465511       0.490667       0.391952       0.307317   \n",
       "min       -10.295397      -2.604551     -22.565679     -11.710896   \n",
       "25%        -0.195935      -0.330347      -0.065124      -0.027056   \n",
       "50%         0.135677      -0.058970       0.008693       0.021151   \n",
       "75%         0.399459       0.272940       0.089729       0.078303   \n",
       "max         7.519589       3.517346      12.152401      33.847808   \n",
       "\n",
       "              Amount  \n",
       "count  170886.000000  \n",
       "mean       87.336246  \n",
       "std       245.952377  \n",
       "min         0.000000  \n",
       "25%         5.480000  \n",
       "50%        21.895000  \n",
       "75%        76.720000  \n",
       "max     19656.530000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first let test model using Scalar taransfomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "      <td>1.708860e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.257784e-17</td>\n",
       "      <td>2.128892e-17</td>\n",
       "      <td>7.983346e-18</td>\n",
       "      <td>-6.386677e-17</td>\n",
       "      <td>-2.128892e-17</td>\n",
       "      <td>3.991673e-17</td>\n",
       "      <td>5.322231e-18</td>\n",
       "      <td>2.661115e-18</td>\n",
       "      <td>-1.064446e-17</td>\n",
       "      <td>4.224521e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>8.648625e-18</td>\n",
       "      <td>-3.991673e-18</td>\n",
       "      <td>1.064446e-17</td>\n",
       "      <td>4.656952e-18</td>\n",
       "      <td>1.896045e-17</td>\n",
       "      <td>-7.983346e-17</td>\n",
       "      <td>-4.656952e-18</td>\n",
       "      <td>-2.827435e-18</td>\n",
       "      <td>3.492714e-18</td>\n",
       "      <td>8.781681e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "      <td>1.000003e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.195294e+00</td>\n",
       "      <td>-3.039022e+01</td>\n",
       "      <td>-4.516624e+01</td>\n",
       "      <td>-2.470572e+01</td>\n",
       "      <td>-4.109010e+00</td>\n",
       "      <td>-3.135488e+01</td>\n",
       "      <td>-2.024412e+01</td>\n",
       "      <td>-3.597523e+01</td>\n",
       "      <td>-5.966726e+01</td>\n",
       "      <td>-1.167500e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.150806e+01</td>\n",
       "      <td>-4.679459e+01</td>\n",
       "      <td>-1.625819e+01</td>\n",
       "      <td>-7.662024e+01</td>\n",
       "      <td>-4.752581e+00</td>\n",
       "      <td>-2.231462e+01</td>\n",
       "      <td>-5.333890e+00</td>\n",
       "      <td>-5.757814e+01</td>\n",
       "      <td>-3.811490e+01</td>\n",
       "      <td>-3.550952e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.142076e-01</td>\n",
       "      <td>-4.414013e-01</td>\n",
       "      <td>-3.600244e-01</td>\n",
       "      <td>-4.032511e-01</td>\n",
       "      <td>-6.275258e-01</td>\n",
       "      <td>-4.875802e-01</td>\n",
       "      <td>-5.786049e-01</td>\n",
       "      <td>-4.184043e-01</td>\n",
       "      <td>-1.587277e-01</td>\n",
       "      <td>-5.892283e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.955650e-01</td>\n",
       "      <td>-2.722068e-01</td>\n",
       "      <td>-6.938723e-01</td>\n",
       "      <td>-2.529335e-01</td>\n",
       "      <td>-5.702895e-01</td>\n",
       "      <td>-6.191203e-01</td>\n",
       "      <td>-6.989555e-01</td>\n",
       "      <td>-1.715110e-01</td>\n",
       "      <td>-9.598774e-02</td>\n",
       "      <td>-3.328144e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.137696e-02</td>\n",
       "      <td>-7.424534e-03</td>\n",
       "      <td>4.278288e-02</td>\n",
       "      <td>9.420951e-02</td>\n",
       "      <td>5.023245e-03</td>\n",
       "      <td>-3.745296e-02</td>\n",
       "      <td>-2.014165e-01</td>\n",
       "      <td>4.033029e-02</td>\n",
       "      <td>1.991464e-02</td>\n",
       "      <td>-8.490739e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.245452e-02</td>\n",
       "      <td>-3.521212e-02</td>\n",
       "      <td>2.541608e-02</td>\n",
       "      <td>-2.353039e-02</td>\n",
       "      <td>8.427964e-02</td>\n",
       "      <td>9.324221e-02</td>\n",
       "      <td>-1.458772e-01</td>\n",
       "      <td>1.682197e-02</td>\n",
       "      <td>6.087712e-02</td>\n",
       "      <td>-2.660736e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.299259e-01</td>\n",
       "      <td>7.318495e-01</td>\n",
       "      <td>4.739408e-01</td>\n",
       "      <td>5.814707e-01</td>\n",
       "      <td>5.978507e-01</td>\n",
       "      <td>4.113029e-01</td>\n",
       "      <td>3.018779e-01</td>\n",
       "      <td>4.495559e-01</td>\n",
       "      <td>2.596717e-01</td>\n",
       "      <td>5.402038e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.719836e-01</td>\n",
       "      <td>2.105796e-01</td>\n",
       "      <td>6.697075e-01</td>\n",
       "      <td>2.072875e-01</td>\n",
       "      <td>6.794951e-01</td>\n",
       "      <td>6.598947e-01</td>\n",
       "      <td>5.305713e-01</td>\n",
       "      <td>2.235738e-01</td>\n",
       "      <td>2.468473e-01</td>\n",
       "      <td>-4.316395e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.131001e+00</td>\n",
       "      <td>1.409910e+00</td>\n",
       "      <td>1.366783e+01</td>\n",
       "      <td>6.426577e+00</td>\n",
       "      <td>1.221516e+01</td>\n",
       "      <td>2.613000e+01</td>\n",
       "      <td>1.735045e+01</td>\n",
       "      <td>3.041582e+01</td>\n",
       "      <td>1.627127e+01</td>\n",
       "      <td>1.351758e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.426886e+01</td>\n",
       "      <td>3.661470e+01</td>\n",
       "      <td>1.586470e+01</td>\n",
       "      <td>3.254934e+01</td>\n",
       "      <td>6.703680e+00</td>\n",
       "      <td>1.595524e+01</td>\n",
       "      <td>7.142823e+00</td>\n",
       "      <td>3.099958e+01</td>\n",
       "      <td>1.101320e+02</td>\n",
       "      <td>7.956520e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean  -4.257784e-17  2.128892e-17  7.983346e-18 -6.386677e-17 -2.128892e-17   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -2.195294e+00 -3.039022e+01 -4.516624e+01 -2.470572e+01 -4.109010e+00   \n",
       "25%   -7.142076e-01 -4.414013e-01 -3.600244e-01 -4.032511e-01 -6.275258e-01   \n",
       "50%   -1.137696e-02 -7.424534e-03  4.278288e-02  9.420951e-02  5.023245e-03   \n",
       "75%    6.299259e-01  7.318495e-01  4.739408e-01  5.814707e-01  5.978507e-01   \n",
       "max    2.131001e+00  1.409910e+00  1.366783e+01  6.426577e+00  1.221516e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean   3.991673e-17  5.322231e-18  2.661115e-18 -1.064446e-17  4.224521e-17   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -3.135488e+01 -2.024412e+01 -3.597523e+01 -5.966726e+01 -1.167500e+01   \n",
       "25%   -4.875802e-01 -5.786049e-01 -4.184043e-01 -1.587277e-01 -5.892283e-01   \n",
       "50%   -3.745296e-02 -2.014165e-01  4.033029e-02  1.991464e-02 -8.490739e-02   \n",
       "75%    4.113029e-01  3.018779e-01  4.495559e-01  2.596717e-01  5.402038e-01   \n",
       "max    2.613000e+01  1.735045e+01  3.041582e+01  1.627127e+01  1.351758e+01   \n",
       "\n",
       "           ...                V20           V21           V22           V23  \\\n",
       "count      ...       1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean       ...       8.648625e-18 -3.991673e-18  1.064446e-17  4.656952e-18   \n",
       "std        ...       1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min        ...      -3.150806e+01 -4.679459e+01 -1.625819e+01 -7.662024e+01   \n",
       "25%        ...      -2.955650e-01 -2.722068e-01 -6.938723e-01 -2.529335e-01   \n",
       "50%        ...      -9.245452e-02 -3.521212e-02  2.541608e-02 -2.353039e-02   \n",
       "75%        ...       1.719836e-01  2.105796e-01  6.697075e-01  2.072875e-01   \n",
       "max        ...       5.426886e+01  3.661470e+01  1.586470e+01  3.254934e+01   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05  1.708860e+05   \n",
       "mean   1.896045e-17 -7.983346e-17 -4.656952e-18 -2.827435e-18  3.492714e-18   \n",
       "std    1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00  1.000003e+00   \n",
       "min   -4.752581e+00 -2.231462e+01 -5.333890e+00 -5.757814e+01 -3.811490e+01   \n",
       "25%   -5.702895e-01 -6.191203e-01 -6.989555e-01 -1.715110e-01 -9.598774e-02   \n",
       "50%    8.427964e-02  9.324221e-02 -1.458772e-01  1.682197e-02  6.087712e-02   \n",
       "75%    6.794951e-01  6.598947e-01  5.305713e-01  2.235738e-01  2.468473e-01   \n",
       "max    6.703680e+00  1.595524e+01  7.142823e+00  3.099958e+01  1.101320e+02   \n",
       "\n",
       "             Amount  \n",
       "count  1.708860e+05  \n",
       "mean   8.781681e-17  \n",
       "std    1.000003e+00  \n",
       "min   -3.550952e-01  \n",
       "25%   -3.328144e-01  \n",
       "50%   -2.660736e-01  \n",
       "75%   -4.316395e-02  \n",
       "max    7.956520e+01  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let supposed that we are done with all steps of data-preparatoion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=Xtr_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170886,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170886, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "firt start with logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let try to use first logistic regression to predict our class we will use the build in class in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our Dataset is very large we will use logisic regression with a sag solver \n",
    "sag means : Stochastics gradient descent you can find more on this doc from sklearn\n",
    "our model will predict using 5000 iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logReg=LogisticRegression(solver=\"sag\",max_iter=5000,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=5000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for time measuremen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 679 epochs took 82 seconds\n",
      "--- 81.2945590019 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "logReg.fit(X,Y)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let try to look how was our first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_data = Xtr_df.iloc[:5]\n",
    "some_labels = Y.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predictions:\\t', array([ 0.,  0.,  0.,  0.,  0.]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions:\\t\", logReg.predict(some_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Labels:\\t\\t', [0.0, 0.0, 0.0, 0.0, 0.0])\n"
     ]
    }
   ],
   "source": [
    "print(\"Labels:\\t\\t\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let check for the RMSE error on our dataset using our predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032724445982166263"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "xPredic= logReg.predict(X)\n",
    "logRegMSE = mean_squared_error(Y, xPredic)\n",
    "logReg_rmse = np.sqrt(logRegMSE)\n",
    "logReg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have found a RMSE of 0.032724445982166263 with our model is it bad or not bad??? we will know with other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class must be a probability so let check again for them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xPredictProba=logReg.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170886, 2)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xPredictProba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.99368538e-01,   6.31462029e-04],\n",
       "       [  9.99823083e-01,   1.76917152e-04]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xPredictProba[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xPredic[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The\n",
    "general idea is to count the number of times instances of class A are classified as class B. For\n",
    "example, to know the number of times the classifier confused images of 5s with 3s, you would look in\n",
    "the 5 th row and 3 rd column of the confusion matrix.\n",
    "To compute the confusion matrix, you first need to have a set of predictions, so they can be compared\n",
    "to the actual targets. You could make predictions on the test set, but let’s keep it untouched for now\n",
    "(remember that you want to use the test set only at the very end of your project, once you have a\n",
    "classifier that you are ready to launch). Instead, you can use the cross_val_predict() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 909 epochs took 77 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1313 epochs took 110 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1353 epochs took 116 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = cross_val_predict(logReg, X, Y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170466,     60],\n",
       "       [   150,    210]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69    0.0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50    0.0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test=test.drop('Class',axis=1)\n",
    "Y_test=test['Class']\n",
    "Xte_s = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFYCAYAAADeLMzTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6f1156cad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(x=X_test['V1'])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let use our predictions on the  test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='sag', tol=0.0001,\n",
       "          verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logReg.set_params(max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['warm_start',\n",
       " 'C',\n",
       " 'n_jobs',\n",
       " 'verbose',\n",
       " 'intercept_scaling',\n",
       " 'fit_intercept',\n",
       " 'max_iter',\n",
       " 'penalty',\n",
       " 'multi_class',\n",
       " 'random_state',\n",
       " 'dual',\n",
       " 'tol',\n",
       " 'solver',\n",
       " 'class_weight']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9982 epochs took 843 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 14.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 3749 epochs took 304 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 9709 epochs took 770 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 12.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 12.8min finished\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = cross_val_predict(logReg, X_test, Y_test, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170515,     11],\n",
       "       [   359,      1]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50135663574274114"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(Y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### logistic regression ROC 50.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very very bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSubmittion=pd.read_csv('sample_submision.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>167</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  Class\n",
       "0  100    0.0\n",
       "1  150    0.0\n",
       "2  151    0.0\n",
       "3  167    0.0\n",
       "4  168    0.0"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSubmittion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=170886, step=1)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xPredictProbaTes=logReg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.26347821e-11,   1.00000000e+00],\n",
       "       [  9.99415637e-01,   5.84363134e-04],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       ..., \n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xPredictProbaTes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logReg=LogisticRegression(solver=\"sag\",max_iter=5000,verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_clf=SGDClassifier(loss='log',n_jobs=-1,learning_rate='optimal',n_iter=5000,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 17.55, NNZs: 30, Bias: -174.382511, T: 170886, Avg. loss: 0.152301\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.94, NNZs: 30, Bias: -169.569351, T: 341772, Avg. loss: 0.123892\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.67, NNZs: 30, Bias: -166.758414, T: 512658, Avg. loss: 0.112987\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.47, NNZs: 30, Bias: -164.803703, T: 683544, Avg. loss: 0.106992\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.22, NNZs: 30, Bias: -163.272972, T: 854430, Avg. loss: 0.102832\n",
      "Total training time: 0.43 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17.16, NNZs: 30, Bias: -162.011905, T: 1025316, Avg. loss: 0.099987\n",
      "Total training time: 0.52 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16.81, NNZs: 30, Bias: -160.980117, T: 1196202, Avg. loss: 0.097840\n",
      "Total training time: 0.61 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 16.37, NNZs: 30, Bias: -160.101745, T: 1367088, Avg. loss: 0.095986\n",
      "Total training time: 0.70 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 16.80, NNZs: 30, Bias: -159.243765, T: 1537974, Avg. loss: 0.094643\n",
      "Total training time: 0.80 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 16.46, NNZs: 30, Bias: -158.552502, T: 1708860, Avg. loss: 0.093469\n",
      "Total training time: 0.88 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 16.47, NNZs: 30, Bias: -157.892241, T: 1879746, Avg. loss: 0.092475\n",
      "Total training time: 0.97 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 16.62, NNZs: 30, Bias: -157.276407, T: 2050632, Avg. loss: 0.091657\n",
      "Total training time: 1.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 16.76, NNZs: 30, Bias: -156.710580, T: 2221518, Avg. loss: 0.090918\n",
      "Total training time: 1.14 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 16.54, NNZs: 30, Bias: -156.221405, T: 2392404, Avg. loss: 0.090243\n",
      "Total training time: 1.23 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 16.38, NNZs: 30, Bias: -155.762151, T: 2563290, Avg. loss: 0.089635\n",
      "Total training time: 1.32 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 16.36, NNZs: 30, Bias: -155.319539, T: 2734176, Avg. loss: 0.089093\n",
      "Total training time: 1.41 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 16.46, NNZs: 30, Bias: -154.891163, T: 2905062, Avg. loss: 0.088602\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 16.47, NNZs: 30, Bias: -154.496614, T: 3075948, Avg. loss: 0.088143\n",
      "Total training time: 1.58 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 16.35, NNZs: 30, Bias: -154.136114, T: 3246834, Avg. loss: 0.087711\n",
      "Total training time: 1.66 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 16.38, NNZs: 30, Bias: -153.780703, T: 3417720, Avg. loss: 0.087325\n",
      "Total training time: 1.75 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 16.50, NNZs: 30, Bias: -153.432944, T: 3588606, Avg. loss: 0.086954\n",
      "Total training time: 1.84 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 16.34, NNZs: 30, Bias: -153.129759, T: 3759492, Avg. loss: 0.086611\n",
      "Total training time: 1.93 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 16.42, NNZs: 30, Bias: -152.815671, T: 3930378, Avg. loss: 0.086287\n",
      "Total training time: 2.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 16.30, NNZs: 30, Bias: -152.535565, T: 4101264, Avg. loss: 0.085986\n",
      "Total training time: 2.10 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 16.18, NNZs: 30, Bias: -152.266579, T: 4272150, Avg. loss: 0.085691\n",
      "Total training time: 2.18 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 16.22, NNZs: 30, Bias: -151.993620, T: 4443036, Avg. loss: 0.085427\n",
      "Total training time: 2.27 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 16.20, NNZs: 30, Bias: -151.736177, T: 4613922, Avg. loss: 0.085173\n",
      "Total training time: 2.37 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 16.17, NNZs: 30, Bias: -151.489452, T: 4784808, Avg. loss: 0.084933\n",
      "Total training time: 2.45 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 16.12, NNZs: 30, Bias: -151.253153, T: 4955694, Avg. loss: 0.084699\n",
      "Total training time: 2.54 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 16.11, NNZs: 30, Bias: -151.021830, T: 5126580, Avg. loss: 0.084479\n",
      "Total training time: 2.62 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 16.12, NNZs: 30, Bias: -150.795648, T: 5297466, Avg. loss: 0.084268\n",
      "Total training time: 2.71 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 16.11, NNZs: 30, Bias: -150.579531, T: 5468352, Avg. loss: 0.084068\n",
      "Total training time: 2.79 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 16.08, NNZs: 30, Bias: -150.370576, T: 5639238, Avg. loss: 0.083873\n",
      "Total training time: 2.89 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 16.03, NNZs: 30, Bias: -150.171741, T: 5810124, Avg. loss: 0.083686\n",
      "Total training time: 2.97 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 16.05, NNZs: 30, Bias: -149.971102, T: 5981010, Avg. loss: 0.083511\n",
      "Total training time: 3.05 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 16.03, NNZs: 30, Bias: -149.780492, T: 6151896, Avg. loss: 0.083339\n",
      "Total training time: 3.14 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 16.00, NNZs: 30, Bias: -149.595234, T: 6322782, Avg. loss: 0.083174\n",
      "Total training time: 3.24 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 16.02, NNZs: 30, Bias: -149.410943, T: 6493668, Avg. loss: 0.083015\n",
      "Total training time: 3.32 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 16.02, NNZs: 30, Bias: -149.232787, T: 6664554, Avg. loss: 0.082864\n",
      "Total training time: 3.41 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 15.97, NNZs: 30, Bias: -149.065073, T: 6835440, Avg. loss: 0.082712\n",
      "Total training time: 3.50 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 15.94, NNZs: 30, Bias: -148.898879, T: 7006326, Avg. loss: 0.082566\n",
      "Total training time: 3.58 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 15.96, NNZs: 30, Bias: -148.731768, T: 7177212, Avg. loss: 0.082428\n",
      "Total training time: 3.67 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 15.94, NNZs: 30, Bias: -148.572846, T: 7348098, Avg. loss: 0.082293\n",
      "Total training time: 3.76 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 15.93, NNZs: 30, Bias: -148.416451, T: 7518984, Avg. loss: 0.082163\n",
      "Total training time: 3.87 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 15.92, NNZs: 30, Bias: -148.264107, T: 7689870, Avg. loss: 0.082037\n",
      "Total training time: 3.96 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 15.93, NNZs: 30, Bias: -148.112960, T: 7860756, Avg. loss: 0.081913\n",
      "Total training time: 4.06 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 15.91, NNZs: 30, Bias: -147.968345, T: 8031642, Avg. loss: 0.081794\n",
      "Total training time: 4.15 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 15.86, NNZs: 30, Bias: -147.829047, T: 8202528, Avg. loss: 0.081675\n",
      "Total training time: 4.24 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 15.85, NNZs: 30, Bias: -147.689401, T: 8373414, Avg. loss: 0.081562\n",
      "Total training time: 4.32 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 15.84, NNZs: 30, Bias: -147.552746, T: 8544300, Avg. loss: 0.081451\n",
      "Total training time: 4.41 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 15.85, NNZs: 30, Bias: -147.416506, T: 8715186, Avg. loss: 0.081344\n",
      "Total training time: 4.50 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 15.83, NNZs: 30, Bias: -147.285996, T: 8886072, Avg. loss: 0.081239\n",
      "Total training time: 4.60 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 15.83, NNZs: 30, Bias: -147.156146, T: 9056958, Avg. loss: 0.081136\n",
      "Total training time: 4.70 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 15.79, NNZs: 30, Bias: -147.032738, T: 9227844, Avg. loss: 0.081034\n",
      "Total training time: 4.80 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 15.80, NNZs: 30, Bias: -146.905762, T: 9398730, Avg. loss: 0.080937\n",
      "Total training time: 4.91 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 15.78, NNZs: 30, Bias: -146.784815, T: 9569616, Avg. loss: 0.080840\n",
      "Total training time: 5.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 15.82, NNZs: 30, Bias: -146.660754, T: 9740502, Avg. loss: 0.080748\n",
      "Total training time: 5.12 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 15.79, NNZs: 30, Bias: -146.544655, T: 9911388, Avg. loss: 0.080655\n",
      "Total training time: 5.22 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 15.77, NNZs: 30, Bias: -146.430697, T: 10082274, Avg. loss: 0.080565\n",
      "Total training time: 5.32 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 15.75, NNZs: 30, Bias: -146.317344, T: 10253160, Avg. loss: 0.080478\n",
      "Total training time: 5.42 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 15.74, NNZs: 30, Bias: -146.205865, T: 10424046, Avg. loss: 0.080391\n",
      "Total training time: 5.51 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 15.73, NNZs: 30, Bias: -146.096322, T: 10594932, Avg. loss: 0.080306\n",
      "Total training time: 5.60 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 15.76, NNZs: 30, Bias: -145.984269, T: 10765818, Avg. loss: 0.080223\n",
      "Total training time: 5.68 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 15.75, NNZs: 30, Bias: -145.877870, T: 10936704, Avg. loss: 0.080142\n",
      "Total training time: 5.77 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 15.75, NNZs: 30, Bias: -145.772338, T: 11107590, Avg. loss: 0.080063\n",
      "Total training time: 5.85 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 15.72, NNZs: 30, Bias: -145.670731, T: 11278476, Avg. loss: 0.079984\n",
      "Total training time: 5.94 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 15.69, NNZs: 30, Bias: -145.571906, T: 11449362, Avg. loss: 0.079905\n",
      "Total training time: 6.03 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 15.68, NNZs: 30, Bias: -145.471928, T: 11620248, Avg. loss: 0.079830\n",
      "Total training time: 6.13 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 15.67, NNZs: 30, Bias: -145.373984, T: 11791134, Avg. loss: 0.079756\n",
      "Total training time: 6.22 seconds.\n",
      "-- Epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 15.68, NNZs: 30, Bias: -145.274178, T: 11962020, Avg. loss: 0.079684\n",
      "Total training time: 6.31 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 15.69, NNZs: 30, Bias: -145.176736, T: 12132906, Avg. loss: 0.079613\n",
      "Total training time: 6.39 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 15.67, NNZs: 30, Bias: -145.083809, T: 12303792, Avg. loss: 0.079542\n",
      "Total training time: 6.48 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 15.65, NNZs: 30, Bias: -144.992395, T: 12474678, Avg. loss: 0.079472\n",
      "Total training time: 6.56 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 15.64, NNZs: 30, Bias: -144.900280, T: 12645564, Avg. loss: 0.079405\n",
      "Total training time: 6.65 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 15.62, NNZs: 30, Bias: -144.810955, T: 12816450, Avg. loss: 0.079338\n",
      "Total training time: 6.73 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 15.61, NNZs: 30, Bias: -144.721761, T: 12987336, Avg. loss: 0.079272\n",
      "Total training time: 6.83 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 15.61, NNZs: 30, Bias: -144.633243, T: 13158222, Avg. loss: 0.079208\n",
      "Total training time: 6.93 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 15.59, NNZs: 30, Bias: -144.546811, T: 13329108, Avg. loss: 0.079144\n",
      "Total training time: 7.02 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 15.59, NNZs: 30, Bias: -144.461157, T: 13499994, Avg. loss: 0.079081\n",
      "Total training time: 7.11 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 15.58, NNZs: 30, Bias: -144.376014, T: 13670880, Avg. loss: 0.079020\n",
      "Total training time: 7.19 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 15.58, NNZs: 30, Bias: -144.291919, T: 13841766, Avg. loss: 0.078959\n",
      "Total training time: 7.27 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 15.58, NNZs: 30, Bias: -144.208099, T: 14012652, Avg. loss: 0.078900\n",
      "Total training time: 7.37 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 15.56, NNZs: 30, Bias: -144.127215, T: 14183538, Avg. loss: 0.078840\n",
      "Total training time: 7.46 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 15.57, NNZs: 30, Bias: -144.045403, T: 14354424, Avg. loss: 0.078782\n",
      "Total training time: 7.55 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 15.56, NNZs: 30, Bias: -143.966171, T: 14525310, Avg. loss: 0.078725\n",
      "Total training time: 7.65 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 15.54, NNZs: 30, Bias: -143.888432, T: 14696196, Avg. loss: 0.078668\n",
      "Total training time: 7.74 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 15.55, NNZs: 30, Bias: -143.808476, T: 14867082, Avg. loss: 0.078612\n",
      "Total training time: 7.83 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 15.55, NNZs: 30, Bias: -143.730828, T: 15037968, Avg. loss: 0.078557\n",
      "Total training time: 7.93 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 15.54, NNZs: 30, Bias: -143.654760, T: 15208854, Avg. loss: 0.078504\n",
      "Total training time: 8.02 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 15.53, NNZs: 30, Bias: -143.580133, T: 15379740, Avg. loss: 0.078450\n",
      "Total training time: 8.11 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 15.53, NNZs: 30, Bias: -143.505105, T: 15550626, Avg. loss: 0.078397\n",
      "Total training time: 8.21 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 15.51, NNZs: 30, Bias: -143.432685, T: 15721512, Avg. loss: 0.078345\n",
      "Total training time: 8.30 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 15.52, NNZs: 30, Bias: -143.358574, T: 15892398, Avg. loss: 0.078294\n",
      "Total training time: 8.39 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 15.52, NNZs: 30, Bias: -143.286076, T: 16063284, Avg. loss: 0.078243\n",
      "Total training time: 8.50 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 15.52, NNZs: 30, Bias: -143.213809, T: 16234170, Avg. loss: 0.078193\n",
      "Total training time: 8.59 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 15.51, NNZs: 30, Bias: -143.143453, T: 16405056, Avg. loss: 0.078144\n",
      "Total training time: 8.67 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 15.51, NNZs: 30, Bias: -143.073965, T: 16575942, Avg. loss: 0.078095\n",
      "Total training time: 8.75 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 15.50, NNZs: 30, Bias: -143.005034, T: 16746828, Avg. loss: 0.078047\n",
      "Total training time: 8.83 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 15.49, NNZs: 30, Bias: -142.936669, T: 16917714, Avg. loss: 0.077999\n",
      "Total training time: 8.93 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 15.47, NNZs: 30, Bias: -142.870736, T: 17088600, Avg. loss: 0.077952\n",
      "Total training time: 9.02 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 15.47, NNZs: 30, Bias: -142.803879, T: 17259486, Avg. loss: 0.077905\n",
      "Total training time: 9.11 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 15.47, NNZs: 30, Bias: -142.736822, T: 17430372, Avg. loss: 0.077859\n",
      "Total training time: 9.20 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 15.46, NNZs: 30, Bias: -142.670991, T: 17601258, Avg. loss: 0.077814\n",
      "Total training time: 9.29 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 15.46, NNZs: 30, Bias: -142.605541, T: 17772144, Avg. loss: 0.077769\n",
      "Total training time: 9.38 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 15.45, NNZs: 30, Bias: -142.541525, T: 17943030, Avg. loss: 0.077724\n",
      "Total training time: 9.46 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 15.44, NNZs: 30, Bias: -142.478106, T: 18113916, Avg. loss: 0.077680\n",
      "Total training time: 9.55 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 15.44, NNZs: 30, Bias: -142.414823, T: 18284802, Avg. loss: 0.077637\n",
      "Total training time: 9.63 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 15.44, NNZs: 30, Bias: -142.351933, T: 18455688, Avg. loss: 0.077594\n",
      "Total training time: 9.74 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 15.43, NNZs: 30, Bias: -142.290504, T: 18626574, Avg. loss: 0.077551\n",
      "Total training time: 9.83 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 15.43, NNZs: 30, Bias: -142.228596, T: 18797460, Avg. loss: 0.077509\n",
      "Total training time: 9.92 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 15.42, NNZs: 30, Bias: -142.167549, T: 18968346, Avg. loss: 0.077468\n",
      "Total training time: 10.01 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 15.42, NNZs: 30, Bias: -142.106987, T: 19139232, Avg. loss: 0.077427\n",
      "Total training time: 10.10 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 15.41, NNZs: 30, Bias: -142.047429, T: 19310118, Avg. loss: 0.077386\n",
      "Total training time: 10.19 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 15.41, NNZs: 30, Bias: -141.987794, T: 19481004, Avg. loss: 0.077346\n",
      "Total training time: 10.28 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 15.41, NNZs: 30, Bias: -141.929313, T: 19651890, Avg. loss: 0.077305\n",
      "Total training time: 10.37 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 15.40, NNZs: 30, Bias: -141.871287, T: 19822776, Avg. loss: 0.077266\n",
      "Total training time: 10.47 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 15.39, NNZs: 30, Bias: -141.814121, T: 19993662, Avg. loss: 0.077226\n",
      "Total training time: 10.56 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 15.39, NNZs: 30, Bias: -141.756649, T: 20164548, Avg. loss: 0.077188\n",
      "Total training time: 10.66 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 15.38, NNZs: 30, Bias: -141.700030, T: 20335434, Avg. loss: 0.077149\n",
      "Total training time: 10.76 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 15.38, NNZs: 30, Bias: -141.643217, T: 20506320, Avg. loss: 0.077111\n",
      "Total training time: 10.86 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 15.37, NNZs: 30, Bias: -141.588105, T: 20677206, Avg. loss: 0.077074\n",
      "Total training time: 10.95 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 15.38, NNZs: 30, Bias: -141.531794, T: 20848092, Avg. loss: 0.077036\n",
      "Total training time: 11.04 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 15.36, NNZs: 30, Bias: -141.477634, T: 21018978, Avg. loss: 0.076999\n",
      "Total training time: 11.14 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 15.36, NNZs: 30, Bias: -141.423337, T: 21189864, Avg. loss: 0.076963\n",
      "Total training time: 11.24 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 15.35, NNZs: 30, Bias: -141.369503, T: 21360750, Avg. loss: 0.076927\n",
      "Total training time: 11.35 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 15.35, NNZs: 30, Bias: -141.316271, T: 21531636, Avg. loss: 0.076890\n",
      "Total training time: 11.46 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 15.34, NNZs: 30, Bias: -141.263785, T: 21702522, Avg. loss: 0.076855\n",
      "Total training time: 11.56 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 15.33, NNZs: 30, Bias: -141.210927, T: 21873408, Avg. loss: 0.076819\n",
      "Total training time: 11.66 seconds.\n",
      "-- Epoch 129\n",
      "Norm: 15.33, NNZs: 30, Bias: -141.158268, T: 22044294, Avg. loss: 0.076785\n",
      "Total training time: 11.76 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 15.33, NNZs: 30, Bias: -141.105742, T: 22215180, Avg. loss: 0.076750\n",
      "Total training time: 11.85 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 15.33, NNZs: 30, Bias: -141.054067, T: 22386066, Avg. loss: 0.076716\n",
      "Total training time: 11.94 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 15.33, NNZs: 30, Bias: -141.003110, T: 22556952, Avg. loss: 0.076682\n",
      "Total training time: 12.03 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 15.32, NNZs: 30, Bias: -140.952784, T: 22727838, Avg. loss: 0.076648\n",
      "Total training time: 12.11 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 15.32, NNZs: 30, Bias: -140.902326, T: 22898724, Avg. loss: 0.076614\n",
      "Total training time: 12.19 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 15.31, NNZs: 30, Bias: -140.852354, T: 23069610, Avg. loss: 0.076581\n",
      "Total training time: 12.28 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 15.30, NNZs: 30, Bias: -140.804096, T: 23240496, Avg. loss: 0.076548\n",
      "Total training time: 12.37 seconds.\n",
      "-- Epoch 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 15.30, NNZs: 30, Bias: -140.754015, T: 23411382, Avg. loss: 0.076516\n",
      "Total training time: 12.47 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 15.30, NNZs: 30, Bias: -140.704719, T: 23582268, Avg. loss: 0.076483\n",
      "Total training time: 12.56 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 15.30, NNZs: 30, Bias: -140.656638, T: 23753154, Avg. loss: 0.076451\n",
      "Total training time: 12.66 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 15.29, NNZs: 30, Bias: -140.608836, T: 23924040, Avg. loss: 0.076420\n",
      "Total training time: 12.75 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 15.29, NNZs: 30, Bias: -140.560755, T: 24094926, Avg. loss: 0.076388\n",
      "Total training time: 12.83 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 15.28, NNZs: 30, Bias: -140.513226, T: 24265812, Avg. loss: 0.076357\n",
      "Total training time: 12.92 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 15.28, NNZs: 30, Bias: -140.466458, T: 24436698, Avg. loss: 0.076326\n",
      "Total training time: 13.01 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 15.27, NNZs: 30, Bias: -140.419887, T: 24607584, Avg. loss: 0.076295\n",
      "Total training time: 13.10 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 15.26, NNZs: 30, Bias: -140.373955, T: 24778470, Avg. loss: 0.076264\n",
      "Total training time: 13.19 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 15.27, NNZs: 30, Bias: -140.326971, T: 24949356, Avg. loss: 0.076234\n",
      "Total training time: 13.28 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 15.27, NNZs: 30, Bias: -140.280671, T: 25120242, Avg. loss: 0.076204\n",
      "Total training time: 13.36 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 15.26, NNZs: 30, Bias: -140.235332, T: 25291128, Avg. loss: 0.076174\n",
      "Total training time: 13.44 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 15.26, NNZs: 30, Bias: -140.189971, T: 25462014, Avg. loss: 0.076145\n",
      "Total training time: 13.54 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 15.25, NNZs: 30, Bias: -140.145446, T: 25632900, Avg. loss: 0.076115\n",
      "Total training time: 13.64 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 15.25, NNZs: 30, Bias: -140.100962, T: 25803786, Avg. loss: 0.076086\n",
      "Total training time: 13.74 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 15.24, NNZs: 30, Bias: -140.056893, T: 25974672, Avg. loss: 0.076057\n",
      "Total training time: 13.83 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 15.24, NNZs: 30, Bias: -140.012731, T: 26145558, Avg. loss: 0.076028\n",
      "Total training time: 13.93 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 15.24, NNZs: 30, Bias: -139.969157, T: 26316444, Avg. loss: 0.076000\n",
      "Total training time: 14.03 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 15.24, NNZs: 30, Bias: -139.925404, T: 26487330, Avg. loss: 0.075972\n",
      "Total training time: 14.11 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 15.23, NNZs: 30, Bias: -139.882368, T: 26658216, Avg. loss: 0.075944\n",
      "Total training time: 14.20 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 15.23, NNZs: 30, Bias: -139.839766, T: 26829102, Avg. loss: 0.075916\n",
      "Total training time: 14.30 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 15.22, NNZs: 30, Bias: -139.797367, T: 26999988, Avg. loss: 0.075888\n",
      "Total training time: 14.38 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 15.22, NNZs: 30, Bias: -139.754730, T: 27170874, Avg. loss: 0.075861\n",
      "Total training time: 14.46 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 15.21, NNZs: 30, Bias: -139.713286, T: 27341760, Avg. loss: 0.075833\n",
      "Total training time: 14.54 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 15.21, NNZs: 30, Bias: -139.671412, T: 27512646, Avg. loss: 0.075806\n",
      "Total training time: 14.62 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 15.21, NNZs: 30, Bias: -139.629656, T: 27683532, Avg. loss: 0.075779\n",
      "Total training time: 14.72 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 15.20, NNZs: 30, Bias: -139.588646, T: 27854418, Avg. loss: 0.075752\n",
      "Total training time: 14.82 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 15.20, NNZs: 30, Bias: -139.547269, T: 28025304, Avg. loss: 0.075726\n",
      "Total training time: 14.93 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 15.20, NNZs: 30, Bias: -139.506576, T: 28196190, Avg. loss: 0.075700\n",
      "Total training time: 15.03 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 15.20, NNZs: 30, Bias: -139.465903, T: 28367076, Avg. loss: 0.075674\n",
      "Total training time: 15.13 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 15.19, NNZs: 30, Bias: -139.425843, T: 28537962, Avg. loss: 0.075648\n",
      "Total training time: 15.21 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 15.19, NNZs: 30, Bias: -139.385765, T: 28708848, Avg. loss: 0.075622\n",
      "Total training time: 15.30 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 15.19, NNZs: 30, Bias: -139.346024, T: 28879734, Avg. loss: 0.075596\n",
      "Total training time: 15.38 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 15.18, NNZs: 30, Bias: -139.306545, T: 29050620, Avg. loss: 0.075571\n",
      "Total training time: 15.46 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 15.18, NNZs: 30, Bias: -139.267035, T: 29221506, Avg. loss: 0.075545\n",
      "Total training time: 15.54 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 15.18, NNZs: 30, Bias: -139.227906, T: 29392392, Avg. loss: 0.075520\n",
      "Total training time: 15.63 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 15.18, NNZs: 30, Bias: -139.189246, T: 29563278, Avg. loss: 0.075495\n",
      "Total training time: 15.72 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 15.18, NNZs: 30, Bias: -139.150117, T: 29734164, Avg. loss: 0.075471\n",
      "Total training time: 15.82 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 15.17, NNZs: 30, Bias: -139.111976, T: 29905050, Avg. loss: 0.075446\n",
      "Total training time: 15.90 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 15.17, NNZs: 30, Bias: -139.073871, T: 30075936, Avg. loss: 0.075421\n",
      "Total training time: 15.98 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 15.16, NNZs: 30, Bias: -139.036403, T: 30246822, Avg. loss: 0.075397\n",
      "Total training time: 16.06 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 15.16, NNZs: 30, Bias: -138.998633, T: 30417708, Avg. loss: 0.075373\n",
      "Total training time: 16.15 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 15.15, NNZs: 30, Bias: -138.961038, T: 30588594, Avg. loss: 0.075349\n",
      "Total training time: 16.25 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 15.15, NNZs: 30, Bias: -138.923448, T: 30759480, Avg. loss: 0.075325\n",
      "Total training time: 16.35 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 15.15, NNZs: 30, Bias: -138.886114, T: 30930366, Avg. loss: 0.075301\n",
      "Total training time: 16.46 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 15.15, NNZs: 30, Bias: -138.849607, T: 31101252, Avg. loss: 0.075278\n",
      "Total training time: 16.56 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 15.14, NNZs: 30, Bias: -138.812993, T: 31272138, Avg. loss: 0.075254\n",
      "Total training time: 16.66 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 15.14, NNZs: 30, Bias: -138.776222, T: 31443024, Avg. loss: 0.075231\n",
      "Total training time: 16.75 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 15.14, NNZs: 30, Bias: -138.739622, T: 31613910, Avg. loss: 0.075208\n",
      "Total training time: 16.84 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 15.14, NNZs: 30, Bias: -138.703670, T: 31784796, Avg. loss: 0.075185\n",
      "Total training time: 16.92 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 15.13, NNZs: 30, Bias: -138.668063, T: 31955682, Avg. loss: 0.075162\n",
      "Total training time: 17.00 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 15.13, NNZs: 30, Bias: -138.632567, T: 32126568, Avg. loss: 0.075139\n",
      "Total training time: 17.10 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 15.13, NNZs: 30, Bias: -138.596841, T: 32297454, Avg. loss: 0.075117\n",
      "Total training time: 17.21 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 15.12, NNZs: 30, Bias: -138.561530, T: 32468340, Avg. loss: 0.075094\n",
      "Total training time: 17.32 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 15.12, NNZs: 30, Bias: -138.526447, T: 32639226, Avg. loss: 0.075072\n",
      "Total training time: 17.41 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 15.12, NNZs: 30, Bias: -138.491642, T: 32810112, Avg. loss: 0.075050\n",
      "Total training time: 17.50 seconds.\n",
      "-- Epoch 193\n",
      "Norm: 15.11, NNZs: 30, Bias: -138.456792, T: 32980998, Avg. loss: 0.075028\n",
      "Total training time: 17.58 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 15.11, NNZs: 30, Bias: -138.422070, T: 33151884, Avg. loss: 0.075006\n",
      "Total training time: 17.67 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 15.11, NNZs: 30, Bias: -138.387682, T: 33322770, Avg. loss: 0.074984\n",
      "Total training time: 17.76 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 15.10, NNZs: 30, Bias: -138.353784, T: 33493656, Avg. loss: 0.074962\n",
      "Total training time: 17.86 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 15.10, NNZs: 30, Bias: -138.319497, T: 33664542, Avg. loss: 0.074941\n",
      "Total training time: 17.95 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 15.10, NNZs: 30, Bias: -138.285581, T: 33835428, Avg. loss: 0.074919\n",
      "Total training time: 18.04 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 15.10, NNZs: 30, Bias: -138.251964, T: 34006314, Avg. loss: 0.074898\n",
      "Total training time: 18.12 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 15.09, NNZs: 30, Bias: -138.218467, T: 34177200, Avg. loss: 0.074877\n",
      "Total training time: 18.21 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 15.09, NNZs: 30, Bias: -138.184744, T: 34348086, Avg. loss: 0.074856\n",
      "Total training time: 18.31 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 15.09, NNZs: 30, Bias: -138.151869, T: 34518972, Avg. loss: 0.074835\n",
      "Total training time: 18.43 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 15.09, NNZs: 30, Bias: -138.118892, T: 34689858, Avg. loss: 0.074814\n",
      "Total training time: 18.54 seconds.\n",
      "-- Epoch 204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 15.09, NNZs: 30, Bias: -138.085681, T: 34860744, Avg. loss: 0.074793\n",
      "Total training time: 18.64 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 15.08, NNZs: 30, Bias: -138.052946, T: 35031630, Avg. loss: 0.074772\n",
      "Total training time: 18.74 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 15.08, NNZs: 30, Bias: -138.020672, T: 35202516, Avg. loss: 0.074752\n",
      "Total training time: 18.83 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 15.08, NNZs: 30, Bias: -137.988290, T: 35373402, Avg. loss: 0.074731\n",
      "Total training time: 18.92 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 15.07, NNZs: 30, Bias: -137.956215, T: 35544288, Avg. loss: 0.074711\n",
      "Total training time: 19.02 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 15.07, NNZs: 30, Bias: -137.924083, T: 35715174, Avg. loss: 0.074691\n",
      "Total training time: 19.10 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 15.07, NNZs: 30, Bias: -137.892163, T: 35886060, Avg. loss: 0.074671\n",
      "Total training time: 19.19 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 15.06, NNZs: 30, Bias: -137.860890, T: 36056946, Avg. loss: 0.074651\n",
      "Total training time: 19.27 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 15.06, NNZs: 30, Bias: -137.829194, T: 36227832, Avg. loss: 0.074631\n",
      "Total training time: 19.36 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 15.05, NNZs: 30, Bias: -137.797770, T: 36398718, Avg. loss: 0.074611\n",
      "Total training time: 19.47 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 15.05, NNZs: 30, Bias: -137.766211, T: 36569604, Avg. loss: 0.074592\n",
      "Total training time: 19.58 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 15.05, NNZs: 30, Bias: -137.734924, T: 36740490, Avg. loss: 0.074572\n",
      "Total training time: 19.68 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 15.05, NNZs: 30, Bias: -137.703828, T: 36911376, Avg. loss: 0.074553\n",
      "Total training time: 19.79 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 15.05, NNZs: 30, Bias: -137.673097, T: 37082262, Avg. loss: 0.074533\n",
      "Total training time: 19.89 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 15.04, NNZs: 30, Bias: -137.642760, T: 37253148, Avg. loss: 0.074514\n",
      "Total training time: 20.00 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 15.04, NNZs: 30, Bias: -137.611813, T: 37424034, Avg. loss: 0.074495\n",
      "Total training time: 20.11 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 15.04, NNZs: 30, Bias: -137.581484, T: 37594920, Avg. loss: 0.074476\n",
      "Total training time: 20.21 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 15.03, NNZs: 30, Bias: -137.551251, T: 37765806, Avg. loss: 0.074457\n",
      "Total training time: 20.30 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 15.03, NNZs: 30, Bias: -137.520869, T: 37936692, Avg. loss: 0.074438\n",
      "Total training time: 20.39 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 15.03, NNZs: 30, Bias: -137.490705, T: 38107578, Avg. loss: 0.074419\n",
      "Total training time: 20.48 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 15.03, NNZs: 30, Bias: -137.460843, T: 38278464, Avg. loss: 0.074400\n",
      "Total training time: 20.58 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 15.03, NNZs: 30, Bias: -137.431140, T: 38449350, Avg. loss: 0.074382\n",
      "Total training time: 20.69 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 15.02, NNZs: 30, Bias: -137.401618, T: 38620236, Avg. loss: 0.074363\n",
      "Total training time: 20.79 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 15.02, NNZs: 30, Bias: -137.372199, T: 38791122, Avg. loss: 0.074345\n",
      "Total training time: 20.89 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 15.02, NNZs: 30, Bias: -137.342627, T: 38962008, Avg. loss: 0.074327\n",
      "Total training time: 20.99 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 15.02, NNZs: 30, Bias: -137.313224, T: 39132894, Avg. loss: 0.074308\n",
      "Total training time: 21.09 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 15.02, NNZs: 30, Bias: -137.284001, T: 39303780, Avg. loss: 0.074290\n",
      "Total training time: 21.20 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 15.01, NNZs: 30, Bias: -137.255201, T: 39474666, Avg. loss: 0.074272\n",
      "Total training time: 21.30 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 15.01, NNZs: 30, Bias: -137.226374, T: 39645552, Avg. loss: 0.074254\n",
      "Total training time: 21.39 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 15.01, NNZs: 30, Bias: -137.197586, T: 39816438, Avg. loss: 0.074236\n",
      "Total training time: 21.48 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 15.01, NNZs: 30, Bias: -137.168979, T: 39987324, Avg. loss: 0.074219\n",
      "Total training time: 21.57 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 15.01, NNZs: 30, Bias: -137.140394, T: 40158210, Avg. loss: 0.074201\n",
      "Total training time: 21.66 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 15.00, NNZs: 30, Bias: -137.111867, T: 40329096, Avg. loss: 0.074183\n",
      "Total training time: 21.76 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 15.00, NNZs: 30, Bias: -137.083597, T: 40499982, Avg. loss: 0.074166\n",
      "Total training time: 21.87 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 15.00, NNZs: 30, Bias: -137.055529, T: 40670868, Avg. loss: 0.074148\n",
      "Total training time: 21.97 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 15.00, NNZs: 30, Bias: -137.027664, T: 40841754, Avg. loss: 0.074131\n",
      "Total training time: 22.07 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 14.99, NNZs: 30, Bias: -136.999694, T: 41012640, Avg. loss: 0.074114\n",
      "Total training time: 22.17 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 14.99, NNZs: 30, Bias: -136.972244, T: 41183526, Avg. loss: 0.074096\n",
      "Total training time: 22.26 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 14.99, NNZs: 30, Bias: -136.944656, T: 41354412, Avg. loss: 0.074079\n",
      "Total training time: 22.35 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 14.98, NNZs: 30, Bias: -136.917133, T: 41525298, Avg. loss: 0.074062\n",
      "Total training time: 22.44 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 14.98, NNZs: 30, Bias: -136.889714, T: 41696184, Avg. loss: 0.074045\n",
      "Total training time: 22.53 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 14.98, NNZs: 30, Bias: -136.862469, T: 41867070, Avg. loss: 0.074028\n",
      "Total training time: 22.62 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 14.98, NNZs: 30, Bias: -136.835228, T: 42037956, Avg. loss: 0.074011\n",
      "Total training time: 22.71 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 14.97, NNZs: 30, Bias: -136.808070, T: 42208842, Avg. loss: 0.073995\n",
      "Total training time: 22.80 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 14.97, NNZs: 30, Bias: -136.781077, T: 42379728, Avg. loss: 0.073978\n",
      "Total training time: 22.89 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 14.97, NNZs: 30, Bias: -136.754134, T: 42550614, Avg. loss: 0.073961\n",
      "Total training time: 22.98 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 14.97, NNZs: 30, Bias: -136.727464, T: 42721500, Avg. loss: 0.073945\n",
      "Total training time: 23.07 seconds.\n",
      "-- Epoch 251\n",
      "Norm: 14.97, NNZs: 30, Bias: -136.700662, T: 42892386, Avg. loss: 0.073928\n",
      "Total training time: 23.17 seconds.\n",
      "-- Epoch 252\n",
      "Norm: 14.97, NNZs: 30, Bias: -136.674142, T: 43063272, Avg. loss: 0.073912\n",
      "Total training time: 23.26 seconds.\n",
      "-- Epoch 253\n",
      "Norm: 14.96, NNZs: 30, Bias: -136.647818, T: 43234158, Avg. loss: 0.073896\n",
      "Total training time: 23.35 seconds.\n",
      "-- Epoch 254\n",
      "Norm: 14.96, NNZs: 30, Bias: -136.621483, T: 43405044, Avg. loss: 0.073879\n",
      "Total training time: 23.44 seconds.\n",
      "-- Epoch 255\n",
      "Norm: 14.96, NNZs: 30, Bias: -136.595311, T: 43575930, Avg. loss: 0.073863\n",
      "Total training time: 23.53 seconds.\n",
      "-- Epoch 256\n",
      "Norm: 14.96, NNZs: 30, Bias: -136.569058, T: 43746816, Avg. loss: 0.073847\n",
      "Total training time: 23.62 seconds.\n",
      "-- Epoch 257\n",
      "Norm: 14.95, NNZs: 30, Bias: -136.543091, T: 43917702, Avg. loss: 0.073831\n",
      "Total training time: 23.71 seconds.\n",
      "-- Epoch 258\n",
      "Norm: 14.95, NNZs: 30, Bias: -136.517213, T: 44088588, Avg. loss: 0.073815\n",
      "Total training time: 23.80 seconds.\n",
      "-- Epoch 259\n",
      "Norm: 14.95, NNZs: 30, Bias: -136.491464, T: 44259474, Avg. loss: 0.073799\n",
      "Total training time: 23.89 seconds.\n",
      "-- Epoch 260\n",
      "Norm: 14.95, NNZs: 30, Bias: -136.465818, T: 44430360, Avg. loss: 0.073783\n",
      "Total training time: 23.98 seconds.\n",
      "-- Epoch 261\n",
      "Norm: 14.94, NNZs: 30, Bias: -136.440241, T: 44601246, Avg. loss: 0.073768\n",
      "Total training time: 24.07 seconds.\n",
      "-- Epoch 262\n",
      "Norm: 14.94, NNZs: 30, Bias: -136.414847, T: 44772132, Avg. loss: 0.073752\n",
      "Total training time: 24.16 seconds.\n",
      "-- Epoch 263\n",
      "Norm: 14.94, NNZs: 30, Bias: -136.389410, T: 44943018, Avg. loss: 0.073736\n",
      "Total training time: 24.25 seconds.\n",
      "-- Epoch 264\n",
      "Norm: 14.93, NNZs: 30, Bias: -136.364231, T: 45113904, Avg. loss: 0.073721\n",
      "Total training time: 24.34 seconds.\n",
      "-- Epoch 265\n",
      "Norm: 14.93, NNZs: 30, Bias: -136.338990, T: 45284790, Avg. loss: 0.073705\n",
      "Total training time: 24.42 seconds.\n",
      "-- Epoch 266\n",
      "Norm: 14.93, NNZs: 30, Bias: -136.313575, T: 45455676, Avg. loss: 0.073690\n",
      "Total training time: 24.51 seconds.\n",
      "-- Epoch 267\n",
      "Norm: 14.93, NNZs: 30, Bias: -136.288274, T: 45626562, Avg. loss: 0.073674\n",
      "Total training time: 24.60 seconds.\n",
      "-- Epoch 268\n",
      "Norm: 14.93, NNZs: 30, Bias: -136.263470, T: 45797448, Avg. loss: 0.073659\n",
      "Total training time: 24.69 seconds.\n",
      "-- Epoch 269\n",
      "Norm: 14.93, NNZs: 30, Bias: -136.238826, T: 45968334, Avg. loss: 0.073644\n",
      "Total training time: 24.77 seconds.\n",
      "-- Epoch 270\n",
      "Norm: 14.92, NNZs: 30, Bias: -136.214287, T: 46139220, Avg. loss: 0.073628\n",
      "Total training time: 24.86 seconds.\n",
      "-- Epoch 271\n",
      "Norm: 14.92, NNZs: 30, Bias: -136.189529, T: 46310106, Avg. loss: 0.073613\n",
      "Total training time: 24.96 seconds.\n",
      "-- Epoch 272\n",
      "Norm: 14.92, NNZs: 30, Bias: -136.164972, T: 46480992, Avg. loss: 0.073598\n",
      "Total training time: 25.05 seconds.\n",
      "-- Epoch 273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.92, NNZs: 30, Bias: -136.140540, T: 46651878, Avg. loss: 0.073583\n",
      "Total training time: 25.14 seconds.\n",
      "-- Epoch 274\n",
      "Norm: 14.91, NNZs: 30, Bias: -136.116094, T: 46822764, Avg. loss: 0.073568\n",
      "Total training time: 25.22 seconds.\n",
      "-- Epoch 275\n",
      "Norm: 14.91, NNZs: 30, Bias: -136.091633, T: 46993650, Avg. loss: 0.073554\n",
      "Total training time: 25.31 seconds.\n",
      "-- Epoch 276\n",
      "Norm: 14.91, NNZs: 30, Bias: -136.067399, T: 47164536, Avg. loss: 0.073539\n",
      "Total training time: 25.40 seconds.\n",
      "-- Epoch 277\n",
      "Norm: 14.91, NNZs: 30, Bias: -136.043526, T: 47335422, Avg. loss: 0.073524\n",
      "Total training time: 25.48 seconds.\n",
      "-- Epoch 278\n",
      "Norm: 14.91, NNZs: 30, Bias: -136.019522, T: 47506308, Avg. loss: 0.073509\n",
      "Total training time: 25.57 seconds.\n",
      "-- Epoch 279\n",
      "Norm: 14.90, NNZs: 30, Bias: -135.995544, T: 47677194, Avg. loss: 0.073495\n",
      "Total training time: 25.66 seconds.\n",
      "-- Epoch 280\n",
      "Norm: 14.90, NNZs: 30, Bias: -135.971812, T: 47848080, Avg. loss: 0.073480\n",
      "Total training time: 25.75 seconds.\n",
      "-- Epoch 281\n",
      "Norm: 14.90, NNZs: 30, Bias: -135.948037, T: 48018966, Avg. loss: 0.073465\n",
      "Total training time: 25.84 seconds.\n",
      "-- Epoch 282\n",
      "Norm: 14.90, NNZs: 30, Bias: -135.924339, T: 48189852, Avg. loss: 0.073451\n",
      "Total training time: 25.93 seconds.\n",
      "-- Epoch 283\n",
      "Norm: 14.89, NNZs: 30, Bias: -135.900747, T: 48360738, Avg. loss: 0.073437\n",
      "Total training time: 26.02 seconds.\n",
      "-- Epoch 284\n",
      "Norm: 14.89, NNZs: 30, Bias: -135.877310, T: 48531624, Avg. loss: 0.073422\n",
      "Total training time: 26.10 seconds.\n",
      "-- Epoch 285\n",
      "Norm: 14.89, NNZs: 30, Bias: -135.853907, T: 48702510, Avg. loss: 0.073408\n",
      "Total training time: 26.19 seconds.\n",
      "-- Epoch 286\n",
      "Norm: 14.89, NNZs: 30, Bias: -135.830489, T: 48873396, Avg. loss: 0.073394\n",
      "Total training time: 26.28 seconds.\n",
      "-- Epoch 287\n",
      "Norm: 14.89, NNZs: 30, Bias: -135.807120, T: 49044282, Avg. loss: 0.073379\n",
      "Total training time: 26.37 seconds.\n",
      "-- Epoch 288\n",
      "Norm: 14.89, NNZs: 30, Bias: -135.783826, T: 49215168, Avg. loss: 0.073365\n",
      "Total training time: 26.46 seconds.\n",
      "-- Epoch 289\n",
      "Norm: 14.88, NNZs: 30, Bias: -135.760774, T: 49386054, Avg. loss: 0.073351\n",
      "Total training time: 26.55 seconds.\n",
      "-- Epoch 290\n",
      "Norm: 14.88, NNZs: 30, Bias: -135.737845, T: 49556940, Avg. loss: 0.073337\n",
      "Total training time: 26.64 seconds.\n",
      "-- Epoch 291\n",
      "Norm: 14.88, NNZs: 30, Bias: -135.714892, T: 49727826, Avg. loss: 0.073323\n",
      "Total training time: 26.73 seconds.\n",
      "-- Epoch 292\n",
      "Norm: 14.88, NNZs: 30, Bias: -135.692125, T: 49898712, Avg. loss: 0.073309\n",
      "Total training time: 26.82 seconds.\n",
      "-- Epoch 293\n",
      "Norm: 14.87, NNZs: 30, Bias: -135.669306, T: 50069598, Avg. loss: 0.073295\n",
      "Total training time: 26.91 seconds.\n",
      "-- Epoch 294\n",
      "Norm: 14.87, NNZs: 30, Bias: -135.646588, T: 50240484, Avg. loss: 0.073282\n",
      "Total training time: 27.00 seconds.\n",
      "-- Epoch 295\n",
      "Norm: 14.87, NNZs: 30, Bias: -135.623975, T: 50411370, Avg. loss: 0.073268\n",
      "Total training time: 27.09 seconds.\n",
      "-- Epoch 296\n",
      "Norm: 14.87, NNZs: 30, Bias: -135.601295, T: 50582256, Avg. loss: 0.073254\n",
      "Total training time: 27.18 seconds.\n",
      "-- Epoch 297\n",
      "Norm: 14.87, NNZs: 30, Bias: -135.578872, T: 50753142, Avg. loss: 0.073240\n",
      "Total training time: 27.27 seconds.\n",
      "-- Epoch 298\n",
      "Norm: 14.87, NNZs: 30, Bias: -135.556549, T: 50924028, Avg. loss: 0.073227\n",
      "Total training time: 27.36 seconds.\n",
      "-- Epoch 299\n",
      "Norm: 14.86, NNZs: 30, Bias: -135.534100, T: 51094914, Avg. loss: 0.073213\n",
      "Total training time: 27.44 seconds.\n",
      "-- Epoch 300\n",
      "Norm: 14.86, NNZs: 30, Bias: -135.511766, T: 51265800, Avg. loss: 0.073200\n",
      "Total training time: 27.53 seconds.\n",
      "-- Epoch 301\n",
      "Norm: 14.86, NNZs: 30, Bias: -135.489397, T: 51436686, Avg. loss: 0.073186\n",
      "Total training time: 27.62 seconds.\n",
      "-- Epoch 302\n",
      "Norm: 14.86, NNZs: 30, Bias: -135.467292, T: 51607572, Avg. loss: 0.073173\n",
      "Total training time: 27.71 seconds.\n",
      "-- Epoch 303\n",
      "Norm: 14.86, NNZs: 30, Bias: -135.445308, T: 51778458, Avg. loss: 0.073160\n",
      "Total training time: 27.80 seconds.\n",
      "-- Epoch 304\n",
      "Norm: 14.86, NNZs: 30, Bias: -135.423316, T: 51949344, Avg. loss: 0.073146\n",
      "Total training time: 27.89 seconds.\n",
      "-- Epoch 305\n",
      "Norm: 14.86, NNZs: 30, Bias: -135.401310, T: 52120230, Avg. loss: 0.073133\n",
      "Total training time: 27.98 seconds.\n",
      "-- Epoch 306\n",
      "Norm: 14.86, NNZs: 30, Bias: -135.379502, T: 52291116, Avg. loss: 0.073120\n",
      "Total training time: 28.07 seconds.\n",
      "-- Epoch 307\n",
      "Norm: 14.85, NNZs: 30, Bias: -135.357926, T: 52462002, Avg. loss: 0.073107\n",
      "Total training time: 28.16 seconds.\n",
      "-- Epoch 308\n",
      "Norm: 14.85, NNZs: 30, Bias: -135.336336, T: 52632888, Avg. loss: 0.073093\n",
      "Total training time: 28.25 seconds.\n",
      "-- Epoch 309\n",
      "Norm: 14.85, NNZs: 30, Bias: -135.314827, T: 52803774, Avg. loss: 0.073080\n",
      "Total training time: 28.34 seconds.\n",
      "-- Epoch 310\n",
      "Norm: 14.84, NNZs: 30, Bias: -135.293306, T: 52974660, Avg. loss: 0.073067\n",
      "Total training time: 28.43 seconds.\n",
      "-- Epoch 311\n",
      "Norm: 14.84, NNZs: 30, Bias: -135.271752, T: 53145546, Avg. loss: 0.073054\n",
      "Total training time: 28.52 seconds.\n",
      "-- Epoch 312\n",
      "Norm: 14.84, NNZs: 30, Bias: -135.250333, T: 53316432, Avg. loss: 0.073041\n",
      "Total training time: 28.61 seconds.\n",
      "-- Epoch 313\n",
      "Norm: 14.84, NNZs: 30, Bias: -135.229116, T: 53487318, Avg. loss: 0.073028\n",
      "Total training time: 28.70 seconds.\n",
      "-- Epoch 314\n",
      "Norm: 14.84, NNZs: 30, Bias: -135.207937, T: 53658204, Avg. loss: 0.073015\n",
      "Total training time: 28.79 seconds.\n",
      "-- Epoch 315\n",
      "Norm: 14.84, NNZs: 30, Bias: -135.186803, T: 53829090, Avg. loss: 0.073003\n",
      "Total training time: 28.88 seconds.\n",
      "-- Epoch 316\n",
      "Norm: 14.83, NNZs: 30, Bias: -135.165610, T: 53999976, Avg. loss: 0.072990\n",
      "Total training time: 28.97 seconds.\n",
      "-- Epoch 317\n",
      "Norm: 14.83, NNZs: 30, Bias: -135.144637, T: 54170862, Avg. loss: 0.072977\n",
      "Total training time: 29.06 seconds.\n",
      "-- Epoch 318\n",
      "Norm: 14.83, NNZs: 30, Bias: -135.123690, T: 54341748, Avg. loss: 0.072964\n",
      "Total training time: 29.15 seconds.\n",
      "-- Epoch 319\n",
      "Norm: 14.83, NNZs: 30, Bias: -135.102830, T: 54512634, Avg. loss: 0.072952\n",
      "Total training time: 29.24 seconds.\n",
      "-- Epoch 320\n",
      "Norm: 14.83, NNZs: 30, Bias: -135.081874, T: 54683520, Avg. loss: 0.072939\n",
      "Total training time: 29.33 seconds.\n",
      "-- Epoch 321\n",
      "Norm: 14.82, NNZs: 30, Bias: -135.061247, T: 54854406, Avg. loss: 0.072927\n",
      "Total training time: 29.42 seconds.\n",
      "-- Epoch 322\n",
      "Norm: 14.82, NNZs: 30, Bias: -135.040415, T: 55025292, Avg. loss: 0.072914\n",
      "Total training time: 29.52 seconds.\n",
      "-- Epoch 323\n",
      "Norm: 14.82, NNZs: 30, Bias: -135.019743, T: 55196178, Avg. loss: 0.072902\n",
      "Total training time: 29.61 seconds.\n",
      "-- Epoch 324\n",
      "Norm: 14.82, NNZs: 30, Bias: -134.999043, T: 55367064, Avg. loss: 0.072889\n",
      "Total training time: 29.70 seconds.\n",
      "-- Epoch 325\n",
      "Norm: 14.82, NNZs: 30, Bias: -134.978607, T: 55537950, Avg. loss: 0.072877\n",
      "Total training time: 29.79 seconds.\n",
      "-- Epoch 326\n",
      "Norm: 14.82, NNZs: 30, Bias: -134.958132, T: 55708836, Avg. loss: 0.072864\n",
      "Total training time: 29.88 seconds.\n",
      "-- Epoch 327\n",
      "Norm: 14.81, NNZs: 30, Bias: -134.937779, T: 55879722, Avg. loss: 0.072852\n",
      "Total training time: 29.98 seconds.\n",
      "-- Epoch 328\n",
      "Norm: 14.81, NNZs: 30, Bias: -134.917428, T: 56050608, Avg. loss: 0.072840\n",
      "Total training time: 30.07 seconds.\n",
      "-- Epoch 329\n",
      "Norm: 14.81, NNZs: 30, Bias: -134.897078, T: 56221494, Avg. loss: 0.072828\n",
      "Total training time: 30.16 seconds.\n",
      "-- Epoch 330\n",
      "Norm: 14.81, NNZs: 30, Bias: -134.876932, T: 56392380, Avg. loss: 0.072815\n",
      "Total training time: 30.25 seconds.\n",
      "-- Epoch 331\n",
      "Norm: 14.81, NNZs: 30, Bias: -134.856693, T: 56563266, Avg. loss: 0.072803\n",
      "Total training time: 30.33 seconds.\n",
      "-- Epoch 332\n",
      "Norm: 14.81, NNZs: 30, Bias: -134.836523, T: 56734152, Avg. loss: 0.072791\n",
      "Total training time: 30.42 seconds.\n",
      "-- Epoch 333\n",
      "Norm: 14.81, NNZs: 30, Bias: -134.816384, T: 56905038, Avg. loss: 0.072779\n",
      "Total training time: 30.51 seconds.\n",
      "-- Epoch 334\n",
      "Norm: 14.81, NNZs: 30, Bias: -134.796374, T: 57075924, Avg. loss: 0.072767\n",
      "Total training time: 30.60 seconds.\n",
      "-- Epoch 335\n",
      "Norm: 14.80, NNZs: 30, Bias: -134.776703, T: 57246810, Avg. loss: 0.072755\n",
      "Total training time: 30.70 seconds.\n",
      "-- Epoch 336\n",
      "Norm: 14.80, NNZs: 30, Bias: -134.756823, T: 57417696, Avg. loss: 0.072743\n",
      "Total training time: 30.79 seconds.\n",
      "-- Epoch 337\n",
      "Norm: 14.80, NNZs: 30, Bias: -134.737058, T: 57588582, Avg. loss: 0.072731\n",
      "Total training time: 30.88 seconds.\n",
      "-- Epoch 338\n",
      "Norm: 14.80, NNZs: 30, Bias: -134.717264, T: 57759468, Avg. loss: 0.072719\n",
      "Total training time: 30.97 seconds.\n",
      "-- Epoch 339\n",
      "Norm: 14.80, NNZs: 30, Bias: -134.697738, T: 57930354, Avg. loss: 0.072707\n",
      "Total training time: 31.07 seconds.\n",
      "-- Epoch 340\n",
      "Norm: 14.79, NNZs: 30, Bias: -134.678019, T: 58101240, Avg. loss: 0.072696\n",
      "Total training time: 31.16 seconds.\n",
      "-- Epoch 341\n",
      "Norm: 14.79, NNZs: 30, Bias: -134.658471, T: 58272126, Avg. loss: 0.072684\n",
      "Total training time: 31.25 seconds.\n",
      "-- Epoch 342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.79, NNZs: 30, Bias: -134.639113, T: 58443012, Avg. loss: 0.072672\n",
      "Total training time: 31.34 seconds.\n",
      "-- Epoch 343\n",
      "Norm: 14.79, NNZs: 30, Bias: -134.619666, T: 58613898, Avg. loss: 0.072661\n",
      "Total training time: 31.43 seconds.\n",
      "-- Epoch 344\n",
      "Norm: 14.79, NNZs: 30, Bias: -134.600307, T: 58784784, Avg. loss: 0.072649\n",
      "Total training time: 31.52 seconds.\n",
      "-- Epoch 345\n",
      "Norm: 14.79, NNZs: 30, Bias: -134.581021, T: 58955670, Avg. loss: 0.072637\n",
      "Total training time: 31.61 seconds.\n",
      "-- Epoch 346\n",
      "Norm: 14.78, NNZs: 30, Bias: -134.561866, T: 59126556, Avg. loss: 0.072626\n",
      "Total training time: 31.70 seconds.\n",
      "-- Epoch 347\n",
      "Norm: 14.78, NNZs: 30, Bias: -134.542574, T: 59297442, Avg. loss: 0.072614\n",
      "Total training time: 31.79 seconds.\n",
      "-- Epoch 348\n",
      "Norm: 14.78, NNZs: 30, Bias: -134.523462, T: 59468328, Avg. loss: 0.072603\n",
      "Total training time: 31.88 seconds.\n",
      "-- Epoch 349\n",
      "Norm: 14.78, NNZs: 30, Bias: -134.504390, T: 59639214, Avg. loss: 0.072591\n",
      "Total training time: 31.97 seconds.\n",
      "-- Epoch 350\n",
      "Norm: 14.78, NNZs: 30, Bias: -134.485284, T: 59810100, Avg. loss: 0.072580\n",
      "Total training time: 32.06 seconds.\n",
      "-- Epoch 351\n",
      "Norm: 14.78, NNZs: 30, Bias: -134.466278, T: 59980986, Avg. loss: 0.072568\n",
      "Total training time: 32.15 seconds.\n",
      "-- Epoch 352\n",
      "Norm: 14.77, NNZs: 30, Bias: -134.447360, T: 60151872, Avg. loss: 0.072557\n",
      "Total training time: 32.23 seconds.\n",
      "-- Epoch 353\n",
      "Norm: 14.77, NNZs: 30, Bias: -134.428578, T: 60322758, Avg. loss: 0.072546\n",
      "Total training time: 32.32 seconds.\n",
      "-- Epoch 354\n",
      "Norm: 14.77, NNZs: 30, Bias: -134.409795, T: 60493644, Avg. loss: 0.072534\n",
      "Total training time: 32.42 seconds.\n",
      "-- Epoch 355\n",
      "Norm: 14.77, NNZs: 30, Bias: -134.391004, T: 60664530, Avg. loss: 0.072523\n",
      "Total training time: 32.51 seconds.\n",
      "-- Epoch 356\n",
      "Norm: 14.77, NNZs: 30, Bias: -134.372395, T: 60835416, Avg. loss: 0.072512\n",
      "Total training time: 32.60 seconds.\n",
      "-- Epoch 357\n",
      "Norm: 14.76, NNZs: 30, Bias: -134.353659, T: 61006302, Avg. loss: 0.072501\n",
      "Total training time: 32.70 seconds.\n",
      "-- Epoch 358\n",
      "Norm: 14.76, NNZs: 30, Bias: -134.334979, T: 61177188, Avg. loss: 0.072490\n",
      "Total training time: 32.79 seconds.\n",
      "-- Epoch 359\n",
      "Norm: 14.76, NNZs: 30, Bias: -134.316451, T: 61348074, Avg. loss: 0.072478\n",
      "Total training time: 32.89 seconds.\n",
      "-- Epoch 360\n",
      "Norm: 14.76, NNZs: 30, Bias: -134.297856, T: 61518960, Avg. loss: 0.072467\n",
      "Total training time: 32.98 seconds.\n",
      "-- Epoch 361\n",
      "Norm: 14.76, NNZs: 30, Bias: -134.279388, T: 61689846, Avg. loss: 0.072456\n",
      "Total training time: 33.07 seconds.\n",
      "-- Epoch 362\n",
      "Norm: 14.76, NNZs: 30, Bias: -134.261037, T: 61860732, Avg. loss: 0.072445\n",
      "Total training time: 33.15 seconds.\n",
      "-- Epoch 363\n",
      "Norm: 14.76, NNZs: 30, Bias: -134.242663, T: 62031618, Avg. loss: 0.072434\n",
      "Total training time: 33.27 seconds.\n",
      "-- Epoch 364\n",
      "Norm: 14.75, NNZs: 30, Bias: -134.224387, T: 62202504, Avg. loss: 0.072423\n",
      "Total training time: 33.35 seconds.\n",
      "-- Epoch 365\n",
      "Norm: 14.75, NNZs: 30, Bias: -134.206182, T: 62373390, Avg. loss: 0.072412\n",
      "Total training time: 33.44 seconds.\n",
      "-- Epoch 366\n",
      "Norm: 14.75, NNZs: 30, Bias: -134.188067, T: 62544276, Avg. loss: 0.072401\n",
      "Total training time: 33.53 seconds.\n",
      "-- Epoch 367\n",
      "Norm: 14.75, NNZs: 30, Bias: -134.169932, T: 62715162, Avg. loss: 0.072391\n",
      "Total training time: 33.62 seconds.\n",
      "-- Epoch 368\n",
      "Norm: 14.75, NNZs: 30, Bias: -134.151807, T: 62886048, Avg. loss: 0.072380\n",
      "Total training time: 33.71 seconds.\n",
      "-- Epoch 369\n",
      "Norm: 14.75, NNZs: 30, Bias: -134.133755, T: 63056934, Avg. loss: 0.072369\n",
      "Total training time: 33.80 seconds.\n",
      "-- Epoch 370\n",
      "Norm: 14.74, NNZs: 30, Bias: -134.115758, T: 63227820, Avg. loss: 0.072358\n",
      "Total training time: 33.90 seconds.\n",
      "-- Epoch 371\n",
      "Norm: 14.74, NNZs: 30, Bias: -134.097770, T: 63398706, Avg. loss: 0.072348\n",
      "Total training time: 33.99 seconds.\n",
      "-- Epoch 372\n",
      "Norm: 14.74, NNZs: 30, Bias: -134.079840, T: 63569592, Avg. loss: 0.072337\n",
      "Total training time: 34.08 seconds.\n",
      "-- Epoch 373\n",
      "Norm: 14.74, NNZs: 30, Bias: -134.061954, T: 63740478, Avg. loss: 0.072326\n",
      "Total training time: 34.17 seconds.\n",
      "-- Epoch 374\n",
      "Norm: 14.74, NNZs: 30, Bias: -134.044123, T: 63911364, Avg. loss: 0.072316\n",
      "Total training time: 34.26 seconds.\n",
      "-- Epoch 375\n",
      "Norm: 14.74, NNZs: 30, Bias: -134.026358, T: 64082250, Avg. loss: 0.072305\n",
      "Total training time: 34.35 seconds.\n",
      "-- Epoch 376\n",
      "Norm: 14.74, NNZs: 30, Bias: -134.008786, T: 64253136, Avg. loss: 0.072294\n",
      "Total training time: 34.44 seconds.\n",
      "-- Epoch 377\n",
      "Norm: 14.73, NNZs: 30, Bias: -133.991088, T: 64424022, Avg. loss: 0.072284\n",
      "Total training time: 34.53 seconds.\n",
      "-- Epoch 378\n",
      "Norm: 14.73, NNZs: 30, Bias: -133.973355, T: 64594908, Avg. loss: 0.072273\n",
      "Total training time: 34.63 seconds.\n",
      "-- Epoch 379\n",
      "Norm: 14.73, NNZs: 30, Bias: -133.955855, T: 64765794, Avg. loss: 0.072263\n",
      "Total training time: 34.72 seconds.\n",
      "-- Epoch 380\n",
      "Norm: 14.73, NNZs: 30, Bias: -133.938341, T: 64936680, Avg. loss: 0.072252\n",
      "Total training time: 34.81 seconds.\n",
      "-- Epoch 381\n",
      "Norm: 14.73, NNZs: 30, Bias: -133.920853, T: 65107566, Avg. loss: 0.072242\n",
      "Total training time: 34.91 seconds.\n",
      "-- Epoch 382\n",
      "Norm: 14.73, NNZs: 30, Bias: -133.903465, T: 65278452, Avg. loss: 0.072231\n",
      "Total training time: 35.00 seconds.\n",
      "-- Epoch 383\n",
      "Norm: 14.73, NNZs: 30, Bias: -133.886133, T: 65449338, Avg. loss: 0.072221\n",
      "Total training time: 35.09 seconds.\n",
      "-- Epoch 384\n",
      "Norm: 14.72, NNZs: 30, Bias: -133.868821, T: 65620224, Avg. loss: 0.072211\n",
      "Total training time: 35.18 seconds.\n",
      "-- Epoch 385\n",
      "Norm: 14.72, NNZs: 30, Bias: -133.851538, T: 65791110, Avg. loss: 0.072200\n",
      "Total training time: 35.27 seconds.\n",
      "-- Epoch 386\n",
      "Norm: 14.72, NNZs: 30, Bias: -133.834323, T: 65961996, Avg. loss: 0.072190\n",
      "Total training time: 35.36 seconds.\n",
      "-- Epoch 387\n",
      "Norm: 14.72, NNZs: 30, Bias: -133.817062, T: 66132882, Avg. loss: 0.072180\n",
      "Total training time: 35.45 seconds.\n",
      "-- Epoch 388\n",
      "Norm: 14.72, NNZs: 30, Bias: -133.799929, T: 66303768, Avg. loss: 0.072170\n",
      "Total training time: 35.54 seconds.\n",
      "-- Epoch 389\n",
      "Norm: 14.72, NNZs: 30, Bias: -133.782822, T: 66474654, Avg. loss: 0.072159\n",
      "Total training time: 35.63 seconds.\n",
      "-- Epoch 390\n",
      "Norm: 14.71, NNZs: 30, Bias: -133.765744, T: 66645540, Avg. loss: 0.072149\n",
      "Total training time: 35.72 seconds.\n",
      "-- Epoch 391\n",
      "Norm: 14.71, NNZs: 30, Bias: -133.748707, T: 66816426, Avg. loss: 0.072139\n",
      "Total training time: 35.81 seconds.\n",
      "-- Epoch 392\n",
      "Norm: 14.71, NNZs: 30, Bias: -133.731721, T: 66987312, Avg. loss: 0.072129\n",
      "Total training time: 35.90 seconds.\n",
      "-- Epoch 393\n",
      "Norm: 14.71, NNZs: 30, Bias: -133.714815, T: 67158198, Avg. loss: 0.072119\n",
      "Total training time: 35.99 seconds.\n",
      "-- Epoch 394\n",
      "Norm: 14.71, NNZs: 30, Bias: -133.697985, T: 67329084, Avg. loss: 0.072109\n",
      "Total training time: 36.09 seconds.\n",
      "-- Epoch 395\n",
      "Norm: 14.71, NNZs: 30, Bias: -133.681223, T: 67499970, Avg. loss: 0.072099\n",
      "Total training time: 36.18 seconds.\n",
      "-- Epoch 396\n",
      "Norm: 14.71, NNZs: 30, Bias: -133.664376, T: 67670856, Avg. loss: 0.072089\n",
      "Total training time: 36.27 seconds.\n",
      "-- Epoch 397\n",
      "Norm: 14.70, NNZs: 30, Bias: -133.647668, T: 67841742, Avg. loss: 0.072079\n",
      "Total training time: 36.36 seconds.\n",
      "-- Epoch 398\n",
      "Norm: 14.70, NNZs: 30, Bias: -133.630937, T: 68012628, Avg. loss: 0.072069\n",
      "Total training time: 36.45 seconds.\n",
      "-- Epoch 399\n",
      "Norm: 14.70, NNZs: 30, Bias: -133.614274, T: 68183514, Avg. loss: 0.072059\n",
      "Total training time: 36.54 seconds.\n",
      "-- Epoch 400\n",
      "Norm: 14.70, NNZs: 30, Bias: -133.597598, T: 68354400, Avg. loss: 0.072049\n",
      "Total training time: 36.63 seconds.\n",
      "-- Epoch 401\n",
      "Norm: 14.70, NNZs: 30, Bias: -133.580934, T: 68525286, Avg. loss: 0.072039\n",
      "Total training time: 36.72 seconds.\n",
      "-- Epoch 402\n",
      "Norm: 14.70, NNZs: 30, Bias: -133.564352, T: 68696172, Avg. loss: 0.072029\n",
      "Total training time: 36.81 seconds.\n",
      "-- Epoch 403\n",
      "Norm: 14.70, NNZs: 30, Bias: -133.547879, T: 68867058, Avg. loss: 0.072019\n",
      "Total training time: 36.90 seconds.\n",
      "-- Epoch 404\n",
      "Norm: 14.69, NNZs: 30, Bias: -133.531374, T: 69037944, Avg. loss: 0.072010\n",
      "Total training time: 37.00 seconds.\n",
      "-- Epoch 405\n",
      "Norm: 14.69, NNZs: 30, Bias: -133.514918, T: 69208830, Avg. loss: 0.072000\n",
      "Total training time: 37.09 seconds.\n",
      "-- Epoch 406\n",
      "Norm: 14.69, NNZs: 30, Bias: -133.498494, T: 69379716, Avg. loss: 0.071990\n",
      "Total training time: 37.18 seconds.\n",
      "-- Epoch 407\n",
      "Norm: 14.69, NNZs: 30, Bias: -133.482111, T: 69550602, Avg. loss: 0.071981\n",
      "Total training time: 37.27 seconds.\n",
      "-- Epoch 408\n",
      "Norm: 14.69, NNZs: 30, Bias: -133.465785, T: 69721488, Avg. loss: 0.071971\n",
      "Total training time: 37.36 seconds.\n",
      "-- Epoch 409\n",
      "Norm: 14.69, NNZs: 30, Bias: -133.449419, T: 69892374, Avg. loss: 0.071961\n",
      "Total training time: 37.46 seconds.\n",
      "-- Epoch 410\n",
      "Norm: 14.69, NNZs: 30, Bias: -133.433248, T: 70063260, Avg. loss: 0.071952\n",
      "Total training time: 37.55 seconds.\n",
      "-- Epoch 411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.69, NNZs: 30, Bias: -133.417125, T: 70234146, Avg. loss: 0.071942\n",
      "Total training time: 37.64 seconds.\n",
      "-- Epoch 412\n",
      "Norm: 14.68, NNZs: 30, Bias: -133.400970, T: 70405032, Avg. loss: 0.071932\n",
      "Total training time: 37.74 seconds.\n",
      "-- Epoch 413\n",
      "Norm: 14.68, NNZs: 30, Bias: -133.384836, T: 70575918, Avg. loss: 0.071923\n",
      "Total training time: 37.83 seconds.\n",
      "-- Epoch 414\n",
      "Norm: 14.68, NNZs: 30, Bias: -133.368876, T: 70746804, Avg. loss: 0.071913\n",
      "Total training time: 37.91 seconds.\n",
      "-- Epoch 415\n",
      "Norm: 14.68, NNZs: 30, Bias: -133.352833, T: 70917690, Avg. loss: 0.071904\n",
      "Total training time: 38.01 seconds.\n",
      "-- Epoch 416\n",
      "Norm: 14.68, NNZs: 30, Bias: -133.336783, T: 71088576, Avg. loss: 0.071894\n",
      "Total training time: 38.10 seconds.\n",
      "-- Epoch 417\n",
      "Norm: 14.68, NNZs: 30, Bias: -133.320899, T: 71259462, Avg. loss: 0.071885\n",
      "Total training time: 38.19 seconds.\n",
      "-- Epoch 418\n",
      "Norm: 14.68, NNZs: 30, Bias: -133.305000, T: 71430348, Avg. loss: 0.071875\n",
      "Total training time: 38.28 seconds.\n",
      "-- Epoch 419\n",
      "Norm: 14.67, NNZs: 30, Bias: -133.289105, T: 71601234, Avg. loss: 0.071866\n",
      "Total training time: 38.38 seconds.\n",
      "-- Epoch 420\n",
      "Norm: 14.67, NNZs: 30, Bias: -133.273273, T: 71772120, Avg. loss: 0.071857\n",
      "Total training time: 38.47 seconds.\n",
      "-- Epoch 421\n",
      "Norm: 14.67, NNZs: 30, Bias: -133.257467, T: 71943006, Avg. loss: 0.071847\n",
      "Total training time: 38.56 seconds.\n",
      "-- Epoch 422\n",
      "Norm: 14.67, NNZs: 30, Bias: -133.241750, T: 72113892, Avg. loss: 0.071838\n",
      "Total training time: 38.65 seconds.\n",
      "-- Epoch 423\n",
      "Norm: 14.67, NNZs: 30, Bias: -133.226026, T: 72284778, Avg. loss: 0.071829\n",
      "Total training time: 38.75 seconds.\n",
      "-- Epoch 424\n",
      "Norm: 14.67, NNZs: 30, Bias: -133.210327, T: 72455664, Avg. loss: 0.071819\n",
      "Total training time: 38.84 seconds.\n",
      "-- Epoch 425\n",
      "Norm: 14.67, NNZs: 30, Bias: -133.194692, T: 72626550, Avg. loss: 0.071810\n",
      "Total training time: 38.95 seconds.\n",
      "-- Epoch 426\n",
      "Norm: 14.67, NNZs: 30, Bias: -133.179115, T: 72797436, Avg. loss: 0.071801\n",
      "Total training time: 39.05 seconds.\n",
      "-- Epoch 427\n",
      "Norm: 14.66, NNZs: 30, Bias: -133.163542, T: 72968322, Avg. loss: 0.071791\n",
      "Total training time: 39.15 seconds.\n",
      "-- Epoch 428\n",
      "Norm: 14.66, NNZs: 30, Bias: -133.147934, T: 73139208, Avg. loss: 0.071782\n",
      "Total training time: 39.25 seconds.\n",
      "-- Epoch 429\n",
      "Norm: 14.66, NNZs: 30, Bias: -133.132493, T: 73310094, Avg. loss: 0.071773\n",
      "Total training time: 39.35 seconds.\n",
      "-- Epoch 430\n",
      "Norm: 14.66, NNZs: 30, Bias: -133.117028, T: 73480980, Avg. loss: 0.071764\n",
      "Total training time: 39.44 seconds.\n",
      "-- Epoch 431\n",
      "Norm: 14.66, NNZs: 30, Bias: -133.101587, T: 73651866, Avg. loss: 0.071755\n",
      "Total training time: 39.53 seconds.\n",
      "-- Epoch 432\n",
      "Norm: 14.66, NNZs: 30, Bias: -133.086259, T: 73822752, Avg. loss: 0.071746\n",
      "Total training time: 39.61 seconds.\n",
      "-- Epoch 433\n",
      "Norm: 14.66, NNZs: 30, Bias: -133.070867, T: 73993638, Avg. loss: 0.071737\n",
      "Total training time: 39.70 seconds.\n",
      "-- Epoch 434\n",
      "Norm: 14.65, NNZs: 30, Bias: -133.055576, T: 74164524, Avg. loss: 0.071728\n",
      "Total training time: 39.79 seconds.\n",
      "-- Epoch 435\n",
      "Norm: 14.65, NNZs: 30, Bias: -133.040280, T: 74335410, Avg. loss: 0.071718\n",
      "Total training time: 39.88 seconds.\n",
      "-- Epoch 436\n",
      "Norm: 14.65, NNZs: 30, Bias: -133.025038, T: 74506296, Avg. loss: 0.071709\n",
      "Total training time: 39.97 seconds.\n",
      "-- Epoch 437\n",
      "Norm: 14.65, NNZs: 30, Bias: -133.009746, T: 74677182, Avg. loss: 0.071700\n",
      "Total training time: 40.06 seconds.\n",
      "-- Epoch 438\n",
      "Norm: 14.65, NNZs: 30, Bias: -132.994502, T: 74848068, Avg. loss: 0.071692\n",
      "Total training time: 40.15 seconds.\n",
      "-- Epoch 439\n",
      "Norm: 14.65, NNZs: 30, Bias: -132.979377, T: 75018954, Avg. loss: 0.071683\n",
      "Total training time: 40.27 seconds.\n",
      "-- Epoch 440\n",
      "Norm: 14.65, NNZs: 30, Bias: -132.964299, T: 75189840, Avg. loss: 0.071674\n",
      "Total training time: 40.36 seconds.\n",
      "-- Epoch 441\n",
      "Norm: 14.65, NNZs: 30, Bias: -132.949220, T: 75360726, Avg. loss: 0.071665\n",
      "Total training time: 40.45 seconds.\n",
      "-- Epoch 442\n",
      "Norm: 14.64, NNZs: 30, Bias: -132.934246, T: 75531612, Avg. loss: 0.071656\n",
      "Total training time: 40.53 seconds.\n",
      "-- Epoch 443\n",
      "Norm: 14.64, NNZs: 30, Bias: -132.919365, T: 75702498, Avg. loss: 0.071647\n",
      "Total training time: 40.63 seconds.\n",
      "-- Epoch 444\n",
      "Norm: 14.64, NNZs: 30, Bias: -132.904401, T: 75873384, Avg. loss: 0.071638\n",
      "Total training time: 40.72 seconds.\n",
      "-- Epoch 445\n",
      "Norm: 14.64, NNZs: 30, Bias: -132.889413, T: 76044270, Avg. loss: 0.071629\n",
      "Total training time: 40.83 seconds.\n",
      "-- Epoch 446\n",
      "Norm: 14.64, NNZs: 30, Bias: -132.874456, T: 76215156, Avg. loss: 0.071620\n",
      "Total training time: 40.92 seconds.\n",
      "-- Epoch 447\n",
      "Norm: 14.64, NNZs: 30, Bias: -132.859615, T: 76386042, Avg. loss: 0.071612\n",
      "Total training time: 41.03 seconds.\n",
      "-- Epoch 448\n",
      "Norm: 14.64, NNZs: 30, Bias: -132.844827, T: 76556928, Avg. loss: 0.071603\n",
      "Total training time: 41.12 seconds.\n",
      "-- Epoch 449\n",
      "Norm: 14.64, NNZs: 30, Bias: -132.829955, T: 76727814, Avg. loss: 0.071594\n",
      "Total training time: 41.20 seconds.\n",
      "-- Epoch 450\n",
      "Norm: 14.63, NNZs: 30, Bias: -132.815199, T: 76898700, Avg. loss: 0.071585\n",
      "Total training time: 41.28 seconds.\n",
      "-- Epoch 451\n",
      "Norm: 14.63, NNZs: 30, Bias: -132.800495, T: 77069586, Avg. loss: 0.071577\n",
      "Total training time: 41.36 seconds.\n",
      "-- Epoch 452\n",
      "Norm: 14.63, NNZs: 30, Bias: -132.785846, T: 77240472, Avg. loss: 0.071568\n",
      "Total training time: 41.44 seconds.\n",
      "-- Epoch 453\n",
      "Norm: 14.63, NNZs: 30, Bias: -132.771154, T: 77411358, Avg. loss: 0.071559\n",
      "Total training time: 41.53 seconds.\n",
      "-- Epoch 454\n",
      "Norm: 14.63, NNZs: 30, Bias: -132.756501, T: 77582244, Avg. loss: 0.071551\n",
      "Total training time: 41.61 seconds.\n",
      "-- Epoch 455\n",
      "Norm: 14.63, NNZs: 30, Bias: -132.741882, T: 77753130, Avg. loss: 0.071542\n",
      "Total training time: 41.69 seconds.\n",
      "-- Epoch 456\n",
      "Norm: 14.63, NNZs: 30, Bias: -132.727240, T: 77924016, Avg. loss: 0.071534\n",
      "Total training time: 41.77 seconds.\n",
      "-- Epoch 457\n",
      "Norm: 14.63, NNZs: 30, Bias: -132.712713, T: 78094902, Avg. loss: 0.071525\n",
      "Total training time: 41.85 seconds.\n",
      "-- Epoch 458\n",
      "Norm: 14.62, NNZs: 30, Bias: -132.698214, T: 78265788, Avg. loss: 0.071516\n",
      "Total training time: 41.93 seconds.\n",
      "-- Epoch 459\n",
      "Norm: 14.62, NNZs: 30, Bias: -132.683805, T: 78436674, Avg. loss: 0.071508\n",
      "Total training time: 42.02 seconds.\n",
      "-- Epoch 460\n",
      "Norm: 14.62, NNZs: 30, Bias: -132.669330, T: 78607560, Avg. loss: 0.071499\n",
      "Total training time: 42.10 seconds.\n",
      "-- Epoch 461\n",
      "Norm: 14.62, NNZs: 30, Bias: -132.654891, T: 78778446, Avg. loss: 0.071491\n",
      "Total training time: 42.18 seconds.\n",
      "-- Epoch 462\n",
      "Norm: 14.62, NNZs: 30, Bias: -132.640522, T: 78949332, Avg. loss: 0.071482\n",
      "Total training time: 42.26 seconds.\n",
      "-- Epoch 463\n",
      "Norm: 14.62, NNZs: 30, Bias: -132.626189, T: 79120218, Avg. loss: 0.071474\n",
      "Total training time: 42.35 seconds.\n",
      "-- Epoch 464\n",
      "Norm: 14.62, NNZs: 30, Bias: -132.611881, T: 79291104, Avg. loss: 0.071466\n",
      "Total training time: 42.43 seconds.\n",
      "-- Epoch 465\n",
      "Norm: 14.62, NNZs: 30, Bias: -132.597619, T: 79461990, Avg. loss: 0.071457\n",
      "Total training time: 42.51 seconds.\n",
      "-- Epoch 466\n",
      "Norm: 14.61, NNZs: 30, Bias: -132.583384, T: 79632876, Avg. loss: 0.071449\n",
      "Total training time: 42.59 seconds.\n",
      "-- Epoch 467\n",
      "Norm: 14.61, NNZs: 30, Bias: -132.569136, T: 79803762, Avg. loss: 0.071440\n",
      "Total training time: 42.67 seconds.\n",
      "-- Epoch 468\n",
      "Norm: 14.61, NNZs: 30, Bias: -132.554943, T: 79974648, Avg. loss: 0.071432\n",
      "Total training time: 42.76 seconds.\n",
      "-- Epoch 469\n",
      "Norm: 14.61, NNZs: 30, Bias: -132.540635, T: 80145534, Avg. loss: 0.071424\n",
      "Total training time: 42.84 seconds.\n",
      "-- Epoch 470\n",
      "Norm: 14.61, NNZs: 30, Bias: -132.526582, T: 80316420, Avg. loss: 0.071415\n",
      "Total training time: 42.92 seconds.\n",
      "-- Epoch 471\n",
      "Norm: 14.61, NNZs: 30, Bias: -132.512430, T: 80487306, Avg. loss: 0.071407\n",
      "Total training time: 43.00 seconds.\n",
      "-- Epoch 472\n",
      "Norm: 14.61, NNZs: 30, Bias: -132.498332, T: 80658192, Avg. loss: 0.071399\n",
      "Total training time: 43.08 seconds.\n",
      "-- Epoch 473\n",
      "Norm: 14.61, NNZs: 30, Bias: -132.484326, T: 80829078, Avg. loss: 0.071390\n",
      "Total training time: 43.16 seconds.\n",
      "-- Epoch 474\n",
      "Norm: 14.60, NNZs: 30, Bias: -132.470368, T: 80999964, Avg. loss: 0.071382\n",
      "Total training time: 43.25 seconds.\n",
      "-- Epoch 475\n",
      "Norm: 14.60, NNZs: 30, Bias: -132.456383, T: 81170850, Avg. loss: 0.071374\n",
      "Total training time: 43.33 seconds.\n",
      "-- Epoch 476\n",
      "Norm: 14.60, NNZs: 30, Bias: -132.442445, T: 81341736, Avg. loss: 0.071366\n",
      "Total training time: 43.41 seconds.\n",
      "-- Epoch 477\n",
      "Norm: 14.60, NNZs: 30, Bias: -132.428515, T: 81512622, Avg. loss: 0.071358\n",
      "Total training time: 43.49 seconds.\n",
      "-- Epoch 478\n",
      "Norm: 14.60, NNZs: 30, Bias: -132.414682, T: 81683508, Avg. loss: 0.071349\n",
      "Total training time: 43.57 seconds.\n",
      "-- Epoch 479\n",
      "Norm: 14.60, NNZs: 30, Bias: -132.400763, T: 81854394, Avg. loss: 0.071341\n",
      "Total training time: 43.66 seconds.\n",
      "-- Epoch 480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.60, NNZs: 30, Bias: -132.386961, T: 82025280, Avg. loss: 0.071333\n",
      "Total training time: 43.74 seconds.\n",
      "-- Epoch 481\n",
      "Norm: 14.60, NNZs: 30, Bias: -132.373150, T: 82196166, Avg. loss: 0.071325\n",
      "Total training time: 43.82 seconds.\n",
      "-- Epoch 482\n",
      "Norm: 14.60, NNZs: 30, Bias: -132.359363, T: 82367052, Avg. loss: 0.071317\n",
      "Total training time: 43.90 seconds.\n",
      "-- Epoch 483\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.345630, T: 82537938, Avg. loss: 0.071309\n",
      "Total training time: 43.99 seconds.\n",
      "-- Epoch 484\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.331834, T: 82708824, Avg. loss: 0.071301\n",
      "Total training time: 44.07 seconds.\n",
      "-- Epoch 485\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.318068, T: 82879710, Avg. loss: 0.071293\n",
      "Total training time: 44.15 seconds.\n",
      "-- Epoch 486\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.304462, T: 83050596, Avg. loss: 0.071285\n",
      "Total training time: 44.23 seconds.\n",
      "-- Epoch 487\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.290867, T: 83221482, Avg. loss: 0.071277\n",
      "Total training time: 44.32 seconds.\n",
      "-- Epoch 488\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.277254, T: 83392368, Avg. loss: 0.071269\n",
      "Total training time: 44.40 seconds.\n",
      "-- Epoch 489\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.263620, T: 83563254, Avg. loss: 0.071261\n",
      "Total training time: 44.48 seconds.\n",
      "-- Epoch 490\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.250070, T: 83734140, Avg. loss: 0.071253\n",
      "Total training time: 44.57 seconds.\n",
      "-- Epoch 491\n",
      "Norm: 14.59, NNZs: 30, Bias: -132.236589, T: 83905026, Avg. loss: 0.071245\n",
      "Total training time: 44.65 seconds.\n",
      "-- Epoch 492\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.223112, T: 84075912, Avg. loss: 0.071237\n",
      "Total training time: 44.73 seconds.\n",
      "-- Epoch 493\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.209637, T: 84246798, Avg. loss: 0.071229\n",
      "Total training time: 44.81 seconds.\n",
      "-- Epoch 494\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.196147, T: 84417684, Avg. loss: 0.071221\n",
      "Total training time: 44.89 seconds.\n",
      "-- Epoch 495\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.182733, T: 84588570, Avg. loss: 0.071213\n",
      "Total training time: 44.97 seconds.\n",
      "-- Epoch 496\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.169342, T: 84759456, Avg. loss: 0.071205\n",
      "Total training time: 45.05 seconds.\n",
      "-- Epoch 497\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.155939, T: 84930342, Avg. loss: 0.071197\n",
      "Total training time: 45.13 seconds.\n",
      "-- Epoch 498\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.142602, T: 85101228, Avg. loss: 0.071190\n",
      "Total training time: 45.21 seconds.\n",
      "-- Epoch 499\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.129345, T: 85272114, Avg. loss: 0.071182\n",
      "Total training time: 45.29 seconds.\n",
      "-- Epoch 500\n",
      "Norm: 14.58, NNZs: 30, Bias: -132.116070, T: 85443000, Avg. loss: 0.071174\n",
      "Total training time: 45.37 seconds.\n",
      "-- Epoch 501\n",
      "Norm: 14.57, NNZs: 30, Bias: -132.102846, T: 85613886, Avg. loss: 0.071166\n",
      "Total training time: 45.46 seconds.\n",
      "-- Epoch 502\n",
      "Norm: 14.57, NNZs: 30, Bias: -132.089669, T: 85784772, Avg. loss: 0.071158\n",
      "Total training time: 45.54 seconds.\n",
      "-- Epoch 503\n",
      "Norm: 14.57, NNZs: 30, Bias: -132.076435, T: 85955658, Avg. loss: 0.071151\n",
      "Total training time: 45.62 seconds.\n",
      "-- Epoch 504\n",
      "Norm: 14.57, NNZs: 30, Bias: -132.063239, T: 86126544, Avg. loss: 0.071143\n",
      "Total training time: 45.70 seconds.\n",
      "-- Epoch 505\n",
      "Norm: 14.57, NNZs: 30, Bias: -132.050102, T: 86297430, Avg. loss: 0.071135\n",
      "Total training time: 45.79 seconds.\n",
      "-- Epoch 506\n",
      "Norm: 14.57, NNZs: 30, Bias: -132.037065, T: 86468316, Avg. loss: 0.071128\n",
      "Total training time: 45.87 seconds.\n",
      "-- Epoch 507\n",
      "Norm: 14.57, NNZs: 30, Bias: -132.023980, T: 86639202, Avg. loss: 0.071120\n",
      "Total training time: 45.95 seconds.\n",
      "-- Epoch 508\n",
      "Norm: 14.57, NNZs: 30, Bias: -132.010873, T: 86810088, Avg. loss: 0.071112\n",
      "Total training time: 46.03 seconds.\n",
      "-- Epoch 509\n",
      "Norm: 14.56, NNZs: 30, Bias: -131.997894, T: 86980974, Avg. loss: 0.071105\n",
      "Total training time: 46.11 seconds.\n",
      "-- Epoch 510\n",
      "Norm: 14.56, NNZs: 30, Bias: -131.984870, T: 87151860, Avg. loss: 0.071097\n",
      "Total training time: 46.19 seconds.\n",
      "-- Epoch 511\n",
      "Norm: 14.56, NNZs: 30, Bias: -131.971885, T: 87322746, Avg. loss: 0.071089\n",
      "Total training time: 46.27 seconds.\n",
      "-- Epoch 512\n",
      "Norm: 14.56, NNZs: 30, Bias: -131.958955, T: 87493632, Avg. loss: 0.071082\n",
      "Total training time: 46.36 seconds.\n",
      "-- Epoch 513\n",
      "Norm: 14.56, NNZs: 30, Bias: -131.946036, T: 87664518, Avg. loss: 0.071074\n",
      "Total training time: 46.44 seconds.\n",
      "-- Epoch 514\n",
      "Norm: 14.56, NNZs: 30, Bias: -131.933130, T: 87835404, Avg. loss: 0.071067\n",
      "Total training time: 46.52 seconds.\n",
      "-- Epoch 515\n",
      "Norm: 14.56, NNZs: 30, Bias: -131.920266, T: 88006290, Avg. loss: 0.071059\n",
      "Total training time: 46.60 seconds.\n",
      "-- Epoch 516\n",
      "Norm: 14.56, NNZs: 30, Bias: -131.907423, T: 88177176, Avg. loss: 0.071052\n",
      "Total training time: 46.69 seconds.\n",
      "-- Epoch 517\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.894582, T: 88348062, Avg. loss: 0.071044\n",
      "Total training time: 46.77 seconds.\n",
      "-- Epoch 518\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.881764, T: 88518948, Avg. loss: 0.071037\n",
      "Total training time: 46.85 seconds.\n",
      "-- Epoch 519\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.868882, T: 88689834, Avg. loss: 0.071029\n",
      "Total training time: 46.93 seconds.\n",
      "-- Epoch 520\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.856121, T: 88860720, Avg. loss: 0.071022\n",
      "Total training time: 47.02 seconds.\n",
      "-- Epoch 521\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.843342, T: 89031606, Avg. loss: 0.071014\n",
      "Total training time: 47.10 seconds.\n",
      "-- Epoch 522\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.830651, T: 89202492, Avg. loss: 0.071007\n",
      "Total training time: 47.18 seconds.\n",
      "-- Epoch 523\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.817990, T: 89373378, Avg. loss: 0.070999\n",
      "Total training time: 47.26 seconds.\n",
      "-- Epoch 524\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.805409, T: 89544264, Avg. loss: 0.070992\n",
      "Total training time: 47.34 seconds.\n",
      "-- Epoch 525\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.792768, T: 89715150, Avg. loss: 0.070984\n",
      "Total training time: 47.43 seconds.\n",
      "-- Epoch 526\n",
      "Norm: 14.55, NNZs: 30, Bias: -131.780160, T: 89886036, Avg. loss: 0.070977\n",
      "Total training time: 47.51 seconds.\n",
      "-- Epoch 527\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.767586, T: 90056922, Avg. loss: 0.070970\n",
      "Total training time: 47.59 seconds.\n",
      "-- Epoch 528\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.755043, T: 90227808, Avg. loss: 0.070962\n",
      "Total training time: 47.68 seconds.\n",
      "-- Epoch 529\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.742490, T: 90398694, Avg. loss: 0.070955\n",
      "Total training time: 47.76 seconds.\n",
      "-- Epoch 530\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.730014, T: 90569580, Avg. loss: 0.070948\n",
      "Total training time: 47.84 seconds.\n",
      "-- Epoch 531\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.717495, T: 90740466, Avg. loss: 0.070940\n",
      "Total training time: 47.92 seconds.\n",
      "-- Epoch 532\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.705059, T: 90911352, Avg. loss: 0.070933\n",
      "Total training time: 48.01 seconds.\n",
      "-- Epoch 533\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.692625, T: 91082238, Avg. loss: 0.070926\n",
      "Total training time: 48.09 seconds.\n",
      "-- Epoch 534\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.680156, T: 91253124, Avg. loss: 0.070919\n",
      "Total training time: 48.17 seconds.\n",
      "-- Epoch 535\n",
      "Norm: 14.54, NNZs: 30, Bias: -131.667714, T: 91424010, Avg. loss: 0.070911\n",
      "Total training time: 48.25 seconds.\n",
      "-- Epoch 536\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.655418, T: 91594896, Avg. loss: 0.070904\n",
      "Total training time: 48.34 seconds.\n",
      "-- Epoch 537\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.643084, T: 91765782, Avg. loss: 0.070897\n",
      "Total training time: 48.42 seconds.\n",
      "-- Epoch 538\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.630730, T: 91936668, Avg. loss: 0.070890\n",
      "Total training time: 48.50 seconds.\n",
      "-- Epoch 539\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.618397, T: 92107554, Avg. loss: 0.070882\n",
      "Total training time: 48.59 seconds.\n",
      "-- Epoch 540\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.606104, T: 92278440, Avg. loss: 0.070875\n",
      "Total training time: 48.67 seconds.\n",
      "-- Epoch 541\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.593824, T: 92449326, Avg. loss: 0.070868\n",
      "Total training time: 48.75 seconds.\n",
      "-- Epoch 542\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.581600, T: 92620212, Avg. loss: 0.070861\n",
      "Total training time: 48.83 seconds.\n",
      "-- Epoch 543\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.569413, T: 92791098, Avg. loss: 0.070854\n",
      "Total training time: 48.92 seconds.\n",
      "-- Epoch 544\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.557239, T: 92961984, Avg. loss: 0.070847\n",
      "Total training time: 49.00 seconds.\n",
      "-- Epoch 545\n",
      "Norm: 14.53, NNZs: 30, Bias: -131.545029, T: 93132870, Avg. loss: 0.070840\n",
      "Total training time: 49.08 seconds.\n",
      "-- Epoch 546\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.532941, T: 93303756, Avg. loss: 0.070832\n",
      "Total training time: 49.16 seconds.\n",
      "-- Epoch 547\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.520808, T: 93474642, Avg. loss: 0.070825\n",
      "Total training time: 49.24 seconds.\n",
      "-- Epoch 548\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.508637, T: 93645528, Avg. loss: 0.070818\n",
      "Total training time: 49.33 seconds.\n",
      "-- Epoch 549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.52, NNZs: 30, Bias: -131.496568, T: 93816414, Avg. loss: 0.070811\n",
      "Total training time: 49.41 seconds.\n",
      "-- Epoch 550\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.484513, T: 93987300, Avg. loss: 0.070804\n",
      "Total training time: 49.49 seconds.\n",
      "-- Epoch 551\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.472480, T: 94158186, Avg. loss: 0.070797\n",
      "Total training time: 49.58 seconds.\n",
      "-- Epoch 552\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.460450, T: 94329072, Avg. loss: 0.070790\n",
      "Total training time: 49.66 seconds.\n",
      "-- Epoch 553\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.448456, T: 94499958, Avg. loss: 0.070783\n",
      "Total training time: 49.74 seconds.\n",
      "-- Epoch 554\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.436463, T: 94670844, Avg. loss: 0.070776\n",
      "Total training time: 49.82 seconds.\n",
      "-- Epoch 555\n",
      "Norm: 14.52, NNZs: 30, Bias: -131.424456, T: 94841730, Avg. loss: 0.070769\n",
      "Total training time: 49.91 seconds.\n",
      "-- Epoch 556\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.412537, T: 95012616, Avg. loss: 0.070762\n",
      "Total training time: 49.99 seconds.\n",
      "-- Epoch 557\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.400567, T: 95183502, Avg. loss: 0.070755\n",
      "Total training time: 50.07 seconds.\n",
      "-- Epoch 558\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.388712, T: 95354388, Avg. loss: 0.070748\n",
      "Total training time: 50.16 seconds.\n",
      "-- Epoch 559\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.376895, T: 95525274, Avg. loss: 0.070741\n",
      "Total training time: 50.24 seconds.\n",
      "-- Epoch 560\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.365074, T: 95696160, Avg. loss: 0.070735\n",
      "Total training time: 50.32 seconds.\n",
      "-- Epoch 561\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.353275, T: 95867046, Avg. loss: 0.070728\n",
      "Total training time: 50.40 seconds.\n",
      "-- Epoch 562\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.341569, T: 96037932, Avg. loss: 0.070721\n",
      "Total training time: 50.49 seconds.\n",
      "-- Epoch 563\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.329776, T: 96208818, Avg. loss: 0.070714\n",
      "Total training time: 50.57 seconds.\n",
      "-- Epoch 564\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.318009, T: 96379704, Avg. loss: 0.070707\n",
      "Total training time: 50.65 seconds.\n",
      "-- Epoch 565\n",
      "Norm: 14.51, NNZs: 30, Bias: -131.306212, T: 96550590, Avg. loss: 0.070700\n",
      "Total training time: 50.73 seconds.\n",
      "-- Epoch 566\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.294488, T: 96721476, Avg. loss: 0.070693\n",
      "Total training time: 50.82 seconds.\n",
      "-- Epoch 567\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.282793, T: 96892362, Avg. loss: 0.070687\n",
      "Total training time: 50.90 seconds.\n",
      "-- Epoch 568\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.271120, T: 97063248, Avg. loss: 0.070680\n",
      "Total training time: 50.98 seconds.\n",
      "-- Epoch 569\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.259477, T: 97234134, Avg. loss: 0.070673\n",
      "Total training time: 51.06 seconds.\n",
      "-- Epoch 570\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.247862, T: 97405020, Avg. loss: 0.070666\n",
      "Total training time: 51.15 seconds.\n",
      "-- Epoch 571\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.236249, T: 97575906, Avg. loss: 0.070659\n",
      "Total training time: 51.23 seconds.\n",
      "-- Epoch 572\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.224638, T: 97746792, Avg. loss: 0.070653\n",
      "Total training time: 51.31 seconds.\n",
      "-- Epoch 573\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.213088, T: 97917678, Avg. loss: 0.070646\n",
      "Total training time: 51.39 seconds.\n",
      "-- Epoch 574\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.201511, T: 98088564, Avg. loss: 0.070639\n",
      "Total training time: 51.47 seconds.\n",
      "-- Epoch 575\n",
      "Norm: 14.50, NNZs: 30, Bias: -131.190000, T: 98259450, Avg. loss: 0.070633\n",
      "Total training time: 51.55 seconds.\n",
      "-- Epoch 576\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.178529, T: 98430336, Avg. loss: 0.070626\n",
      "Total training time: 51.64 seconds.\n",
      "-- Epoch 577\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.167047, T: 98601222, Avg. loss: 0.070619\n",
      "Total training time: 51.72 seconds.\n",
      "-- Epoch 578\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.155614, T: 98772108, Avg. loss: 0.070612\n",
      "Total training time: 51.80 seconds.\n",
      "-- Epoch 579\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.144132, T: 98942994, Avg. loss: 0.070606\n",
      "Total training time: 51.88 seconds.\n",
      "-- Epoch 580\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.132713, T: 99113880, Avg. loss: 0.070599\n",
      "Total training time: 51.96 seconds.\n",
      "-- Epoch 581\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.121303, T: 99284766, Avg. loss: 0.070592\n",
      "Total training time: 52.04 seconds.\n",
      "-- Epoch 582\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.109939, T: 99455652, Avg. loss: 0.070586\n",
      "Total training time: 52.12 seconds.\n",
      "-- Epoch 583\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.098595, T: 99626538, Avg. loss: 0.070579\n",
      "Total training time: 52.21 seconds.\n",
      "-- Epoch 584\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.087209, T: 99797424, Avg. loss: 0.070573\n",
      "Total training time: 52.29 seconds.\n",
      "-- Epoch 585\n",
      "Norm: 14.49, NNZs: 30, Bias: -131.075858, T: 99968310, Avg. loss: 0.070566\n",
      "Total training time: 52.37 seconds.\n",
      "-- Epoch 586\n",
      "Norm: 14.48, NNZs: 30, Bias: -131.064551, T: 100139196, Avg. loss: 0.070559\n",
      "Total training time: 52.45 seconds.\n",
      "-- Epoch 587\n",
      "Norm: 14.48, NNZs: 30, Bias: -131.053272, T: 100310082, Avg. loss: 0.070553\n",
      "Total training time: 52.54 seconds.\n",
      "-- Epoch 588\n",
      "Norm: 14.48, NNZs: 30, Bias: -131.042012, T: 100480968, Avg. loss: 0.070546\n",
      "Total training time: 52.62 seconds.\n",
      "-- Epoch 589\n",
      "Norm: 14.48, NNZs: 30, Bias: -131.030789, T: 100651854, Avg. loss: 0.070540\n",
      "Total training time: 52.70 seconds.\n",
      "-- Epoch 590\n",
      "Norm: 14.48, NNZs: 30, Bias: -131.019557, T: 100822740, Avg. loss: 0.070533\n",
      "Total training time: 52.78 seconds.\n",
      "-- Epoch 591\n",
      "Norm: 14.48, NNZs: 30, Bias: -131.008373, T: 100993626, Avg. loss: 0.070527\n",
      "Total training time: 52.86 seconds.\n",
      "-- Epoch 592\n",
      "Norm: 14.48, NNZs: 30, Bias: -130.997184, T: 101164512, Avg. loss: 0.070520\n",
      "Total training time: 52.94 seconds.\n",
      "-- Epoch 593\n",
      "Norm: 14.48, NNZs: 30, Bias: -130.986023, T: 101335398, Avg. loss: 0.070514\n",
      "Total training time: 53.03 seconds.\n",
      "-- Epoch 594\n",
      "Norm: 14.48, NNZs: 30, Bias: -130.974885, T: 101506284, Avg. loss: 0.070507\n",
      "Total training time: 53.11 seconds.\n",
      "-- Epoch 595\n",
      "Norm: 14.48, NNZs: 30, Bias: -130.963716, T: 101677170, Avg. loss: 0.070501\n",
      "Total training time: 53.19 seconds.\n",
      "-- Epoch 596\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.952597, T: 101848056, Avg. loss: 0.070494\n",
      "Total training time: 53.27 seconds.\n",
      "-- Epoch 597\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.941519, T: 102018942, Avg. loss: 0.070488\n",
      "Total training time: 53.36 seconds.\n",
      "-- Epoch 598\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.930433, T: 102189828, Avg. loss: 0.070481\n",
      "Total training time: 53.44 seconds.\n",
      "-- Epoch 599\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.919368, T: 102360714, Avg. loss: 0.070475\n",
      "Total training time: 53.52 seconds.\n",
      "-- Epoch 600\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.908362, T: 102531600, Avg. loss: 0.070468\n",
      "Total training time: 53.60 seconds.\n",
      "-- Epoch 601\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.897273, T: 102702486, Avg. loss: 0.070462\n",
      "Total training time: 53.68 seconds.\n",
      "-- Epoch 602\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.886239, T: 102873372, Avg. loss: 0.070456\n",
      "Total training time: 53.77 seconds.\n",
      "-- Epoch 603\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.875240, T: 103044258, Avg. loss: 0.070449\n",
      "Total training time: 53.85 seconds.\n",
      "-- Epoch 604\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.864245, T: 103215144, Avg. loss: 0.070443\n",
      "Total training time: 53.93 seconds.\n",
      "-- Epoch 605\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.853319, T: 103386030, Avg. loss: 0.070437\n",
      "Total training time: 54.01 seconds.\n",
      "-- Epoch 606\n",
      "Norm: 14.47, NNZs: 30, Bias: -130.842382, T: 103556916, Avg. loss: 0.070430\n",
      "Total training time: 54.09 seconds.\n",
      "-- Epoch 607\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.831448, T: 103727802, Avg. loss: 0.070424\n",
      "Total training time: 54.17 seconds.\n",
      "-- Epoch 608\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.820537, T: 103898688, Avg. loss: 0.070418\n",
      "Total training time: 54.26 seconds.\n",
      "-- Epoch 609\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.809650, T: 104069574, Avg. loss: 0.070411\n",
      "Total training time: 54.34 seconds.\n",
      "-- Epoch 610\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.798795, T: 104240460, Avg. loss: 0.070405\n",
      "Total training time: 54.42 seconds.\n",
      "-- Epoch 611\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.787938, T: 104411346, Avg. loss: 0.070399\n",
      "Total training time: 54.50 seconds.\n",
      "-- Epoch 612\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.777128, T: 104582232, Avg. loss: 0.070392\n",
      "Total training time: 54.59 seconds.\n",
      "-- Epoch 613\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.766297, T: 104753118, Avg. loss: 0.070386\n",
      "Total training time: 54.67 seconds.\n",
      "-- Epoch 614\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.755477, T: 104924004, Avg. loss: 0.070380\n",
      "Total training time: 54.75 seconds.\n",
      "-- Epoch 615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.46, NNZs: 30, Bias: -130.744685, T: 105094890, Avg. loss: 0.070374\n",
      "Total training time: 54.83 seconds.\n",
      "-- Epoch 616\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.733897, T: 105265776, Avg. loss: 0.070367\n",
      "Total training time: 54.91 seconds.\n",
      "-- Epoch 617\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.723187, T: 105436662, Avg. loss: 0.070361\n",
      "Total training time: 55.00 seconds.\n",
      "-- Epoch 618\n",
      "Norm: 14.46, NNZs: 30, Bias: -130.712464, T: 105607548, Avg. loss: 0.070355\n",
      "Total training time: 55.08 seconds.\n",
      "-- Epoch 619\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.701770, T: 105778434, Avg. loss: 0.070349\n",
      "Total training time: 55.16 seconds.\n",
      "-- Epoch 620\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.691077, T: 105949320, Avg. loss: 0.070343\n",
      "Total training time: 55.24 seconds.\n",
      "-- Epoch 621\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.680404, T: 106120206, Avg. loss: 0.070336\n",
      "Total training time: 55.33 seconds.\n",
      "-- Epoch 622\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.669775, T: 106291092, Avg. loss: 0.070330\n",
      "Total training time: 55.41 seconds.\n",
      "-- Epoch 623\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.659146, T: 106461978, Avg. loss: 0.070324\n",
      "Total training time: 55.49 seconds.\n",
      "-- Epoch 624\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.648551, T: 106632864, Avg. loss: 0.070318\n",
      "Total training time: 55.57 seconds.\n",
      "-- Epoch 625\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.637951, T: 106803750, Avg. loss: 0.070312\n",
      "Total training time: 55.65 seconds.\n",
      "-- Epoch 626\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.627390, T: 106974636, Avg. loss: 0.070306\n",
      "Total training time: 55.74 seconds.\n",
      "-- Epoch 627\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.616835, T: 107145522, Avg. loss: 0.070299\n",
      "Total training time: 55.82 seconds.\n",
      "-- Epoch 628\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.606305, T: 107316408, Avg. loss: 0.070293\n",
      "Total training time: 55.90 seconds.\n",
      "-- Epoch 629\n",
      "Norm: 14.45, NNZs: 30, Bias: -130.595747, T: 107487294, Avg. loss: 0.070287\n",
      "Total training time: 55.98 seconds.\n",
      "-- Epoch 630\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.585229, T: 107658180, Avg. loss: 0.070281\n",
      "Total training time: 56.06 seconds.\n",
      "-- Epoch 631\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.574734, T: 107829066, Avg. loss: 0.070275\n",
      "Total training time: 56.14 seconds.\n",
      "-- Epoch 632\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.564285, T: 107999952, Avg. loss: 0.070269\n",
      "Total training time: 56.22 seconds.\n",
      "-- Epoch 633\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.553830, T: 108170838, Avg. loss: 0.070263\n",
      "Total training time: 56.31 seconds.\n",
      "-- Epoch 634\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.543413, T: 108341724, Avg. loss: 0.070257\n",
      "Total training time: 56.39 seconds.\n",
      "-- Epoch 635\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.532990, T: 108512610, Avg. loss: 0.070251\n",
      "Total training time: 56.47 seconds.\n",
      "-- Epoch 636\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.522573, T: 108683496, Avg. loss: 0.070245\n",
      "Total training time: 56.55 seconds.\n",
      "-- Epoch 637\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.512193, T: 108854382, Avg. loss: 0.070239\n",
      "Total training time: 56.63 seconds.\n",
      "-- Epoch 638\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.501777, T: 109025268, Avg. loss: 0.070233\n",
      "Total training time: 56.71 seconds.\n",
      "-- Epoch 639\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.491399, T: 109196154, Avg. loss: 0.070227\n",
      "Total training time: 56.79 seconds.\n",
      "-- Epoch 640\n",
      "Norm: 14.44, NNZs: 30, Bias: -130.481028, T: 109367040, Avg. loss: 0.070221\n",
      "Total training time: 56.88 seconds.\n",
      "-- Epoch 641\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.470711, T: 109537926, Avg. loss: 0.070215\n",
      "Total training time: 56.96 seconds.\n",
      "-- Epoch 642\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.460405, T: 109708812, Avg. loss: 0.070209\n",
      "Total training time: 57.04 seconds.\n",
      "-- Epoch 643\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.450148, T: 109879698, Avg. loss: 0.070203\n",
      "Total training time: 57.12 seconds.\n",
      "-- Epoch 644\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.439833, T: 110050584, Avg. loss: 0.070197\n",
      "Total training time: 57.20 seconds.\n",
      "-- Epoch 645\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.429543, T: 110221470, Avg. loss: 0.070191\n",
      "Total training time: 57.28 seconds.\n",
      "-- Epoch 646\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.419284, T: 110392356, Avg. loss: 0.070185\n",
      "Total training time: 57.36 seconds.\n",
      "-- Epoch 647\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.409049, T: 110563242, Avg. loss: 0.070179\n",
      "Total training time: 57.44 seconds.\n",
      "-- Epoch 648\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.398848, T: 110734128, Avg. loss: 0.070173\n",
      "Total training time: 57.53 seconds.\n",
      "-- Epoch 649\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.388645, T: 110905014, Avg. loss: 0.070167\n",
      "Total training time: 57.61 seconds.\n",
      "-- Epoch 650\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.378483, T: 111075900, Avg. loss: 0.070161\n",
      "Total training time: 57.69 seconds.\n",
      "-- Epoch 651\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.368312, T: 111246786, Avg. loss: 0.070155\n",
      "Total training time: 57.77 seconds.\n",
      "-- Epoch 652\n",
      "Norm: 14.43, NNZs: 30, Bias: -130.358102, T: 111417672, Avg. loss: 0.070150\n",
      "Total training time: 57.85 seconds.\n",
      "-- Epoch 653\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.347988, T: 111588558, Avg. loss: 0.070144\n",
      "Total training time: 57.93 seconds.\n",
      "-- Epoch 654\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.337869, T: 111759444, Avg. loss: 0.070138\n",
      "Total training time: 58.01 seconds.\n",
      "-- Epoch 655\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.327760, T: 111930330, Avg. loss: 0.070132\n",
      "Total training time: 58.09 seconds.\n",
      "-- Epoch 656\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.317662, T: 112101216, Avg. loss: 0.070126\n",
      "Total training time: 58.17 seconds.\n",
      "-- Epoch 657\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.307596, T: 112272102, Avg. loss: 0.070120\n",
      "Total training time: 58.26 seconds.\n",
      "-- Epoch 658\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.297531, T: 112442988, Avg. loss: 0.070114\n",
      "Total training time: 58.34 seconds.\n",
      "-- Epoch 659\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.287492, T: 112613874, Avg. loss: 0.070109\n",
      "Total training time: 58.42 seconds.\n",
      "-- Epoch 660\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.277446, T: 112784760, Avg. loss: 0.070103\n",
      "Total training time: 58.50 seconds.\n",
      "-- Epoch 661\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.267438, T: 112955646, Avg. loss: 0.070097\n",
      "Total training time: 58.59 seconds.\n",
      "-- Epoch 662\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.257441, T: 113126532, Avg. loss: 0.070091\n",
      "Total training time: 58.67 seconds.\n",
      "-- Epoch 663\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.247454, T: 113297418, Avg. loss: 0.070086\n",
      "Total training time: 58.75 seconds.\n",
      "-- Epoch 664\n",
      "Norm: 14.42, NNZs: 30, Bias: -130.237488, T: 113468304, Avg. loss: 0.070080\n",
      "Total training time: 58.83 seconds.\n",
      "-- Epoch 665\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.227559, T: 113639190, Avg. loss: 0.070074\n",
      "Total training time: 58.91 seconds.\n",
      "-- Epoch 666\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.217613, T: 113810076, Avg. loss: 0.070068\n",
      "Total training time: 58.99 seconds.\n",
      "-- Epoch 667\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.207711, T: 113980962, Avg. loss: 0.070062\n",
      "Total training time: 59.07 seconds.\n",
      "-- Epoch 668\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.197842, T: 114151848, Avg. loss: 0.070057\n",
      "Total training time: 59.15 seconds.\n",
      "-- Epoch 669\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.187967, T: 114322734, Avg. loss: 0.070051\n",
      "Total training time: 59.23 seconds.\n",
      "-- Epoch 670\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.178122, T: 114493620, Avg. loss: 0.070045\n",
      "Total training time: 59.31 seconds.\n",
      "-- Epoch 671\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.168262, T: 114664506, Avg. loss: 0.070040\n",
      "Total training time: 59.39 seconds.\n",
      "-- Epoch 672\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.158426, T: 114835392, Avg. loss: 0.070034\n",
      "Total training time: 59.48 seconds.\n",
      "-- Epoch 673\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.148586, T: 115006278, Avg. loss: 0.070028\n",
      "Total training time: 59.56 seconds.\n",
      "-- Epoch 674\n",
      "Norm: 14.41, NNZs: 30, Bias: -130.138785, T: 115177164, Avg. loss: 0.070023\n",
      "Total training time: 59.64 seconds.\n",
      "-- Epoch 675\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.128983, T: 115348050, Avg. loss: 0.070017\n",
      "Total training time: 59.72 seconds.\n",
      "-- Epoch 676\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.119193, T: 115518936, Avg. loss: 0.070011\n",
      "Total training time: 59.80 seconds.\n",
      "-- Epoch 677\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.109396, T: 115689822, Avg. loss: 0.070006\n",
      "Total training time: 59.88 seconds.\n",
      "-- Epoch 678\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.099653, T: 115860708, Avg. loss: 0.070000\n",
      "Total training time: 59.96 seconds.\n",
      "-- Epoch 679\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.089885, T: 116031594, Avg. loss: 0.069994\n",
      "Total training time: 60.04 seconds.\n",
      "-- Epoch 680\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.080190, T: 116202480, Avg. loss: 0.069989\n",
      "Total training time: 60.12 seconds.\n",
      "-- Epoch 681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.40, NNZs: 30, Bias: -130.070496, T: 116373366, Avg. loss: 0.069983\n",
      "Total training time: 60.20 seconds.\n",
      "-- Epoch 682\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.060790, T: 116544252, Avg. loss: 0.069977\n",
      "Total training time: 60.28 seconds.\n",
      "-- Epoch 683\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.051113, T: 116715138, Avg. loss: 0.069972\n",
      "Total training time: 60.37 seconds.\n",
      "-- Epoch 684\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.041419, T: 116886024, Avg. loss: 0.069966\n",
      "Total training time: 60.45 seconds.\n",
      "-- Epoch 685\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.031726, T: 117056910, Avg. loss: 0.069961\n",
      "Total training time: 60.53 seconds.\n",
      "-- Epoch 686\n",
      "Norm: 14.40, NNZs: 30, Bias: -130.022097, T: 117227796, Avg. loss: 0.069955\n",
      "Total training time: 60.61 seconds.\n",
      "-- Epoch 687\n",
      "Norm: 14.39, NNZs: 30, Bias: -130.012508, T: 117398682, Avg. loss: 0.069950\n",
      "Total training time: 60.70 seconds.\n",
      "-- Epoch 688\n",
      "Norm: 14.39, NNZs: 30, Bias: -130.002859, T: 117569568, Avg. loss: 0.069944\n",
      "Total training time: 60.78 seconds.\n",
      "-- Epoch 689\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.993240, T: 117740454, Avg. loss: 0.069938\n",
      "Total training time: 60.86 seconds.\n",
      "-- Epoch 690\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.983650, T: 117911340, Avg. loss: 0.069933\n",
      "Total training time: 60.94 seconds.\n",
      "-- Epoch 691\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.974077, T: 118082226, Avg. loss: 0.069927\n",
      "Total training time: 61.02 seconds.\n",
      "-- Epoch 692\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.964471, T: 118253112, Avg. loss: 0.069922\n",
      "Total training time: 61.11 seconds.\n",
      "-- Epoch 693\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.954931, T: 118423998, Avg. loss: 0.069916\n",
      "Total training time: 61.20 seconds.\n",
      "-- Epoch 694\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.945415, T: 118594884, Avg. loss: 0.069911\n",
      "Total training time: 61.29 seconds.\n",
      "-- Epoch 695\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.935900, T: 118765770, Avg. loss: 0.069905\n",
      "Total training time: 61.37 seconds.\n",
      "-- Epoch 696\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.926405, T: 118936656, Avg. loss: 0.069900\n",
      "Total training time: 61.46 seconds.\n",
      "-- Epoch 697\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.916898, T: 119107542, Avg. loss: 0.069894\n",
      "Total training time: 61.55 seconds.\n",
      "-- Epoch 698\n",
      "Norm: 14.39, NNZs: 30, Bias: -129.907458, T: 119278428, Avg. loss: 0.069889\n",
      "Total training time: 61.63 seconds.\n",
      "-- Epoch 699\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.898014, T: 119449314, Avg. loss: 0.069883\n",
      "Total training time: 61.72 seconds.\n",
      "-- Epoch 700\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.888551, T: 119620200, Avg. loss: 0.069878\n",
      "Total training time: 61.81 seconds.\n",
      "-- Epoch 701\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.879128, T: 119791086, Avg. loss: 0.069873\n",
      "Total training time: 61.90 seconds.\n",
      "-- Epoch 702\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.869681, T: 119961972, Avg. loss: 0.069867\n",
      "Total training time: 61.99 seconds.\n",
      "-- Epoch 703\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.860268, T: 120132858, Avg. loss: 0.069862\n",
      "Total training time: 62.07 seconds.\n",
      "-- Epoch 704\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.850861, T: 120303744, Avg. loss: 0.069856\n",
      "Total training time: 62.16 seconds.\n",
      "-- Epoch 705\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.841503, T: 120474630, Avg. loss: 0.069851\n",
      "Total training time: 62.24 seconds.\n",
      "-- Epoch 706\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.832135, T: 120645516, Avg. loss: 0.069845\n",
      "Total training time: 62.33 seconds.\n",
      "-- Epoch 707\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.822783, T: 120816402, Avg. loss: 0.069840\n",
      "Total training time: 62.42 seconds.\n",
      "-- Epoch 708\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.813450, T: 120987288, Avg. loss: 0.069835\n",
      "Total training time: 62.50 seconds.\n",
      "-- Epoch 709\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.804121, T: 121158174, Avg. loss: 0.069829\n",
      "Total training time: 62.58 seconds.\n",
      "-- Epoch 710\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.794798, T: 121329060, Avg. loss: 0.069824\n",
      "Total training time: 62.67 seconds.\n",
      "-- Epoch 711\n",
      "Norm: 14.38, NNZs: 30, Bias: -129.785493, T: 121499946, Avg. loss: 0.069819\n",
      "Total training time: 62.75 seconds.\n",
      "-- Epoch 712\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.776181, T: 121670832, Avg. loss: 0.069813\n",
      "Total training time: 62.83 seconds.\n",
      "-- Epoch 713\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.766895, T: 121841718, Avg. loss: 0.069808\n",
      "Total training time: 62.92 seconds.\n",
      "-- Epoch 714\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.757619, T: 122012604, Avg. loss: 0.069803\n",
      "Total training time: 63.01 seconds.\n",
      "-- Epoch 715\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.748367, T: 122183490, Avg. loss: 0.069797\n",
      "Total training time: 63.10 seconds.\n",
      "-- Epoch 716\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.739112, T: 122354376, Avg. loss: 0.069792\n",
      "Total training time: 63.19 seconds.\n",
      "-- Epoch 717\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.729909, T: 122525262, Avg. loss: 0.069787\n",
      "Total training time: 63.28 seconds.\n",
      "-- Epoch 718\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.720703, T: 122696148, Avg. loss: 0.069781\n",
      "Total training time: 63.36 seconds.\n",
      "-- Epoch 719\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.711515, T: 122867034, Avg. loss: 0.069776\n",
      "Total training time: 63.45 seconds.\n",
      "-- Epoch 720\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.702326, T: 123037920, Avg. loss: 0.069771\n",
      "Total training time: 63.54 seconds.\n",
      "-- Epoch 721\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.693156, T: 123208806, Avg. loss: 0.069765\n",
      "Total training time: 63.62 seconds.\n",
      "-- Epoch 722\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.683979, T: 123379692, Avg. loss: 0.069760\n",
      "Total training time: 63.71 seconds.\n",
      "-- Epoch 723\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.674845, T: 123550578, Avg. loss: 0.069755\n",
      "Total training time: 63.79 seconds.\n",
      "-- Epoch 724\n",
      "Norm: 14.37, NNZs: 30, Bias: -129.665690, T: 123721464, Avg. loss: 0.069750\n",
      "Total training time: 63.88 seconds.\n",
      "-- Epoch 725\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.656565, T: 123892350, Avg. loss: 0.069744\n",
      "Total training time: 63.97 seconds.\n",
      "-- Epoch 726\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.647482, T: 124063236, Avg. loss: 0.069739\n",
      "Total training time: 64.05 seconds.\n",
      "-- Epoch 727\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.638413, T: 124234122, Avg. loss: 0.069734\n",
      "Total training time: 64.14 seconds.\n",
      "-- Epoch 728\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.629322, T: 124405008, Avg. loss: 0.069729\n",
      "Total training time: 64.23 seconds.\n",
      "-- Epoch 729\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.620265, T: 124575894, Avg. loss: 0.069723\n",
      "Total training time: 64.32 seconds.\n",
      "-- Epoch 730\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.611188, T: 124746780, Avg. loss: 0.069718\n",
      "Total training time: 64.40 seconds.\n",
      "-- Epoch 731\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.602152, T: 124917666, Avg. loss: 0.069713\n",
      "Total training time: 64.49 seconds.\n",
      "-- Epoch 732\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.593129, T: 125088552, Avg. loss: 0.069708\n",
      "Total training time: 64.58 seconds.\n",
      "-- Epoch 733\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.584129, T: 125259438, Avg. loss: 0.069703\n",
      "Total training time: 64.67 seconds.\n",
      "-- Epoch 734\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.575110, T: 125430324, Avg. loss: 0.069697\n",
      "Total training time: 64.76 seconds.\n",
      "-- Epoch 735\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.566125, T: 125601210, Avg. loss: 0.069692\n",
      "Total training time: 64.84 seconds.\n",
      "-- Epoch 736\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.557131, T: 125772096, Avg. loss: 0.069687\n",
      "Total training time: 64.93 seconds.\n",
      "-- Epoch 737\n",
      "Norm: 14.36, NNZs: 30, Bias: -129.548163, T: 125942982, Avg. loss: 0.069682\n",
      "Total training time: 65.02 seconds.\n",
      "-- Epoch 738\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.539205, T: 126113868, Avg. loss: 0.069677\n",
      "Total training time: 65.14 seconds.\n",
      "-- Epoch 739\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.530236, T: 126284754, Avg. loss: 0.069671\n",
      "Total training time: 65.23 seconds.\n",
      "-- Epoch 740\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.521314, T: 126455640, Avg. loss: 0.069666\n",
      "Total training time: 65.31 seconds.\n",
      "-- Epoch 741\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.512401, T: 126626526, Avg. loss: 0.069661\n",
      "Total training time: 65.40 seconds.\n",
      "-- Epoch 742\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.503474, T: 126797412, Avg. loss: 0.069656\n",
      "Total training time: 65.48 seconds.\n",
      "-- Epoch 743\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.494577, T: 126968298, Avg. loss: 0.069651\n",
      "Total training time: 65.56 seconds.\n",
      "-- Epoch 744\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.485701, T: 127139184, Avg. loss: 0.069646\n",
      "Total training time: 65.65 seconds.\n",
      "-- Epoch 745\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.476808, T: 127310070, Avg. loss: 0.069641\n",
      "Total training time: 65.73 seconds.\n",
      "-- Epoch 746\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.467928, T: 127480956, Avg. loss: 0.069636\n",
      "Total training time: 65.81 seconds.\n",
      "-- Epoch 747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.35, NNZs: 30, Bias: -129.459099, T: 127651842, Avg. loss: 0.069631\n",
      "Total training time: 65.89 seconds.\n",
      "-- Epoch 748\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.450270, T: 127822728, Avg. loss: 0.069625\n",
      "Total training time: 65.97 seconds.\n",
      "-- Epoch 749\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.441446, T: 127993614, Avg. loss: 0.069620\n",
      "Total training time: 66.05 seconds.\n",
      "-- Epoch 750\n",
      "Norm: 14.35, NNZs: 30, Bias: -129.432632, T: 128164500, Avg. loss: 0.069615\n",
      "Total training time: 66.14 seconds.\n",
      "-- Epoch 751\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.423847, T: 128335386, Avg. loss: 0.069610\n",
      "Total training time: 66.22 seconds.\n",
      "-- Epoch 752\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.415065, T: 128506272, Avg. loss: 0.069605\n",
      "Total training time: 66.30 seconds.\n",
      "-- Epoch 753\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.406303, T: 128677158, Avg. loss: 0.069600\n",
      "Total training time: 66.38 seconds.\n",
      "-- Epoch 754\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.397547, T: 128848044, Avg. loss: 0.069595\n",
      "Total training time: 66.47 seconds.\n",
      "-- Epoch 755\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.388797, T: 129018930, Avg. loss: 0.069590\n",
      "Total training time: 66.55 seconds.\n",
      "-- Epoch 756\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.380052, T: 129189816, Avg. loss: 0.069585\n",
      "Total training time: 66.63 seconds.\n",
      "-- Epoch 757\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.371316, T: 129360702, Avg. loss: 0.069580\n",
      "Total training time: 66.72 seconds.\n",
      "-- Epoch 758\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.362579, T: 129531588, Avg. loss: 0.069575\n",
      "Total training time: 66.80 seconds.\n",
      "-- Epoch 759\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.353876, T: 129702474, Avg. loss: 0.069570\n",
      "Total training time: 66.88 seconds.\n",
      "-- Epoch 760\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.345166, T: 129873360, Avg. loss: 0.069565\n",
      "Total training time: 66.96 seconds.\n",
      "-- Epoch 761\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.336461, T: 130044246, Avg. loss: 0.069560\n",
      "Total training time: 67.04 seconds.\n",
      "-- Epoch 762\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.327787, T: 130215132, Avg. loss: 0.069555\n",
      "Total training time: 67.12 seconds.\n",
      "-- Epoch 763\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.319111, T: 130386018, Avg. loss: 0.069550\n",
      "Total training time: 67.20 seconds.\n",
      "-- Epoch 764\n",
      "Norm: 14.34, NNZs: 30, Bias: -129.310453, T: 130556904, Avg. loss: 0.069545\n",
      "Total training time: 67.28 seconds.\n",
      "-- Epoch 765\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.301830, T: 130727790, Avg. loss: 0.069540\n",
      "Total training time: 67.37 seconds.\n",
      "-- Epoch 766\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.293186, T: 130898676, Avg. loss: 0.069535\n",
      "Total training time: 67.45 seconds.\n",
      "-- Epoch 767\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.284573, T: 131069562, Avg. loss: 0.069530\n",
      "Total training time: 67.53 seconds.\n",
      "-- Epoch 768\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.275976, T: 131240448, Avg. loss: 0.069525\n",
      "Total training time: 67.61 seconds.\n",
      "-- Epoch 769\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.267396, T: 131411334, Avg. loss: 0.069520\n",
      "Total training time: 67.69 seconds.\n",
      "-- Epoch 770\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.258821, T: 131582220, Avg. loss: 0.069515\n",
      "Total training time: 67.77 seconds.\n",
      "-- Epoch 771\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.250265, T: 131753106, Avg. loss: 0.069510\n",
      "Total training time: 67.86 seconds.\n",
      "-- Epoch 772\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.241700, T: 131923992, Avg. loss: 0.069505\n",
      "Total training time: 67.94 seconds.\n",
      "-- Epoch 773\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.233150, T: 132094878, Avg. loss: 0.069501\n",
      "Total training time: 68.02 seconds.\n",
      "-- Epoch 774\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.224609, T: 132265764, Avg. loss: 0.069496\n",
      "Total training time: 68.10 seconds.\n",
      "-- Epoch 775\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.216072, T: 132436650, Avg. loss: 0.069491\n",
      "Total training time: 68.18 seconds.\n",
      "-- Epoch 776\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.207541, T: 132607536, Avg. loss: 0.069486\n",
      "Total training time: 68.26 seconds.\n",
      "-- Epoch 777\n",
      "Norm: 14.33, NNZs: 30, Bias: -129.199052, T: 132778422, Avg. loss: 0.069481\n",
      "Total training time: 68.34 seconds.\n",
      "-- Epoch 778\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.190565, T: 132949308, Avg. loss: 0.069476\n",
      "Total training time: 68.43 seconds.\n",
      "-- Epoch 779\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.182059, T: 133120194, Avg. loss: 0.069471\n",
      "Total training time: 68.51 seconds.\n",
      "-- Epoch 780\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.173572, T: 133291080, Avg. loss: 0.069466\n",
      "Total training time: 68.59 seconds.\n",
      "-- Epoch 781\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.165093, T: 133461966, Avg. loss: 0.069462\n",
      "Total training time: 68.67 seconds.\n",
      "-- Epoch 782\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.156651, T: 133632852, Avg. loss: 0.069457\n",
      "Total training time: 68.75 seconds.\n",
      "-- Epoch 783\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.148217, T: 133803738, Avg. loss: 0.069452\n",
      "Total training time: 68.84 seconds.\n",
      "-- Epoch 784\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.139799, T: 133974624, Avg. loss: 0.069447\n",
      "Total training time: 68.92 seconds.\n",
      "-- Epoch 785\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.131397, T: 134145510, Avg. loss: 0.069442\n",
      "Total training time: 69.00 seconds.\n",
      "-- Epoch 786\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.122987, T: 134316396, Avg. loss: 0.069437\n",
      "Total training time: 69.08 seconds.\n",
      "-- Epoch 787\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.114589, T: 134487282, Avg. loss: 0.069432\n",
      "Total training time: 69.16 seconds.\n",
      "-- Epoch 788\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.106185, T: 134658168, Avg. loss: 0.069428\n",
      "Total training time: 69.24 seconds.\n",
      "-- Epoch 789\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.097818, T: 134829054, Avg. loss: 0.069423\n",
      "Total training time: 69.32 seconds.\n",
      "-- Epoch 790\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.089453, T: 134999940, Avg. loss: 0.069418\n",
      "Total training time: 69.41 seconds.\n",
      "-- Epoch 791\n",
      "Norm: 14.32, NNZs: 30, Bias: -129.081110, T: 135170826, Avg. loss: 0.069413\n",
      "Total training time: 69.49 seconds.\n",
      "-- Epoch 792\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.072770, T: 135341712, Avg. loss: 0.069408\n",
      "Total training time: 69.57 seconds.\n",
      "-- Epoch 793\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.064429, T: 135512598, Avg. loss: 0.069404\n",
      "Total training time: 69.65 seconds.\n",
      "-- Epoch 794\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.056138, T: 135683484, Avg. loss: 0.069399\n",
      "Total training time: 69.73 seconds.\n",
      "-- Epoch 795\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.047845, T: 135854370, Avg. loss: 0.069394\n",
      "Total training time: 69.81 seconds.\n",
      "-- Epoch 796\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.039545, T: 136025256, Avg. loss: 0.069389\n",
      "Total training time: 69.89 seconds.\n",
      "-- Epoch 797\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.031244, T: 136196142, Avg. loss: 0.069385\n",
      "Total training time: 69.98 seconds.\n",
      "-- Epoch 798\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.022980, T: 136367028, Avg. loss: 0.069380\n",
      "Total training time: 70.07 seconds.\n",
      "-- Epoch 799\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.014677, T: 136537914, Avg. loss: 0.069375\n",
      "Total training time: 70.15 seconds.\n",
      "-- Epoch 800\n",
      "Norm: 14.31, NNZs: 30, Bias: -129.006410, T: 136708800, Avg. loss: 0.069370\n",
      "Total training time: 70.23 seconds.\n",
      "-- Epoch 801\n",
      "Norm: 14.31, NNZs: 30, Bias: -128.998158, T: 136879686, Avg. loss: 0.069366\n",
      "Total training time: 70.32 seconds.\n",
      "-- Epoch 802\n",
      "Norm: 14.31, NNZs: 30, Bias: -128.989946, T: 137050572, Avg. loss: 0.069361\n",
      "Total training time: 70.40 seconds.\n",
      "-- Epoch 803\n",
      "Norm: 14.31, NNZs: 30, Bias: -128.981688, T: 137221458, Avg. loss: 0.069356\n",
      "Total training time: 70.48 seconds.\n",
      "-- Epoch 804\n",
      "Norm: 14.31, NNZs: 30, Bias: -128.973499, T: 137392344, Avg. loss: 0.069351\n",
      "Total training time: 70.57 seconds.\n",
      "-- Epoch 805\n",
      "Norm: 14.31, NNZs: 30, Bias: -128.965283, T: 137563230, Avg. loss: 0.069347\n",
      "Total training time: 70.65 seconds.\n",
      "-- Epoch 806\n",
      "Norm: 14.31, NNZs: 30, Bias: -128.957082, T: 137734116, Avg. loss: 0.069342\n",
      "Total training time: 70.73 seconds.\n",
      "-- Epoch 807\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.948918, T: 137905002, Avg. loss: 0.069337\n",
      "Total training time: 70.82 seconds.\n",
      "-- Epoch 808\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.940768, T: 138075888, Avg. loss: 0.069333\n",
      "Total training time: 70.90 seconds.\n",
      "-- Epoch 809\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.932619, T: 138246774, Avg. loss: 0.069328\n",
      "Total training time: 70.98 seconds.\n",
      "-- Epoch 810\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.924484, T: 138417660, Avg. loss: 0.069323\n",
      "Total training time: 71.06 seconds.\n",
      "-- Epoch 811\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.916340, T: 138588546, Avg. loss: 0.069319\n",
      "Total training time: 71.14 seconds.\n",
      "-- Epoch 812\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.908192, T: 138759432, Avg. loss: 0.069314\n",
      "Total training time: 71.23 seconds.\n",
      "-- Epoch 813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.30, NNZs: 30, Bias: -128.900049, T: 138930318, Avg. loss: 0.069309\n",
      "Total training time: 71.31 seconds.\n",
      "-- Epoch 814\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.891918, T: 139101204, Avg. loss: 0.069305\n",
      "Total training time: 71.39 seconds.\n",
      "-- Epoch 815\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.883821, T: 139272090, Avg. loss: 0.069300\n",
      "Total training time: 71.47 seconds.\n",
      "-- Epoch 816\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.875701, T: 139442976, Avg. loss: 0.069295\n",
      "Total training time: 71.56 seconds.\n",
      "-- Epoch 817\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.867596, T: 139613862, Avg. loss: 0.069291\n",
      "Total training time: 71.64 seconds.\n",
      "-- Epoch 818\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.859530, T: 139784748, Avg. loss: 0.069286\n",
      "Total training time: 71.72 seconds.\n",
      "-- Epoch 819\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.851468, T: 139955634, Avg. loss: 0.069281\n",
      "Total training time: 71.80 seconds.\n",
      "-- Epoch 820\n",
      "Norm: 14.30, NNZs: 30, Bias: -128.843428, T: 140126520, Avg. loss: 0.069277\n",
      "Total training time: 71.88 seconds.\n",
      "-- Epoch 821\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.835397, T: 140297406, Avg. loss: 0.069272\n",
      "Total training time: 71.97 seconds.\n",
      "-- Epoch 822\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.827348, T: 140468292, Avg. loss: 0.069268\n",
      "Total training time: 72.05 seconds.\n",
      "-- Epoch 823\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.819313, T: 140639178, Avg. loss: 0.069263\n",
      "Total training time: 72.13 seconds.\n",
      "-- Epoch 824\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.811288, T: 140810064, Avg. loss: 0.069258\n",
      "Total training time: 72.21 seconds.\n",
      "-- Epoch 825\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.803285, T: 140980950, Avg. loss: 0.069254\n",
      "Total training time: 72.29 seconds.\n",
      "-- Epoch 826\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.795290, T: 141151836, Avg. loss: 0.069249\n",
      "Total training time: 72.38 seconds.\n",
      "-- Epoch 827\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.787319, T: 141322722, Avg. loss: 0.069245\n",
      "Total training time: 72.46 seconds.\n",
      "-- Epoch 828\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.779338, T: 141493608, Avg. loss: 0.069240\n",
      "Total training time: 72.54 seconds.\n",
      "-- Epoch 829\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.771345, T: 141664494, Avg. loss: 0.069236\n",
      "Total training time: 72.63 seconds.\n",
      "-- Epoch 830\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.763396, T: 141835380, Avg. loss: 0.069231\n",
      "Total training time: 72.71 seconds.\n",
      "-- Epoch 831\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.755486, T: 142006266, Avg. loss: 0.069226\n",
      "Total training time: 72.79 seconds.\n",
      "-- Epoch 832\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.747570, T: 142177152, Avg. loss: 0.069222\n",
      "Total training time: 72.88 seconds.\n",
      "-- Epoch 833\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.739642, T: 142348038, Avg. loss: 0.069217\n",
      "Total training time: 72.96 seconds.\n",
      "-- Epoch 834\n",
      "Norm: 14.29, NNZs: 30, Bias: -128.731713, T: 142518924, Avg. loss: 0.069213\n",
      "Total training time: 73.05 seconds.\n",
      "-- Epoch 835\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.723789, T: 142689810, Avg. loss: 0.069208\n",
      "Total training time: 73.13 seconds.\n",
      "-- Epoch 836\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.715885, T: 142860696, Avg. loss: 0.069204\n",
      "Total training time: 73.21 seconds.\n",
      "-- Epoch 837\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.707989, T: 143031582, Avg. loss: 0.069199\n",
      "Total training time: 73.29 seconds.\n",
      "-- Epoch 838\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.700106, T: 143202468, Avg. loss: 0.069195\n",
      "Total training time: 73.38 seconds.\n",
      "-- Epoch 839\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.692224, T: 143373354, Avg. loss: 0.069190\n",
      "Total training time: 73.46 seconds.\n",
      "-- Epoch 840\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.684354, T: 143544240, Avg. loss: 0.069186\n",
      "Total training time: 73.54 seconds.\n",
      "-- Epoch 841\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.676540, T: 143715126, Avg. loss: 0.069181\n",
      "Total training time: 73.62 seconds.\n",
      "-- Epoch 842\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.668704, T: 143886012, Avg. loss: 0.069177\n",
      "Total training time: 73.70 seconds.\n",
      "-- Epoch 843\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.660870, T: 144056898, Avg. loss: 0.069172\n",
      "Total training time: 73.79 seconds.\n",
      "-- Epoch 844\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.653050, T: 144227784, Avg. loss: 0.069168\n",
      "Total training time: 73.87 seconds.\n",
      "-- Epoch 845\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.645251, T: 144398670, Avg. loss: 0.069163\n",
      "Total training time: 73.95 seconds.\n",
      "-- Epoch 846\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.637436, T: 144569556, Avg. loss: 0.069159\n",
      "Total training time: 74.04 seconds.\n",
      "-- Epoch 847\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.629663, T: 144740442, Avg. loss: 0.069154\n",
      "Total training time: 74.13 seconds.\n",
      "-- Epoch 848\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.621876, T: 144911328, Avg. loss: 0.069150\n",
      "Total training time: 74.21 seconds.\n",
      "-- Epoch 849\n",
      "Norm: 14.28, NNZs: 30, Bias: -128.614094, T: 145082214, Avg. loss: 0.069145\n",
      "Total training time: 74.30 seconds.\n",
      "-- Epoch 850\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.606333, T: 145253100, Avg. loss: 0.069141\n",
      "Total training time: 74.38 seconds.\n",
      "-- Epoch 851\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.598568, T: 145423986, Avg. loss: 0.069137\n",
      "Total training time: 74.47 seconds.\n",
      "-- Epoch 852\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.590827, T: 145594872, Avg. loss: 0.069132\n",
      "Total training time: 74.55 seconds.\n",
      "-- Epoch 853\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.583071, T: 145765758, Avg. loss: 0.069128\n",
      "Total training time: 74.63 seconds.\n",
      "-- Epoch 854\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.575332, T: 145936644, Avg. loss: 0.069123\n",
      "Total training time: 74.71 seconds.\n",
      "-- Epoch 855\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.567619, T: 146107530, Avg. loss: 0.069119\n",
      "Total training time: 74.79 seconds.\n",
      "-- Epoch 856\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.559899, T: 146278416, Avg. loss: 0.069114\n",
      "Total training time: 74.88 seconds.\n",
      "-- Epoch 857\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.552206, T: 146449302, Avg. loss: 0.069110\n",
      "Total training time: 74.96 seconds.\n",
      "-- Epoch 858\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.544486, T: 146620188, Avg. loss: 0.069106\n",
      "Total training time: 75.05 seconds.\n",
      "-- Epoch 859\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.536809, T: 146791074, Avg. loss: 0.069101\n",
      "Total training time: 75.13 seconds.\n",
      "-- Epoch 860\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.529166, T: 146961960, Avg. loss: 0.069097\n",
      "Total training time: 75.21 seconds.\n",
      "-- Epoch 861\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.521481, T: 147132846, Avg. loss: 0.069092\n",
      "Total training time: 75.30 seconds.\n",
      "-- Epoch 862\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.513837, T: 147303732, Avg. loss: 0.069088\n",
      "Total training time: 75.39 seconds.\n",
      "-- Epoch 863\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.506179, T: 147474618, Avg. loss: 0.069084\n",
      "Total training time: 75.47 seconds.\n",
      "-- Epoch 864\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.498533, T: 147645504, Avg. loss: 0.069079\n",
      "Total training time: 75.56 seconds.\n",
      "-- Epoch 865\n",
      "Norm: 14.27, NNZs: 30, Bias: -128.490889, T: 147816390, Avg. loss: 0.069075\n",
      "Total training time: 75.64 seconds.\n",
      "-- Epoch 866\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.483260, T: 147987276, Avg. loss: 0.069071\n",
      "Total training time: 75.72 seconds.\n",
      "-- Epoch 867\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.475669, T: 148158162, Avg. loss: 0.069066\n",
      "Total training time: 75.80 seconds.\n",
      "-- Epoch 868\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.468070, T: 148329048, Avg. loss: 0.069062\n",
      "Total training time: 75.88 seconds.\n",
      "-- Epoch 869\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.460486, T: 148499934, Avg. loss: 0.069057\n",
      "Total training time: 75.97 seconds.\n",
      "-- Epoch 870\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.452888, T: 148670820, Avg. loss: 0.069053\n",
      "Total training time: 76.05 seconds.\n",
      "-- Epoch 871\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.445325, T: 148841706, Avg. loss: 0.069049\n",
      "Total training time: 76.13 seconds.\n",
      "-- Epoch 872\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.437766, T: 149012592, Avg. loss: 0.069044\n",
      "Total training time: 76.22 seconds.\n",
      "-- Epoch 873\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.430208, T: 149183478, Avg. loss: 0.069040\n",
      "Total training time: 76.30 seconds.\n",
      "-- Epoch 874\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.422644, T: 149354364, Avg. loss: 0.069036\n",
      "Total training time: 76.38 seconds.\n",
      "-- Epoch 875\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.415121, T: 149525250, Avg. loss: 0.069031\n",
      "Total training time: 76.46 seconds.\n",
      "-- Epoch 876\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.407593, T: 149696136, Avg. loss: 0.069027\n",
      "Total training time: 76.54 seconds.\n",
      "-- Epoch 877\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.400076, T: 149867022, Avg. loss: 0.069023\n",
      "Total training time: 76.62 seconds.\n",
      "-- Epoch 878\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.392547, T: 150037908, Avg. loss: 0.069019\n",
      "Total training time: 76.71 seconds.\n",
      "-- Epoch 879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.26, NNZs: 30, Bias: -128.385034, T: 150208794, Avg. loss: 0.069014\n",
      "Total training time: 76.79 seconds.\n",
      "-- Epoch 880\n",
      "Norm: 14.26, NNZs: 30, Bias: -128.377519, T: 150379680, Avg. loss: 0.069010\n",
      "Total training time: 76.87 seconds.\n",
      "-- Epoch 881\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.370013, T: 150550566, Avg. loss: 0.069006\n",
      "Total training time: 76.95 seconds.\n",
      "-- Epoch 882\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.362524, T: 150721452, Avg. loss: 0.069001\n",
      "Total training time: 77.03 seconds.\n",
      "-- Epoch 883\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.355042, T: 150892338, Avg. loss: 0.068997\n",
      "Total training time: 77.12 seconds.\n",
      "-- Epoch 884\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.347569, T: 151063224, Avg. loss: 0.068993\n",
      "Total training time: 77.20 seconds.\n",
      "-- Epoch 885\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.340097, T: 151234110, Avg. loss: 0.068989\n",
      "Total training time: 77.28 seconds.\n",
      "-- Epoch 886\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.332660, T: 151404996, Avg. loss: 0.068984\n",
      "Total training time: 77.36 seconds.\n",
      "-- Epoch 887\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.325217, T: 151575882, Avg. loss: 0.068980\n",
      "Total training time: 77.45 seconds.\n",
      "-- Epoch 888\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.317789, T: 151746768, Avg. loss: 0.068976\n",
      "Total training time: 77.53 seconds.\n",
      "-- Epoch 889\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.310362, T: 151917654, Avg. loss: 0.068972\n",
      "Total training time: 77.62 seconds.\n",
      "-- Epoch 890\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.302945, T: 152088540, Avg. loss: 0.068967\n",
      "Total training time: 77.70 seconds.\n",
      "-- Epoch 891\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.295539, T: 152259426, Avg. loss: 0.068963\n",
      "Total training time: 77.78 seconds.\n",
      "-- Epoch 892\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.288146, T: 152430312, Avg. loss: 0.068959\n",
      "Total training time: 77.86 seconds.\n",
      "-- Epoch 893\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.280777, T: 152601198, Avg. loss: 0.068955\n",
      "Total training time: 77.94 seconds.\n",
      "-- Epoch 894\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.273402, T: 152772084, Avg. loss: 0.068950\n",
      "Total training time: 78.03 seconds.\n",
      "-- Epoch 895\n",
      "Norm: 14.25, NNZs: 30, Bias: -128.266042, T: 152942970, Avg. loss: 0.068946\n",
      "Total training time: 78.11 seconds.\n",
      "-- Epoch 896\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.258688, T: 153113856, Avg. loss: 0.068942\n",
      "Total training time: 78.19 seconds.\n",
      "-- Epoch 897\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.251329, T: 153284742, Avg. loss: 0.068938\n",
      "Total training time: 78.27 seconds.\n",
      "-- Epoch 898\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.243992, T: 153455628, Avg. loss: 0.068934\n",
      "Total training time: 78.35 seconds.\n",
      "-- Epoch 899\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.236632, T: 153626514, Avg. loss: 0.068929\n",
      "Total training time: 78.44 seconds.\n",
      "-- Epoch 900\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.229282, T: 153797400, Avg. loss: 0.068925\n",
      "Total training time: 78.53 seconds.\n",
      "-- Epoch 901\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.221949, T: 153968286, Avg. loss: 0.068921\n",
      "Total training time: 78.61 seconds.\n",
      "-- Epoch 902\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.214651, T: 154139172, Avg. loss: 0.068917\n",
      "Total training time: 78.69 seconds.\n",
      "-- Epoch 903\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.207342, T: 154310058, Avg. loss: 0.068913\n",
      "Total training time: 78.78 seconds.\n",
      "-- Epoch 904\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.200064, T: 154480944, Avg. loss: 0.068909\n",
      "Total training time: 78.86 seconds.\n",
      "-- Epoch 905\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.192785, T: 154651830, Avg. loss: 0.068904\n",
      "Total training time: 78.95 seconds.\n",
      "-- Epoch 906\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.185480, T: 154822716, Avg. loss: 0.068900\n",
      "Total training time: 79.03 seconds.\n",
      "-- Epoch 907\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.178219, T: 154993602, Avg. loss: 0.068896\n",
      "Total training time: 79.11 seconds.\n",
      "-- Epoch 908\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.170964, T: 155164488, Avg. loss: 0.068892\n",
      "Total training time: 79.20 seconds.\n",
      "-- Epoch 909\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.163713, T: 155335374, Avg. loss: 0.068888\n",
      "Total training time: 79.28 seconds.\n",
      "-- Epoch 910\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.156491, T: 155506260, Avg. loss: 0.068884\n",
      "Total training time: 79.36 seconds.\n",
      "-- Epoch 911\n",
      "Norm: 14.24, NNZs: 30, Bias: -128.149264, T: 155677146, Avg. loss: 0.068879\n",
      "Total training time: 79.44 seconds.\n",
      "-- Epoch 912\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.142021, T: 155848032, Avg. loss: 0.068875\n",
      "Total training time: 79.52 seconds.\n",
      "-- Epoch 913\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.134794, T: 156018918, Avg. loss: 0.068871\n",
      "Total training time: 79.61 seconds.\n",
      "-- Epoch 914\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.127558, T: 156189804, Avg. loss: 0.068867\n",
      "Total training time: 79.69 seconds.\n",
      "-- Epoch 915\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.120332, T: 156360690, Avg. loss: 0.068863\n",
      "Total training time: 79.78 seconds.\n",
      "-- Epoch 916\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.113132, T: 156531576, Avg. loss: 0.068859\n",
      "Total training time: 79.86 seconds.\n",
      "-- Epoch 917\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.105940, T: 156702462, Avg. loss: 0.068855\n",
      "Total training time: 79.94 seconds.\n",
      "-- Epoch 918\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.098746, T: 156873348, Avg. loss: 0.068851\n",
      "Total training time: 80.02 seconds.\n",
      "-- Epoch 919\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.091567, T: 157044234, Avg. loss: 0.068847\n",
      "Total training time: 80.10 seconds.\n",
      "-- Epoch 920\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.084397, T: 157215120, Avg. loss: 0.068842\n",
      "Total training time: 80.19 seconds.\n",
      "-- Epoch 921\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.077237, T: 157386006, Avg. loss: 0.068838\n",
      "Total training time: 80.27 seconds.\n",
      "-- Epoch 922\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.070078, T: 157556892, Avg. loss: 0.068834\n",
      "Total training time: 80.35 seconds.\n",
      "-- Epoch 923\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.062954, T: 157727778, Avg. loss: 0.068830\n",
      "Total training time: 80.43 seconds.\n",
      "-- Epoch 924\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.055824, T: 157898664, Avg. loss: 0.068826\n",
      "Total training time: 80.51 seconds.\n",
      "-- Epoch 925\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.048682, T: 158069550, Avg. loss: 0.068822\n",
      "Total training time: 80.59 seconds.\n",
      "-- Epoch 926\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.041551, T: 158240436, Avg. loss: 0.068818\n",
      "Total training time: 80.68 seconds.\n",
      "-- Epoch 927\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.034435, T: 158411322, Avg. loss: 0.068814\n",
      "Total training time: 80.76 seconds.\n",
      "-- Epoch 928\n",
      "Norm: 14.23, NNZs: 30, Bias: -128.027321, T: 158582208, Avg. loss: 0.068810\n",
      "Total training time: 80.84 seconds.\n",
      "-- Epoch 929\n",
      "Norm: 14.22, NNZs: 30, Bias: -128.020217, T: 158753094, Avg. loss: 0.068806\n",
      "Total training time: 80.92 seconds.\n",
      "-- Epoch 930\n",
      "Norm: 14.22, NNZs: 30, Bias: -128.013116, T: 158923980, Avg. loss: 0.068802\n",
      "Total training time: 81.00 seconds.\n",
      "-- Epoch 931\n",
      "Norm: 14.22, NNZs: 30, Bias: -128.006019, T: 159094866, Avg. loss: 0.068798\n",
      "Total training time: 81.08 seconds.\n",
      "-- Epoch 932\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.998953, T: 159265752, Avg. loss: 0.068794\n",
      "Total training time: 81.16 seconds.\n",
      "-- Epoch 933\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.991888, T: 159436638, Avg. loss: 0.068790\n",
      "Total training time: 81.25 seconds.\n",
      "-- Epoch 934\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.984832, T: 159607524, Avg. loss: 0.068786\n",
      "Total training time: 81.33 seconds.\n",
      "-- Epoch 935\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.977773, T: 159778410, Avg. loss: 0.068782\n",
      "Total training time: 81.41 seconds.\n",
      "-- Epoch 936\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.970727, T: 159949296, Avg. loss: 0.068778\n",
      "Total training time: 81.49 seconds.\n",
      "-- Epoch 937\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.963683, T: 160120182, Avg. loss: 0.068774\n",
      "Total training time: 81.57 seconds.\n",
      "-- Epoch 938\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.956661, T: 160291068, Avg. loss: 0.068770\n",
      "Total training time: 81.66 seconds.\n",
      "-- Epoch 939\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.949624, T: 160461954, Avg. loss: 0.068766\n",
      "Total training time: 81.74 seconds.\n",
      "-- Epoch 940\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.942609, T: 160632840, Avg. loss: 0.068762\n",
      "Total training time: 81.82 seconds.\n",
      "-- Epoch 941\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.935609, T: 160803726, Avg. loss: 0.068758\n",
      "Total training time: 81.91 seconds.\n",
      "-- Epoch 942\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.928617, T: 160974612, Avg. loss: 0.068754\n",
      "Total training time: 81.99 seconds.\n",
      "-- Epoch 943\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.921628, T: 161145498, Avg. loss: 0.068750\n",
      "Total training time: 82.07 seconds.\n",
      "-- Epoch 944\n",
      "Norm: 14.22, NNZs: 30, Bias: -127.914633, T: 161316384, Avg. loss: 0.068746\n",
      "Total training time: 82.15 seconds.\n",
      "-- Epoch 945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.21, NNZs: 30, Bias: -127.907639, T: 161487270, Avg. loss: 0.068742\n",
      "Total training time: 82.24 seconds.\n",
      "-- Epoch 946\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.900668, T: 161658156, Avg. loss: 0.068738\n",
      "Total training time: 82.32 seconds.\n",
      "-- Epoch 947\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.893690, T: 161829042, Avg. loss: 0.068734\n",
      "Total training time: 82.40 seconds.\n",
      "-- Epoch 948\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.886726, T: 161999928, Avg. loss: 0.068730\n",
      "Total training time: 82.48 seconds.\n",
      "-- Epoch 949\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.879780, T: 162170814, Avg. loss: 0.068726\n",
      "Total training time: 82.56 seconds.\n",
      "-- Epoch 950\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.872841, T: 162341700, Avg. loss: 0.068722\n",
      "Total training time: 82.65 seconds.\n",
      "-- Epoch 951\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.865909, T: 162512586, Avg. loss: 0.068718\n",
      "Total training time: 82.73 seconds.\n",
      "-- Epoch 952\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.858987, T: 162683472, Avg. loss: 0.068714\n",
      "Total training time: 82.81 seconds.\n",
      "-- Epoch 953\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.852062, T: 162854358, Avg. loss: 0.068710\n",
      "Total training time: 82.89 seconds.\n",
      "-- Epoch 954\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.845133, T: 163025244, Avg. loss: 0.068706\n",
      "Total training time: 82.98 seconds.\n",
      "-- Epoch 955\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.838221, T: 163196130, Avg. loss: 0.068702\n",
      "Total training time: 83.06 seconds.\n",
      "-- Epoch 956\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.831334, T: 163367016, Avg. loss: 0.068698\n",
      "Total training time: 83.14 seconds.\n",
      "-- Epoch 957\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.824434, T: 163537902, Avg. loss: 0.068694\n",
      "Total training time: 83.23 seconds.\n",
      "-- Epoch 958\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.817561, T: 163708788, Avg. loss: 0.068690\n",
      "Total training time: 83.31 seconds.\n",
      "-- Epoch 959\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.810704, T: 163879674, Avg. loss: 0.068686\n",
      "Total training time: 83.39 seconds.\n",
      "-- Epoch 960\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.803834, T: 164050560, Avg. loss: 0.068682\n",
      "Total training time: 83.47 seconds.\n",
      "-- Epoch 961\n",
      "Norm: 14.21, NNZs: 30, Bias: -127.796979, T: 164221446, Avg. loss: 0.068678\n",
      "Total training time: 83.55 seconds.\n",
      "-- Epoch 962\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.790128, T: 164392332, Avg. loss: 0.068675\n",
      "Total training time: 83.64 seconds.\n",
      "-- Epoch 963\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.783277, T: 164563218, Avg. loss: 0.068671\n",
      "Total training time: 83.72 seconds.\n",
      "-- Epoch 964\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.776451, T: 164734104, Avg. loss: 0.068667\n",
      "Total training time: 83.80 seconds.\n",
      "-- Epoch 965\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.769601, T: 164904990, Avg. loss: 0.068663\n",
      "Total training time: 83.88 seconds.\n",
      "-- Epoch 966\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.762787, T: 165075876, Avg. loss: 0.068659\n",
      "Total training time: 83.97 seconds.\n",
      "-- Epoch 967\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.755952, T: 165246762, Avg. loss: 0.068655\n",
      "Total training time: 84.05 seconds.\n",
      "-- Epoch 968\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.749136, T: 165417648, Avg. loss: 0.068651\n",
      "Total training time: 84.13 seconds.\n",
      "-- Epoch 969\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.742342, T: 165588534, Avg. loss: 0.068647\n",
      "Total training time: 84.21 seconds.\n",
      "-- Epoch 970\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.735553, T: 165759420, Avg. loss: 0.068643\n",
      "Total training time: 84.30 seconds.\n",
      "-- Epoch 971\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.728751, T: 165930306, Avg. loss: 0.068640\n",
      "Total training time: 84.38 seconds.\n",
      "-- Epoch 972\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.721968, T: 166101192, Avg. loss: 0.068636\n",
      "Total training time: 84.46 seconds.\n",
      "-- Epoch 973\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.715189, T: 166272078, Avg. loss: 0.068632\n",
      "Total training time: 84.55 seconds.\n",
      "-- Epoch 974\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.708416, T: 166442964, Avg. loss: 0.068628\n",
      "Total training time: 84.63 seconds.\n",
      "-- Epoch 975\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.701651, T: 166613850, Avg. loss: 0.068624\n",
      "Total training time: 84.71 seconds.\n",
      "-- Epoch 976\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.694887, T: 166784736, Avg. loss: 0.068620\n",
      "Total training time: 84.79 seconds.\n",
      "-- Epoch 977\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.688144, T: 166955622, Avg. loss: 0.068616\n",
      "Total training time: 84.88 seconds.\n",
      "-- Epoch 978\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.681402, T: 167126508, Avg. loss: 0.068613\n",
      "Total training time: 84.96 seconds.\n",
      "-- Epoch 979\n",
      "Norm: 14.20, NNZs: 30, Bias: -127.674651, T: 167297394, Avg. loss: 0.068609\n",
      "Total training time: 85.04 seconds.\n",
      "-- Epoch 980\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.667920, T: 167468280, Avg. loss: 0.068605\n",
      "Total training time: 85.12 seconds.\n",
      "-- Epoch 981\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.661198, T: 167639166, Avg. loss: 0.068601\n",
      "Total training time: 85.20 seconds.\n",
      "-- Epoch 982\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.654497, T: 167810052, Avg. loss: 0.068597\n",
      "Total training time: 85.28 seconds.\n",
      "-- Epoch 983\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.647784, T: 167980938, Avg. loss: 0.068593\n",
      "Total training time: 85.36 seconds.\n",
      "-- Epoch 984\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.641066, T: 168151824, Avg. loss: 0.068590\n",
      "Total training time: 85.44 seconds.\n",
      "-- Epoch 985\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.634374, T: 168322710, Avg. loss: 0.068586\n",
      "Total training time: 85.53 seconds.\n",
      "-- Epoch 986\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.627697, T: 168493596, Avg. loss: 0.068582\n",
      "Total training time: 85.61 seconds.\n",
      "-- Epoch 987\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.621029, T: 168664482, Avg. loss: 0.068578\n",
      "Total training time: 85.69 seconds.\n",
      "-- Epoch 988\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.614359, T: 168835368, Avg. loss: 0.068574\n",
      "Total training time: 85.77 seconds.\n",
      "-- Epoch 989\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.607687, T: 169006254, Avg. loss: 0.068571\n",
      "Total training time: 85.86 seconds.\n",
      "-- Epoch 990\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.601016, T: 169177140, Avg. loss: 0.068567\n",
      "Total training time: 85.94 seconds.\n",
      "-- Epoch 991\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.594363, T: 169348026, Avg. loss: 0.068563\n",
      "Total training time: 86.02 seconds.\n",
      "-- Epoch 992\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.587731, T: 169518912, Avg. loss: 0.068559\n",
      "Total training time: 86.10 seconds.\n",
      "-- Epoch 993\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.581091, T: 169689798, Avg. loss: 0.068555\n",
      "Total training time: 86.18 seconds.\n",
      "-- Epoch 994\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.574465, T: 169860684, Avg. loss: 0.068552\n",
      "Total training time: 86.27 seconds.\n",
      "-- Epoch 995\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.567839, T: 170031570, Avg. loss: 0.068548\n",
      "Total training time: 86.35 seconds.\n",
      "-- Epoch 996\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.561210, T: 170202456, Avg. loss: 0.068544\n",
      "Total training time: 86.43 seconds.\n",
      "-- Epoch 997\n",
      "Norm: 14.19, NNZs: 30, Bias: -127.554592, T: 170373342, Avg. loss: 0.068540\n",
      "Total training time: 86.51 seconds.\n",
      "-- Epoch 998\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.547982, T: 170544228, Avg. loss: 0.068537\n",
      "Total training time: 86.59 seconds.\n",
      "-- Epoch 999\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.541402, T: 170715114, Avg. loss: 0.068533\n",
      "Total training time: 86.68 seconds.\n",
      "-- Epoch 1000\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.534822, T: 170886000, Avg. loss: 0.068529\n",
      "Total training time: 86.76 seconds.\n",
      "-- Epoch 1001\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.528267, T: 171056886, Avg. loss: 0.068525\n",
      "Total training time: 86.84 seconds.\n",
      "-- Epoch 1002\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.521679, T: 171227772, Avg. loss: 0.068522\n",
      "Total training time: 86.92 seconds.\n",
      "-- Epoch 1003\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.515096, T: 171398658, Avg. loss: 0.068518\n",
      "Total training time: 87.00 seconds.\n",
      "-- Epoch 1004\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.508549, T: 171569544, Avg. loss: 0.068514\n",
      "Total training time: 87.08 seconds.\n",
      "-- Epoch 1005\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.501986, T: 171740430, Avg. loss: 0.068510\n",
      "Total training time: 87.17 seconds.\n",
      "-- Epoch 1006\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.495433, T: 171911316, Avg. loss: 0.068507\n",
      "Total training time: 87.25 seconds.\n",
      "-- Epoch 1007\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.488880, T: 172082202, Avg. loss: 0.068503\n",
      "Total training time: 87.33 seconds.\n",
      "-- Epoch 1008\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.482333, T: 172253088, Avg. loss: 0.068499\n",
      "Total training time: 87.41 seconds.\n",
      "-- Epoch 1009\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.475798, T: 172423974, Avg. loss: 0.068496\n",
      "Total training time: 87.49 seconds.\n",
      "-- Epoch 1010\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.469281, T: 172594860, Avg. loss: 0.068492\n",
      "Total training time: 87.58 seconds.\n",
      "-- Epoch 1011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.18, NNZs: 30, Bias: -127.462755, T: 172765746, Avg. loss: 0.068488\n",
      "Total training time: 87.66 seconds.\n",
      "-- Epoch 1012\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.456224, T: 172936632, Avg. loss: 0.068484\n",
      "Total training time: 87.74 seconds.\n",
      "-- Epoch 1013\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.449730, T: 173107518, Avg. loss: 0.068481\n",
      "Total training time: 87.82 seconds.\n",
      "-- Epoch 1014\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.443243, T: 173278404, Avg. loss: 0.068477\n",
      "Total training time: 87.90 seconds.\n",
      "-- Epoch 1015\n",
      "Norm: 14.18, NNZs: 30, Bias: -127.436747, T: 173449290, Avg. loss: 0.068473\n",
      "Total training time: 87.99 seconds.\n",
      "-- Epoch 1016\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.430246, T: 173620176, Avg. loss: 0.068470\n",
      "Total training time: 88.07 seconds.\n",
      "-- Epoch 1017\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.423777, T: 173791062, Avg. loss: 0.068466\n",
      "Total training time: 88.15 seconds.\n",
      "-- Epoch 1018\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.417307, T: 173961948, Avg. loss: 0.068462\n",
      "Total training time: 88.23 seconds.\n",
      "-- Epoch 1019\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.410838, T: 174132834, Avg. loss: 0.068459\n",
      "Total training time: 88.32 seconds.\n",
      "-- Epoch 1020\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.404386, T: 174303720, Avg. loss: 0.068455\n",
      "Total training time: 88.40 seconds.\n",
      "-- Epoch 1021\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.397932, T: 174474606, Avg. loss: 0.068451\n",
      "Total training time: 88.48 seconds.\n",
      "-- Epoch 1022\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.391496, T: 174645492, Avg. loss: 0.068448\n",
      "Total training time: 88.56 seconds.\n",
      "-- Epoch 1023\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.385061, T: 174816378, Avg. loss: 0.068444\n",
      "Total training time: 88.64 seconds.\n",
      "-- Epoch 1024\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.378623, T: 174987264, Avg. loss: 0.068440\n",
      "Total training time: 88.72 seconds.\n",
      "-- Epoch 1025\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.372189, T: 175158150, Avg. loss: 0.068437\n",
      "Total training time: 88.80 seconds.\n",
      "-- Epoch 1026\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.365760, T: 175329036, Avg. loss: 0.068433\n",
      "Total training time: 88.88 seconds.\n",
      "-- Epoch 1027\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.359338, T: 175499922, Avg. loss: 0.068429\n",
      "Total training time: 88.97 seconds.\n",
      "-- Epoch 1028\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.352921, T: 175670808, Avg. loss: 0.068426\n",
      "Total training time: 89.05 seconds.\n",
      "-- Epoch 1029\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.346523, T: 175841694, Avg. loss: 0.068422\n",
      "Total training time: 89.13 seconds.\n",
      "-- Epoch 1030\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.340116, T: 176012580, Avg. loss: 0.068418\n",
      "Total training time: 89.21 seconds.\n",
      "-- Epoch 1031\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.333743, T: 176183466, Avg. loss: 0.068415\n",
      "Total training time: 89.29 seconds.\n",
      "-- Epoch 1032\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.327369, T: 176354352, Avg. loss: 0.068411\n",
      "Total training time: 89.37 seconds.\n",
      "-- Epoch 1033\n",
      "Norm: 14.17, NNZs: 30, Bias: -127.320989, T: 176525238, Avg. loss: 0.068407\n",
      "Total training time: 89.46 seconds.\n",
      "-- Epoch 1034\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.314615, T: 176696124, Avg. loss: 0.068404\n",
      "Total training time: 89.54 seconds.\n",
      "-- Epoch 1035\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.308238, T: 176867010, Avg. loss: 0.068400\n",
      "Total training time: 89.62 seconds.\n",
      "-- Epoch 1036\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.301878, T: 177037896, Avg. loss: 0.068397\n",
      "Total training time: 89.70 seconds.\n",
      "-- Epoch 1037\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.295523, T: 177208782, Avg. loss: 0.068393\n",
      "Total training time: 89.79 seconds.\n",
      "-- Epoch 1038\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.289186, T: 177379668, Avg. loss: 0.068389\n",
      "Total training time: 89.87 seconds.\n",
      "-- Epoch 1039\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.282845, T: 177550554, Avg. loss: 0.068386\n",
      "Total training time: 89.95 seconds.\n",
      "-- Epoch 1040\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.276511, T: 177721440, Avg. loss: 0.068382\n",
      "Total training time: 90.03 seconds.\n",
      "-- Epoch 1041\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.270187, T: 177892326, Avg. loss: 0.068379\n",
      "Total training time: 90.11 seconds.\n",
      "-- Epoch 1042\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.263862, T: 178063212, Avg. loss: 0.068375\n",
      "Total training time: 90.19 seconds.\n",
      "-- Epoch 1043\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.257553, T: 178234098, Avg. loss: 0.068371\n",
      "Total training time: 90.28 seconds.\n",
      "-- Epoch 1044\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.251238, T: 178404984, Avg. loss: 0.068368\n",
      "Total training time: 90.36 seconds.\n",
      "-- Epoch 1045\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.244935, T: 178575870, Avg. loss: 0.068364\n",
      "Total training time: 90.44 seconds.\n",
      "-- Epoch 1046\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.238631, T: 178746756, Avg. loss: 0.068361\n",
      "Total training time: 90.52 seconds.\n",
      "-- Epoch 1047\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.232331, T: 178917642, Avg. loss: 0.068357\n",
      "Total training time: 90.61 seconds.\n",
      "-- Epoch 1048\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.226057, T: 179088528, Avg. loss: 0.068353\n",
      "Total training time: 90.69 seconds.\n",
      "-- Epoch 1049\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.219770, T: 179259414, Avg. loss: 0.068350\n",
      "Total training time: 90.79 seconds.\n",
      "-- Epoch 1050\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.213511, T: 179430300, Avg. loss: 0.068346\n",
      "Total training time: 90.88 seconds.\n",
      "-- Epoch 1051\n",
      "Norm: 14.16, NNZs: 30, Bias: -127.207241, T: 179601186, Avg. loss: 0.068343\n",
      "Total training time: 90.96 seconds.\n",
      "-- Epoch 1052\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.200977, T: 179772072, Avg. loss: 0.068339\n",
      "Total training time: 91.05 seconds.\n",
      "-- Epoch 1053\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.194730, T: 179942958, Avg. loss: 0.068336\n",
      "Total training time: 91.13 seconds.\n",
      "-- Epoch 1054\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.188482, T: 180113844, Avg. loss: 0.068332\n",
      "Total training time: 91.21 seconds.\n",
      "-- Epoch 1055\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.182232, T: 180284730, Avg. loss: 0.068328\n",
      "Total training time: 91.29 seconds.\n",
      "-- Epoch 1056\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.175993, T: 180455616, Avg. loss: 0.068325\n",
      "Total training time: 91.38 seconds.\n",
      "-- Epoch 1057\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.169761, T: 180626502, Avg. loss: 0.068321\n",
      "Total training time: 91.46 seconds.\n",
      "-- Epoch 1058\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.163529, T: 180797388, Avg. loss: 0.068318\n",
      "Total training time: 91.54 seconds.\n",
      "-- Epoch 1059\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.157300, T: 180968274, Avg. loss: 0.068314\n",
      "Total training time: 91.62 seconds.\n",
      "-- Epoch 1060\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.151071, T: 181139160, Avg. loss: 0.068311\n",
      "Total training time: 91.70 seconds.\n",
      "-- Epoch 1061\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.144861, T: 181310046, Avg. loss: 0.068307\n",
      "Total training time: 91.78 seconds.\n",
      "-- Epoch 1062\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.138650, T: 181480932, Avg. loss: 0.068304\n",
      "Total training time: 91.86 seconds.\n",
      "-- Epoch 1063\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.132440, T: 181651818, Avg. loss: 0.068300\n",
      "Total training time: 91.94 seconds.\n",
      "-- Epoch 1064\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.126232, T: 181822704, Avg. loss: 0.068297\n",
      "Total training time: 92.02 seconds.\n",
      "-- Epoch 1065\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.120054, T: 181993590, Avg. loss: 0.068293\n",
      "Total training time: 92.11 seconds.\n",
      "-- Epoch 1066\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.113869, T: 182164476, Avg. loss: 0.068290\n",
      "Total training time: 92.19 seconds.\n",
      "-- Epoch 1067\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.107705, T: 182335362, Avg. loss: 0.068286\n",
      "Total training time: 92.28 seconds.\n",
      "-- Epoch 1068\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.101528, T: 182506248, Avg. loss: 0.068283\n",
      "Total training time: 92.36 seconds.\n",
      "-- Epoch 1069\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.095378, T: 182677134, Avg. loss: 0.068279\n",
      "Total training time: 92.44 seconds.\n",
      "-- Epoch 1070\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.089210, T: 182848020, Avg. loss: 0.068276\n",
      "Total training time: 92.53 seconds.\n",
      "-- Epoch 1071\n",
      "Norm: 14.15, NNZs: 30, Bias: -127.083069, T: 183018906, Avg. loss: 0.068272\n",
      "Total training time: 92.61 seconds.\n",
      "-- Epoch 1072\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.076916, T: 183189792, Avg. loss: 0.068269\n",
      "Total training time: 92.69 seconds.\n",
      "-- Epoch 1073\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.070776, T: 183360678, Avg. loss: 0.068265\n",
      "Total training time: 92.77 seconds.\n",
      "-- Epoch 1074\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.064638, T: 183531564, Avg. loss: 0.068262\n",
      "Total training time: 92.86 seconds.\n",
      "-- Epoch 1075\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.058503, T: 183702450, Avg. loss: 0.068258\n",
      "Total training time: 92.94 seconds.\n",
      "-- Epoch 1076\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.052386, T: 183873336, Avg. loss: 0.068255\n",
      "Total training time: 93.02 seconds.\n",
      "-- Epoch 1077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.14, NNZs: 30, Bias: -127.046268, T: 184044222, Avg. loss: 0.068251\n",
      "Total training time: 93.10 seconds.\n",
      "-- Epoch 1078\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.040159, T: 184215108, Avg. loss: 0.068248\n",
      "Total training time: 93.18 seconds.\n",
      "-- Epoch 1079\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.034052, T: 184385994, Avg. loss: 0.068244\n",
      "Total training time: 93.26 seconds.\n",
      "-- Epoch 1080\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.027948, T: 184556880, Avg. loss: 0.068241\n",
      "Total training time: 93.35 seconds.\n",
      "-- Epoch 1081\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.021837, T: 184727766, Avg. loss: 0.068237\n",
      "Total training time: 93.43 seconds.\n",
      "-- Epoch 1082\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.015754, T: 184898652, Avg. loss: 0.068234\n",
      "Total training time: 93.51 seconds.\n",
      "-- Epoch 1083\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.009678, T: 185069538, Avg. loss: 0.068231\n",
      "Total training time: 93.59 seconds.\n",
      "-- Epoch 1084\n",
      "Norm: 14.14, NNZs: 30, Bias: -127.003608, T: 185240424, Avg. loss: 0.068227\n",
      "Total training time: 93.67 seconds.\n",
      "-- Epoch 1085\n",
      "Norm: 14.14, NNZs: 30, Bias: -126.997540, T: 185411310, Avg. loss: 0.068224\n",
      "Total training time: 93.75 seconds.\n",
      "-- Epoch 1086\n",
      "Norm: 14.14, NNZs: 30, Bias: -126.991480, T: 185582196, Avg. loss: 0.068220\n",
      "Total training time: 93.83 seconds.\n",
      "-- Epoch 1087\n",
      "Norm: 14.14, NNZs: 30, Bias: -126.985420, T: 185753082, Avg. loss: 0.068217\n",
      "Total training time: 93.91 seconds.\n",
      "-- Epoch 1088\n",
      "Norm: 14.14, NNZs: 30, Bias: -126.979375, T: 185923968, Avg. loss: 0.068213\n",
      "Total training time: 93.99 seconds.\n",
      "-- Epoch 1089\n",
      "Norm: 14.14, NNZs: 30, Bias: -126.973322, T: 186094854, Avg. loss: 0.068210\n",
      "Total training time: 94.08 seconds.\n",
      "-- Epoch 1090\n",
      "Norm: 14.14, NNZs: 30, Bias: -126.967282, T: 186265740, Avg. loss: 0.068206\n",
      "Total training time: 94.16 seconds.\n",
      "-- Epoch 1091\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.961241, T: 186436626, Avg. loss: 0.068203\n",
      "Total training time: 94.24 seconds.\n",
      "-- Epoch 1092\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.955206, T: 186607512, Avg. loss: 0.068200\n",
      "Total training time: 94.32 seconds.\n",
      "-- Epoch 1093\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.949172, T: 186778398, Avg. loss: 0.068196\n",
      "Total training time: 94.40 seconds.\n",
      "-- Epoch 1094\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.943150, T: 186949284, Avg. loss: 0.068193\n",
      "Total training time: 94.48 seconds.\n",
      "-- Epoch 1095\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.937144, T: 187120170, Avg. loss: 0.068189\n",
      "Total training time: 94.56 seconds.\n",
      "-- Epoch 1096\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.931125, T: 187291056, Avg. loss: 0.068186\n",
      "Total training time: 94.64 seconds.\n",
      "-- Epoch 1097\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.925127, T: 187461942, Avg. loss: 0.068182\n",
      "Total training time: 94.72 seconds.\n",
      "-- Epoch 1098\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.919133, T: 187632828, Avg. loss: 0.068179\n",
      "Total training time: 94.80 seconds.\n",
      "-- Epoch 1099\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.913149, T: 187803714, Avg. loss: 0.068176\n",
      "Total training time: 94.88 seconds.\n",
      "-- Epoch 1100\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.907157, T: 187974600, Avg. loss: 0.068172\n",
      "Total training time: 94.97 seconds.\n",
      "-- Epoch 1101\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.901176, T: 188145486, Avg. loss: 0.068169\n",
      "Total training time: 95.05 seconds.\n",
      "-- Epoch 1102\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.895203, T: 188316372, Avg. loss: 0.068165\n",
      "Total training time: 95.13 seconds.\n",
      "-- Epoch 1103\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.889238, T: 188487258, Avg. loss: 0.068162\n",
      "Total training time: 95.21 seconds.\n",
      "-- Epoch 1104\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.883289, T: 188658144, Avg. loss: 0.068159\n",
      "Total training time: 95.29 seconds.\n",
      "-- Epoch 1105\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.877336, T: 188829030, Avg. loss: 0.068155\n",
      "Total training time: 95.38 seconds.\n",
      "-- Epoch 1106\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.871375, T: 188999916, Avg. loss: 0.068152\n",
      "Total training time: 95.46 seconds.\n",
      "-- Epoch 1107\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.865425, T: 189170802, Avg. loss: 0.068149\n",
      "Total training time: 95.54 seconds.\n",
      "-- Epoch 1108\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.859472, T: 189341688, Avg. loss: 0.068145\n",
      "Total training time: 95.62 seconds.\n",
      "-- Epoch 1109\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.853543, T: 189512574, Avg. loss: 0.068142\n",
      "Total training time: 95.71 seconds.\n",
      "-- Epoch 1110\n",
      "Norm: 14.13, NNZs: 30, Bias: -126.847595, T: 189683460, Avg. loss: 0.068138\n",
      "Total training time: 95.79 seconds.\n",
      "-- Epoch 1111\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.841682, T: 189854346, Avg. loss: 0.068135\n",
      "Total training time: 95.87 seconds.\n",
      "-- Epoch 1112\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.835773, T: 190025232, Avg. loss: 0.068132\n",
      "Total training time: 95.95 seconds.\n",
      "-- Epoch 1113\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.829853, T: 190196118, Avg. loss: 0.068128\n",
      "Total training time: 96.03 seconds.\n",
      "-- Epoch 1114\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.823948, T: 190367004, Avg. loss: 0.068125\n",
      "Total training time: 96.12 seconds.\n",
      "-- Epoch 1115\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.818061, T: 190537890, Avg. loss: 0.068122\n",
      "Total training time: 96.20 seconds.\n",
      "-- Epoch 1116\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.812168, T: 190708776, Avg. loss: 0.068118\n",
      "Total training time: 96.28 seconds.\n",
      "-- Epoch 1117\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.806275, T: 190879662, Avg. loss: 0.068115\n",
      "Total training time: 96.36 seconds.\n",
      "-- Epoch 1118\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.800390, T: 191050548, Avg. loss: 0.068112\n",
      "Total training time: 96.45 seconds.\n",
      "-- Epoch 1119\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.794514, T: 191221434, Avg. loss: 0.068108\n",
      "Total training time: 96.53 seconds.\n",
      "-- Epoch 1120\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.788633, T: 191392320, Avg. loss: 0.068105\n",
      "Total training time: 96.61 seconds.\n",
      "-- Epoch 1121\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.782758, T: 191563206, Avg. loss: 0.068102\n",
      "Total training time: 96.70 seconds.\n",
      "-- Epoch 1122\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.776900, T: 191734092, Avg. loss: 0.068098\n",
      "Total training time: 96.78 seconds.\n",
      "-- Epoch 1123\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.771038, T: 191904978, Avg. loss: 0.068095\n",
      "Total training time: 96.86 seconds.\n",
      "-- Epoch 1124\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.765184, T: 192075864, Avg. loss: 0.068092\n",
      "Total training time: 96.94 seconds.\n",
      "-- Epoch 1125\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.759321, T: 192246750, Avg. loss: 0.068088\n",
      "Total training time: 97.02 seconds.\n",
      "-- Epoch 1126\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.753472, T: 192417636, Avg. loss: 0.068085\n",
      "Total training time: 97.10 seconds.\n",
      "-- Epoch 1127\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.747625, T: 192588522, Avg. loss: 0.068082\n",
      "Total training time: 97.19 seconds.\n",
      "-- Epoch 1128\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.741788, T: 192759408, Avg. loss: 0.068078\n",
      "Total training time: 97.27 seconds.\n",
      "-- Epoch 1129\n",
      "Norm: 14.12, NNZs: 30, Bias: -126.735950, T: 192930294, Avg. loss: 0.068075\n",
      "Total training time: 97.35 seconds.\n",
      "-- Epoch 1130\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.730111, T: 193101180, Avg. loss: 0.068072\n",
      "Total training time: 97.43 seconds.\n",
      "-- Epoch 1131\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.724291, T: 193272066, Avg. loss: 0.068068\n",
      "Total training time: 97.51 seconds.\n",
      "-- Epoch 1132\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.718475, T: 193442952, Avg. loss: 0.068065\n",
      "Total training time: 97.59 seconds.\n",
      "-- Epoch 1133\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.712661, T: 193613838, Avg. loss: 0.068062\n",
      "Total training time: 97.67 seconds.\n",
      "-- Epoch 1134\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.706841, T: 193784724, Avg. loss: 0.068059\n",
      "Total training time: 97.76 seconds.\n",
      "-- Epoch 1135\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.701038, T: 193955610, Avg. loss: 0.068055\n",
      "Total training time: 97.84 seconds.\n",
      "-- Epoch 1136\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.695248, T: 194126496, Avg. loss: 0.068052\n",
      "Total training time: 97.92 seconds.\n",
      "-- Epoch 1137\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.689459, T: 194297382, Avg. loss: 0.068049\n",
      "Total training time: 98.00 seconds.\n",
      "-- Epoch 1138\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.683662, T: 194468268, Avg. loss: 0.068045\n",
      "Total training time: 98.08 seconds.\n",
      "-- Epoch 1139\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.677889, T: 194639154, Avg. loss: 0.068042\n",
      "Total training time: 98.16 seconds.\n",
      "-- Epoch 1140\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.672111, T: 194810040, Avg. loss: 0.068039\n",
      "Total training time: 98.24 seconds.\n",
      "-- Epoch 1141\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.666339, T: 194980926, Avg. loss: 0.068036\n",
      "Total training time: 98.32 seconds.\n",
      "-- Epoch 1142\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.660569, T: 195151812, Avg. loss: 0.068032\n",
      "Total training time: 98.41 seconds.\n",
      "-- Epoch 1143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.11, NNZs: 30, Bias: -126.654803, T: 195322698, Avg. loss: 0.068029\n",
      "Total training time: 98.49 seconds.\n",
      "-- Epoch 1144\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.649062, T: 195493584, Avg. loss: 0.068026\n",
      "Total training time: 98.57 seconds.\n",
      "-- Epoch 1145\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.643308, T: 195664470, Avg. loss: 0.068023\n",
      "Total training time: 98.65 seconds.\n",
      "-- Epoch 1146\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.637564, T: 195835356, Avg. loss: 0.068019\n",
      "Total training time: 98.73 seconds.\n",
      "-- Epoch 1147\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.631822, T: 196006242, Avg. loss: 0.068016\n",
      "Total training time: 98.82 seconds.\n",
      "-- Epoch 1148\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.626090, T: 196177128, Avg. loss: 0.068013\n",
      "Total training time: 98.90 seconds.\n",
      "-- Epoch 1149\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.620365, T: 196348014, Avg. loss: 0.068010\n",
      "Total training time: 98.98 seconds.\n",
      "-- Epoch 1150\n",
      "Norm: 14.11, NNZs: 30, Bias: -126.614647, T: 196518900, Avg. loss: 0.068006\n",
      "Total training time: 99.06 seconds.\n",
      "-- Epoch 1151\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.608936, T: 196689786, Avg. loss: 0.068003\n",
      "Total training time: 99.14 seconds.\n",
      "-- Epoch 1152\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.603214, T: 196860672, Avg. loss: 0.068000\n",
      "Total training time: 99.22 seconds.\n",
      "-- Epoch 1153\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.597505, T: 197031558, Avg. loss: 0.067997\n",
      "Total training time: 99.30 seconds.\n",
      "-- Epoch 1154\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.591804, T: 197202444, Avg. loss: 0.067993\n",
      "Total training time: 99.38 seconds.\n",
      "-- Epoch 1155\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.586101, T: 197373330, Avg. loss: 0.067990\n",
      "Total training time: 99.47 seconds.\n",
      "-- Epoch 1156\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.580399, T: 197544216, Avg. loss: 0.067987\n",
      "Total training time: 99.55 seconds.\n",
      "-- Epoch 1157\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.574710, T: 197715102, Avg. loss: 0.067984\n",
      "Total training time: 99.63 seconds.\n",
      "-- Epoch 1158\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.569020, T: 197885988, Avg. loss: 0.067980\n",
      "Total training time: 99.71 seconds.\n",
      "-- Epoch 1159\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.563342, T: 198056874, Avg. loss: 0.067977\n",
      "Total training time: 99.79 seconds.\n",
      "-- Epoch 1160\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.557671, T: 198227760, Avg. loss: 0.067974\n",
      "Total training time: 99.87 seconds.\n",
      "-- Epoch 1161\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.552002, T: 198398646, Avg. loss: 0.067971\n",
      "Total training time: 99.96 seconds.\n",
      "-- Epoch 1162\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.546339, T: 198569532, Avg. loss: 0.067968\n",
      "Total training time: 100.04 seconds.\n",
      "-- Epoch 1163\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.540686, T: 198740418, Avg. loss: 0.067964\n",
      "Total training time: 100.12 seconds.\n",
      "-- Epoch 1164\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.535025, T: 198911304, Avg. loss: 0.067961\n",
      "Total training time: 100.20 seconds.\n",
      "-- Epoch 1165\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.529372, T: 199082190, Avg. loss: 0.067958\n",
      "Total training time: 100.28 seconds.\n",
      "-- Epoch 1166\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.523724, T: 199253076, Avg. loss: 0.067955\n",
      "Total training time: 100.37 seconds.\n",
      "-- Epoch 1167\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.518083, T: 199423962, Avg. loss: 0.067952\n",
      "Total training time: 100.45 seconds.\n",
      "-- Epoch 1168\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.512445, T: 199594848, Avg. loss: 0.067948\n",
      "Total training time: 100.53 seconds.\n",
      "-- Epoch 1169\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.506817, T: 199765734, Avg. loss: 0.067945\n",
      "Total training time: 100.61 seconds.\n",
      "-- Epoch 1170\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.501190, T: 199936620, Avg. loss: 0.067942\n",
      "Total training time: 100.69 seconds.\n",
      "-- Epoch 1171\n",
      "Norm: 14.10, NNZs: 30, Bias: -126.495577, T: 200107506, Avg. loss: 0.067939\n",
      "Total training time: 100.78 seconds.\n",
      "-- Epoch 1172\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.489967, T: 200278392, Avg. loss: 0.067936\n",
      "Total training time: 100.86 seconds.\n",
      "-- Epoch 1173\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.484369, T: 200449278, Avg. loss: 0.067932\n",
      "Total training time: 100.94 seconds.\n",
      "-- Epoch 1174\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.478773, T: 200620164, Avg. loss: 0.067929\n",
      "Total training time: 101.02 seconds.\n",
      "-- Epoch 1175\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.473167, T: 200791050, Avg. loss: 0.067926\n",
      "Total training time: 101.10 seconds.\n",
      "-- Epoch 1176\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.467585, T: 200961936, Avg. loss: 0.067923\n",
      "Total training time: 101.18 seconds.\n",
      "-- Epoch 1177\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.461990, T: 201132822, Avg. loss: 0.067920\n",
      "Total training time: 101.27 seconds.\n",
      "-- Epoch 1178\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.456390, T: 201303708, Avg. loss: 0.067917\n",
      "Total training time: 101.35 seconds.\n",
      "-- Epoch 1179\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.450811, T: 201474594, Avg. loss: 0.067913\n",
      "Total training time: 101.46 seconds.\n",
      "-- Epoch 1180\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.445232, T: 201645480, Avg. loss: 0.067910\n",
      "Total training time: 101.57 seconds.\n",
      "-- Epoch 1181\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.439658, T: 201816366, Avg. loss: 0.067907\n",
      "Total training time: 101.65 seconds.\n",
      "-- Epoch 1182\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.434084, T: 201987252, Avg. loss: 0.067904\n",
      "Total training time: 101.73 seconds.\n",
      "-- Epoch 1183\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.428513, T: 202158138, Avg. loss: 0.067901\n",
      "Total training time: 101.81 seconds.\n",
      "-- Epoch 1184\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.422957, T: 202329024, Avg. loss: 0.067898\n",
      "Total training time: 101.89 seconds.\n",
      "-- Epoch 1185\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.417405, T: 202499910, Avg. loss: 0.067895\n",
      "Total training time: 101.97 seconds.\n",
      "-- Epoch 1186\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.411867, T: 202670796, Avg. loss: 0.067891\n",
      "Total training time: 102.06 seconds.\n",
      "-- Epoch 1187\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.406311, T: 202841682, Avg. loss: 0.067888\n",
      "Total training time: 102.13 seconds.\n",
      "-- Epoch 1188\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.400752, T: 203012568, Avg. loss: 0.067885\n",
      "Total training time: 102.22 seconds.\n",
      "-- Epoch 1189\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.395220, T: 203183454, Avg. loss: 0.067882\n",
      "Total training time: 102.30 seconds.\n",
      "-- Epoch 1190\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.389703, T: 203354340, Avg. loss: 0.067879\n",
      "Total training time: 102.38 seconds.\n",
      "-- Epoch 1191\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.384188, T: 203525226, Avg. loss: 0.067876\n",
      "Total training time: 102.46 seconds.\n",
      "-- Epoch 1192\n",
      "Norm: 14.09, NNZs: 30, Bias: -126.378663, T: 203696112, Avg. loss: 0.067873\n",
      "Total training time: 102.54 seconds.\n",
      "-- Epoch 1193\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.373150, T: 203866998, Avg. loss: 0.067869\n",
      "Total training time: 102.62 seconds.\n",
      "-- Epoch 1194\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.367644, T: 204037884, Avg. loss: 0.067866\n",
      "Total training time: 102.71 seconds.\n",
      "-- Epoch 1195\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.362141, T: 204208770, Avg. loss: 0.067863\n",
      "Total training time: 102.79 seconds.\n",
      "-- Epoch 1196\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.356638, T: 204379656, Avg. loss: 0.067860\n",
      "Total training time: 102.87 seconds.\n",
      "-- Epoch 1197\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.351146, T: 204550542, Avg. loss: 0.067857\n",
      "Total training time: 102.95 seconds.\n",
      "-- Epoch 1198\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.345650, T: 204721428, Avg. loss: 0.067854\n",
      "Total training time: 103.03 seconds.\n",
      "-- Epoch 1199\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.340162, T: 204892314, Avg. loss: 0.067851\n",
      "Total training time: 103.11 seconds.\n",
      "-- Epoch 1200\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.334677, T: 205063200, Avg. loss: 0.067848\n",
      "Total training time: 103.19 seconds.\n",
      "-- Epoch 1201\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.329192, T: 205234086, Avg. loss: 0.067845\n",
      "Total training time: 103.27 seconds.\n",
      "-- Epoch 1202\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.323720, T: 205404972, Avg. loss: 0.067841\n",
      "Total training time: 103.36 seconds.\n",
      "-- Epoch 1203\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.318260, T: 205575858, Avg. loss: 0.067838\n",
      "Total training time: 103.44 seconds.\n",
      "-- Epoch 1204\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.312801, T: 205746744, Avg. loss: 0.067835\n",
      "Total training time: 103.52 seconds.\n",
      "-- Epoch 1205\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.307344, T: 205917630, Avg. loss: 0.067832\n",
      "Total training time: 103.60 seconds.\n",
      "-- Epoch 1206\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.301894, T: 206088516, Avg. loss: 0.067829\n",
      "Total training time: 103.69 seconds.\n",
      "-- Epoch 1207\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.296444, T: 206259402, Avg. loss: 0.067826\n",
      "Total training time: 103.77 seconds.\n",
      "-- Epoch 1208\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.290996, T: 206430288, Avg. loss: 0.067823\n",
      "Total training time: 103.85 seconds.\n",
      "-- Epoch 1209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.08, NNZs: 30, Bias: -126.285559, T: 206601174, Avg. loss: 0.067820\n",
      "Total training time: 103.94 seconds.\n",
      "-- Epoch 1210\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.280127, T: 206772060, Avg. loss: 0.067817\n",
      "Total training time: 104.02 seconds.\n",
      "-- Epoch 1211\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.274695, T: 206942946, Avg. loss: 0.067814\n",
      "Total training time: 104.10 seconds.\n",
      "-- Epoch 1212\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.269270, T: 207113832, Avg. loss: 0.067811\n",
      "Total training time: 104.18 seconds.\n",
      "-- Epoch 1213\n",
      "Norm: 14.08, NNZs: 30, Bias: -126.263841, T: 207284718, Avg. loss: 0.067808\n",
      "Total training time: 104.26 seconds.\n",
      "-- Epoch 1214\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.258432, T: 207455604, Avg. loss: 0.067804\n",
      "Total training time: 104.34 seconds.\n",
      "-- Epoch 1215\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.253017, T: 207626490, Avg. loss: 0.067801\n",
      "Total training time: 104.43 seconds.\n",
      "-- Epoch 1216\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.247616, T: 207797376, Avg. loss: 0.067798\n",
      "Total training time: 104.51 seconds.\n",
      "-- Epoch 1217\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.242219, T: 207968262, Avg. loss: 0.067795\n",
      "Total training time: 104.59 seconds.\n",
      "-- Epoch 1218\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.236822, T: 208139148, Avg. loss: 0.067792\n",
      "Total training time: 104.68 seconds.\n",
      "-- Epoch 1219\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.231424, T: 208310034, Avg. loss: 0.067789\n",
      "Total training time: 104.76 seconds.\n",
      "-- Epoch 1220\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.226029, T: 208480920, Avg. loss: 0.067786\n",
      "Total training time: 104.84 seconds.\n",
      "-- Epoch 1221\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.220646, T: 208651806, Avg. loss: 0.067783\n",
      "Total training time: 104.92 seconds.\n",
      "-- Epoch 1222\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.215268, T: 208822692, Avg. loss: 0.067780\n",
      "Total training time: 105.01 seconds.\n",
      "-- Epoch 1223\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.209887, T: 208993578, Avg. loss: 0.067777\n",
      "Total training time: 105.09 seconds.\n",
      "-- Epoch 1224\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.204508, T: 209164464, Avg. loss: 0.067774\n",
      "Total training time: 105.18 seconds.\n",
      "-- Epoch 1225\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.199144, T: 209335350, Avg. loss: 0.067771\n",
      "Total training time: 105.26 seconds.\n",
      "-- Epoch 1226\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.193773, T: 209506236, Avg. loss: 0.067768\n",
      "Total training time: 105.34 seconds.\n",
      "-- Epoch 1227\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.188414, T: 209677122, Avg. loss: 0.067765\n",
      "Total training time: 105.43 seconds.\n",
      "-- Epoch 1228\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.183054, T: 209848008, Avg. loss: 0.067762\n",
      "Total training time: 105.51 seconds.\n",
      "-- Epoch 1229\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.177698, T: 210018894, Avg. loss: 0.067759\n",
      "Total training time: 105.59 seconds.\n",
      "-- Epoch 1230\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.172356, T: 210189780, Avg. loss: 0.067756\n",
      "Total training time: 105.67 seconds.\n",
      "-- Epoch 1231\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.167016, T: 210360666, Avg. loss: 0.067753\n",
      "Total training time: 105.75 seconds.\n",
      "-- Epoch 1232\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.161660, T: 210531552, Avg. loss: 0.067750\n",
      "Total training time: 105.84 seconds.\n",
      "-- Epoch 1233\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.156321, T: 210702438, Avg. loss: 0.067747\n",
      "Total training time: 105.92 seconds.\n",
      "-- Epoch 1234\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.150994, T: 210873324, Avg. loss: 0.067744\n",
      "Total training time: 106.00 seconds.\n",
      "-- Epoch 1235\n",
      "Norm: 14.07, NNZs: 30, Bias: -126.145664, T: 211044210, Avg. loss: 0.067741\n",
      "Total training time: 106.08 seconds.\n",
      "-- Epoch 1236\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.140335, T: 211215096, Avg. loss: 0.067738\n",
      "Total training time: 106.16 seconds.\n",
      "-- Epoch 1237\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.135018, T: 211385982, Avg. loss: 0.067735\n",
      "Total training time: 106.24 seconds.\n",
      "-- Epoch 1238\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.129722, T: 211556868, Avg. loss: 0.067732\n",
      "Total training time: 106.33 seconds.\n",
      "-- Epoch 1239\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.124408, T: 211727754, Avg. loss: 0.067729\n",
      "Total training time: 106.41 seconds.\n",
      "-- Epoch 1240\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.119097, T: 211898640, Avg. loss: 0.067726\n",
      "Total training time: 106.49 seconds.\n",
      "-- Epoch 1241\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.113811, T: 212069526, Avg. loss: 0.067723\n",
      "Total training time: 106.57 seconds.\n",
      "-- Epoch 1242\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.108516, T: 212240412, Avg. loss: 0.067720\n",
      "Total training time: 106.65 seconds.\n",
      "-- Epoch 1243\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.103221, T: 212411298, Avg. loss: 0.067717\n",
      "Total training time: 106.73 seconds.\n",
      "-- Epoch 1244\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.097938, T: 212582184, Avg. loss: 0.067714\n",
      "Total training time: 106.82 seconds.\n",
      "-- Epoch 1245\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.092648, T: 212753070, Avg. loss: 0.067711\n",
      "Total training time: 106.90 seconds.\n",
      "-- Epoch 1246\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.087372, T: 212923956, Avg. loss: 0.067708\n",
      "Total training time: 106.98 seconds.\n",
      "-- Epoch 1247\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.082095, T: 213094842, Avg. loss: 0.067705\n",
      "Total training time: 107.06 seconds.\n",
      "-- Epoch 1248\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.076827, T: 213265728, Avg. loss: 0.067702\n",
      "Total training time: 107.15 seconds.\n",
      "-- Epoch 1249\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.071568, T: 213436614, Avg. loss: 0.067699\n",
      "Total training time: 107.22 seconds.\n",
      "-- Epoch 1250\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.066311, T: 213607500, Avg. loss: 0.067696\n",
      "Total training time: 107.31 seconds.\n",
      "-- Epoch 1251\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.061052, T: 213778386, Avg. loss: 0.067693\n",
      "Total training time: 107.39 seconds.\n",
      "-- Epoch 1252\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.055794, T: 213949272, Avg. loss: 0.067690\n",
      "Total training time: 107.47 seconds.\n",
      "-- Epoch 1253\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.050555, T: 214120158, Avg. loss: 0.067687\n",
      "Total training time: 107.55 seconds.\n",
      "-- Epoch 1254\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.045303, T: 214291044, Avg. loss: 0.067684\n",
      "Total training time: 107.64 seconds.\n",
      "-- Epoch 1255\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.040069, T: 214461930, Avg. loss: 0.067681\n",
      "Total training time: 107.72 seconds.\n",
      "-- Epoch 1256\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.034826, T: 214632816, Avg. loss: 0.067678\n",
      "Total training time: 107.80 seconds.\n",
      "-- Epoch 1257\n",
      "Norm: 14.06, NNZs: 30, Bias: -126.029592, T: 214803702, Avg. loss: 0.067675\n",
      "Total training time: 107.88 seconds.\n",
      "-- Epoch 1258\n",
      "Norm: 14.05, NNZs: 30, Bias: -126.024366, T: 214974588, Avg. loss: 0.067672\n",
      "Total training time: 107.97 seconds.\n",
      "-- Epoch 1259\n",
      "Norm: 14.05, NNZs: 30, Bias: -126.019143, T: 215145474, Avg. loss: 0.067669\n",
      "Total training time: 108.05 seconds.\n",
      "-- Epoch 1260\n",
      "Norm: 14.05, NNZs: 30, Bias: -126.013908, T: 215316360, Avg. loss: 0.067666\n",
      "Total training time: 108.13 seconds.\n",
      "-- Epoch 1261\n",
      "Norm: 14.05, NNZs: 30, Bias: -126.008693, T: 215487246, Avg. loss: 0.067663\n",
      "Total training time: 108.21 seconds.\n",
      "-- Epoch 1262\n",
      "Norm: 14.05, NNZs: 30, Bias: -126.003484, T: 215658132, Avg. loss: 0.067660\n",
      "Total training time: 108.30 seconds.\n",
      "-- Epoch 1263\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.998281, T: 215829018, Avg. loss: 0.067657\n",
      "Total training time: 108.39 seconds.\n",
      "-- Epoch 1264\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.993078, T: 215999904, Avg. loss: 0.067654\n",
      "Total training time: 108.47 seconds.\n",
      "-- Epoch 1265\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.987883, T: 216170790, Avg. loss: 0.067651\n",
      "Total training time: 108.55 seconds.\n",
      "-- Epoch 1266\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.982689, T: 216341676, Avg. loss: 0.067648\n",
      "Total training time: 108.63 seconds.\n",
      "-- Epoch 1267\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.977498, T: 216512562, Avg. loss: 0.067645\n",
      "Total training time: 108.71 seconds.\n",
      "-- Epoch 1268\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.972313, T: 216683448, Avg. loss: 0.067643\n",
      "Total training time: 108.80 seconds.\n",
      "-- Epoch 1269\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.967133, T: 216854334, Avg. loss: 0.067640\n",
      "Total training time: 108.88 seconds.\n",
      "-- Epoch 1270\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.961956, T: 217025220, Avg. loss: 0.067637\n",
      "Total training time: 108.96 seconds.\n",
      "-- Epoch 1271\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.956777, T: 217196106, Avg. loss: 0.067634\n",
      "Total training time: 109.04 seconds.\n",
      "-- Epoch 1272\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.951610, T: 217366992, Avg. loss: 0.067631\n",
      "Total training time: 109.12 seconds.\n",
      "-- Epoch 1273\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.946444, T: 217537878, Avg. loss: 0.067628\n",
      "Total training time: 109.21 seconds.\n",
      "-- Epoch 1274\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.941279, T: 217708764, Avg. loss: 0.067625\n",
      "Total training time: 109.29 seconds.\n",
      "-- Epoch 1275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.05, NNZs: 30, Bias: -125.936121, T: 217879650, Avg. loss: 0.067622\n",
      "Total training time: 109.37 seconds.\n",
      "-- Epoch 1276\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.930959, T: 218050536, Avg. loss: 0.067619\n",
      "Total training time: 109.45 seconds.\n",
      "-- Epoch 1277\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.925812, T: 218221422, Avg. loss: 0.067616\n",
      "Total training time: 109.53 seconds.\n",
      "-- Epoch 1278\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.920662, T: 218392308, Avg. loss: 0.067613\n",
      "Total training time: 109.62 seconds.\n",
      "-- Epoch 1279\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.915522, T: 218563194, Avg. loss: 0.067610\n",
      "Total training time: 109.70 seconds.\n",
      "-- Epoch 1280\n",
      "Norm: 14.05, NNZs: 30, Bias: -125.910379, T: 218734080, Avg. loss: 0.067608\n",
      "Total training time: 109.78 seconds.\n",
      "-- Epoch 1281\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.905243, T: 218904966, Avg. loss: 0.067605\n",
      "Total training time: 109.86 seconds.\n",
      "-- Epoch 1282\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.900116, T: 219075852, Avg. loss: 0.067602\n",
      "Total training time: 109.94 seconds.\n",
      "-- Epoch 1283\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.894987, T: 219246738, Avg. loss: 0.067599\n",
      "Total training time: 110.03 seconds.\n",
      "-- Epoch 1284\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.889862, T: 219417624, Avg. loss: 0.067596\n",
      "Total training time: 110.11 seconds.\n",
      "-- Epoch 1285\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.884739, T: 219588510, Avg. loss: 0.067593\n",
      "Total training time: 110.19 seconds.\n",
      "-- Epoch 1286\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.879633, T: 219759396, Avg. loss: 0.067590\n",
      "Total training time: 110.27 seconds.\n",
      "-- Epoch 1287\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.874528, T: 219930282, Avg. loss: 0.067587\n",
      "Total training time: 110.35 seconds.\n",
      "-- Epoch 1288\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.869418, T: 220101168, Avg. loss: 0.067584\n",
      "Total training time: 110.43 seconds.\n",
      "-- Epoch 1289\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.864322, T: 220272054, Avg. loss: 0.067582\n",
      "Total training time: 110.52 seconds.\n",
      "-- Epoch 1290\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.859233, T: 220442940, Avg. loss: 0.067579\n",
      "Total training time: 110.60 seconds.\n",
      "-- Epoch 1291\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.854142, T: 220613826, Avg. loss: 0.067576\n",
      "Total training time: 110.68 seconds.\n",
      "-- Epoch 1292\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.849051, T: 220784712, Avg. loss: 0.067573\n",
      "Total training time: 110.76 seconds.\n",
      "-- Epoch 1293\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.843970, T: 220955598, Avg. loss: 0.067570\n",
      "Total training time: 110.84 seconds.\n",
      "-- Epoch 1294\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.838904, T: 221126484, Avg. loss: 0.067567\n",
      "Total training time: 110.93 seconds.\n",
      "-- Epoch 1295\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.833833, T: 221297370, Avg. loss: 0.067564\n",
      "Total training time: 111.01 seconds.\n",
      "-- Epoch 1296\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.828763, T: 221468256, Avg. loss: 0.067561\n",
      "Total training time: 111.09 seconds.\n",
      "-- Epoch 1297\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.823696, T: 221639142, Avg. loss: 0.067559\n",
      "Total training time: 111.17 seconds.\n",
      "-- Epoch 1298\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.818636, T: 221810028, Avg. loss: 0.067556\n",
      "Total training time: 111.26 seconds.\n",
      "-- Epoch 1299\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.813571, T: 221980914, Avg. loss: 0.067553\n",
      "Total training time: 111.34 seconds.\n",
      "-- Epoch 1300\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.808521, T: 222151800, Avg. loss: 0.067550\n",
      "Total training time: 111.42 seconds.\n",
      "-- Epoch 1301\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.803473, T: 222322686, Avg. loss: 0.067547\n",
      "Total training time: 111.50 seconds.\n",
      "-- Epoch 1302\n",
      "Norm: 14.04, NNZs: 30, Bias: -125.798427, T: 222493572, Avg. loss: 0.067544\n",
      "Total training time: 111.59 seconds.\n",
      "-- Epoch 1303\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.793383, T: 222664458, Avg. loss: 0.067541\n",
      "Total training time: 111.67 seconds.\n",
      "-- Epoch 1304\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.788340, T: 222835344, Avg. loss: 0.067539\n",
      "Total training time: 111.75 seconds.\n",
      "-- Epoch 1305\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.783304, T: 223006230, Avg. loss: 0.067536\n",
      "Total training time: 111.83 seconds.\n",
      "-- Epoch 1306\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.778269, T: 223177116, Avg. loss: 0.067533\n",
      "Total training time: 111.92 seconds.\n",
      "-- Epoch 1307\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.773235, T: 223348002, Avg. loss: 0.067530\n",
      "Total training time: 112.00 seconds.\n",
      "-- Epoch 1308\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.768215, T: 223518888, Avg. loss: 0.067527\n",
      "Total training time: 112.08 seconds.\n",
      "-- Epoch 1309\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.763189, T: 223689774, Avg. loss: 0.067524\n",
      "Total training time: 112.16 seconds.\n",
      "-- Epoch 1310\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.758171, T: 223860660, Avg. loss: 0.067522\n",
      "Total training time: 112.24 seconds.\n",
      "-- Epoch 1311\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.753158, T: 224031546, Avg. loss: 0.067519\n",
      "Total training time: 112.33 seconds.\n",
      "-- Epoch 1312\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.748153, T: 224202432, Avg. loss: 0.067516\n",
      "Total training time: 112.41 seconds.\n",
      "-- Epoch 1313\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.743140, T: 224373318, Avg. loss: 0.067513\n",
      "Total training time: 112.49 seconds.\n",
      "-- Epoch 1314\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.738139, T: 224544204, Avg. loss: 0.067510\n",
      "Total training time: 112.58 seconds.\n",
      "-- Epoch 1315\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.733129, T: 224715090, Avg. loss: 0.067507\n",
      "Total training time: 112.66 seconds.\n",
      "-- Epoch 1316\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.728139, T: 224885976, Avg. loss: 0.067505\n",
      "Total training time: 112.74 seconds.\n",
      "-- Epoch 1317\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.723147, T: 225056862, Avg. loss: 0.067502\n",
      "Total training time: 112.82 seconds.\n",
      "-- Epoch 1318\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.718167, T: 225227748, Avg. loss: 0.067499\n",
      "Total training time: 112.90 seconds.\n",
      "-- Epoch 1319\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.713180, T: 225398634, Avg. loss: 0.067496\n",
      "Total training time: 112.99 seconds.\n",
      "-- Epoch 1320\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.708205, T: 225569520, Avg. loss: 0.067493\n",
      "Total training time: 113.07 seconds.\n",
      "-- Epoch 1321\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.703220, T: 225740406, Avg. loss: 0.067490\n",
      "Total training time: 113.15 seconds.\n",
      "-- Epoch 1322\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.698257, T: 225911292, Avg. loss: 0.067488\n",
      "Total training time: 113.23 seconds.\n",
      "-- Epoch 1323\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.693289, T: 226082178, Avg. loss: 0.067485\n",
      "Total training time: 113.31 seconds.\n",
      "-- Epoch 1324\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.688319, T: 226253064, Avg. loss: 0.067482\n",
      "Total training time: 113.40 seconds.\n",
      "-- Epoch 1325\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.683363, T: 226423950, Avg. loss: 0.067479\n",
      "Total training time: 113.48 seconds.\n",
      "-- Epoch 1326\n",
      "Norm: 14.03, NNZs: 30, Bias: -125.678405, T: 226594836, Avg. loss: 0.067476\n",
      "Total training time: 113.57 seconds.\n",
      "-- Epoch 1327\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.673450, T: 226765722, Avg. loss: 0.067474\n",
      "Total training time: 113.65 seconds.\n",
      "-- Epoch 1328\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.668504, T: 226936608, Avg. loss: 0.067471\n",
      "Total training time: 113.73 seconds.\n",
      "-- Epoch 1329\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.663549, T: 227107494, Avg. loss: 0.067468\n",
      "Total training time: 113.81 seconds.\n",
      "-- Epoch 1330\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.658601, T: 227278380, Avg. loss: 0.067465\n",
      "Total training time: 113.89 seconds.\n",
      "-- Epoch 1331\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.653661, T: 227449266, Avg. loss: 0.067462\n",
      "Total training time: 113.98 seconds.\n",
      "-- Epoch 1332\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.648730, T: 227620152, Avg. loss: 0.067460\n",
      "Total training time: 114.06 seconds.\n",
      "-- Epoch 1333\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.643799, T: 227791038, Avg. loss: 0.067457\n",
      "Total training time: 114.14 seconds.\n",
      "-- Epoch 1334\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.638857, T: 227961924, Avg. loss: 0.067454\n",
      "Total training time: 114.22 seconds.\n",
      "-- Epoch 1335\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.633942, T: 228132810, Avg. loss: 0.067451\n",
      "Total training time: 114.31 seconds.\n",
      "-- Epoch 1336\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.629025, T: 228303696, Avg. loss: 0.067449\n",
      "Total training time: 114.40 seconds.\n",
      "-- Epoch 1337\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.624102, T: 228474582, Avg. loss: 0.067446\n",
      "Total training time: 114.48 seconds.\n",
      "-- Epoch 1338\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.619186, T: 228645468, Avg. loss: 0.067443\n",
      "Total training time: 114.57 seconds.\n",
      "-- Epoch 1339\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.614276, T: 228816354, Avg. loss: 0.067440\n",
      "Total training time: 114.66 seconds.\n",
      "-- Epoch 1340\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.609369, T: 228987240, Avg. loss: 0.067437\n",
      "Total training time: 114.74 seconds.\n",
      "-- Epoch 1341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 14.02, NNZs: 30, Bias: -125.604454, T: 229158126, Avg. loss: 0.067435\n",
      "Total training time: 114.83 seconds.\n",
      "-- Epoch 1342\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.599553, T: 229329012, Avg. loss: 0.067432\n",
      "Total training time: 114.92 seconds.\n",
      "-- Epoch 1343\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.594661, T: 229499898, Avg. loss: 0.067429\n",
      "Total training time: 115.01 seconds.\n",
      "-- Epoch 1344\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.589767, T: 229670784, Avg. loss: 0.067426\n",
      "Total training time: 115.09 seconds.\n",
      "-- Epoch 1345\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.584890, T: 229841670, Avg. loss: 0.067424\n",
      "Total training time: 115.18 seconds.\n",
      "-- Epoch 1346\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.580013, T: 230012556, Avg. loss: 0.067421\n",
      "Total training time: 115.26 seconds.\n",
      "-- Epoch 1347\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.575138, T: 230183442, Avg. loss: 0.067418\n",
      "Total training time: 115.34 seconds.\n",
      "-- Epoch 1348\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.570263, T: 230354328, Avg. loss: 0.067415\n",
      "Total training time: 115.43 seconds.\n",
      "-- Epoch 1349\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.565392, T: 230525214, Avg. loss: 0.067413\n",
      "Total training time: 115.51 seconds.\n",
      "-- Epoch 1350\n",
      "Norm: 14.02, NNZs: 30, Bias: -125.560530, T: 230696100, Avg. loss: 0.067410\n",
      "Total training time: 115.59 seconds.\n",
      "-- Epoch 1351\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.555661, T: 230866986, Avg. loss: 0.067407\n",
      "Total training time: 115.67 seconds.\n",
      "-- Epoch 1352\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.550801, T: 231037872, Avg. loss: 0.067404\n",
      "Total training time: 115.75 seconds.\n",
      "-- Epoch 1353\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.545946, T: 231208758, Avg. loss: 0.067402\n",
      "Total training time: 115.84 seconds.\n",
      "-- Epoch 1354\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.541090, T: 231379644, Avg. loss: 0.067399\n",
      "Total training time: 115.92 seconds.\n",
      "-- Epoch 1355\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.536239, T: 231550530, Avg. loss: 0.067396\n",
      "Total training time: 116.00 seconds.\n",
      "-- Epoch 1356\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.531392, T: 231721416, Avg. loss: 0.067393\n",
      "Total training time: 116.08 seconds.\n",
      "-- Epoch 1357\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.526546, T: 231892302, Avg. loss: 0.067391\n",
      "Total training time: 116.17 seconds.\n",
      "-- Epoch 1358\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.521706, T: 232063188, Avg. loss: 0.067388\n",
      "Total training time: 116.25 seconds.\n",
      "-- Epoch 1359\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.516870, T: 232234074, Avg. loss: 0.067385\n",
      "Total training time: 116.33 seconds.\n",
      "-- Epoch 1360\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.512034, T: 232404960, Avg. loss: 0.067383\n",
      "Total training time: 116.41 seconds.\n",
      "-- Epoch 1361\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.507208, T: 232575846, Avg. loss: 0.067380\n",
      "Total training time: 116.49 seconds.\n",
      "-- Epoch 1362\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.502379, T: 232746732, Avg. loss: 0.067377\n",
      "Total training time: 116.58 seconds.\n",
      "-- Epoch 1363\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.497561, T: 232917618, Avg. loss: 0.067374\n",
      "Total training time: 116.66 seconds.\n",
      "-- Epoch 1364\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.492750, T: 233088504, Avg. loss: 0.067372\n",
      "Total training time: 116.74 seconds.\n",
      "-- Epoch 1365\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.487937, T: 233259390, Avg. loss: 0.067369\n",
      "Total training time: 116.82 seconds.\n",
      "-- Epoch 1366\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.483124, T: 233430276, Avg. loss: 0.067366\n",
      "Total training time: 116.90 seconds.\n",
      "-- Epoch 1367\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.478310, T: 233601162, Avg. loss: 0.067364\n",
      "Total training time: 116.98 seconds.\n",
      "-- Epoch 1368\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.473512, T: 233772048, Avg. loss: 0.067361\n",
      "Total training time: 117.07 seconds.\n",
      "-- Epoch 1369\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.468712, T: 233942934, Avg. loss: 0.067358\n",
      "Total training time: 117.15 seconds.\n",
      "-- Epoch 1370\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.463910, T: 234113820, Avg. loss: 0.067355\n",
      "Total training time: 117.23 seconds.\n",
      "-- Epoch 1371\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.459116, T: 234284706, Avg. loss: 0.067353\n",
      "Total training time: 117.31 seconds.\n",
      "-- Epoch 1372\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.454323, T: 234455592, Avg. loss: 0.067350\n",
      "Total training time: 117.40 seconds.\n",
      "-- Epoch 1373\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.449545, T: 234626478, Avg. loss: 0.067347\n",
      "Total training time: 117.48 seconds.\n",
      "-- Epoch 1374\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.444756, T: 234797364, Avg. loss: 0.067345\n",
      "Total training time: 117.56 seconds.\n",
      "-- Epoch 1375\n",
      "Norm: 14.01, NNZs: 30, Bias: -125.439979, T: 234968250, Avg. loss: 0.067342\n",
      "Total training time: 117.64 seconds.\n",
      "-- Epoch 1376\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.435206, T: 235139136, Avg. loss: 0.067339\n",
      "Total training time: 117.73 seconds.\n",
      "-- Epoch 1377\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.430435, T: 235310022, Avg. loss: 0.067336\n",
      "Total training time: 117.81 seconds.\n",
      "-- Epoch 1378\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.425676, T: 235480908, Avg. loss: 0.067334\n",
      "Total training time: 117.89 seconds.\n",
      "-- Epoch 1379\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.420917, T: 235651794, Avg. loss: 0.067331\n",
      "Total training time: 117.97 seconds.\n",
      "-- Epoch 1380\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.416159, T: 235822680, Avg. loss: 0.067328\n",
      "Total training time: 118.05 seconds.\n",
      "-- Epoch 1381\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.411400, T: 235993566, Avg. loss: 0.067326\n",
      "Total training time: 118.13 seconds.\n",
      "-- Epoch 1382\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.406647, T: 236164452, Avg. loss: 0.067323\n",
      "Total training time: 118.21 seconds.\n",
      "-- Epoch 1383\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.401892, T: 236335338, Avg. loss: 0.067320\n",
      "Total training time: 118.29 seconds.\n",
      "-- Epoch 1384\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.397146, T: 236506224, Avg. loss: 0.067318\n",
      "Total training time: 118.38 seconds.\n",
      "-- Epoch 1385\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.392403, T: 236677110, Avg. loss: 0.067315\n",
      "Total training time: 118.46 seconds.\n",
      "-- Epoch 1386\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.387673, T: 236847996, Avg. loss: 0.067312\n",
      "Total training time: 118.54 seconds.\n",
      "-- Epoch 1387\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.382939, T: 237018882, Avg. loss: 0.067310\n",
      "Total training time: 118.63 seconds.\n",
      "-- Epoch 1388\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.378201, T: 237189768, Avg. loss: 0.067307\n",
      "Total training time: 118.71 seconds.\n",
      "-- Epoch 1389\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.373466, T: 237360654, Avg. loss: 0.067304\n",
      "Total training time: 118.79 seconds.\n",
      "-- Epoch 1390\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.368742, T: 237531540, Avg. loss: 0.067302\n",
      "Total training time: 118.87 seconds.\n",
      "-- Epoch 1391\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.364022, T: 237702426, Avg. loss: 0.067299\n",
      "Total training time: 118.95 seconds.\n",
      "-- Epoch 1392\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.359302, T: 237873312, Avg. loss: 0.067296\n",
      "Total training time: 119.03 seconds.\n",
      "-- Epoch 1393\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.354582, T: 238044198, Avg. loss: 0.067294\n",
      "Total training time: 119.11 seconds.\n",
      "-- Epoch 1394\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.349867, T: 238215084, Avg. loss: 0.067291\n",
      "Total training time: 119.19 seconds.\n",
      "-- Epoch 1395\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.345151, T: 238385970, Avg. loss: 0.067288\n",
      "Total training time: 119.27 seconds.\n",
      "-- Epoch 1396\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.340447, T: 238556856, Avg. loss: 0.067286\n",
      "Total training time: 119.36 seconds.\n",
      "-- Epoch 1397\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.335739, T: 238727742, Avg. loss: 0.067283\n",
      "Total training time: 119.44 seconds.\n",
      "-- Epoch 1398\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.331052, T: 238898628, Avg. loss: 0.067280\n",
      "Total training time: 119.52 seconds.\n",
      "-- Epoch 1399\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.326356, T: 239069514, Avg. loss: 0.067278\n",
      "Total training time: 119.61 seconds.\n",
      "-- Epoch 1400\n",
      "Norm: 14.00, NNZs: 30, Bias: -125.321657, T: 239240400, Avg. loss: 0.067275\n",
      "Total training time: 119.69 seconds.\n",
      "-- Epoch 1401\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.316968, T: 239411286, Avg. loss: 0.067272\n",
      "Total training time: 119.78 seconds.\n",
      "-- Epoch 1402\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.312285, T: 239582172, Avg. loss: 0.067270\n",
      "Total training time: 119.86 seconds.\n",
      "-- Epoch 1403\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.307603, T: 239753058, Avg. loss: 0.067267\n",
      "Total training time: 119.94 seconds.\n",
      "-- Epoch 1404\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.302927, T: 239923944, Avg. loss: 0.067265\n",
      "Total training time: 120.02 seconds.\n",
      "-- Epoch 1405\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.298255, T: 240094830, Avg. loss: 0.067262\n",
      "Total training time: 120.10 seconds.\n",
      "-- Epoch 1406\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.293592, T: 240265716, Avg. loss: 0.067259\n",
      "Total training time: 120.18 seconds.\n",
      "-- Epoch 1407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.99, NNZs: 30, Bias: -125.288918, T: 240436602, Avg. loss: 0.067257\n",
      "Total training time: 120.27 seconds.\n",
      "-- Epoch 1408\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.284254, T: 240607488, Avg. loss: 0.067254\n",
      "Total training time: 120.35 seconds.\n",
      "-- Epoch 1409\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.279593, T: 240778374, Avg. loss: 0.067251\n",
      "Total training time: 120.43 seconds.\n",
      "-- Epoch 1410\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.274931, T: 240949260, Avg. loss: 0.067249\n",
      "Total training time: 120.51 seconds.\n",
      "-- Epoch 1411\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.270275, T: 241120146, Avg. loss: 0.067246\n",
      "Total training time: 120.59 seconds.\n",
      "-- Epoch 1412\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.265618, T: 241291032, Avg. loss: 0.067244\n",
      "Total training time: 120.68 seconds.\n",
      "-- Epoch 1413\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.260964, T: 241461918, Avg. loss: 0.067241\n",
      "Total training time: 120.76 seconds.\n",
      "-- Epoch 1414\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.256321, T: 241632804, Avg. loss: 0.067238\n",
      "Total training time: 120.84 seconds.\n",
      "-- Epoch 1415\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.251684, T: 241803690, Avg. loss: 0.067236\n",
      "Total training time: 120.92 seconds.\n",
      "-- Epoch 1416\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.247051, T: 241974576, Avg. loss: 0.067233\n",
      "Total training time: 121.00 seconds.\n",
      "-- Epoch 1417\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.242415, T: 242145462, Avg. loss: 0.067230\n",
      "Total training time: 121.09 seconds.\n",
      "-- Epoch 1418\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.237791, T: 242316348, Avg. loss: 0.067228\n",
      "Total training time: 121.17 seconds.\n",
      "-- Epoch 1419\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.233156, T: 242487234, Avg. loss: 0.067225\n",
      "Total training time: 121.25 seconds.\n",
      "-- Epoch 1420\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.228537, T: 242658120, Avg. loss: 0.067223\n",
      "Total training time: 121.33 seconds.\n",
      "-- Epoch 1421\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.223912, T: 242829006, Avg. loss: 0.067220\n",
      "Total training time: 121.41 seconds.\n",
      "-- Epoch 1422\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.219290, T: 242999892, Avg. loss: 0.067217\n",
      "Total training time: 121.49 seconds.\n",
      "-- Epoch 1423\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.214666, T: 243170778, Avg. loss: 0.067215\n",
      "Total training time: 121.57 seconds.\n",
      "-- Epoch 1424\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.210054, T: 243341664, Avg. loss: 0.067212\n",
      "Total training time: 121.66 seconds.\n",
      "-- Epoch 1425\n",
      "Norm: 13.99, NNZs: 30, Bias: -125.205442, T: 243512550, Avg. loss: 0.067210\n",
      "Total training time: 121.74 seconds.\n",
      "-- Epoch 1426\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.200829, T: 243683436, Avg. loss: 0.067207\n",
      "Total training time: 121.82 seconds.\n",
      "-- Epoch 1427\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.196224, T: 243854322, Avg. loss: 0.067204\n",
      "Total training time: 121.90 seconds.\n",
      "-- Epoch 1428\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.191627, T: 244025208, Avg. loss: 0.067202\n",
      "Total training time: 121.99 seconds.\n",
      "-- Epoch 1429\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.187034, T: 244196094, Avg. loss: 0.067199\n",
      "Total training time: 122.07 seconds.\n",
      "-- Epoch 1430\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.182434, T: 244366980, Avg. loss: 0.067197\n",
      "Total training time: 122.15 seconds.\n",
      "-- Epoch 1431\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.177842, T: 244537866, Avg. loss: 0.067194\n",
      "Total training time: 122.23 seconds.\n",
      "-- Epoch 1432\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.173249, T: 244708752, Avg. loss: 0.067191\n",
      "Total training time: 122.31 seconds.\n",
      "-- Epoch 1433\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.168663, T: 244879638, Avg. loss: 0.067189\n",
      "Total training time: 122.40 seconds.\n",
      "-- Epoch 1434\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.164093, T: 245050524, Avg. loss: 0.067186\n",
      "Total training time: 122.48 seconds.\n",
      "-- Epoch 1435\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.159517, T: 245221410, Avg. loss: 0.067184\n",
      "Total training time: 122.57 seconds.\n",
      "-- Epoch 1436\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.154939, T: 245392296, Avg. loss: 0.067181\n",
      "Total training time: 122.65 seconds.\n",
      "-- Epoch 1437\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.150368, T: 245563182, Avg. loss: 0.067179\n",
      "Total training time: 122.73 seconds.\n",
      "-- Epoch 1438\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.145810, T: 245734068, Avg. loss: 0.067176\n",
      "Total training time: 122.81 seconds.\n",
      "-- Epoch 1439\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.141241, T: 245904954, Avg. loss: 0.067173\n",
      "Total training time: 122.89 seconds.\n",
      "-- Epoch 1440\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.136679, T: 246075840, Avg. loss: 0.067171\n",
      "Total training time: 122.98 seconds.\n",
      "-- Epoch 1441\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.132118, T: 246246726, Avg. loss: 0.067168\n",
      "Total training time: 123.06 seconds.\n",
      "-- Epoch 1442\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.127573, T: 246417612, Avg. loss: 0.067166\n",
      "Total training time: 123.14 seconds.\n",
      "-- Epoch 1443\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.123024, T: 246588498, Avg. loss: 0.067163\n",
      "Total training time: 123.22 seconds.\n",
      "-- Epoch 1444\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.118474, T: 246759384, Avg. loss: 0.067161\n",
      "Total training time: 123.31 seconds.\n",
      "-- Epoch 1445\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.113931, T: 246930270, Avg. loss: 0.067158\n",
      "Total training time: 123.39 seconds.\n",
      "-- Epoch 1446\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.109392, T: 247101156, Avg. loss: 0.067155\n",
      "Total training time: 123.47 seconds.\n",
      "-- Epoch 1447\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.104854, T: 247272042, Avg. loss: 0.067153\n",
      "Total training time: 123.56 seconds.\n",
      "-- Epoch 1448\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.100319, T: 247442928, Avg. loss: 0.067150\n",
      "Total training time: 123.64 seconds.\n",
      "-- Epoch 1449\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.095787, T: 247613814, Avg. loss: 0.067148\n",
      "Total training time: 123.72 seconds.\n",
      "-- Epoch 1450\n",
      "Norm: 13.98, NNZs: 30, Bias: -125.091253, T: 247784700, Avg. loss: 0.067145\n",
      "Total training time: 123.80 seconds.\n",
      "-- Epoch 1451\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.086730, T: 247955586, Avg. loss: 0.067143\n",
      "Total training time: 123.88 seconds.\n",
      "-- Epoch 1452\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.082209, T: 248126472, Avg. loss: 0.067140\n",
      "Total training time: 123.97 seconds.\n",
      "-- Epoch 1453\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.077687, T: 248297358, Avg. loss: 0.067138\n",
      "Total training time: 124.05 seconds.\n",
      "-- Epoch 1454\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.073167, T: 248468244, Avg. loss: 0.067135\n",
      "Total training time: 124.13 seconds.\n",
      "-- Epoch 1455\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.068646, T: 248639130, Avg. loss: 0.067132\n",
      "Total training time: 124.21 seconds.\n",
      "-- Epoch 1456\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.064141, T: 248810016, Avg. loss: 0.067130\n",
      "Total training time: 124.29 seconds.\n",
      "-- Epoch 1457\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.059632, T: 248980902, Avg. loss: 0.067127\n",
      "Total training time: 124.37 seconds.\n",
      "-- Epoch 1458\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.055137, T: 249151788, Avg. loss: 0.067125\n",
      "Total training time: 124.47 seconds.\n",
      "-- Epoch 1459\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.050638, T: 249322674, Avg. loss: 0.067122\n",
      "Total training time: 124.57 seconds.\n",
      "-- Epoch 1460\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.046136, T: 249493560, Avg. loss: 0.067120\n",
      "Total training time: 124.65 seconds.\n",
      "-- Epoch 1461\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.041644, T: 249664446, Avg. loss: 0.067117\n",
      "Total training time: 124.73 seconds.\n",
      "-- Epoch 1462\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.037148, T: 249835332, Avg. loss: 0.067115\n",
      "Total training time: 124.81 seconds.\n",
      "-- Epoch 1463\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.032652, T: 250006218, Avg. loss: 0.067112\n",
      "Total training time: 124.89 seconds.\n",
      "-- Epoch 1464\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.028170, T: 250177104, Avg. loss: 0.067110\n",
      "Total training time: 124.98 seconds.\n",
      "-- Epoch 1465\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.023683, T: 250347990, Avg. loss: 0.067107\n",
      "Total training time: 125.06 seconds.\n",
      "-- Epoch 1466\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.019202, T: 250518876, Avg. loss: 0.067105\n",
      "Total training time: 125.14 seconds.\n",
      "-- Epoch 1467\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.014722, T: 250689762, Avg. loss: 0.067102\n",
      "Total training time: 125.22 seconds.\n",
      "-- Epoch 1468\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.010249, T: 250860648, Avg. loss: 0.067100\n",
      "Total training time: 125.30 seconds.\n",
      "-- Epoch 1469\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.005778, T: 251031534, Avg. loss: 0.067097\n",
      "Total training time: 125.38 seconds.\n",
      "-- Epoch 1470\n",
      "Norm: 13.97, NNZs: 30, Bias: -125.001319, T: 251202420, Avg. loss: 0.067095\n",
      "Total training time: 125.47 seconds.\n",
      "-- Epoch 1471\n",
      "Norm: 13.97, NNZs: 30, Bias: -124.996860, T: 251373306, Avg. loss: 0.067092\n",
      "Total training time: 125.55 seconds.\n",
      "-- Epoch 1472\n",
      "Norm: 13.97, NNZs: 30, Bias: -124.992399, T: 251544192, Avg. loss: 0.067090\n",
      "Total training time: 125.64 seconds.\n",
      "-- Epoch 1473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.97, NNZs: 30, Bias: -124.987944, T: 251715078, Avg. loss: 0.067087\n",
      "Total training time: 125.72 seconds.\n",
      "-- Epoch 1474\n",
      "Norm: 13.97, NNZs: 30, Bias: -124.983493, T: 251885964, Avg. loss: 0.067084\n",
      "Total training time: 125.80 seconds.\n",
      "-- Epoch 1475\n",
      "Norm: 13.97, NNZs: 30, Bias: -124.979038, T: 252056850, Avg. loss: 0.067082\n",
      "Total training time: 125.88 seconds.\n",
      "-- Epoch 1476\n",
      "Norm: 13.97, NNZs: 30, Bias: -124.974592, T: 252227736, Avg. loss: 0.067079\n",
      "Total training time: 125.96 seconds.\n",
      "-- Epoch 1477\n",
      "Norm: 13.97, NNZs: 30, Bias: -124.970150, T: 252398622, Avg. loss: 0.067077\n",
      "Total training time: 126.05 seconds.\n",
      "-- Epoch 1478\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.965700, T: 252569508, Avg. loss: 0.067074\n",
      "Total training time: 126.13 seconds.\n",
      "-- Epoch 1479\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.961265, T: 252740394, Avg. loss: 0.067072\n",
      "Total training time: 126.21 seconds.\n",
      "-- Epoch 1480\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.956827, T: 252911280, Avg. loss: 0.067069\n",
      "Total training time: 126.29 seconds.\n",
      "-- Epoch 1481\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.952396, T: 253082166, Avg. loss: 0.067067\n",
      "Total training time: 126.37 seconds.\n",
      "-- Epoch 1482\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.947964, T: 253253052, Avg. loss: 0.067064\n",
      "Total training time: 126.46 seconds.\n",
      "-- Epoch 1483\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.943538, T: 253423938, Avg. loss: 0.067062\n",
      "Total training time: 126.54 seconds.\n",
      "-- Epoch 1484\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.939115, T: 253594824, Avg. loss: 0.067059\n",
      "Total training time: 126.62 seconds.\n",
      "-- Epoch 1485\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.934695, T: 253765710, Avg. loss: 0.067057\n",
      "Total training time: 126.70 seconds.\n",
      "-- Epoch 1486\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.930274, T: 253936596, Avg. loss: 0.067055\n",
      "Total training time: 126.78 seconds.\n",
      "-- Epoch 1487\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.925855, T: 254107482, Avg. loss: 0.067052\n",
      "Total training time: 126.86 seconds.\n",
      "-- Epoch 1488\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.921445, T: 254278368, Avg. loss: 0.067050\n",
      "Total training time: 126.94 seconds.\n",
      "-- Epoch 1489\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.917035, T: 254449254, Avg. loss: 0.067047\n",
      "Total training time: 127.03 seconds.\n",
      "-- Epoch 1490\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.912632, T: 254620140, Avg. loss: 0.067045\n",
      "Total training time: 127.11 seconds.\n",
      "-- Epoch 1491\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.908224, T: 254791026, Avg. loss: 0.067042\n",
      "Total training time: 127.19 seconds.\n",
      "-- Epoch 1492\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.903825, T: 254961912, Avg. loss: 0.067040\n",
      "Total training time: 127.27 seconds.\n",
      "-- Epoch 1493\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.899434, T: 255132798, Avg. loss: 0.067037\n",
      "Total training time: 127.35 seconds.\n",
      "-- Epoch 1494\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.895034, T: 255303684, Avg. loss: 0.067035\n",
      "Total training time: 127.44 seconds.\n",
      "-- Epoch 1495\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.890643, T: 255474570, Avg. loss: 0.067032\n",
      "Total training time: 127.52 seconds.\n",
      "-- Epoch 1496\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.886255, T: 255645456, Avg. loss: 0.067030\n",
      "Total training time: 127.60 seconds.\n",
      "-- Epoch 1497\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.881867, T: 255816342, Avg. loss: 0.067027\n",
      "Total training time: 127.68 seconds.\n",
      "-- Epoch 1498\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.877475, T: 255987228, Avg. loss: 0.067025\n",
      "Total training time: 127.76 seconds.\n",
      "-- Epoch 1499\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.873094, T: 256158114, Avg. loss: 0.067022\n",
      "Total training time: 127.85 seconds.\n",
      "-- Epoch 1500\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.868721, T: 256329000, Avg. loss: 0.067020\n",
      "Total training time: 127.93 seconds.\n",
      "-- Epoch 1501\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.864347, T: 256499886, Avg. loss: 0.067017\n",
      "Total training time: 128.01 seconds.\n",
      "-- Epoch 1502\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.859979, T: 256670772, Avg. loss: 0.067015\n",
      "Total training time: 128.09 seconds.\n",
      "-- Epoch 1503\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.855612, T: 256841658, Avg. loss: 0.067012\n",
      "Total training time: 128.18 seconds.\n",
      "-- Epoch 1504\n",
      "Norm: 13.96, NNZs: 30, Bias: -124.851245, T: 257012544, Avg. loss: 0.067010\n",
      "Total training time: 128.26 seconds.\n",
      "-- Epoch 1505\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.846885, T: 257183430, Avg. loss: 0.067008\n",
      "Total training time: 128.34 seconds.\n",
      "-- Epoch 1506\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.842524, T: 257354316, Avg. loss: 0.067005\n",
      "Total training time: 128.42 seconds.\n",
      "-- Epoch 1507\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.838170, T: 257525202, Avg. loss: 0.067003\n",
      "Total training time: 128.50 seconds.\n",
      "-- Epoch 1508\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.833822, T: 257696088, Avg. loss: 0.067000\n",
      "Total training time: 128.59 seconds.\n",
      "-- Epoch 1509\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.829480, T: 257866974, Avg. loss: 0.066998\n",
      "Total training time: 128.67 seconds.\n",
      "-- Epoch 1510\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.825130, T: 258037860, Avg. loss: 0.066995\n",
      "Total training time: 128.75 seconds.\n",
      "-- Epoch 1511\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.820784, T: 258208746, Avg. loss: 0.066993\n",
      "Total training time: 128.83 seconds.\n",
      "-- Epoch 1512\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.816444, T: 258379632, Avg. loss: 0.066990\n",
      "Total training time: 128.92 seconds.\n",
      "-- Epoch 1513\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.812108, T: 258550518, Avg. loss: 0.066988\n",
      "Total training time: 129.00 seconds.\n",
      "-- Epoch 1514\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.807772, T: 258721404, Avg. loss: 0.066986\n",
      "Total training time: 129.08 seconds.\n",
      "-- Epoch 1515\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.803441, T: 258892290, Avg. loss: 0.066983\n",
      "Total training time: 129.16 seconds.\n",
      "-- Epoch 1516\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.799109, T: 259063176, Avg. loss: 0.066981\n",
      "Total training time: 129.25 seconds.\n",
      "-- Epoch 1517\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.794779, T: 259234062, Avg. loss: 0.066978\n",
      "Total training time: 129.33 seconds.\n",
      "-- Epoch 1518\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.790454, T: 259404948, Avg. loss: 0.066976\n",
      "Total training time: 129.41 seconds.\n",
      "-- Epoch 1519\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.786127, T: 259575834, Avg. loss: 0.066973\n",
      "Total training time: 129.49 seconds.\n",
      "-- Epoch 1520\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.781811, T: 259746720, Avg. loss: 0.066971\n",
      "Total training time: 129.58 seconds.\n",
      "-- Epoch 1521\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.777491, T: 259917606, Avg. loss: 0.066968\n",
      "Total training time: 129.66 seconds.\n",
      "-- Epoch 1522\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.773176, T: 260088492, Avg. loss: 0.066966\n",
      "Total training time: 129.74 seconds.\n",
      "-- Epoch 1523\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.768865, T: 260259378, Avg. loss: 0.066964\n",
      "Total training time: 129.82 seconds.\n",
      "-- Epoch 1524\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.764558, T: 260430264, Avg. loss: 0.066961\n",
      "Total training time: 129.91 seconds.\n",
      "-- Epoch 1525\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.760251, T: 260601150, Avg. loss: 0.066959\n",
      "Total training time: 129.99 seconds.\n",
      "-- Epoch 1526\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.755938, T: 260772036, Avg. loss: 0.066956\n",
      "Total training time: 130.08 seconds.\n",
      "-- Epoch 1527\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.751638, T: 260942922, Avg. loss: 0.066954\n",
      "Total training time: 130.16 seconds.\n",
      "-- Epoch 1528\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.747341, T: 261113808, Avg. loss: 0.066952\n",
      "Total training time: 130.24 seconds.\n",
      "-- Epoch 1529\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.743048, T: 261284694, Avg. loss: 0.066949\n",
      "Total training time: 130.32 seconds.\n",
      "-- Epoch 1530\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.738762, T: 261455580, Avg. loss: 0.066947\n",
      "Total training time: 130.40 seconds.\n",
      "-- Epoch 1531\n",
      "Norm: 13.95, NNZs: 30, Bias: -124.734474, T: 261626466, Avg. loss: 0.066944\n",
      "Total training time: 130.49 seconds.\n",
      "-- Epoch 1532\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.730193, T: 261797352, Avg. loss: 0.066942\n",
      "Total training time: 130.57 seconds.\n",
      "-- Epoch 1533\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.725901, T: 261968238, Avg. loss: 0.066939\n",
      "Total training time: 130.65 seconds.\n",
      "-- Epoch 1534\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.721618, T: 262139124, Avg. loss: 0.066937\n",
      "Total training time: 130.73 seconds.\n",
      "-- Epoch 1535\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.717343, T: 262310010, Avg. loss: 0.066935\n",
      "Total training time: 130.81 seconds.\n",
      "-- Epoch 1536\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.713071, T: 262480896, Avg. loss: 0.066932\n",
      "Total training time: 130.89 seconds.\n",
      "-- Epoch 1537\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.708802, T: 262651782, Avg. loss: 0.066930\n",
      "Total training time: 130.97 seconds.\n",
      "-- Epoch 1538\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.704529, T: 262822668, Avg. loss: 0.066927\n",
      "Total training time: 131.06 seconds.\n",
      "-- Epoch 1539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.94, NNZs: 30, Bias: -124.700265, T: 262993554, Avg. loss: 0.066925\n",
      "Total training time: 131.14 seconds.\n",
      "-- Epoch 1540\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.696007, T: 263164440, Avg. loss: 0.066923\n",
      "Total training time: 131.22 seconds.\n",
      "-- Epoch 1541\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.691752, T: 263335326, Avg. loss: 0.066920\n",
      "Total training time: 131.30 seconds.\n",
      "-- Epoch 1542\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.687491, T: 263506212, Avg. loss: 0.066918\n",
      "Total training time: 131.38 seconds.\n",
      "-- Epoch 1543\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.683241, T: 263677098, Avg. loss: 0.066915\n",
      "Total training time: 131.47 seconds.\n",
      "-- Epoch 1544\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.678995, T: 263847984, Avg. loss: 0.066913\n",
      "Total training time: 131.55 seconds.\n",
      "-- Epoch 1545\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.674742, T: 264018870, Avg. loss: 0.066911\n",
      "Total training time: 131.63 seconds.\n",
      "-- Epoch 1546\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.670496, T: 264189756, Avg. loss: 0.066908\n",
      "Total training time: 131.71 seconds.\n",
      "-- Epoch 1547\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.666254, T: 264360642, Avg. loss: 0.066906\n",
      "Total training time: 131.79 seconds.\n",
      "-- Epoch 1548\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.662012, T: 264531528, Avg. loss: 0.066904\n",
      "Total training time: 131.88 seconds.\n",
      "-- Epoch 1549\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.657779, T: 264702414, Avg. loss: 0.066901\n",
      "Total training time: 131.96 seconds.\n",
      "-- Epoch 1550\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.653548, T: 264873300, Avg. loss: 0.066899\n",
      "Total training time: 132.04 seconds.\n",
      "-- Epoch 1551\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.649320, T: 265044186, Avg. loss: 0.066896\n",
      "Total training time: 132.12 seconds.\n",
      "-- Epoch 1552\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.645085, T: 265215072, Avg. loss: 0.066894\n",
      "Total training time: 132.21 seconds.\n",
      "-- Epoch 1553\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.640864, T: 265385958, Avg. loss: 0.066892\n",
      "Total training time: 132.29 seconds.\n",
      "-- Epoch 1554\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.636635, T: 265556844, Avg. loss: 0.066889\n",
      "Total training time: 132.37 seconds.\n",
      "-- Epoch 1555\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.632417, T: 265727730, Avg. loss: 0.066887\n",
      "Total training time: 132.45 seconds.\n",
      "-- Epoch 1556\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.628208, T: 265898616, Avg. loss: 0.066884\n",
      "Total training time: 132.53 seconds.\n",
      "-- Epoch 1557\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.623994, T: 266069502, Avg. loss: 0.066882\n",
      "Total training time: 132.61 seconds.\n",
      "-- Epoch 1558\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.619784, T: 266240388, Avg. loss: 0.066880\n",
      "Total training time: 132.72 seconds.\n",
      "-- Epoch 1559\n",
      "Norm: 13.94, NNZs: 30, Bias: -124.615573, T: 266411274, Avg. loss: 0.066877\n",
      "Total training time: 132.80 seconds.\n",
      "-- Epoch 1560\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.611367, T: 266582160, Avg. loss: 0.066875\n",
      "Total training time: 132.89 seconds.\n",
      "-- Epoch 1561\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.607157, T: 266753046, Avg. loss: 0.066873\n",
      "Total training time: 132.97 seconds.\n",
      "-- Epoch 1562\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.602954, T: 266923932, Avg. loss: 0.066870\n",
      "Total training time: 133.05 seconds.\n",
      "-- Epoch 1563\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.598754, T: 267094818, Avg. loss: 0.066868\n",
      "Total training time: 133.13 seconds.\n",
      "-- Epoch 1564\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.594562, T: 267265704, Avg. loss: 0.066866\n",
      "Total training time: 133.22 seconds.\n",
      "-- Epoch 1565\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.590371, T: 267436590, Avg. loss: 0.066863\n",
      "Total training time: 133.30 seconds.\n",
      "-- Epoch 1566\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.586182, T: 267607476, Avg. loss: 0.066861\n",
      "Total training time: 133.38 seconds.\n",
      "-- Epoch 1567\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.581996, T: 267778362, Avg. loss: 0.066858\n",
      "Total training time: 133.46 seconds.\n",
      "-- Epoch 1568\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.577813, T: 267949248, Avg. loss: 0.066856\n",
      "Total training time: 133.55 seconds.\n",
      "-- Epoch 1569\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.573632, T: 268120134, Avg. loss: 0.066854\n",
      "Total training time: 133.63 seconds.\n",
      "-- Epoch 1570\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.569459, T: 268291020, Avg. loss: 0.066851\n",
      "Total training time: 133.71 seconds.\n",
      "-- Epoch 1571\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.565277, T: 268461906, Avg. loss: 0.066849\n",
      "Total training time: 133.79 seconds.\n",
      "-- Epoch 1572\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.561098, T: 268632792, Avg. loss: 0.066847\n",
      "Total training time: 133.88 seconds.\n",
      "-- Epoch 1573\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.556920, T: 268803678, Avg. loss: 0.066844\n",
      "Total training time: 133.96 seconds.\n",
      "-- Epoch 1574\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.552750, T: 268974564, Avg. loss: 0.066842\n",
      "Total training time: 134.04 seconds.\n",
      "-- Epoch 1575\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.548577, T: 269145450, Avg. loss: 0.066840\n",
      "Total training time: 134.12 seconds.\n",
      "-- Epoch 1576\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.544409, T: 269316336, Avg. loss: 0.066837\n",
      "Total training time: 134.20 seconds.\n",
      "-- Epoch 1577\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.540246, T: 269487222, Avg. loss: 0.066835\n",
      "Total training time: 134.28 seconds.\n",
      "-- Epoch 1578\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.536089, T: 269658108, Avg. loss: 0.066833\n",
      "Total training time: 134.37 seconds.\n",
      "-- Epoch 1579\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.531933, T: 269828994, Avg. loss: 0.066830\n",
      "Total training time: 134.45 seconds.\n",
      "-- Epoch 1580\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.527782, T: 269999880, Avg. loss: 0.066828\n",
      "Total training time: 134.53 seconds.\n",
      "-- Epoch 1581\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.523635, T: 270170766, Avg. loss: 0.066826\n",
      "Total training time: 134.61 seconds.\n",
      "-- Epoch 1582\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.519491, T: 270341652, Avg. loss: 0.066823\n",
      "Total training time: 134.69 seconds.\n",
      "-- Epoch 1583\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.515350, T: 270512538, Avg. loss: 0.066821\n",
      "Total training time: 134.78 seconds.\n",
      "-- Epoch 1584\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.511203, T: 270683424, Avg. loss: 0.066819\n",
      "Total training time: 134.86 seconds.\n",
      "-- Epoch 1585\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.507059, T: 270854310, Avg. loss: 0.066816\n",
      "Total training time: 134.94 seconds.\n",
      "-- Epoch 1586\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.502927, T: 271025196, Avg. loss: 0.066814\n",
      "Total training time: 135.02 seconds.\n",
      "-- Epoch 1587\n",
      "Norm: 13.93, NNZs: 30, Bias: -124.498793, T: 271196082, Avg. loss: 0.066812\n",
      "Total training time: 135.10 seconds.\n",
      "-- Epoch 1588\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.494657, T: 271366968, Avg. loss: 0.066809\n",
      "Total training time: 135.19 seconds.\n",
      "-- Epoch 1589\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.490527, T: 271537854, Avg. loss: 0.066807\n",
      "Total training time: 135.27 seconds.\n",
      "-- Epoch 1590\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.486397, T: 271708740, Avg. loss: 0.066805\n",
      "Total training time: 135.35 seconds.\n",
      "-- Epoch 1591\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.482272, T: 271879626, Avg. loss: 0.066802\n",
      "Total training time: 135.44 seconds.\n",
      "-- Epoch 1592\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.478144, T: 272050512, Avg. loss: 0.066800\n",
      "Total training time: 135.52 seconds.\n",
      "-- Epoch 1593\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.474028, T: 272221398, Avg. loss: 0.066798\n",
      "Total training time: 135.60 seconds.\n",
      "-- Epoch 1594\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.469919, T: 272392284, Avg. loss: 0.066795\n",
      "Total training time: 135.68 seconds.\n",
      "-- Epoch 1595\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.465806, T: 272563170, Avg. loss: 0.066793\n",
      "Total training time: 135.76 seconds.\n",
      "-- Epoch 1596\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.461698, T: 272734056, Avg. loss: 0.066791\n",
      "Total training time: 135.85 seconds.\n",
      "-- Epoch 1597\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.457587, T: 272904942, Avg. loss: 0.066789\n",
      "Total training time: 135.93 seconds.\n",
      "-- Epoch 1598\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.453484, T: 273075828, Avg. loss: 0.066786\n",
      "Total training time: 136.01 seconds.\n",
      "-- Epoch 1599\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.449375, T: 273246714, Avg. loss: 0.066784\n",
      "Total training time: 136.09 seconds.\n",
      "-- Epoch 1600\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.445282, T: 273417600, Avg. loss: 0.066782\n",
      "Total training time: 136.17 seconds.\n",
      "-- Epoch 1601\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.441189, T: 273588486, Avg. loss: 0.066779\n",
      "Total training time: 136.26 seconds.\n",
      "-- Epoch 1602\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.437092, T: 273759372, Avg. loss: 0.066777\n",
      "Total training time: 136.34 seconds.\n",
      "-- Epoch 1603\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.433003, T: 273930258, Avg. loss: 0.066775\n",
      "Total training time: 136.42 seconds.\n",
      "-- Epoch 1604\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.428916, T: 274101144, Avg. loss: 0.066772\n",
      "Total training time: 136.50 seconds.\n",
      "-- Epoch 1605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.92, NNZs: 30, Bias: -124.424821, T: 274272030, Avg. loss: 0.066770\n",
      "Total training time: 136.59 seconds.\n",
      "-- Epoch 1606\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.420738, T: 274442916, Avg. loss: 0.066768\n",
      "Total training time: 136.67 seconds.\n",
      "-- Epoch 1607\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.416657, T: 274613802, Avg. loss: 0.066765\n",
      "Total training time: 136.75 seconds.\n",
      "-- Epoch 1608\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.412575, T: 274784688, Avg. loss: 0.066763\n",
      "Total training time: 136.83 seconds.\n",
      "-- Epoch 1609\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.408493, T: 274955574, Avg. loss: 0.066761\n",
      "Total training time: 136.92 seconds.\n",
      "-- Epoch 1610\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.404424, T: 275126460, Avg. loss: 0.066759\n",
      "Total training time: 137.00 seconds.\n",
      "-- Epoch 1611\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.400349, T: 275297346, Avg. loss: 0.066756\n",
      "Total training time: 137.08 seconds.\n",
      "-- Epoch 1612\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.396278, T: 275468232, Avg. loss: 0.066754\n",
      "Total training time: 137.17 seconds.\n",
      "-- Epoch 1613\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.392210, T: 275639118, Avg. loss: 0.066752\n",
      "Total training time: 137.25 seconds.\n",
      "-- Epoch 1614\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.388146, T: 275810004, Avg. loss: 0.066749\n",
      "Total training time: 137.33 seconds.\n",
      "-- Epoch 1615\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.384084, T: 275980890, Avg. loss: 0.066747\n",
      "Total training time: 137.41 seconds.\n",
      "-- Epoch 1616\n",
      "Norm: 13.92, NNZs: 30, Bias: -124.380023, T: 276151776, Avg. loss: 0.066745\n",
      "Total training time: 137.50 seconds.\n",
      "-- Epoch 1617\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.375972, T: 276322662, Avg. loss: 0.066743\n",
      "Total training time: 137.58 seconds.\n",
      "-- Epoch 1618\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.371911, T: 276493548, Avg. loss: 0.066740\n",
      "Total training time: 137.66 seconds.\n",
      "-- Epoch 1619\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.367855, T: 276664434, Avg. loss: 0.066738\n",
      "Total training time: 137.75 seconds.\n",
      "-- Epoch 1620\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.363805, T: 276835320, Avg. loss: 0.066736\n",
      "Total training time: 137.83 seconds.\n",
      "-- Epoch 1621\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.359760, T: 277006206, Avg. loss: 0.066734\n",
      "Total training time: 137.91 seconds.\n",
      "-- Epoch 1622\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.355712, T: 277177092, Avg. loss: 0.066731\n",
      "Total training time: 137.99 seconds.\n",
      "-- Epoch 1623\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.351666, T: 277347978, Avg. loss: 0.066729\n",
      "Total training time: 138.07 seconds.\n",
      "-- Epoch 1624\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.347628, T: 277518864, Avg. loss: 0.066727\n",
      "Total training time: 138.19 seconds.\n",
      "-- Epoch 1625\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.343588, T: 277689750, Avg. loss: 0.066724\n",
      "Total training time: 138.28 seconds.\n",
      "-- Epoch 1626\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.339557, T: 277860636, Avg. loss: 0.066722\n",
      "Total training time: 138.37 seconds.\n",
      "-- Epoch 1627\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.335527, T: 278031522, Avg. loss: 0.066720\n",
      "Total training time: 138.45 seconds.\n",
      "-- Epoch 1628\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.331501, T: 278202408, Avg. loss: 0.066718\n",
      "Total training time: 138.54 seconds.\n",
      "-- Epoch 1629\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.327476, T: 278373294, Avg. loss: 0.066715\n",
      "Total training time: 138.62 seconds.\n",
      "-- Epoch 1630\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.323452, T: 278544180, Avg. loss: 0.066713\n",
      "Total training time: 138.70 seconds.\n",
      "-- Epoch 1631\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.319429, T: 278715066, Avg. loss: 0.066711\n",
      "Total training time: 138.78 seconds.\n",
      "-- Epoch 1632\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.315409, T: 278885952, Avg. loss: 0.066709\n",
      "Total training time: 138.86 seconds.\n",
      "-- Epoch 1633\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.311389, T: 279056838, Avg. loss: 0.066706\n",
      "Total training time: 138.94 seconds.\n",
      "-- Epoch 1634\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.307373, T: 279227724, Avg. loss: 0.066704\n",
      "Total training time: 139.02 seconds.\n",
      "-- Epoch 1635\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.303366, T: 279398610, Avg. loss: 0.066702\n",
      "Total training time: 139.11 seconds.\n",
      "-- Epoch 1636\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.299356, T: 279569496, Avg. loss: 0.066700\n",
      "Total training time: 139.19 seconds.\n",
      "-- Epoch 1637\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.295350, T: 279740382, Avg. loss: 0.066697\n",
      "Total training time: 139.27 seconds.\n",
      "-- Epoch 1638\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.291341, T: 279911268, Avg. loss: 0.066695\n",
      "Total training time: 139.35 seconds.\n",
      "-- Epoch 1639\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.287342, T: 280082154, Avg. loss: 0.066693\n",
      "Total training time: 139.43 seconds.\n",
      "-- Epoch 1640\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.283342, T: 280253040, Avg. loss: 0.066691\n",
      "Total training time: 139.51 seconds.\n",
      "-- Epoch 1641\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.279346, T: 280423926, Avg. loss: 0.066688\n",
      "Total training time: 139.60 seconds.\n",
      "-- Epoch 1642\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.275351, T: 280594812, Avg. loss: 0.066686\n",
      "Total training time: 139.68 seconds.\n",
      "-- Epoch 1643\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.271359, T: 280765698, Avg. loss: 0.066684\n",
      "Total training time: 139.76 seconds.\n",
      "-- Epoch 1644\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.267371, T: 280936584, Avg. loss: 0.066682\n",
      "Total training time: 139.84 seconds.\n",
      "-- Epoch 1645\n",
      "Norm: 13.91, NNZs: 30, Bias: -124.263385, T: 281107470, Avg. loss: 0.066679\n",
      "Total training time: 139.93 seconds.\n",
      "-- Epoch 1646\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.259402, T: 281278356, Avg. loss: 0.066677\n",
      "Total training time: 140.01 seconds.\n",
      "-- Epoch 1647\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.255420, T: 281449242, Avg. loss: 0.066675\n",
      "Total training time: 140.09 seconds.\n",
      "-- Epoch 1648\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.251436, T: 281620128, Avg. loss: 0.066673\n",
      "Total training time: 140.17 seconds.\n",
      "-- Epoch 1649\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.247459, T: 281791014, Avg. loss: 0.066670\n",
      "Total training time: 140.25 seconds.\n",
      "-- Epoch 1650\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.243486, T: 281961900, Avg. loss: 0.066668\n",
      "Total training time: 140.34 seconds.\n",
      "-- Epoch 1651\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.239510, T: 282132786, Avg. loss: 0.066666\n",
      "Total training time: 140.42 seconds.\n",
      "-- Epoch 1652\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.235536, T: 282303672, Avg. loss: 0.066664\n",
      "Total training time: 140.50 seconds.\n",
      "-- Epoch 1653\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.231576, T: 282474558, Avg. loss: 0.066661\n",
      "Total training time: 140.59 seconds.\n",
      "-- Epoch 1654\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.227609, T: 282645444, Avg. loss: 0.066659\n",
      "Total training time: 140.67 seconds.\n",
      "-- Epoch 1655\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.223643, T: 282816330, Avg. loss: 0.066657\n",
      "Total training time: 140.75 seconds.\n",
      "-- Epoch 1656\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.219681, T: 282987216, Avg. loss: 0.066655\n",
      "Total training time: 140.83 seconds.\n",
      "-- Epoch 1657\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.215725, T: 283158102, Avg. loss: 0.066653\n",
      "Total training time: 140.92 seconds.\n",
      "-- Epoch 1658\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.211770, T: 283328988, Avg. loss: 0.066650\n",
      "Total training time: 141.00 seconds.\n",
      "-- Epoch 1659\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.207817, T: 283499874, Avg. loss: 0.066648\n",
      "Total training time: 141.08 seconds.\n",
      "-- Epoch 1660\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.203870, T: 283670760, Avg. loss: 0.066646\n",
      "Total training time: 141.16 seconds.\n",
      "-- Epoch 1661\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.199920, T: 283841646, Avg. loss: 0.066644\n",
      "Total training time: 141.25 seconds.\n",
      "-- Epoch 1662\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.195973, T: 284012532, Avg. loss: 0.066641\n",
      "Total training time: 141.33 seconds.\n",
      "-- Epoch 1663\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.192033, T: 284183418, Avg. loss: 0.066639\n",
      "Total training time: 141.41 seconds.\n",
      "-- Epoch 1664\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.188088, T: 284354304, Avg. loss: 0.066637\n",
      "Total training time: 141.50 seconds.\n",
      "-- Epoch 1665\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.184158, T: 284525190, Avg. loss: 0.066635\n",
      "Total training time: 141.58 seconds.\n",
      "-- Epoch 1666\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.180227, T: 284696076, Avg. loss: 0.066633\n",
      "Total training time: 141.66 seconds.\n",
      "-- Epoch 1667\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.176294, T: 284866962, Avg. loss: 0.066630\n",
      "Total training time: 141.75 seconds.\n",
      "-- Epoch 1668\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.172364, T: 285037848, Avg. loss: 0.066628\n",
      "Total training time: 141.83 seconds.\n",
      "-- Epoch 1669\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.168427, T: 285208734, Avg. loss: 0.066626\n",
      "Total training time: 141.91 seconds.\n",
      "-- Epoch 1670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.90, NNZs: 30, Bias: -124.164506, T: 285379620, Avg. loss: 0.066624\n",
      "Total training time: 142.00 seconds.\n",
      "-- Epoch 1671\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.160576, T: 285550506, Avg. loss: 0.066622\n",
      "Total training time: 142.08 seconds.\n",
      "-- Epoch 1672\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.156654, T: 285721392, Avg. loss: 0.066619\n",
      "Total training time: 142.16 seconds.\n",
      "-- Epoch 1673\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.152729, T: 285892278, Avg. loss: 0.066617\n",
      "Total training time: 142.24 seconds.\n",
      "-- Epoch 1674\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.148806, T: 286063164, Avg. loss: 0.066615\n",
      "Total training time: 142.33 seconds.\n",
      "-- Epoch 1675\n",
      "Norm: 13.90, NNZs: 30, Bias: -124.144886, T: 286234050, Avg. loss: 0.066613\n",
      "Total training time: 142.41 seconds.\n",
      "-- Epoch 1676\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.140975, T: 286404936, Avg. loss: 0.066611\n",
      "Total training time: 142.49 seconds.\n",
      "-- Epoch 1677\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.137065, T: 286575822, Avg. loss: 0.066608\n",
      "Total training time: 142.58 seconds.\n",
      "-- Epoch 1678\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.133157, T: 286746708, Avg. loss: 0.066606\n",
      "Total training time: 142.66 seconds.\n",
      "-- Epoch 1679\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.129251, T: 286917594, Avg. loss: 0.066604\n",
      "Total training time: 142.74 seconds.\n",
      "-- Epoch 1680\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.125345, T: 287088480, Avg. loss: 0.066602\n",
      "Total training time: 142.82 seconds.\n",
      "-- Epoch 1681\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.121447, T: 287259366, Avg. loss: 0.066600\n",
      "Total training time: 142.90 seconds.\n",
      "-- Epoch 1682\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.117548, T: 287430252, Avg. loss: 0.066597\n",
      "Total training time: 142.98 seconds.\n",
      "-- Epoch 1683\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.113650, T: 287601138, Avg. loss: 0.066595\n",
      "Total training time: 143.06 seconds.\n",
      "-- Epoch 1684\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.109758, T: 287772024, Avg. loss: 0.066593\n",
      "Total training time: 143.17 seconds.\n",
      "-- Epoch 1685\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.105861, T: 287942910, Avg. loss: 0.066591\n",
      "Total training time: 143.26 seconds.\n",
      "-- Epoch 1686\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.101970, T: 288113796, Avg. loss: 0.066589\n",
      "Total training time: 143.34 seconds.\n",
      "-- Epoch 1687\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.098079, T: 288284682, Avg. loss: 0.066586\n",
      "Total training time: 143.42 seconds.\n",
      "-- Epoch 1688\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.094192, T: 288455568, Avg. loss: 0.066584\n",
      "Total training time: 143.51 seconds.\n",
      "-- Epoch 1689\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.090314, T: 288626454, Avg. loss: 0.066582\n",
      "Total training time: 143.59 seconds.\n",
      "-- Epoch 1690\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.086438, T: 288797340, Avg. loss: 0.066580\n",
      "Total training time: 143.67 seconds.\n",
      "-- Epoch 1691\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.082561, T: 288968226, Avg. loss: 0.066578\n",
      "Total training time: 143.75 seconds.\n",
      "-- Epoch 1692\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.078687, T: 289139112, Avg. loss: 0.066576\n",
      "Total training time: 143.83 seconds.\n",
      "-- Epoch 1693\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.074811, T: 289309998, Avg. loss: 0.066573\n",
      "Total training time: 143.92 seconds.\n",
      "-- Epoch 1694\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.070945, T: 289480884, Avg. loss: 0.066571\n",
      "Total training time: 144.00 seconds.\n",
      "-- Epoch 1695\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.067074, T: 289651770, Avg. loss: 0.066569\n",
      "Total training time: 144.08 seconds.\n",
      "-- Epoch 1696\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.063209, T: 289822656, Avg. loss: 0.066567\n",
      "Total training time: 144.17 seconds.\n",
      "-- Epoch 1697\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.059351, T: 289993542, Avg. loss: 0.066565\n",
      "Total training time: 144.25 seconds.\n",
      "-- Epoch 1698\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.055488, T: 290164428, Avg. loss: 0.066563\n",
      "Total training time: 144.33 seconds.\n",
      "-- Epoch 1699\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.051628, T: 290335314, Avg. loss: 0.066560\n",
      "Total training time: 144.41 seconds.\n",
      "-- Epoch 1700\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.047767, T: 290506200, Avg. loss: 0.066558\n",
      "Total training time: 144.50 seconds.\n",
      "-- Epoch 1701\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.043913, T: 290677086, Avg. loss: 0.066556\n",
      "Total training time: 144.58 seconds.\n",
      "-- Epoch 1702\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.040058, T: 290847972, Avg. loss: 0.066554\n",
      "Total training time: 144.66 seconds.\n",
      "-- Epoch 1703\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.036209, T: 291018858, Avg. loss: 0.066552\n",
      "Total training time: 144.74 seconds.\n",
      "-- Epoch 1704\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.032357, T: 291189744, Avg. loss: 0.066550\n",
      "Total training time: 144.83 seconds.\n",
      "-- Epoch 1705\n",
      "Norm: 13.89, NNZs: 30, Bias: -124.028509, T: 291360630, Avg. loss: 0.066547\n",
      "Total training time: 144.91 seconds.\n",
      "-- Epoch 1706\n",
      "Norm: 13.88, NNZs: 30, Bias: -124.024666, T: 291531516, Avg. loss: 0.066545\n",
      "Total training time: 144.99 seconds.\n",
      "-- Epoch 1707\n",
      "Norm: 13.88, NNZs: 30, Bias: -124.020826, T: 291702402, Avg. loss: 0.066543\n",
      "Total training time: 145.07 seconds.\n",
      "-- Epoch 1708\n",
      "Norm: 13.88, NNZs: 30, Bias: -124.016983, T: 291873288, Avg. loss: 0.066541\n",
      "Total training time: 145.15 seconds.\n",
      "-- Epoch 1709\n",
      "Norm: 13.88, NNZs: 30, Bias: -124.013146, T: 292044174, Avg. loss: 0.066539\n",
      "Total training time: 145.23 seconds.\n",
      "-- Epoch 1710\n",
      "Norm: 13.88, NNZs: 30, Bias: -124.009310, T: 292215060, Avg. loss: 0.066537\n",
      "Total training time: 145.31 seconds.\n",
      "-- Epoch 1711\n",
      "Norm: 13.88, NNZs: 30, Bias: -124.005477, T: 292385946, Avg. loss: 0.066535\n",
      "Total training time: 145.39 seconds.\n",
      "-- Epoch 1712\n",
      "Norm: 13.88, NNZs: 30, Bias: -124.001648, T: 292556832, Avg. loss: 0.066532\n",
      "Total training time: 145.48 seconds.\n",
      "-- Epoch 1713\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.997821, T: 292727718, Avg. loss: 0.066530\n",
      "Total training time: 145.56 seconds.\n",
      "-- Epoch 1714\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.993997, T: 292898604, Avg. loss: 0.066528\n",
      "Total training time: 145.64 seconds.\n",
      "-- Epoch 1715\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.990172, T: 293069490, Avg. loss: 0.066526\n",
      "Total training time: 145.72 seconds.\n",
      "-- Epoch 1716\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.986353, T: 293240376, Avg. loss: 0.066524\n",
      "Total training time: 145.80 seconds.\n",
      "-- Epoch 1717\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.982534, T: 293411262, Avg. loss: 0.066522\n",
      "Total training time: 145.88 seconds.\n",
      "-- Epoch 1718\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.978719, T: 293582148, Avg. loss: 0.066519\n",
      "Total training time: 145.97 seconds.\n",
      "-- Epoch 1719\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.974902, T: 293753034, Avg. loss: 0.066517\n",
      "Total training time: 146.05 seconds.\n",
      "-- Epoch 1720\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.971095, T: 293923920, Avg. loss: 0.066515\n",
      "Total training time: 146.13 seconds.\n",
      "-- Epoch 1721\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.967289, T: 294094806, Avg. loss: 0.066513\n",
      "Total training time: 146.21 seconds.\n",
      "-- Epoch 1722\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.963487, T: 294265692, Avg. loss: 0.066511\n",
      "Total training time: 146.30 seconds.\n",
      "-- Epoch 1723\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.959683, T: 294436578, Avg. loss: 0.066509\n",
      "Total training time: 146.38 seconds.\n",
      "-- Epoch 1724\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.955880, T: 294607464, Avg. loss: 0.066507\n",
      "Total training time: 146.46 seconds.\n",
      "-- Epoch 1725\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.952081, T: 294778350, Avg. loss: 0.066505\n",
      "Total training time: 146.54 seconds.\n",
      "-- Epoch 1726\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.948282, T: 294949236, Avg. loss: 0.066502\n",
      "Total training time: 146.62 seconds.\n",
      "-- Epoch 1727\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.944486, T: 295120122, Avg. loss: 0.066500\n",
      "Total training time: 146.71 seconds.\n",
      "-- Epoch 1728\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.940693, T: 295291008, Avg. loss: 0.066498\n",
      "Total training time: 146.79 seconds.\n",
      "-- Epoch 1729\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.936892, T: 295461894, Avg. loss: 0.066496\n",
      "Total training time: 146.87 seconds.\n",
      "-- Epoch 1730\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.933108, T: 295632780, Avg. loss: 0.066494\n",
      "Total training time: 146.95 seconds.\n",
      "-- Epoch 1731\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.929327, T: 295803666, Avg. loss: 0.066492\n",
      "Total training time: 147.03 seconds.\n",
      "-- Epoch 1732\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.925546, T: 295974552, Avg. loss: 0.066490\n",
      "Total training time: 147.12 seconds.\n",
      "-- Epoch 1733\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.921760, T: 296145438, Avg. loss: 0.066487\n",
      "Total training time: 147.20 seconds.\n",
      "-- Epoch 1734\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.917982, T: 296316324, Avg. loss: 0.066485\n",
      "Total training time: 147.28 seconds.\n",
      "-- Epoch 1735\n",
      "Norm: 13.88, NNZs: 30, Bias: -123.914206, T: 296487210, Avg. loss: 0.066483\n",
      "Total training time: 147.36 seconds.\n",
      "-- Epoch 1736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.88, NNZs: 30, Bias: -123.910430, T: 296658096, Avg. loss: 0.066481\n",
      "Total training time: 147.45 seconds.\n",
      "-- Epoch 1737\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.906655, T: 296828982, Avg. loss: 0.066479\n",
      "Total training time: 147.53 seconds.\n",
      "-- Epoch 1738\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.902880, T: 296999868, Avg. loss: 0.066477\n",
      "Total training time: 147.61 seconds.\n",
      "-- Epoch 1739\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.899111, T: 297170754, Avg. loss: 0.066475\n",
      "Total training time: 147.69 seconds.\n",
      "-- Epoch 1740\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.895342, T: 297341640, Avg. loss: 0.066473\n",
      "Total training time: 147.81 seconds.\n",
      "-- Epoch 1741\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.891575, T: 297512526, Avg. loss: 0.066471\n",
      "Total training time: 147.90 seconds.\n",
      "-- Epoch 1742\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.887816, T: 297683412, Avg. loss: 0.066468\n",
      "Total training time: 147.98 seconds.\n",
      "-- Epoch 1743\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.884052, T: 297854298, Avg. loss: 0.066466\n",
      "Total training time: 148.06 seconds.\n",
      "-- Epoch 1744\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.880295, T: 298025184, Avg. loss: 0.066464\n",
      "Total training time: 148.14 seconds.\n",
      "-- Epoch 1745\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.876544, T: 298196070, Avg. loss: 0.066462\n",
      "Total training time: 148.23 seconds.\n",
      "-- Epoch 1746\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.872786, T: 298366956, Avg. loss: 0.066460\n",
      "Total training time: 148.31 seconds.\n",
      "-- Epoch 1747\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.869037, T: 298537842, Avg. loss: 0.066458\n",
      "Total training time: 148.39 seconds.\n",
      "-- Epoch 1748\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.865286, T: 298708728, Avg. loss: 0.066456\n",
      "Total training time: 148.47 seconds.\n",
      "-- Epoch 1749\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.861542, T: 298879614, Avg. loss: 0.066454\n",
      "Total training time: 148.56 seconds.\n",
      "-- Epoch 1750\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.857797, T: 299050500, Avg. loss: 0.066452\n",
      "Total training time: 148.64 seconds.\n",
      "-- Epoch 1751\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.854050, T: 299221386, Avg. loss: 0.066449\n",
      "Total training time: 148.72 seconds.\n",
      "-- Epoch 1752\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.850305, T: 299392272, Avg. loss: 0.066447\n",
      "Total training time: 148.80 seconds.\n",
      "-- Epoch 1753\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.846562, T: 299563158, Avg. loss: 0.066445\n",
      "Total training time: 148.88 seconds.\n",
      "-- Epoch 1754\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.842822, T: 299734044, Avg. loss: 0.066443\n",
      "Total training time: 148.96 seconds.\n",
      "-- Epoch 1755\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.839082, T: 299904930, Avg. loss: 0.066441\n",
      "Total training time: 149.05 seconds.\n",
      "-- Epoch 1756\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.835350, T: 300075816, Avg. loss: 0.066439\n",
      "Total training time: 149.13 seconds.\n",
      "-- Epoch 1757\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.831618, T: 300246702, Avg. loss: 0.066437\n",
      "Total training time: 149.21 seconds.\n",
      "-- Epoch 1758\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.827888, T: 300417588, Avg. loss: 0.066435\n",
      "Total training time: 149.29 seconds.\n",
      "-- Epoch 1759\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.824158, T: 300588474, Avg. loss: 0.066433\n",
      "Total training time: 149.37 seconds.\n",
      "-- Epoch 1760\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.820435, T: 300759360, Avg. loss: 0.066431\n",
      "Total training time: 149.45 seconds.\n",
      "-- Epoch 1761\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.816706, T: 300930246, Avg. loss: 0.066429\n",
      "Total training time: 149.54 seconds.\n",
      "-- Epoch 1762\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.812983, T: 301101132, Avg. loss: 0.066426\n",
      "Total training time: 149.62 seconds.\n",
      "-- Epoch 1763\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.809264, T: 301272018, Avg. loss: 0.066424\n",
      "Total training time: 149.70 seconds.\n",
      "-- Epoch 1764\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.805547, T: 301442904, Avg. loss: 0.066422\n",
      "Total training time: 149.78 seconds.\n",
      "-- Epoch 1765\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.801835, T: 301613790, Avg. loss: 0.066420\n",
      "Total training time: 149.86 seconds.\n",
      "-- Epoch 1766\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.798120, T: 301784676, Avg. loss: 0.066418\n",
      "Total training time: 149.95 seconds.\n",
      "-- Epoch 1767\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.794416, T: 301955562, Avg. loss: 0.066416\n",
      "Total training time: 150.03 seconds.\n",
      "-- Epoch 1768\n",
      "Norm: 13.87, NNZs: 30, Bias: -123.790712, T: 302126448, Avg. loss: 0.066414\n",
      "Total training time: 150.11 seconds.\n",
      "-- Epoch 1769\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.787009, T: 302297334, Avg. loss: 0.066412\n",
      "Total training time: 150.19 seconds.\n",
      "-- Epoch 1770\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.783310, T: 302468220, Avg. loss: 0.066410\n",
      "Total training time: 150.27 seconds.\n",
      "-- Epoch 1771\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.779610, T: 302639106, Avg. loss: 0.066408\n",
      "Total training time: 150.35 seconds.\n",
      "-- Epoch 1772\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.775910, T: 302809992, Avg. loss: 0.066406\n",
      "Total training time: 150.44 seconds.\n",
      "-- Epoch 1773\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.772213, T: 302980878, Avg. loss: 0.066404\n",
      "Total training time: 150.52 seconds.\n",
      "-- Epoch 1774\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.768519, T: 303151764, Avg. loss: 0.066402\n",
      "Total training time: 150.60 seconds.\n",
      "-- Epoch 1775\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.764832, T: 303322650, Avg. loss: 0.066399\n",
      "Total training time: 150.68 seconds.\n",
      "-- Epoch 1776\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.761137, T: 303493536, Avg. loss: 0.066397\n",
      "Total training time: 150.76 seconds.\n",
      "-- Epoch 1777\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.757444, T: 303664422, Avg. loss: 0.066395\n",
      "Total training time: 150.84 seconds.\n",
      "-- Epoch 1778\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.753757, T: 303835308, Avg. loss: 0.066393\n",
      "Total training time: 150.93 seconds.\n",
      "-- Epoch 1779\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.750079, T: 304006194, Avg. loss: 0.066391\n",
      "Total training time: 151.01 seconds.\n",
      "-- Epoch 1780\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.746405, T: 304177080, Avg. loss: 0.066389\n",
      "Total training time: 151.09 seconds.\n",
      "-- Epoch 1781\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.742728, T: 304347966, Avg. loss: 0.066387\n",
      "Total training time: 151.17 seconds.\n",
      "-- Epoch 1782\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.739047, T: 304518852, Avg. loss: 0.066385\n",
      "Total training time: 151.25 seconds.\n",
      "-- Epoch 1783\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.735369, T: 304689738, Avg. loss: 0.066383\n",
      "Total training time: 151.34 seconds.\n",
      "-- Epoch 1784\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.731694, T: 304860624, Avg. loss: 0.066381\n",
      "Total training time: 151.42 seconds.\n",
      "-- Epoch 1785\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.728022, T: 305031510, Avg. loss: 0.066379\n",
      "Total training time: 151.50 seconds.\n",
      "-- Epoch 1786\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.724352, T: 305202396, Avg. loss: 0.066377\n",
      "Total training time: 151.58 seconds.\n",
      "-- Epoch 1787\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.720685, T: 305373282, Avg. loss: 0.066375\n",
      "Total training time: 151.66 seconds.\n",
      "-- Epoch 1788\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.717023, T: 305544168, Avg. loss: 0.066373\n",
      "Total training time: 151.75 seconds.\n",
      "-- Epoch 1789\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.713360, T: 305715054, Avg. loss: 0.066371\n",
      "Total training time: 151.83 seconds.\n",
      "-- Epoch 1790\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.709704, T: 305885940, Avg. loss: 0.066368\n",
      "Total training time: 151.91 seconds.\n",
      "-- Epoch 1791\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.706044, T: 306056826, Avg. loss: 0.066366\n",
      "Total training time: 151.99 seconds.\n",
      "-- Epoch 1792\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.702388, T: 306227712, Avg. loss: 0.066364\n",
      "Total training time: 152.07 seconds.\n",
      "-- Epoch 1793\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.698732, T: 306398598, Avg. loss: 0.066362\n",
      "Total training time: 152.15 seconds.\n",
      "-- Epoch 1794\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.695080, T: 306569484, Avg. loss: 0.066360\n",
      "Total training time: 152.23 seconds.\n",
      "-- Epoch 1795\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.691429, T: 306740370, Avg. loss: 0.066358\n",
      "Total training time: 152.31 seconds.\n",
      "-- Epoch 1796\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.687784, T: 306911256, Avg. loss: 0.066356\n",
      "Total training time: 152.40 seconds.\n",
      "-- Epoch 1797\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.684138, T: 307082142, Avg. loss: 0.066354\n",
      "Total training time: 152.48 seconds.\n",
      "-- Epoch 1798\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.680492, T: 307253028, Avg. loss: 0.066352\n",
      "Total training time: 152.56 seconds.\n",
      "-- Epoch 1799\n",
      "Norm: 13.86, NNZs: 30, Bias: -123.676852, T: 307423914, Avg. loss: 0.066350\n",
      "Total training time: 152.65 seconds.\n",
      "-- Epoch 1800\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.673209, T: 307594800, Avg. loss: 0.066348\n",
      "Total training time: 152.73 seconds.\n",
      "-- Epoch 1801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.85, NNZs: 30, Bias: -123.669571, T: 307765686, Avg. loss: 0.066346\n",
      "Total training time: 152.81 seconds.\n",
      "-- Epoch 1802\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.665928, T: 307936572, Avg. loss: 0.066344\n",
      "Total training time: 152.89 seconds.\n",
      "-- Epoch 1803\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.662296, T: 308107458, Avg. loss: 0.066342\n",
      "Total training time: 152.97 seconds.\n",
      "-- Epoch 1804\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.658660, T: 308278344, Avg. loss: 0.066340\n",
      "Total training time: 153.05 seconds.\n",
      "-- Epoch 1805\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.655025, T: 308449230, Avg. loss: 0.066338\n",
      "Total training time: 153.14 seconds.\n",
      "-- Epoch 1806\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.651402, T: 308620116, Avg. loss: 0.066336\n",
      "Total training time: 153.22 seconds.\n",
      "-- Epoch 1807\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.647775, T: 308791002, Avg. loss: 0.066334\n",
      "Total training time: 153.30 seconds.\n",
      "-- Epoch 1808\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.644141, T: 308961888, Avg. loss: 0.066332\n",
      "Total training time: 153.38 seconds.\n",
      "-- Epoch 1809\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.640521, T: 309132774, Avg. loss: 0.066330\n",
      "Total training time: 153.46 seconds.\n",
      "-- Epoch 1810\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.636898, T: 309303660, Avg. loss: 0.066328\n",
      "Total training time: 153.55 seconds.\n",
      "-- Epoch 1811\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.633278, T: 309474546, Avg. loss: 0.066326\n",
      "Total training time: 153.63 seconds.\n",
      "-- Epoch 1812\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.629661, T: 309645432, Avg. loss: 0.066324\n",
      "Total training time: 153.71 seconds.\n",
      "-- Epoch 1813\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.626046, T: 309816318, Avg. loss: 0.066322\n",
      "Total training time: 153.79 seconds.\n",
      "-- Epoch 1814\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.622435, T: 309987204, Avg. loss: 0.066320\n",
      "Total training time: 153.88 seconds.\n",
      "-- Epoch 1815\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.618825, T: 310158090, Avg. loss: 0.066318\n",
      "Total training time: 153.96 seconds.\n",
      "-- Epoch 1816\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.615215, T: 310328976, Avg. loss: 0.066316\n",
      "Total training time: 154.04 seconds.\n",
      "-- Epoch 1817\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.611610, T: 310499862, Avg. loss: 0.066313\n",
      "Total training time: 154.12 seconds.\n",
      "-- Epoch 1818\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.608005, T: 310670748, Avg. loss: 0.066311\n",
      "Total training time: 154.20 seconds.\n",
      "-- Epoch 1819\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.604401, T: 310841634, Avg. loss: 0.066309\n",
      "Total training time: 154.28 seconds.\n",
      "-- Epoch 1820\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.600796, T: 311012520, Avg. loss: 0.066307\n",
      "Total training time: 154.37 seconds.\n",
      "-- Epoch 1821\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.597194, T: 311183406, Avg. loss: 0.066305\n",
      "Total training time: 154.45 seconds.\n",
      "-- Epoch 1822\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.593598, T: 311354292, Avg. loss: 0.066303\n",
      "Total training time: 154.53 seconds.\n",
      "-- Epoch 1823\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.590002, T: 311525178, Avg. loss: 0.066301\n",
      "Total training time: 154.61 seconds.\n",
      "-- Epoch 1824\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.586409, T: 311696064, Avg. loss: 0.066299\n",
      "Total training time: 154.70 seconds.\n",
      "-- Epoch 1825\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.582818, T: 311866950, Avg. loss: 0.066297\n",
      "Total training time: 154.78 seconds.\n",
      "-- Epoch 1826\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.579231, T: 312037836, Avg. loss: 0.066295\n",
      "Total training time: 154.86 seconds.\n",
      "-- Epoch 1827\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.575644, T: 312208722, Avg. loss: 0.066293\n",
      "Total training time: 154.94 seconds.\n",
      "-- Epoch 1828\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.572057, T: 312379608, Avg. loss: 0.066291\n",
      "Total training time: 155.02 seconds.\n",
      "-- Epoch 1829\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.568473, T: 312550494, Avg. loss: 0.066289\n",
      "Total training time: 155.13 seconds.\n",
      "-- Epoch 1830\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.564892, T: 312721380, Avg. loss: 0.066287\n",
      "Total training time: 155.21 seconds.\n",
      "-- Epoch 1831\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.561318, T: 312892266, Avg. loss: 0.066285\n",
      "Total training time: 155.29 seconds.\n",
      "-- Epoch 1832\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.557743, T: 313063152, Avg. loss: 0.066283\n",
      "Total training time: 155.38 seconds.\n",
      "-- Epoch 1833\n",
      "Norm: 13.85, NNZs: 30, Bias: -123.554168, T: 313234038, Avg. loss: 0.066281\n",
      "Total training time: 155.46 seconds.\n",
      "-- Epoch 1834\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.550592, T: 313404924, Avg. loss: 0.066279\n",
      "Total training time: 155.54 seconds.\n",
      "-- Epoch 1835\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.547022, T: 313575810, Avg. loss: 0.066277\n",
      "Total training time: 155.62 seconds.\n",
      "-- Epoch 1836\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.543454, T: 313746696, Avg. loss: 0.066275\n",
      "Total training time: 155.70 seconds.\n",
      "-- Epoch 1837\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.539880, T: 313917582, Avg. loss: 0.066273\n",
      "Total training time: 155.78 seconds.\n",
      "-- Epoch 1838\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.536318, T: 314088468, Avg. loss: 0.066271\n",
      "Total training time: 155.87 seconds.\n",
      "-- Epoch 1839\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.532757, T: 314259354, Avg. loss: 0.066269\n",
      "Total training time: 155.95 seconds.\n",
      "-- Epoch 1840\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.529193, T: 314430240, Avg. loss: 0.066267\n",
      "Total training time: 156.03 seconds.\n",
      "-- Epoch 1841\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.525639, T: 314601126, Avg. loss: 0.066265\n",
      "Total training time: 156.11 seconds.\n",
      "-- Epoch 1842\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.522088, T: 314772012, Avg. loss: 0.066263\n",
      "Total training time: 156.19 seconds.\n",
      "-- Epoch 1843\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.518532, T: 314942898, Avg. loss: 0.066261\n",
      "Total training time: 156.28 seconds.\n",
      "-- Epoch 1844\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.514984, T: 315113784, Avg. loss: 0.066259\n",
      "Total training time: 156.36 seconds.\n",
      "-- Epoch 1845\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.511429, T: 315284670, Avg. loss: 0.066257\n",
      "Total training time: 156.45 seconds.\n",
      "-- Epoch 1846\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.507882, T: 315455556, Avg. loss: 0.066255\n",
      "Total training time: 156.53 seconds.\n",
      "-- Epoch 1847\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.504331, T: 315626442, Avg. loss: 0.066253\n",
      "Total training time: 156.61 seconds.\n",
      "-- Epoch 1848\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.500787, T: 315797328, Avg. loss: 0.066251\n",
      "Total training time: 156.69 seconds.\n",
      "-- Epoch 1849\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.497244, T: 315968214, Avg. loss: 0.066249\n",
      "Total training time: 156.78 seconds.\n",
      "-- Epoch 1850\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.493700, T: 316139100, Avg. loss: 0.066247\n",
      "Total training time: 156.86 seconds.\n",
      "-- Epoch 1851\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.490158, T: 316309986, Avg. loss: 0.066245\n",
      "Total training time: 156.94 seconds.\n",
      "-- Epoch 1852\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.486618, T: 316480872, Avg. loss: 0.066243\n",
      "Total training time: 157.02 seconds.\n",
      "-- Epoch 1853\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.483086, T: 316651758, Avg. loss: 0.066241\n",
      "Total training time: 157.10 seconds.\n",
      "-- Epoch 1854\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.479553, T: 316822644, Avg. loss: 0.066239\n",
      "Total training time: 157.18 seconds.\n",
      "-- Epoch 1855\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.476019, T: 316993530, Avg. loss: 0.066237\n",
      "Total training time: 157.27 seconds.\n",
      "-- Epoch 1856\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.472487, T: 317164416, Avg. loss: 0.066236\n",
      "Total training time: 157.35 seconds.\n",
      "-- Epoch 1857\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.468961, T: 317335302, Avg. loss: 0.066234\n",
      "Total training time: 157.43 seconds.\n",
      "-- Epoch 1858\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.465433, T: 317506188, Avg. loss: 0.066232\n",
      "Total training time: 157.51 seconds.\n",
      "-- Epoch 1859\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.461909, T: 317677074, Avg. loss: 0.066230\n",
      "Total training time: 157.59 seconds.\n",
      "-- Epoch 1860\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.458386, T: 317847960, Avg. loss: 0.066228\n",
      "Total training time: 157.68 seconds.\n",
      "-- Epoch 1861\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.454861, T: 318018846, Avg. loss: 0.066226\n",
      "Total training time: 157.76 seconds.\n",
      "-- Epoch 1862\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.451343, T: 318189732, Avg. loss: 0.066224\n",
      "Total training time: 157.84 seconds.\n",
      "-- Epoch 1863\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.447828, T: 318360618, Avg. loss: 0.066222\n",
      "Total training time: 157.92 seconds.\n",
      "-- Epoch 1864\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.444307, T: 318531504, Avg. loss: 0.066220\n",
      "Total training time: 158.00 seconds.\n",
      "-- Epoch 1865\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.440796, T: 318702390, Avg. loss: 0.066218\n",
      "Total training time: 158.08 seconds.\n",
      "-- Epoch 1866\n",
      "Norm: 13.84, NNZs: 30, Bias: -123.437282, T: 318873276, Avg. loss: 0.066216\n",
      "Total training time: 158.16 seconds.\n",
      "-- Epoch 1867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.83, NNZs: 30, Bias: -123.433778, T: 319044162, Avg. loss: 0.066214\n",
      "Total training time: 158.24 seconds.\n",
      "-- Epoch 1868\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.430271, T: 319215048, Avg. loss: 0.066212\n",
      "Total training time: 158.32 seconds.\n",
      "-- Epoch 1869\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.426768, T: 319385934, Avg. loss: 0.066210\n",
      "Total training time: 158.40 seconds.\n",
      "-- Epoch 1870\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.423266, T: 319556820, Avg. loss: 0.066208\n",
      "Total training time: 158.48 seconds.\n",
      "-- Epoch 1871\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.419766, T: 319727706, Avg. loss: 0.066206\n",
      "Total training time: 158.57 seconds.\n",
      "-- Epoch 1872\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.416268, T: 319898592, Avg. loss: 0.066204\n",
      "Total training time: 158.65 seconds.\n",
      "-- Epoch 1873\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.412772, T: 320069478, Avg. loss: 0.066202\n",
      "Total training time: 158.73 seconds.\n",
      "-- Epoch 1874\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.409285, T: 320240364, Avg. loss: 0.066200\n",
      "Total training time: 158.82 seconds.\n",
      "-- Epoch 1875\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.405793, T: 320411250, Avg. loss: 0.066198\n",
      "Total training time: 158.90 seconds.\n",
      "-- Epoch 1876\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.402306, T: 320582136, Avg. loss: 0.066196\n",
      "Total training time: 158.99 seconds.\n",
      "-- Epoch 1877\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.398814, T: 320753022, Avg. loss: 0.066194\n",
      "Total training time: 159.07 seconds.\n",
      "-- Epoch 1878\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.395325, T: 320923908, Avg. loss: 0.066192\n",
      "Total training time: 159.15 seconds.\n",
      "-- Epoch 1879\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.391840, T: 321094794, Avg. loss: 0.066190\n",
      "Total training time: 159.23 seconds.\n",
      "-- Epoch 1880\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.388354, T: 321265680, Avg. loss: 0.066188\n",
      "Total training time: 159.31 seconds.\n",
      "-- Epoch 1881\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.384870, T: 321436566, Avg. loss: 0.066186\n",
      "Total training time: 159.40 seconds.\n",
      "-- Epoch 1882\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.381398, T: 321607452, Avg. loss: 0.066184\n",
      "Total training time: 159.48 seconds.\n",
      "-- Epoch 1883\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.377916, T: 321778338, Avg. loss: 0.066182\n",
      "Total training time: 159.56 seconds.\n",
      "-- Epoch 1884\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.374439, T: 321949224, Avg. loss: 0.066181\n",
      "Total training time: 159.65 seconds.\n",
      "-- Epoch 1885\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.370960, T: 322120110, Avg. loss: 0.066179\n",
      "Total training time: 159.73 seconds.\n",
      "-- Epoch 1886\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.367488, T: 322290996, Avg. loss: 0.066177\n",
      "Total training time: 159.81 seconds.\n",
      "-- Epoch 1887\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.364021, T: 322461882, Avg. loss: 0.066175\n",
      "Total training time: 159.89 seconds.\n",
      "-- Epoch 1888\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.360553, T: 322632768, Avg. loss: 0.066173\n",
      "Total training time: 159.97 seconds.\n",
      "-- Epoch 1889\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.357085, T: 322803654, Avg. loss: 0.066171\n",
      "Total training time: 160.05 seconds.\n",
      "-- Epoch 1890\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.353620, T: 322974540, Avg. loss: 0.066169\n",
      "Total training time: 160.14 seconds.\n",
      "-- Epoch 1891\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.350156, T: 323145426, Avg. loss: 0.066167\n",
      "Total training time: 160.22 seconds.\n",
      "-- Epoch 1892\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.346692, T: 323316312, Avg. loss: 0.066165\n",
      "Total training time: 160.30 seconds.\n",
      "-- Epoch 1893\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.343232, T: 323487198, Avg. loss: 0.066163\n",
      "Total training time: 160.39 seconds.\n",
      "-- Epoch 1894\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.339772, T: 323658084, Avg. loss: 0.066161\n",
      "Total training time: 160.47 seconds.\n",
      "-- Epoch 1895\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.336314, T: 323828970, Avg. loss: 0.066159\n",
      "Total training time: 160.55 seconds.\n",
      "-- Epoch 1896\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.332860, T: 323999856, Avg. loss: 0.066157\n",
      "Total training time: 160.64 seconds.\n",
      "-- Epoch 1897\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.329407, T: 324170742, Avg. loss: 0.066155\n",
      "Total training time: 160.72 seconds.\n",
      "-- Epoch 1898\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.325949, T: 324341628, Avg. loss: 0.066153\n",
      "Total training time: 160.80 seconds.\n",
      "-- Epoch 1899\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.322498, T: 324512514, Avg. loss: 0.066151\n",
      "Total training time: 160.88 seconds.\n",
      "-- Epoch 1900\n",
      "Norm: 13.83, NNZs: 30, Bias: -123.319049, T: 324683400, Avg. loss: 0.066150\n",
      "Total training time: 160.96 seconds.\n",
      "-- Epoch 1901\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.315606, T: 324854286, Avg. loss: 0.066148\n",
      "Total training time: 161.05 seconds.\n",
      "-- Epoch 1902\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.312162, T: 325025172, Avg. loss: 0.066146\n",
      "Total training time: 161.13 seconds.\n",
      "-- Epoch 1903\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.308718, T: 325196058, Avg. loss: 0.066144\n",
      "Total training time: 161.22 seconds.\n",
      "-- Epoch 1904\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.305281, T: 325366944, Avg. loss: 0.066142\n",
      "Total training time: 161.29 seconds.\n",
      "-- Epoch 1905\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.301836, T: 325537830, Avg. loss: 0.066140\n",
      "Total training time: 161.38 seconds.\n",
      "-- Epoch 1906\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.298398, T: 325708716, Avg. loss: 0.066138\n",
      "Total training time: 161.46 seconds.\n",
      "-- Epoch 1907\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.294965, T: 325879602, Avg. loss: 0.066136\n",
      "Total training time: 161.54 seconds.\n",
      "-- Epoch 1908\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.291536, T: 326050488, Avg. loss: 0.066134\n",
      "Total training time: 161.62 seconds.\n",
      "-- Epoch 1909\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.288107, T: 326221374, Avg. loss: 0.066132\n",
      "Total training time: 161.71 seconds.\n",
      "-- Epoch 1910\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.284680, T: 326392260, Avg. loss: 0.066130\n",
      "Total training time: 161.79 seconds.\n",
      "-- Epoch 1911\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.281254, T: 326563146, Avg. loss: 0.066128\n",
      "Total training time: 161.87 seconds.\n",
      "-- Epoch 1912\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.277827, T: 326734032, Avg. loss: 0.066126\n",
      "Total training time: 161.95 seconds.\n",
      "-- Epoch 1913\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.274401, T: 326904918, Avg. loss: 0.066124\n",
      "Total training time: 162.03 seconds.\n",
      "-- Epoch 1914\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.270982, T: 327075804, Avg. loss: 0.066123\n",
      "Total training time: 162.11 seconds.\n",
      "-- Epoch 1915\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.267562, T: 327246690, Avg. loss: 0.066121\n",
      "Total training time: 162.20 seconds.\n",
      "-- Epoch 1916\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.264146, T: 327417576, Avg. loss: 0.066119\n",
      "Total training time: 162.28 seconds.\n",
      "-- Epoch 1917\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.260729, T: 327588462, Avg. loss: 0.066117\n",
      "Total training time: 162.36 seconds.\n",
      "-- Epoch 1918\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.257311, T: 327759348, Avg. loss: 0.066115\n",
      "Total training time: 162.44 seconds.\n",
      "-- Epoch 1919\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.253897, T: 327930234, Avg. loss: 0.066113\n",
      "Total training time: 162.52 seconds.\n",
      "-- Epoch 1920\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.250485, T: 328101120, Avg. loss: 0.066111\n",
      "Total training time: 162.61 seconds.\n",
      "-- Epoch 1921\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.247077, T: 328272006, Avg. loss: 0.066109\n",
      "Total training time: 162.69 seconds.\n",
      "-- Epoch 1922\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.243671, T: 328442892, Avg. loss: 0.066107\n",
      "Total training time: 162.77 seconds.\n",
      "-- Epoch 1923\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.240265, T: 328613778, Avg. loss: 0.066105\n",
      "Total training time: 162.85 seconds.\n",
      "-- Epoch 1924\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.236859, T: 328784664, Avg. loss: 0.066103\n",
      "Total training time: 162.93 seconds.\n",
      "-- Epoch 1925\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.233463, T: 328955550, Avg. loss: 0.066102\n",
      "Total training time: 163.01 seconds.\n",
      "-- Epoch 1926\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.230063, T: 329126436, Avg. loss: 0.066100\n",
      "Total training time: 163.09 seconds.\n",
      "-- Epoch 1927\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.226664, T: 329297322, Avg. loss: 0.066098\n",
      "Total training time: 163.18 seconds.\n",
      "-- Epoch 1928\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.223266, T: 329468208, Avg. loss: 0.066096\n",
      "Total training time: 163.26 seconds.\n",
      "-- Epoch 1929\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.219868, T: 329639094, Avg. loss: 0.066094\n",
      "Total training time: 163.34 seconds.\n",
      "-- Epoch 1930\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.216476, T: 329809980, Avg. loss: 0.066092\n",
      "Total training time: 163.42 seconds.\n",
      "-- Epoch 1931\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.213085, T: 329980866, Avg. loss: 0.066090\n",
      "Total training time: 163.50 seconds.\n",
      "-- Epoch 1932\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.209696, T: 330151752, Avg. loss: 0.066088\n",
      "Total training time: 163.58 seconds.\n",
      "-- Epoch 1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.82, NNZs: 30, Bias: -123.206311, T: 330322638, Avg. loss: 0.066086\n",
      "Total training time: 163.67 seconds.\n",
      "-- Epoch 1934\n",
      "Norm: 13.82, NNZs: 30, Bias: -123.202924, T: 330493524, Avg. loss: 0.066084\n",
      "Total training time: 163.75 seconds.\n",
      "-- Epoch 1935\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.199538, T: 330664410, Avg. loss: 0.066083\n",
      "Total training time: 163.83 seconds.\n",
      "-- Epoch 1936\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.196156, T: 330835296, Avg. loss: 0.066081\n",
      "Total training time: 163.92 seconds.\n",
      "-- Epoch 1937\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.192778, T: 331006182, Avg. loss: 0.066079\n",
      "Total training time: 164.00 seconds.\n",
      "-- Epoch 1938\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.189399, T: 331177068, Avg. loss: 0.066077\n",
      "Total training time: 164.10 seconds.\n",
      "-- Epoch 1939\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.186020, T: 331347954, Avg. loss: 0.066075\n",
      "Total training time: 164.19 seconds.\n",
      "-- Epoch 1940\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.182642, T: 331518840, Avg. loss: 0.066073\n",
      "Total training time: 164.27 seconds.\n",
      "-- Epoch 1941\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.179265, T: 331689726, Avg. loss: 0.066071\n",
      "Total training time: 164.35 seconds.\n",
      "-- Epoch 1942\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.175892, T: 331860612, Avg. loss: 0.066069\n",
      "Total training time: 164.43 seconds.\n",
      "-- Epoch 1943\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.172516, T: 332031498, Avg. loss: 0.066067\n",
      "Total training time: 164.51 seconds.\n",
      "-- Epoch 1944\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.169149, T: 332202384, Avg. loss: 0.066066\n",
      "Total training time: 164.60 seconds.\n",
      "-- Epoch 1945\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.165783, T: 332373270, Avg. loss: 0.066064\n",
      "Total training time: 164.68 seconds.\n",
      "-- Epoch 1946\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.162419, T: 332544156, Avg. loss: 0.066062\n",
      "Total training time: 164.76 seconds.\n",
      "-- Epoch 1947\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.159055, T: 332715042, Avg. loss: 0.066060\n",
      "Total training time: 164.84 seconds.\n",
      "-- Epoch 1948\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.155694, T: 332885928, Avg. loss: 0.066058\n",
      "Total training time: 164.92 seconds.\n",
      "-- Epoch 1949\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.152335, T: 333056814, Avg. loss: 0.066056\n",
      "Total training time: 165.00 seconds.\n",
      "-- Epoch 1950\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.148978, T: 333227700, Avg. loss: 0.066054\n",
      "Total training time: 165.08 seconds.\n",
      "-- Epoch 1951\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.145620, T: 333398586, Avg. loss: 0.066052\n",
      "Total training time: 165.16 seconds.\n",
      "-- Epoch 1952\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.142260, T: 333569472, Avg. loss: 0.066050\n",
      "Total training time: 165.25 seconds.\n",
      "-- Epoch 1953\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.138908, T: 333740358, Avg. loss: 0.066049\n",
      "Total training time: 165.33 seconds.\n",
      "-- Epoch 1954\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.135562, T: 333911244, Avg. loss: 0.066047\n",
      "Total training time: 165.41 seconds.\n",
      "-- Epoch 1955\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.132213, T: 334082130, Avg. loss: 0.066045\n",
      "Total training time: 165.49 seconds.\n",
      "-- Epoch 1956\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.128866, T: 334253016, Avg. loss: 0.066043\n",
      "Total training time: 165.57 seconds.\n",
      "-- Epoch 1957\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.125519, T: 334423902, Avg. loss: 0.066041\n",
      "Total training time: 165.66 seconds.\n",
      "-- Epoch 1958\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.122175, T: 334594788, Avg. loss: 0.066039\n",
      "Total training time: 165.74 seconds.\n",
      "-- Epoch 1959\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.118835, T: 334765674, Avg. loss: 0.066037\n",
      "Total training time: 165.82 seconds.\n",
      "-- Epoch 1960\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.115496, T: 334936560, Avg. loss: 0.066035\n",
      "Total training time: 165.90 seconds.\n",
      "-- Epoch 1961\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.112157, T: 335107446, Avg. loss: 0.066034\n",
      "Total training time: 165.98 seconds.\n",
      "-- Epoch 1962\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.108815, T: 335278332, Avg. loss: 0.066032\n",
      "Total training time: 166.06 seconds.\n",
      "-- Epoch 1963\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.105477, T: 335449218, Avg. loss: 0.066030\n",
      "Total training time: 166.15 seconds.\n",
      "-- Epoch 1964\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.102139, T: 335620104, Avg. loss: 0.066028\n",
      "Total training time: 166.23 seconds.\n",
      "-- Epoch 1965\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.098808, T: 335790990, Avg. loss: 0.066026\n",
      "Total training time: 166.31 seconds.\n",
      "-- Epoch 1966\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.095476, T: 335961876, Avg. loss: 0.066024\n",
      "Total training time: 166.39 seconds.\n",
      "-- Epoch 1967\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.092148, T: 336132762, Avg. loss: 0.066022\n",
      "Total training time: 166.47 seconds.\n",
      "-- Epoch 1968\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.088822, T: 336303648, Avg. loss: 0.066021\n",
      "Total training time: 166.56 seconds.\n",
      "-- Epoch 1969\n",
      "Norm: 13.81, NNZs: 30, Bias: -123.085497, T: 336474534, Avg. loss: 0.066019\n",
      "Total training time: 166.64 seconds.\n",
      "-- Epoch 1970\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.082174, T: 336645420, Avg. loss: 0.066017\n",
      "Total training time: 166.72 seconds.\n",
      "-- Epoch 1971\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.078854, T: 336816306, Avg. loss: 0.066015\n",
      "Total training time: 166.80 seconds.\n",
      "-- Epoch 1972\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.075533, T: 336987192, Avg. loss: 0.066013\n",
      "Total training time: 166.88 seconds.\n",
      "-- Epoch 1973\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.072215, T: 337158078, Avg. loss: 0.066011\n",
      "Total training time: 166.96 seconds.\n",
      "-- Epoch 1974\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.068899, T: 337328964, Avg. loss: 0.066009\n",
      "Total training time: 167.04 seconds.\n",
      "-- Epoch 1975\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.065588, T: 337499850, Avg. loss: 0.066008\n",
      "Total training time: 167.12 seconds.\n",
      "-- Epoch 1976\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.062276, T: 337670736, Avg. loss: 0.066006\n",
      "Total training time: 167.21 seconds.\n",
      "-- Epoch 1977\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.058962, T: 337841622, Avg. loss: 0.066004\n",
      "Total training time: 167.29 seconds.\n",
      "-- Epoch 1978\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.055651, T: 338012508, Avg. loss: 0.066002\n",
      "Total training time: 167.37 seconds.\n",
      "-- Epoch 1979\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.052345, T: 338183394, Avg. loss: 0.066000\n",
      "Total training time: 167.46 seconds.\n",
      "-- Epoch 1980\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.049039, T: 338354280, Avg. loss: 0.065998\n",
      "Total training time: 167.54 seconds.\n",
      "-- Epoch 1981\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.045736, T: 338525166, Avg. loss: 0.065996\n",
      "Total training time: 167.62 seconds.\n",
      "-- Epoch 1982\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.042430, T: 338696052, Avg. loss: 0.065995\n",
      "Total training time: 167.70 seconds.\n",
      "-- Epoch 1983\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.039125, T: 338866938, Avg. loss: 0.065993\n",
      "Total training time: 167.78 seconds.\n",
      "-- Epoch 1984\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.035826, T: 339037824, Avg. loss: 0.065991\n",
      "Total training time: 167.87 seconds.\n",
      "-- Epoch 1985\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.032526, T: 339208710, Avg. loss: 0.065989\n",
      "Total training time: 167.95 seconds.\n",
      "-- Epoch 1986\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.029226, T: 339379596, Avg. loss: 0.065987\n",
      "Total training time: 168.03 seconds.\n",
      "-- Epoch 1987\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.025935, T: 339550482, Avg. loss: 0.065985\n",
      "Total training time: 168.11 seconds.\n",
      "-- Epoch 1988\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.022642, T: 339721368, Avg. loss: 0.065984\n",
      "Total training time: 168.19 seconds.\n",
      "-- Epoch 1989\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.019351, T: 339892254, Avg. loss: 0.065982\n",
      "Total training time: 168.27 seconds.\n",
      "-- Epoch 1990\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.016057, T: 340063140, Avg. loss: 0.065980\n",
      "Total training time: 168.35 seconds.\n",
      "-- Epoch 1991\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.012768, T: 340234026, Avg. loss: 0.065978\n",
      "Total training time: 168.44 seconds.\n",
      "-- Epoch 1992\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.009479, T: 340404912, Avg. loss: 0.065976\n",
      "Total training time: 168.52 seconds.\n",
      "-- Epoch 1993\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.006190, T: 340575798, Avg. loss: 0.065974\n",
      "Total training time: 168.60 seconds.\n",
      "-- Epoch 1994\n",
      "Norm: 13.80, NNZs: 30, Bias: -123.002908, T: 340746684, Avg. loss: 0.065972\n",
      "Total training time: 168.68 seconds.\n",
      "-- Epoch 1995\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.999625, T: 340917570, Avg. loss: 0.065971\n",
      "Total training time: 168.76 seconds.\n",
      "-- Epoch 1996\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.996345, T: 341088456, Avg. loss: 0.065969\n",
      "Total training time: 168.84 seconds.\n",
      "-- Epoch 1997\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.993068, T: 341259342, Avg. loss: 0.065967\n",
      "Total training time: 168.92 seconds.\n",
      "-- Epoch 1998\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.989793, T: 341430228, Avg. loss: 0.065965\n",
      "Total training time: 169.01 seconds.\n",
      "-- Epoch 1999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.80, NNZs: 30, Bias: -122.986515, T: 341601114, Avg. loss: 0.065963\n",
      "Total training time: 169.09 seconds.\n",
      "-- Epoch 2000\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.983240, T: 341772000, Avg. loss: 0.065961\n",
      "Total training time: 169.17 seconds.\n",
      "-- Epoch 2001\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.979972, T: 341942886, Avg. loss: 0.065960\n",
      "Total training time: 169.25 seconds.\n",
      "-- Epoch 2002\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.976699, T: 342113772, Avg. loss: 0.065958\n",
      "Total training time: 169.34 seconds.\n",
      "-- Epoch 2003\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.973434, T: 342284658, Avg. loss: 0.065956\n",
      "Total training time: 169.41 seconds.\n",
      "-- Epoch 2004\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.970169, T: 342455544, Avg. loss: 0.065954\n",
      "Total training time: 169.50 seconds.\n",
      "-- Epoch 2005\n",
      "Norm: 13.80, NNZs: 30, Bias: -122.966907, T: 342626430, Avg. loss: 0.065952\n",
      "Total training time: 169.58 seconds.\n",
      "-- Epoch 2006\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.963646, T: 342797316, Avg. loss: 0.065950\n",
      "Total training time: 169.66 seconds.\n",
      "-- Epoch 2007\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.960382, T: 342968202, Avg. loss: 0.065949\n",
      "Total training time: 169.74 seconds.\n",
      "-- Epoch 2008\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.957128, T: 343139088, Avg. loss: 0.065947\n",
      "Total training time: 169.83 seconds.\n",
      "-- Epoch 2009\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.953866, T: 343309974, Avg. loss: 0.065945\n",
      "Total training time: 169.91 seconds.\n",
      "-- Epoch 2010\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.950610, T: 343480860, Avg. loss: 0.065943\n",
      "Total training time: 169.99 seconds.\n",
      "-- Epoch 2011\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.947360, T: 343651746, Avg. loss: 0.065941\n",
      "Total training time: 170.07 seconds.\n",
      "-- Epoch 2012\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.944107, T: 343822632, Avg. loss: 0.065940\n",
      "Total training time: 170.15 seconds.\n",
      "-- Epoch 2013\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.940850, T: 343993518, Avg. loss: 0.065938\n",
      "Total training time: 170.24 seconds.\n",
      "-- Epoch 2014\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.937601, T: 344164404, Avg. loss: 0.065936\n",
      "Total training time: 170.32 seconds.\n",
      "-- Epoch 2015\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.934351, T: 344335290, Avg. loss: 0.065934\n",
      "Total training time: 170.40 seconds.\n",
      "-- Epoch 2016\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.931107, T: 344506176, Avg. loss: 0.065932\n",
      "Total training time: 170.48 seconds.\n",
      "-- Epoch 2017\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.927862, T: 344677062, Avg. loss: 0.065930\n",
      "Total training time: 170.57 seconds.\n",
      "-- Epoch 2018\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.924616, T: 344847948, Avg. loss: 0.065929\n",
      "Total training time: 170.65 seconds.\n",
      "-- Epoch 2019\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.921378, T: 345018834, Avg. loss: 0.065927\n",
      "Total training time: 170.73 seconds.\n",
      "-- Epoch 2020\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.918133, T: 345189720, Avg. loss: 0.065925\n",
      "Total training time: 170.81 seconds.\n",
      "-- Epoch 2021\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.914888, T: 345360606, Avg. loss: 0.065923\n",
      "Total training time: 170.89 seconds.\n",
      "-- Epoch 2022\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.911652, T: 345531492, Avg. loss: 0.065921\n",
      "Total training time: 170.98 seconds.\n",
      "-- Epoch 2023\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.908417, T: 345702378, Avg. loss: 0.065920\n",
      "Total training time: 171.06 seconds.\n",
      "-- Epoch 2024\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.905182, T: 345873264, Avg. loss: 0.065918\n",
      "Total training time: 171.14 seconds.\n",
      "-- Epoch 2025\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.901950, T: 346044150, Avg. loss: 0.065916\n",
      "Total training time: 171.22 seconds.\n",
      "-- Epoch 2026\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.898721, T: 346215036, Avg. loss: 0.065914\n",
      "Total training time: 171.30 seconds.\n",
      "-- Epoch 2027\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.895496, T: 346385922, Avg. loss: 0.065912\n",
      "Total training time: 171.39 seconds.\n",
      "-- Epoch 2028\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.892267, T: 346556808, Avg. loss: 0.065911\n",
      "Total training time: 171.47 seconds.\n",
      "-- Epoch 2029\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.889044, T: 346727694, Avg. loss: 0.065909\n",
      "Total training time: 171.55 seconds.\n",
      "-- Epoch 2030\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.885816, T: 346898580, Avg. loss: 0.065907\n",
      "Total training time: 171.64 seconds.\n",
      "-- Epoch 2031\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.882590, T: 347069466, Avg. loss: 0.065905\n",
      "Total training time: 171.72 seconds.\n",
      "-- Epoch 2032\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.879369, T: 347240352, Avg. loss: 0.065903\n",
      "Total training time: 171.80 seconds.\n",
      "-- Epoch 2033\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.876144, T: 347411238, Avg. loss: 0.065902\n",
      "Total training time: 171.88 seconds.\n",
      "-- Epoch 2034\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.872923, T: 347582124, Avg. loss: 0.065900\n",
      "Total training time: 171.96 seconds.\n",
      "-- Epoch 2035\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.869710, T: 347753010, Avg. loss: 0.065898\n",
      "Total training time: 172.04 seconds.\n",
      "-- Epoch 2036\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.866498, T: 347923896, Avg. loss: 0.065896\n",
      "Total training time: 172.13 seconds.\n",
      "-- Epoch 2037\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.863284, T: 348094782, Avg. loss: 0.065894\n",
      "Total training time: 172.21 seconds.\n",
      "-- Epoch 2038\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.860074, T: 348265668, Avg. loss: 0.065893\n",
      "Total training time: 172.29 seconds.\n",
      "-- Epoch 2039\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.856866, T: 348436554, Avg. loss: 0.065891\n",
      "Total training time: 172.37 seconds.\n",
      "-- Epoch 2040\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.853657, T: 348607440, Avg. loss: 0.065889\n",
      "Total training time: 172.45 seconds.\n",
      "-- Epoch 2041\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.850452, T: 348778326, Avg. loss: 0.065887\n",
      "Total training time: 172.53 seconds.\n",
      "-- Epoch 2042\n",
      "Norm: 13.79, NNZs: 30, Bias: -122.847244, T: 348949212, Avg. loss: 0.065885\n",
      "Total training time: 172.62 seconds.\n",
      "-- Epoch 2043\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.844039, T: 349120098, Avg. loss: 0.065884\n",
      "Total training time: 172.70 seconds.\n",
      "-- Epoch 2044\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.840836, T: 349290984, Avg. loss: 0.065882\n",
      "Total training time: 172.78 seconds.\n",
      "-- Epoch 2045\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.837639, T: 349461870, Avg. loss: 0.065880\n",
      "Total training time: 172.86 seconds.\n",
      "-- Epoch 2046\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.834444, T: 349632756, Avg. loss: 0.065878\n",
      "Total training time: 172.94 seconds.\n",
      "-- Epoch 2047\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.831250, T: 349803642, Avg. loss: 0.065876\n",
      "Total training time: 173.03 seconds.\n",
      "-- Epoch 2048\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.828056, T: 349974528, Avg. loss: 0.065875\n",
      "Total training time: 173.11 seconds.\n",
      "-- Epoch 2049\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.824863, T: 350145414, Avg. loss: 0.065873\n",
      "Total training time: 173.19 seconds.\n",
      "-- Epoch 2050\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.821667, T: 350316300, Avg. loss: 0.065871\n",
      "Total training time: 173.27 seconds.\n",
      "-- Epoch 2051\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.818474, T: 350487186, Avg. loss: 0.065869\n",
      "Total training time: 173.36 seconds.\n",
      "-- Epoch 2052\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.815281, T: 350658072, Avg. loss: 0.065867\n",
      "Total training time: 173.44 seconds.\n",
      "-- Epoch 2053\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.812091, T: 350828958, Avg. loss: 0.065866\n",
      "Total training time: 173.52 seconds.\n",
      "-- Epoch 2054\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.808906, T: 350999844, Avg. loss: 0.065864\n",
      "Total training time: 173.61 seconds.\n",
      "-- Epoch 2055\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.805721, T: 351170730, Avg. loss: 0.065862\n",
      "Total training time: 173.71 seconds.\n",
      "-- Epoch 2056\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.802537, T: 351341616, Avg. loss: 0.065860\n",
      "Total training time: 173.81 seconds.\n",
      "-- Epoch 2057\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.799356, T: 351512502, Avg. loss: 0.065859\n",
      "Total training time: 173.89 seconds.\n",
      "-- Epoch 2058\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.796174, T: 351683388, Avg. loss: 0.065857\n",
      "Total training time: 173.97 seconds.\n",
      "-- Epoch 2059\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.792997, T: 351854274, Avg. loss: 0.065855\n",
      "Total training time: 174.05 seconds.\n",
      "-- Epoch 2060\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.789818, T: 352025160, Avg. loss: 0.065853\n",
      "Total training time: 174.13 seconds.\n",
      "-- Epoch 2061\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.786642, T: 352196046, Avg. loss: 0.065851\n",
      "Total training time: 174.22 seconds.\n",
      "-- Epoch 2062\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.783465, T: 352366932, Avg. loss: 0.065850\n",
      "Total training time: 174.30 seconds.\n",
      "-- Epoch 2063\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.780294, T: 352537818, Avg. loss: 0.065848\n",
      "Total training time: 174.38 seconds.\n",
      "-- Epoch 2064\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.777126, T: 352708704, Avg. loss: 0.065846\n",
      "Total training time: 174.46 seconds.\n",
      "-- Epoch 2065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.78, NNZs: 30, Bias: -122.773957, T: 352879590, Avg. loss: 0.065844\n",
      "Total training time: 174.54 seconds.\n",
      "-- Epoch 2066\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.770788, T: 353050476, Avg. loss: 0.065843\n",
      "Total training time: 174.63 seconds.\n",
      "-- Epoch 2067\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.767619, T: 353221362, Avg. loss: 0.065841\n",
      "Total training time: 174.71 seconds.\n",
      "-- Epoch 2068\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.764450, T: 353392248, Avg. loss: 0.065839\n",
      "Total training time: 174.79 seconds.\n",
      "-- Epoch 2069\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.761286, T: 353563134, Avg. loss: 0.065837\n",
      "Total training time: 174.88 seconds.\n",
      "-- Epoch 2070\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.758127, T: 353734020, Avg. loss: 0.065835\n",
      "Total training time: 174.96 seconds.\n",
      "-- Epoch 2071\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.754967, T: 353904906, Avg. loss: 0.065834\n",
      "Total training time: 175.04 seconds.\n",
      "-- Epoch 2072\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.751806, T: 354075792, Avg. loss: 0.065832\n",
      "Total training time: 175.12 seconds.\n",
      "-- Epoch 2073\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.748648, T: 354246678, Avg. loss: 0.065830\n",
      "Total training time: 175.20 seconds.\n",
      "-- Epoch 2074\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.745492, T: 354417564, Avg. loss: 0.065828\n",
      "Total training time: 175.29 seconds.\n",
      "-- Epoch 2075\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.742339, T: 354588450, Avg. loss: 0.065827\n",
      "Total training time: 175.37 seconds.\n",
      "-- Epoch 2076\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.739187, T: 354759336, Avg. loss: 0.065825\n",
      "Total training time: 175.45 seconds.\n",
      "-- Epoch 2077\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.736037, T: 354930222, Avg. loss: 0.065823\n",
      "Total training time: 175.53 seconds.\n",
      "-- Epoch 2078\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.732890, T: 355101108, Avg. loss: 0.065821\n",
      "Total training time: 175.61 seconds.\n",
      "-- Epoch 2079\n",
      "Norm: 13.78, NNZs: 30, Bias: -122.729744, T: 355271994, Avg. loss: 0.065820\n",
      "Total training time: 175.70 seconds.\n",
      "-- Epoch 2080\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.726600, T: 355442880, Avg. loss: 0.065818\n",
      "Total training time: 175.78 seconds.\n",
      "-- Epoch 2081\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.723457, T: 355613766, Avg. loss: 0.065816\n",
      "Total training time: 175.86 seconds.\n",
      "-- Epoch 2082\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.720314, T: 355784652, Avg. loss: 0.065814\n",
      "Total training time: 175.94 seconds.\n",
      "-- Epoch 2083\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.717169, T: 355955538, Avg. loss: 0.065813\n",
      "Total training time: 176.02 seconds.\n",
      "-- Epoch 2084\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.714028, T: 356126424, Avg. loss: 0.065811\n",
      "Total training time: 176.11 seconds.\n",
      "-- Epoch 2085\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.710890, T: 356297310, Avg. loss: 0.065809\n",
      "Total training time: 176.19 seconds.\n",
      "-- Epoch 2086\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.707754, T: 356468196, Avg. loss: 0.065807\n",
      "Total training time: 176.27 seconds.\n",
      "-- Epoch 2087\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.704620, T: 356639082, Avg. loss: 0.065806\n",
      "Total training time: 176.36 seconds.\n",
      "-- Epoch 2088\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.701486, T: 356809968, Avg. loss: 0.065804\n",
      "Total training time: 176.45 seconds.\n",
      "-- Epoch 2089\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.698354, T: 356980854, Avg. loss: 0.065802\n",
      "Total training time: 176.53 seconds.\n",
      "-- Epoch 2090\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.695224, T: 357151740, Avg. loss: 0.065800\n",
      "Total training time: 176.61 seconds.\n",
      "-- Epoch 2091\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.692095, T: 357322626, Avg. loss: 0.065799\n",
      "Total training time: 176.70 seconds.\n",
      "-- Epoch 2092\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.688966, T: 357493512, Avg. loss: 0.065797\n",
      "Total training time: 176.78 seconds.\n",
      "-- Epoch 2093\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.685840, T: 357664398, Avg. loss: 0.065795\n",
      "Total training time: 176.86 seconds.\n",
      "-- Epoch 2094\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.682713, T: 357835284, Avg. loss: 0.065793\n",
      "Total training time: 176.94 seconds.\n",
      "-- Epoch 2095\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.679591, T: 358006170, Avg. loss: 0.065792\n",
      "Total training time: 177.02 seconds.\n",
      "-- Epoch 2096\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.676466, T: 358177056, Avg. loss: 0.065790\n",
      "Total training time: 177.11 seconds.\n",
      "-- Epoch 2097\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.673345, T: 358347942, Avg. loss: 0.065788\n",
      "Total training time: 177.19 seconds.\n",
      "-- Epoch 2098\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.670228, T: 358518828, Avg. loss: 0.065786\n",
      "Total training time: 177.27 seconds.\n",
      "-- Epoch 2099\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.667112, T: 358689714, Avg. loss: 0.065785\n",
      "Total training time: 177.36 seconds.\n",
      "-- Epoch 2100\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.663996, T: 358860600, Avg. loss: 0.065783\n",
      "Total training time: 177.44 seconds.\n",
      "-- Epoch 2101\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.660877, T: 359031486, Avg. loss: 0.065781\n",
      "Total training time: 177.52 seconds.\n",
      "-- Epoch 2102\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.657766, T: 359202372, Avg. loss: 0.065779\n",
      "Total training time: 177.60 seconds.\n",
      "-- Epoch 2103\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.654657, T: 359373258, Avg. loss: 0.065778\n",
      "Total training time: 177.69 seconds.\n",
      "-- Epoch 2104\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.651546, T: 359544144, Avg. loss: 0.065776\n",
      "Total training time: 177.77 seconds.\n",
      "-- Epoch 2105\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.648435, T: 359715030, Avg. loss: 0.065774\n",
      "Total training time: 177.85 seconds.\n",
      "-- Epoch 2106\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.645324, T: 359885916, Avg. loss: 0.065772\n",
      "Total training time: 177.93 seconds.\n",
      "-- Epoch 2107\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.642221, T: 360056802, Avg. loss: 0.065771\n",
      "Total training time: 178.01 seconds.\n",
      "-- Epoch 2108\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.639113, T: 360227688, Avg. loss: 0.065769\n",
      "Total training time: 178.09 seconds.\n",
      "-- Epoch 2109\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.636013, T: 360398574, Avg. loss: 0.065767\n",
      "Total training time: 178.17 seconds.\n",
      "-- Epoch 2110\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.632913, T: 360569460, Avg. loss: 0.065765\n",
      "Total training time: 178.25 seconds.\n",
      "-- Epoch 2111\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.629811, T: 360740346, Avg. loss: 0.065764\n",
      "Total training time: 178.33 seconds.\n",
      "-- Epoch 2112\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.626716, T: 360911232, Avg. loss: 0.065762\n",
      "Total training time: 178.42 seconds.\n",
      "-- Epoch 2113\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.623619, T: 361082118, Avg. loss: 0.065760\n",
      "Total training time: 178.50 seconds.\n",
      "-- Epoch 2114\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.620521, T: 361253004, Avg. loss: 0.065759\n",
      "Total training time: 178.58 seconds.\n",
      "-- Epoch 2115\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.617427, T: 361423890, Avg. loss: 0.065757\n",
      "Total training time: 178.67 seconds.\n",
      "-- Epoch 2116\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.614335, T: 361594776, Avg. loss: 0.065755\n",
      "Total training time: 178.75 seconds.\n",
      "-- Epoch 2117\n",
      "Norm: 13.77, NNZs: 30, Bias: -122.611247, T: 361765662, Avg. loss: 0.065753\n",
      "Total training time: 178.83 seconds.\n",
      "-- Epoch 2118\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.608157, T: 361936548, Avg. loss: 0.065752\n",
      "Total training time: 178.91 seconds.\n",
      "-- Epoch 2119\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.605068, T: 362107434, Avg. loss: 0.065750\n",
      "Total training time: 179.00 seconds.\n",
      "-- Epoch 2120\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.601977, T: 362278320, Avg. loss: 0.065748\n",
      "Total training time: 179.08 seconds.\n",
      "-- Epoch 2121\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.598892, T: 362449206, Avg. loss: 0.065746\n",
      "Total training time: 179.16 seconds.\n",
      "-- Epoch 2122\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.595808, T: 362620092, Avg. loss: 0.065745\n",
      "Total training time: 179.24 seconds.\n",
      "-- Epoch 2123\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.592728, T: 362790978, Avg. loss: 0.065743\n",
      "Total training time: 179.32 seconds.\n",
      "-- Epoch 2124\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.589646, T: 362961864, Avg. loss: 0.065741\n",
      "Total training time: 179.40 seconds.\n",
      "-- Epoch 2125\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.586566, T: 363132750, Avg. loss: 0.065740\n",
      "Total training time: 179.48 seconds.\n",
      "-- Epoch 2126\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.583488, T: 363303636, Avg. loss: 0.065738\n",
      "Total training time: 179.57 seconds.\n",
      "-- Epoch 2127\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.580415, T: 363474522, Avg. loss: 0.065736\n",
      "Total training time: 179.65 seconds.\n",
      "-- Epoch 2128\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.577338, T: 363645408, Avg. loss: 0.065734\n",
      "Total training time: 179.74 seconds.\n",
      "-- Epoch 2129\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.574263, T: 363816294, Avg. loss: 0.065733\n",
      "Total training time: 179.83 seconds.\n",
      "-- Epoch 2130\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.571195, T: 363987180, Avg. loss: 0.065731\n",
      "Total training time: 179.91 seconds.\n",
      "-- Epoch 2131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.76, NNZs: 30, Bias: -122.568125, T: 364158066, Avg. loss: 0.065729\n",
      "Total training time: 179.99 seconds.\n",
      "-- Epoch 2132\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.565056, T: 364328952, Avg. loss: 0.065728\n",
      "Total training time: 180.08 seconds.\n",
      "-- Epoch 2133\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.561994, T: 364499838, Avg. loss: 0.065726\n",
      "Total training time: 180.16 seconds.\n",
      "-- Epoch 2134\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.558926, T: 364670724, Avg. loss: 0.065724\n",
      "Total training time: 180.24 seconds.\n",
      "-- Epoch 2135\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.555866, T: 364841610, Avg. loss: 0.065722\n",
      "Total training time: 180.32 seconds.\n",
      "-- Epoch 2136\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.552804, T: 365012496, Avg. loss: 0.065721\n",
      "Total training time: 180.41 seconds.\n",
      "-- Epoch 2137\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.549742, T: 365183382, Avg. loss: 0.065719\n",
      "Total training time: 180.49 seconds.\n",
      "-- Epoch 2138\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.546682, T: 365354268, Avg. loss: 0.065717\n",
      "Total training time: 180.57 seconds.\n",
      "-- Epoch 2139\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.543623, T: 365525154, Avg. loss: 0.065716\n",
      "Total training time: 180.66 seconds.\n",
      "-- Epoch 2140\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.540563, T: 365696040, Avg. loss: 0.065714\n",
      "Total training time: 180.74 seconds.\n",
      "-- Epoch 2141\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.537506, T: 365866926, Avg. loss: 0.065712\n",
      "Total training time: 180.82 seconds.\n",
      "-- Epoch 2142\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.534452, T: 366037812, Avg. loss: 0.065710\n",
      "Total training time: 180.90 seconds.\n",
      "-- Epoch 2143\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.531398, T: 366208698, Avg. loss: 0.065709\n",
      "Total training time: 180.98 seconds.\n",
      "-- Epoch 2144\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.528348, T: 366379584, Avg. loss: 0.065707\n",
      "Total training time: 181.06 seconds.\n",
      "-- Epoch 2145\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.525300, T: 366550470, Avg. loss: 0.065705\n",
      "Total training time: 181.15 seconds.\n",
      "-- Epoch 2146\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.522249, T: 366721356, Avg. loss: 0.065704\n",
      "Total training time: 181.22 seconds.\n",
      "-- Epoch 2147\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.519206, T: 366892242, Avg. loss: 0.065702\n",
      "Total training time: 181.31 seconds.\n",
      "-- Epoch 2148\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.516161, T: 367063128, Avg. loss: 0.065700\n",
      "Total training time: 181.39 seconds.\n",
      "-- Epoch 2149\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.513118, T: 367234014, Avg. loss: 0.065698\n",
      "Total training time: 181.47 seconds.\n",
      "-- Epoch 2150\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.510076, T: 367404900, Avg. loss: 0.065697\n",
      "Total training time: 181.55 seconds.\n",
      "-- Epoch 2151\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.507036, T: 367575786, Avg. loss: 0.065695\n",
      "Total training time: 181.64 seconds.\n",
      "-- Epoch 2152\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.503996, T: 367746672, Avg. loss: 0.065693\n",
      "Total training time: 181.72 seconds.\n",
      "-- Epoch 2153\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.500958, T: 367917558, Avg. loss: 0.065692\n",
      "Total training time: 181.80 seconds.\n",
      "-- Epoch 2154\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.497921, T: 368088444, Avg. loss: 0.065690\n",
      "Total training time: 181.88 seconds.\n",
      "-- Epoch 2155\n",
      "Norm: 13.76, NNZs: 30, Bias: -122.494884, T: 368259330, Avg. loss: 0.065688\n",
      "Total training time: 181.96 seconds.\n",
      "-- Epoch 2156\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.491850, T: 368430216, Avg. loss: 0.065687\n",
      "Total training time: 182.05 seconds.\n",
      "-- Epoch 2157\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.488815, T: 368601102, Avg. loss: 0.065685\n",
      "Total training time: 182.13 seconds.\n",
      "-- Epoch 2158\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.485785, T: 368771988, Avg. loss: 0.065683\n",
      "Total training time: 182.21 seconds.\n",
      "-- Epoch 2159\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.482759, T: 368942874, Avg. loss: 0.065682\n",
      "Total training time: 182.29 seconds.\n",
      "-- Epoch 2160\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.479729, T: 369113760, Avg. loss: 0.065680\n",
      "Total training time: 182.37 seconds.\n",
      "-- Epoch 2161\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.476704, T: 369284646, Avg. loss: 0.065678\n",
      "Total training time: 182.46 seconds.\n",
      "-- Epoch 2162\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.473679, T: 369455532, Avg. loss: 0.065676\n",
      "Total training time: 182.54 seconds.\n",
      "-- Epoch 2163\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.470653, T: 369626418, Avg. loss: 0.065675\n",
      "Total training time: 182.62 seconds.\n",
      "-- Epoch 2164\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.467631, T: 369797304, Avg. loss: 0.065673\n",
      "Total training time: 182.70 seconds.\n",
      "-- Epoch 2165\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.464610, T: 369968190, Avg. loss: 0.065671\n",
      "Total training time: 182.78 seconds.\n",
      "-- Epoch 2166\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.461592, T: 370139076, Avg. loss: 0.065670\n",
      "Total training time: 182.87 seconds.\n",
      "-- Epoch 2167\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.458569, T: 370309962, Avg. loss: 0.065668\n",
      "Total training time: 182.95 seconds.\n",
      "-- Epoch 2168\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.455554, T: 370480848, Avg. loss: 0.065666\n",
      "Total training time: 183.03 seconds.\n",
      "-- Epoch 2169\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.452535, T: 370651734, Avg. loss: 0.065665\n",
      "Total training time: 183.11 seconds.\n",
      "-- Epoch 2170\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.449519, T: 370822620, Avg. loss: 0.065663\n",
      "Total training time: 183.19 seconds.\n",
      "-- Epoch 2171\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.446506, T: 370993506, Avg. loss: 0.065661\n",
      "Total training time: 183.27 seconds.\n",
      "-- Epoch 2172\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.443493, T: 371164392, Avg. loss: 0.065660\n",
      "Total training time: 183.35 seconds.\n",
      "-- Epoch 2173\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.440484, T: 371335278, Avg. loss: 0.065658\n",
      "Total training time: 183.43 seconds.\n",
      "-- Epoch 2174\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.437477, T: 371506164, Avg. loss: 0.065656\n",
      "Total training time: 183.52 seconds.\n",
      "-- Epoch 2175\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.434472, T: 371677050, Avg. loss: 0.065655\n",
      "Total training time: 183.60 seconds.\n",
      "-- Epoch 2176\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.431463, T: 371847936, Avg. loss: 0.065653\n",
      "Total training time: 183.68 seconds.\n",
      "-- Epoch 2177\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.428460, T: 372018822, Avg. loss: 0.065651\n",
      "Total training time: 183.76 seconds.\n",
      "-- Epoch 2178\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.425459, T: 372189708, Avg. loss: 0.065649\n",
      "Total training time: 183.84 seconds.\n",
      "-- Epoch 2179\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.422456, T: 372360594, Avg. loss: 0.065648\n",
      "Total training time: 183.92 seconds.\n",
      "-- Epoch 2180\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.419456, T: 372531480, Avg. loss: 0.065646\n",
      "Total training time: 184.01 seconds.\n",
      "-- Epoch 2181\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.416456, T: 372702366, Avg. loss: 0.065644\n",
      "Total training time: 184.09 seconds.\n",
      "-- Epoch 2182\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.413455, T: 372873252, Avg. loss: 0.065643\n",
      "Total training time: 184.17 seconds.\n",
      "-- Epoch 2183\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.410460, T: 373044138, Avg. loss: 0.065641\n",
      "Total training time: 184.25 seconds.\n",
      "-- Epoch 2184\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.407464, T: 373215024, Avg. loss: 0.065639\n",
      "Total training time: 184.33 seconds.\n",
      "-- Epoch 2185\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.404468, T: 373385910, Avg. loss: 0.065638\n",
      "Total training time: 184.41 seconds.\n",
      "-- Epoch 2186\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.401481, T: 373556796, Avg. loss: 0.065636\n",
      "Total training time: 184.49 seconds.\n",
      "-- Epoch 2187\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.398488, T: 373727682, Avg. loss: 0.065634\n",
      "Total training time: 184.57 seconds.\n",
      "-- Epoch 2188\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.395497, T: 373898568, Avg. loss: 0.065633\n",
      "Total training time: 184.66 seconds.\n",
      "-- Epoch 2189\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.392508, T: 374069454, Avg. loss: 0.065631\n",
      "Total training time: 184.74 seconds.\n",
      "-- Epoch 2190\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.389521, T: 374240340, Avg. loss: 0.065629\n",
      "Total training time: 184.82 seconds.\n",
      "-- Epoch 2191\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.386535, T: 374411226, Avg. loss: 0.065628\n",
      "Total training time: 184.90 seconds.\n",
      "-- Epoch 2192\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.383551, T: 374582112, Avg. loss: 0.065626\n",
      "Total training time: 184.98 seconds.\n",
      "-- Epoch 2193\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.380568, T: 374752998, Avg. loss: 0.065624\n",
      "Total training time: 185.06 seconds.\n",
      "-- Epoch 2194\n",
      "Norm: 13.75, NNZs: 30, Bias: -122.377588, T: 374923884, Avg. loss: 0.065623\n",
      "Total training time: 185.14 seconds.\n",
      "-- Epoch 2195\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.374610, T: 375094770, Avg. loss: 0.065621\n",
      "Total training time: 185.23 seconds.\n",
      "-- Epoch 2196\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.371630, T: 375265656, Avg. loss: 0.065619\n",
      "Total training time: 185.31 seconds.\n",
      "-- Epoch 2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.74, NNZs: 30, Bias: -122.368654, T: 375436542, Avg. loss: 0.065618\n",
      "Total training time: 185.39 seconds.\n",
      "-- Epoch 2198\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.365677, T: 375607428, Avg. loss: 0.065616\n",
      "Total training time: 185.47 seconds.\n",
      "-- Epoch 2199\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.362706, T: 375778314, Avg. loss: 0.065614\n",
      "Total training time: 185.55 seconds.\n",
      "-- Epoch 2200\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.359733, T: 375949200, Avg. loss: 0.065613\n",
      "Total training time: 185.63 seconds.\n",
      "-- Epoch 2201\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.356760, T: 376120086, Avg. loss: 0.065611\n",
      "Total training time: 185.72 seconds.\n",
      "-- Epoch 2202\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.353789, T: 376290972, Avg. loss: 0.065609\n",
      "Total training time: 185.80 seconds.\n",
      "-- Epoch 2203\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.350820, T: 376461858, Avg. loss: 0.065608\n",
      "Total training time: 185.88 seconds.\n",
      "-- Epoch 2204\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.347850, T: 376632744, Avg. loss: 0.065606\n",
      "Total training time: 185.96 seconds.\n",
      "-- Epoch 2205\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.344881, T: 376803630, Avg. loss: 0.065604\n",
      "Total training time: 186.04 seconds.\n",
      "-- Epoch 2206\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.341916, T: 376974516, Avg. loss: 0.065603\n",
      "Total training time: 186.12 seconds.\n",
      "-- Epoch 2207\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.338951, T: 377145402, Avg. loss: 0.065601\n",
      "Total training time: 186.20 seconds.\n",
      "-- Epoch 2208\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.335989, T: 377316288, Avg. loss: 0.065599\n",
      "Total training time: 186.28 seconds.\n",
      "-- Epoch 2209\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.333027, T: 377487174, Avg. loss: 0.065598\n",
      "Total training time: 186.36 seconds.\n",
      "-- Epoch 2210\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.330063, T: 377658060, Avg. loss: 0.065596\n",
      "Total training time: 186.44 seconds.\n",
      "-- Epoch 2211\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.327107, T: 377828946, Avg. loss: 0.065595\n",
      "Total training time: 186.52 seconds.\n",
      "-- Epoch 2212\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.324148, T: 377999832, Avg. loss: 0.065593\n",
      "Total training time: 186.61 seconds.\n",
      "-- Epoch 2213\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.321192, T: 378170718, Avg. loss: 0.065591\n",
      "Total training time: 186.69 seconds.\n",
      "-- Epoch 2214\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.318236, T: 378341604, Avg. loss: 0.065590\n",
      "Total training time: 186.77 seconds.\n",
      "-- Epoch 2215\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.315285, T: 378512490, Avg. loss: 0.065588\n",
      "Total training time: 186.85 seconds.\n",
      "-- Epoch 2216\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.312333, T: 378683376, Avg. loss: 0.065586\n",
      "Total training time: 186.94 seconds.\n",
      "-- Epoch 2217\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.309387, T: 378854262, Avg. loss: 0.065585\n",
      "Total training time: 187.02 seconds.\n",
      "-- Epoch 2218\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.306438, T: 379025148, Avg. loss: 0.065583\n",
      "Total training time: 187.10 seconds.\n",
      "-- Epoch 2219\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.303488, T: 379196034, Avg. loss: 0.065581\n",
      "Total training time: 187.18 seconds.\n",
      "-- Epoch 2220\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.300544, T: 379366920, Avg. loss: 0.065580\n",
      "Total training time: 187.26 seconds.\n",
      "-- Epoch 2221\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.297599, T: 379537806, Avg. loss: 0.065578\n",
      "Total training time: 187.34 seconds.\n",
      "-- Epoch 2222\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.294654, T: 379708692, Avg. loss: 0.065576\n",
      "Total training time: 187.43 seconds.\n",
      "-- Epoch 2223\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.291713, T: 379879578, Avg. loss: 0.065575\n",
      "Total training time: 187.51 seconds.\n",
      "-- Epoch 2224\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.288771, T: 380050464, Avg. loss: 0.065573\n",
      "Total training time: 187.59 seconds.\n",
      "-- Epoch 2225\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.285829, T: 380221350, Avg. loss: 0.065571\n",
      "Total training time: 187.67 seconds.\n",
      "-- Epoch 2226\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.282888, T: 380392236, Avg. loss: 0.065570\n",
      "Total training time: 187.75 seconds.\n",
      "-- Epoch 2227\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.279950, T: 380563122, Avg. loss: 0.065568\n",
      "Total training time: 187.84 seconds.\n",
      "-- Epoch 2228\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.277014, T: 380734008, Avg. loss: 0.065567\n",
      "Total training time: 187.92 seconds.\n",
      "-- Epoch 2229\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.274082, T: 380904894, Avg. loss: 0.065565\n",
      "Total training time: 188.00 seconds.\n",
      "-- Epoch 2230\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.271149, T: 381075780, Avg. loss: 0.065563\n",
      "Total training time: 188.08 seconds.\n",
      "-- Epoch 2231\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.268216, T: 381246666, Avg. loss: 0.065562\n",
      "Total training time: 188.16 seconds.\n",
      "-- Epoch 2232\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.265287, T: 381417552, Avg. loss: 0.065560\n",
      "Total training time: 188.24 seconds.\n",
      "-- Epoch 2233\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.262357, T: 381588438, Avg. loss: 0.065558\n",
      "Total training time: 188.33 seconds.\n",
      "-- Epoch 2234\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.259429, T: 381759324, Avg. loss: 0.065557\n",
      "Total training time: 188.41 seconds.\n",
      "-- Epoch 2235\n",
      "Norm: 13.74, NNZs: 30, Bias: -122.256504, T: 381930210, Avg. loss: 0.065555\n",
      "Total training time: 188.49 seconds.\n",
      "-- Epoch 2236\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.253581, T: 382101096, Avg. loss: 0.065553\n",
      "Total training time: 188.57 seconds.\n",
      "-- Epoch 2237\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.250659, T: 382271982, Avg. loss: 0.065552\n",
      "Total training time: 188.65 seconds.\n",
      "-- Epoch 2238\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.247738, T: 382442868, Avg. loss: 0.065550\n",
      "Total training time: 188.73 seconds.\n",
      "-- Epoch 2239\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.244820, T: 382613754, Avg. loss: 0.065549\n",
      "Total training time: 188.81 seconds.\n",
      "-- Epoch 2240\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.241900, T: 382784640, Avg. loss: 0.065547\n",
      "Total training time: 188.89 seconds.\n",
      "-- Epoch 2241\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.238984, T: 382955526, Avg. loss: 0.065545\n",
      "Total training time: 188.97 seconds.\n",
      "-- Epoch 2242\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.236068, T: 383126412, Avg. loss: 0.065544\n",
      "Total training time: 189.06 seconds.\n",
      "-- Epoch 2243\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.233154, T: 383297298, Avg. loss: 0.065542\n",
      "Total training time: 189.14 seconds.\n",
      "-- Epoch 2244\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.230240, T: 383468184, Avg. loss: 0.065540\n",
      "Total training time: 189.22 seconds.\n",
      "-- Epoch 2245\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.227327, T: 383639070, Avg. loss: 0.065539\n",
      "Total training time: 189.30 seconds.\n",
      "-- Epoch 2246\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.224416, T: 383809956, Avg. loss: 0.065537\n",
      "Total training time: 189.38 seconds.\n",
      "-- Epoch 2247\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.221506, T: 383980842, Avg. loss: 0.065536\n",
      "Total training time: 189.46 seconds.\n",
      "-- Epoch 2248\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.218598, T: 384151728, Avg. loss: 0.065534\n",
      "Total training time: 189.55 seconds.\n",
      "-- Epoch 2249\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.215690, T: 384322614, Avg. loss: 0.065532\n",
      "Total training time: 189.63 seconds.\n",
      "-- Epoch 2250\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.212784, T: 384493500, Avg. loss: 0.065531\n",
      "Total training time: 189.71 seconds.\n",
      "-- Epoch 2251\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.209879, T: 384664386, Avg. loss: 0.065529\n",
      "Total training time: 189.79 seconds.\n",
      "-- Epoch 2252\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.206975, T: 384835272, Avg. loss: 0.065527\n",
      "Total training time: 189.87 seconds.\n",
      "-- Epoch 2253\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.204075, T: 385006158, Avg. loss: 0.065526\n",
      "Total training time: 189.95 seconds.\n",
      "-- Epoch 2254\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.201171, T: 385177044, Avg. loss: 0.065524\n",
      "Total training time: 190.03 seconds.\n",
      "-- Epoch 2255\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.198268, T: 385347930, Avg. loss: 0.065523\n",
      "Total training time: 190.11 seconds.\n",
      "-- Epoch 2256\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.195367, T: 385518816, Avg. loss: 0.065521\n",
      "Total training time: 190.19 seconds.\n",
      "-- Epoch 2257\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.192472, T: 385689702, Avg. loss: 0.065519\n",
      "Total training time: 190.28 seconds.\n",
      "-- Epoch 2258\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.189577, T: 385860588, Avg. loss: 0.065518\n",
      "Total training time: 190.36 seconds.\n",
      "-- Epoch 2259\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.186682, T: 386031474, Avg. loss: 0.065516\n",
      "Total training time: 190.44 seconds.\n",
      "-- Epoch 2260\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.183790, T: 386202360, Avg. loss: 0.065514\n",
      "Total training time: 190.52 seconds.\n",
      "-- Epoch 2261\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.180894, T: 386373246, Avg. loss: 0.065513\n",
      "Total training time: 190.60 seconds.\n",
      "-- Epoch 2262\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.178004, T: 386544132, Avg. loss: 0.065511\n",
      "Total training time: 190.68 seconds.\n",
      "-- Epoch 2263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.73, NNZs: 30, Bias: -122.175116, T: 386715018, Avg. loss: 0.065510\n",
      "Total training time: 190.77 seconds.\n",
      "-- Epoch 2264\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.172228, T: 386885904, Avg. loss: 0.065508\n",
      "Total training time: 190.84 seconds.\n",
      "-- Epoch 2265\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.169342, T: 387056790, Avg. loss: 0.065506\n",
      "Total training time: 190.93 seconds.\n",
      "-- Epoch 2266\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.166462, T: 387227676, Avg. loss: 0.065505\n",
      "Total training time: 191.01 seconds.\n",
      "-- Epoch 2267\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.163577, T: 387398562, Avg. loss: 0.065503\n",
      "Total training time: 191.09 seconds.\n",
      "-- Epoch 2268\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.160692, T: 387569448, Avg. loss: 0.065502\n",
      "Total training time: 191.17 seconds.\n",
      "-- Epoch 2269\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.157813, T: 387740334, Avg. loss: 0.065500\n",
      "Total training time: 191.26 seconds.\n",
      "-- Epoch 2270\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.154934, T: 387911220, Avg. loss: 0.065498\n",
      "Total training time: 191.34 seconds.\n",
      "-- Epoch 2271\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.152055, T: 388082106, Avg. loss: 0.065497\n",
      "Total training time: 191.42 seconds.\n",
      "-- Epoch 2272\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.149176, T: 388252992, Avg. loss: 0.065495\n",
      "Total training time: 191.50 seconds.\n",
      "-- Epoch 2273\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.146300, T: 388423878, Avg. loss: 0.065494\n",
      "Total training time: 191.59 seconds.\n",
      "-- Epoch 2274\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.143426, T: 388594764, Avg. loss: 0.065492\n",
      "Total training time: 191.67 seconds.\n",
      "-- Epoch 2275\n",
      "Norm: 13.73, NNZs: 30, Bias: -122.140553, T: 388765650, Avg. loss: 0.065490\n",
      "Total training time: 191.75 seconds.\n",
      "-- Epoch 2276\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.137679, T: 388936536, Avg. loss: 0.065489\n",
      "Total training time: 191.83 seconds.\n",
      "-- Epoch 2277\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.134807, T: 389107422, Avg. loss: 0.065487\n",
      "Total training time: 191.91 seconds.\n",
      "-- Epoch 2278\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.131938, T: 389278308, Avg. loss: 0.065486\n",
      "Total training time: 192.00 seconds.\n",
      "-- Epoch 2279\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.129071, T: 389449194, Avg. loss: 0.065484\n",
      "Total training time: 192.08 seconds.\n",
      "-- Epoch 2280\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.126203, T: 389620080, Avg. loss: 0.065482\n",
      "Total training time: 192.16 seconds.\n",
      "-- Epoch 2281\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.123339, T: 389790966, Avg. loss: 0.065481\n",
      "Total training time: 192.24 seconds.\n",
      "-- Epoch 2282\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.120470, T: 389961852, Avg. loss: 0.065479\n",
      "Total training time: 192.32 seconds.\n",
      "-- Epoch 2283\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.117604, T: 390132738, Avg. loss: 0.065478\n",
      "Total training time: 192.40 seconds.\n",
      "-- Epoch 2284\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.114739, T: 390303624, Avg. loss: 0.065476\n",
      "Total training time: 192.49 seconds.\n",
      "-- Epoch 2285\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.111877, T: 390474510, Avg. loss: 0.065474\n",
      "Total training time: 192.57 seconds.\n",
      "-- Epoch 2286\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.109019, T: 390645396, Avg. loss: 0.065473\n",
      "Total training time: 192.65 seconds.\n",
      "-- Epoch 2287\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.106163, T: 390816282, Avg. loss: 0.065471\n",
      "Total training time: 192.74 seconds.\n",
      "-- Epoch 2288\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.103307, T: 390987168, Avg. loss: 0.065470\n",
      "Total training time: 192.82 seconds.\n",
      "-- Epoch 2289\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.100451, T: 391158054, Avg. loss: 0.065468\n",
      "Total training time: 192.90 seconds.\n",
      "-- Epoch 2290\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.097596, T: 391328940, Avg. loss: 0.065466\n",
      "Total training time: 192.98 seconds.\n",
      "-- Epoch 2291\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.094744, T: 391499826, Avg. loss: 0.065465\n",
      "Total training time: 193.06 seconds.\n",
      "-- Epoch 2292\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.091890, T: 391670712, Avg. loss: 0.065463\n",
      "Total training time: 193.14 seconds.\n",
      "-- Epoch 2293\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.089039, T: 391841598, Avg. loss: 0.065462\n",
      "Total training time: 193.23 seconds.\n",
      "-- Epoch 2294\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.086187, T: 392012484, Avg. loss: 0.065460\n",
      "Total training time: 193.31 seconds.\n",
      "-- Epoch 2295\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.083340, T: 392183370, Avg. loss: 0.065458\n",
      "Total training time: 193.39 seconds.\n",
      "-- Epoch 2296\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.080494, T: 392354256, Avg. loss: 0.065457\n",
      "Total training time: 193.47 seconds.\n",
      "-- Epoch 2297\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.077651, T: 392525142, Avg. loss: 0.065455\n",
      "Total training time: 193.56 seconds.\n",
      "-- Epoch 2298\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.074805, T: 392696028, Avg. loss: 0.065454\n",
      "Total training time: 193.64 seconds.\n",
      "-- Epoch 2299\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.071966, T: 392866914, Avg. loss: 0.065452\n",
      "Total training time: 193.72 seconds.\n",
      "-- Epoch 2300\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.069124, T: 393037800, Avg. loss: 0.065450\n",
      "Total training time: 193.80 seconds.\n",
      "-- Epoch 2301\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.066282, T: 393208686, Avg. loss: 0.065449\n",
      "Total training time: 193.88 seconds.\n",
      "-- Epoch 2302\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.063440, T: 393379572, Avg. loss: 0.065447\n",
      "Total training time: 193.96 seconds.\n",
      "-- Epoch 2303\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.060599, T: 393550458, Avg. loss: 0.065446\n",
      "Total training time: 194.05 seconds.\n",
      "-- Epoch 2304\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.057761, T: 393721344, Avg. loss: 0.065444\n",
      "Total training time: 194.13 seconds.\n",
      "-- Epoch 2305\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.054925, T: 393892230, Avg. loss: 0.065442\n",
      "Total training time: 194.21 seconds.\n",
      "-- Epoch 2306\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.052090, T: 394063116, Avg. loss: 0.065441\n",
      "Total training time: 194.29 seconds.\n",
      "-- Epoch 2307\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.049260, T: 394234002, Avg. loss: 0.065439\n",
      "Total training time: 194.38 seconds.\n",
      "-- Epoch 2308\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.046426, T: 394404888, Avg. loss: 0.065438\n",
      "Total training time: 194.46 seconds.\n",
      "-- Epoch 2309\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.043593, T: 394575774, Avg. loss: 0.065436\n",
      "Total training time: 194.54 seconds.\n",
      "-- Epoch 2310\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.040764, T: 394746660, Avg. loss: 0.065435\n",
      "Total training time: 194.63 seconds.\n",
      "-- Epoch 2311\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.037933, T: 394917546, Avg. loss: 0.065433\n",
      "Total training time: 194.71 seconds.\n",
      "-- Epoch 2312\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.035106, T: 395088432, Avg. loss: 0.065431\n",
      "Total training time: 194.79 seconds.\n",
      "-- Epoch 2313\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.032280, T: 395259318, Avg. loss: 0.065430\n",
      "Total training time: 194.87 seconds.\n",
      "-- Epoch 2314\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.029455, T: 395430204, Avg. loss: 0.065428\n",
      "Total training time: 194.95 seconds.\n",
      "-- Epoch 2315\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.026632, T: 395601090, Avg. loss: 0.065427\n",
      "Total training time: 195.03 seconds.\n",
      "-- Epoch 2316\n",
      "Norm: 13.72, NNZs: 30, Bias: -122.023808, T: 395771976, Avg. loss: 0.065425\n",
      "Total training time: 195.11 seconds.\n",
      "-- Epoch 2317\n",
      "Norm: 13.71, NNZs: 30, Bias: -122.020987, T: 395942862, Avg. loss: 0.065424\n",
      "Total training time: 195.19 seconds.\n",
      "-- Epoch 2318\n",
      "Norm: 13.71, NNZs: 30, Bias: -122.018168, T: 396113748, Avg. loss: 0.065422\n",
      "Total training time: 195.27 seconds.\n",
      "-- Epoch 2319\n",
      "Norm: 13.71, NNZs: 30, Bias: -122.015349, T: 396284634, Avg. loss: 0.065420\n",
      "Total training time: 195.35 seconds.\n",
      "-- Epoch 2320\n",
      "Norm: 13.71, NNZs: 30, Bias: -122.012532, T: 396455520, Avg. loss: 0.065419\n",
      "Total training time: 195.43 seconds.\n",
      "-- Epoch 2321\n",
      "Norm: 13.71, NNZs: 30, Bias: -122.009719, T: 396626406, Avg. loss: 0.065417\n",
      "Total training time: 195.52 seconds.\n",
      "-- Epoch 2322\n",
      "Norm: 13.71, NNZs: 30, Bias: -122.006901, T: 396797292, Avg. loss: 0.065416\n",
      "Total training time: 195.60 seconds.\n",
      "-- Epoch 2323\n",
      "Norm: 13.71, NNZs: 30, Bias: -122.004089, T: 396968178, Avg. loss: 0.065414\n",
      "Total training time: 195.68 seconds.\n",
      "-- Epoch 2324\n",
      "Norm: 13.71, NNZs: 30, Bias: -122.001275, T: 397139064, Avg. loss: 0.065413\n",
      "Total training time: 195.77 seconds.\n",
      "-- Epoch 2325\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.998467, T: 397309950, Avg. loss: 0.065411\n",
      "Total training time: 195.85 seconds.\n",
      "-- Epoch 2326\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.995655, T: 397480836, Avg. loss: 0.065409\n",
      "Total training time: 195.93 seconds.\n",
      "-- Epoch 2327\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.992847, T: 397651722, Avg. loss: 0.065408\n",
      "Total training time: 196.02 seconds.\n",
      "-- Epoch 2328\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.990042, T: 397822608, Avg. loss: 0.065406\n",
      "Total training time: 196.10 seconds.\n",
      "-- Epoch 2329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.71, NNZs: 30, Bias: -121.987235, T: 397993494, Avg. loss: 0.065405\n",
      "Total training time: 196.18 seconds.\n",
      "-- Epoch 2330\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.984434, T: 398164380, Avg. loss: 0.065403\n",
      "Total training time: 196.28 seconds.\n",
      "-- Epoch 2331\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.981633, T: 398335266, Avg. loss: 0.065402\n",
      "Total training time: 196.36 seconds.\n",
      "-- Epoch 2332\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.978830, T: 398506152, Avg. loss: 0.065400\n",
      "Total training time: 196.44 seconds.\n",
      "-- Epoch 2333\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.976030, T: 398677038, Avg. loss: 0.065398\n",
      "Total training time: 196.52 seconds.\n",
      "-- Epoch 2334\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.973232, T: 398847924, Avg. loss: 0.065397\n",
      "Total training time: 196.61 seconds.\n",
      "-- Epoch 2335\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.970433, T: 399018810, Avg. loss: 0.065395\n",
      "Total training time: 196.69 seconds.\n",
      "-- Epoch 2336\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.967635, T: 399189696, Avg. loss: 0.065394\n",
      "Total training time: 196.77 seconds.\n",
      "-- Epoch 2337\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.964836, T: 399360582, Avg. loss: 0.065392\n",
      "Total training time: 196.85 seconds.\n",
      "-- Epoch 2338\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.962041, T: 399531468, Avg. loss: 0.065391\n",
      "Total training time: 196.94 seconds.\n",
      "-- Epoch 2339\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.959246, T: 399702354, Avg. loss: 0.065389\n",
      "Total training time: 197.02 seconds.\n",
      "-- Epoch 2340\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.956452, T: 399873240, Avg. loss: 0.065388\n",
      "Total training time: 197.10 seconds.\n",
      "-- Epoch 2341\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.953660, T: 400044126, Avg. loss: 0.065386\n",
      "Total training time: 197.19 seconds.\n",
      "-- Epoch 2342\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.950870, T: 400215012, Avg. loss: 0.065384\n",
      "Total training time: 197.27 seconds.\n",
      "-- Epoch 2343\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.948077, T: 400385898, Avg. loss: 0.065383\n",
      "Total training time: 197.35 seconds.\n",
      "-- Epoch 2344\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.945288, T: 400556784, Avg. loss: 0.065381\n",
      "Total training time: 197.43 seconds.\n",
      "-- Epoch 2345\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.942502, T: 400727670, Avg. loss: 0.065380\n",
      "Total training time: 197.52 seconds.\n",
      "-- Epoch 2346\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.939714, T: 400898556, Avg. loss: 0.065378\n",
      "Total training time: 197.60 seconds.\n",
      "-- Epoch 2347\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.936928, T: 401069442, Avg. loss: 0.065377\n",
      "Total training time: 197.68 seconds.\n",
      "-- Epoch 2348\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.934143, T: 401240328, Avg. loss: 0.065375\n",
      "Total training time: 197.76 seconds.\n",
      "-- Epoch 2349\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.931358, T: 401411214, Avg. loss: 0.065373\n",
      "Total training time: 197.85 seconds.\n",
      "-- Epoch 2350\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.928576, T: 401582100, Avg. loss: 0.065372\n",
      "Total training time: 197.93 seconds.\n",
      "-- Epoch 2351\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.925796, T: 401752986, Avg. loss: 0.065370\n",
      "Total training time: 198.01 seconds.\n",
      "-- Epoch 2352\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.923017, T: 401923872, Avg. loss: 0.065369\n",
      "Total training time: 198.09 seconds.\n",
      "-- Epoch 2353\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.920240, T: 402094758, Avg. loss: 0.065367\n",
      "Total training time: 198.17 seconds.\n",
      "-- Epoch 2354\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.917462, T: 402265644, Avg. loss: 0.065366\n",
      "Total training time: 198.28 seconds.\n",
      "-- Epoch 2355\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.914685, T: 402436530, Avg. loss: 0.065364\n",
      "Total training time: 198.36 seconds.\n",
      "-- Epoch 2356\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.911909, T: 402607416, Avg. loss: 0.065363\n",
      "Total training time: 198.45 seconds.\n",
      "-- Epoch 2357\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.909139, T: 402778302, Avg. loss: 0.065361\n",
      "Total training time: 198.53 seconds.\n",
      "-- Epoch 2358\n",
      "Norm: 13.71, NNZs: 30, Bias: -121.906365, T: 402949188, Avg. loss: 0.065360\n",
      "Total training time: 198.62 seconds.\n",
      "-- Epoch 2359\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.903594, T: 403120074, Avg. loss: 0.065358\n",
      "Total training time: 198.70 seconds.\n",
      "-- Epoch 2360\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.900824, T: 403290960, Avg. loss: 0.065356\n",
      "Total training time: 198.78 seconds.\n",
      "-- Epoch 2361\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.898056, T: 403461846, Avg. loss: 0.065355\n",
      "Total training time: 198.86 seconds.\n",
      "-- Epoch 2362\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.895289, T: 403632732, Avg. loss: 0.065353\n",
      "Total training time: 198.95 seconds.\n",
      "-- Epoch 2363\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.892523, T: 403803618, Avg. loss: 0.065352\n",
      "Total training time: 199.03 seconds.\n",
      "-- Epoch 2364\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.889758, T: 403974504, Avg. loss: 0.065350\n",
      "Total training time: 199.11 seconds.\n",
      "-- Epoch 2365\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.886994, T: 404145390, Avg. loss: 0.065349\n",
      "Total training time: 199.19 seconds.\n",
      "-- Epoch 2366\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.884230, T: 404316276, Avg. loss: 0.065347\n",
      "Total training time: 199.28 seconds.\n",
      "-- Epoch 2367\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.881467, T: 404487162, Avg. loss: 0.065346\n",
      "Total training time: 199.36 seconds.\n",
      "-- Epoch 2368\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.878707, T: 404658048, Avg. loss: 0.065344\n",
      "Total training time: 199.44 seconds.\n",
      "-- Epoch 2369\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.875949, T: 404828934, Avg. loss: 0.065343\n",
      "Total training time: 199.52 seconds.\n",
      "-- Epoch 2370\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.873191, T: 404999820, Avg. loss: 0.065341\n",
      "Total training time: 199.60 seconds.\n",
      "-- Epoch 2371\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.870436, T: 405170706, Avg. loss: 0.065340\n",
      "Total training time: 199.68 seconds.\n",
      "-- Epoch 2372\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.867680, T: 405341592, Avg. loss: 0.065338\n",
      "Total training time: 199.76 seconds.\n",
      "-- Epoch 2373\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.864926, T: 405512478, Avg. loss: 0.065336\n",
      "Total training time: 199.85 seconds.\n",
      "-- Epoch 2374\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.862171, T: 405683364, Avg. loss: 0.065335\n",
      "Total training time: 199.93 seconds.\n",
      "-- Epoch 2375\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.859420, T: 405854250, Avg. loss: 0.065333\n",
      "Total training time: 200.01 seconds.\n",
      "-- Epoch 2376\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.856672, T: 406025136, Avg. loss: 0.065332\n",
      "Total training time: 200.09 seconds.\n",
      "-- Epoch 2377\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.853924, T: 406196022, Avg. loss: 0.065330\n",
      "Total training time: 200.17 seconds.\n",
      "-- Epoch 2378\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.851174, T: 406366908, Avg. loss: 0.065329\n",
      "Total training time: 200.26 seconds.\n",
      "-- Epoch 2379\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.848421, T: 406537794, Avg. loss: 0.065327\n",
      "Total training time: 200.34 seconds.\n",
      "-- Epoch 2380\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.845676, T: 406708680, Avg. loss: 0.065326\n",
      "Total training time: 200.42 seconds.\n",
      "-- Epoch 2381\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.842932, T: 406879566, Avg. loss: 0.065324\n",
      "Total training time: 200.50 seconds.\n",
      "-- Epoch 2382\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.840185, T: 407050452, Avg. loss: 0.065323\n",
      "Total training time: 200.58 seconds.\n",
      "-- Epoch 2383\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.837443, T: 407221338, Avg. loss: 0.065321\n",
      "Total training time: 200.66 seconds.\n",
      "-- Epoch 2384\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.834702, T: 407392224, Avg. loss: 0.065320\n",
      "Total training time: 200.75 seconds.\n",
      "-- Epoch 2385\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.831961, T: 407563110, Avg. loss: 0.065318\n",
      "Total training time: 200.82 seconds.\n",
      "-- Epoch 2386\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.829226, T: 407733996, Avg. loss: 0.065317\n",
      "Total training time: 200.91 seconds.\n",
      "-- Epoch 2387\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.826486, T: 407904882, Avg. loss: 0.065315\n",
      "Total training time: 200.99 seconds.\n",
      "-- Epoch 2388\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.823750, T: 408075768, Avg. loss: 0.065313\n",
      "Total training time: 201.07 seconds.\n",
      "-- Epoch 2389\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.821015, T: 408246654, Avg. loss: 0.065312\n",
      "Total training time: 201.15 seconds.\n",
      "-- Epoch 2390\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.818279, T: 408417540, Avg. loss: 0.065310\n",
      "Total training time: 201.23 seconds.\n",
      "-- Epoch 2391\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.815544, T: 408588426, Avg. loss: 0.065309\n",
      "Total training time: 201.31 seconds.\n",
      "-- Epoch 2392\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.812811, T: 408759312, Avg. loss: 0.065307\n",
      "Total training time: 201.40 seconds.\n",
      "-- Epoch 2393\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.810081, T: 408930198, Avg. loss: 0.065306\n",
      "Total training time: 201.48 seconds.\n",
      "-- Epoch 2394\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.807351, T: 409101084, Avg. loss: 0.065304\n",
      "Total training time: 201.56 seconds.\n",
      "-- Epoch 2395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.70, NNZs: 30, Bias: -121.804623, T: 409271970, Avg. loss: 0.065303\n",
      "Total training time: 201.64 seconds.\n",
      "-- Epoch 2396\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.801894, T: 409442856, Avg. loss: 0.065301\n",
      "Total training time: 201.73 seconds.\n",
      "-- Epoch 2397\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.799167, T: 409613742, Avg. loss: 0.065300\n",
      "Total training time: 201.81 seconds.\n",
      "-- Epoch 2398\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.796440, T: 409784628, Avg. loss: 0.065298\n",
      "Total training time: 201.89 seconds.\n",
      "-- Epoch 2399\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.793717, T: 409955514, Avg. loss: 0.065297\n",
      "Total training time: 201.97 seconds.\n",
      "-- Epoch 2400\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.790992, T: 410126400, Avg. loss: 0.065295\n",
      "Total training time: 202.05 seconds.\n",
      "-- Epoch 2401\n",
      "Norm: 13.70, NNZs: 30, Bias: -121.788270, T: 410297286, Avg. loss: 0.065294\n",
      "Total training time: 202.13 seconds.\n",
      "-- Epoch 2402\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.785551, T: 410468172, Avg. loss: 0.065292\n",
      "Total training time: 202.21 seconds.\n",
      "-- Epoch 2403\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.782832, T: 410639058, Avg. loss: 0.065291\n",
      "Total training time: 202.30 seconds.\n",
      "-- Epoch 2404\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.780113, T: 410809944, Avg. loss: 0.065289\n",
      "Total training time: 202.38 seconds.\n",
      "-- Epoch 2405\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.777397, T: 410980830, Avg. loss: 0.065288\n",
      "Total training time: 202.46 seconds.\n",
      "-- Epoch 2406\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.774682, T: 411151716, Avg. loss: 0.065286\n",
      "Total training time: 202.54 seconds.\n",
      "-- Epoch 2407\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.771968, T: 411322602, Avg. loss: 0.065285\n",
      "Total training time: 202.63 seconds.\n",
      "-- Epoch 2408\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.769256, T: 411493488, Avg. loss: 0.065283\n",
      "Total training time: 202.71 seconds.\n",
      "-- Epoch 2409\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.766544, T: 411664374, Avg. loss: 0.065282\n",
      "Total training time: 202.79 seconds.\n",
      "-- Epoch 2410\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.763828, T: 411835260, Avg. loss: 0.065280\n",
      "Total training time: 202.87 seconds.\n",
      "-- Epoch 2411\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.761115, T: 412006146, Avg. loss: 0.065279\n",
      "Total training time: 202.95 seconds.\n",
      "-- Epoch 2412\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.758402, T: 412177032, Avg. loss: 0.065277\n",
      "Total training time: 203.03 seconds.\n",
      "-- Epoch 2413\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.755692, T: 412347918, Avg. loss: 0.065275\n",
      "Total training time: 203.11 seconds.\n",
      "-- Epoch 2414\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.752983, T: 412518804, Avg. loss: 0.065274\n",
      "Total training time: 203.19 seconds.\n",
      "-- Epoch 2415\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.750279, T: 412689690, Avg. loss: 0.065272\n",
      "Total training time: 203.28 seconds.\n",
      "-- Epoch 2416\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.747578, T: 412860576, Avg. loss: 0.065271\n",
      "Total training time: 203.36 seconds.\n",
      "-- Epoch 2417\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.744873, T: 413031462, Avg. loss: 0.065269\n",
      "Total training time: 203.44 seconds.\n",
      "-- Epoch 2418\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.742168, T: 413202348, Avg. loss: 0.065268\n",
      "Total training time: 203.52 seconds.\n",
      "-- Epoch 2419\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.739466, T: 413373234, Avg. loss: 0.065266\n",
      "Total training time: 203.60 seconds.\n",
      "-- Epoch 2420\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.736767, T: 413544120, Avg. loss: 0.065265\n",
      "Total training time: 203.69 seconds.\n",
      "-- Epoch 2421\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.734071, T: 413715006, Avg. loss: 0.065263\n",
      "Total training time: 203.77 seconds.\n",
      "-- Epoch 2422\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.731377, T: 413885892, Avg. loss: 0.065262\n",
      "Total training time: 203.85 seconds.\n",
      "-- Epoch 2423\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.728679, T: 414056778, Avg. loss: 0.065260\n",
      "Total training time: 203.93 seconds.\n",
      "-- Epoch 2424\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.725981, T: 414227664, Avg. loss: 0.065259\n",
      "Total training time: 204.01 seconds.\n",
      "-- Epoch 2425\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.723286, T: 414398550, Avg. loss: 0.065257\n",
      "Total training time: 204.10 seconds.\n",
      "-- Epoch 2426\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.720593, T: 414569436, Avg. loss: 0.065256\n",
      "Total training time: 204.18 seconds.\n",
      "-- Epoch 2427\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.717902, T: 414740322, Avg. loss: 0.065254\n",
      "Total training time: 204.26 seconds.\n",
      "-- Epoch 2428\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.715211, T: 414911208, Avg. loss: 0.065253\n",
      "Total training time: 204.34 seconds.\n",
      "-- Epoch 2429\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.712519, T: 415082094, Avg. loss: 0.065251\n",
      "Total training time: 204.42 seconds.\n",
      "-- Epoch 2430\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.709830, T: 415252980, Avg. loss: 0.065250\n",
      "Total training time: 204.50 seconds.\n",
      "-- Epoch 2431\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.707145, T: 415423866, Avg. loss: 0.065248\n",
      "Total training time: 204.59 seconds.\n",
      "-- Epoch 2432\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.704457, T: 415594752, Avg. loss: 0.065247\n",
      "Total training time: 204.67 seconds.\n",
      "-- Epoch 2433\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.701771, T: 415765638, Avg. loss: 0.065245\n",
      "Total training time: 204.75 seconds.\n",
      "-- Epoch 2434\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.699087, T: 415936524, Avg. loss: 0.065244\n",
      "Total training time: 204.83 seconds.\n",
      "-- Epoch 2435\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.696403, T: 416107410, Avg. loss: 0.065242\n",
      "Total training time: 204.91 seconds.\n",
      "-- Epoch 2436\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.693718, T: 416278296, Avg. loss: 0.065241\n",
      "Total training time: 204.99 seconds.\n",
      "-- Epoch 2437\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.691036, T: 416449182, Avg. loss: 0.065239\n",
      "Total training time: 205.07 seconds.\n",
      "-- Epoch 2438\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.688356, T: 416620068, Avg. loss: 0.065238\n",
      "Total training time: 205.15 seconds.\n",
      "-- Epoch 2439\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.685677, T: 416790954, Avg. loss: 0.065236\n",
      "Total training time: 205.23 seconds.\n",
      "-- Epoch 2440\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.682997, T: 416961840, Avg. loss: 0.065235\n",
      "Total training time: 205.32 seconds.\n",
      "-- Epoch 2441\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.680320, T: 417132726, Avg. loss: 0.065233\n",
      "Total training time: 205.39 seconds.\n",
      "-- Epoch 2442\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.677645, T: 417303612, Avg. loss: 0.065232\n",
      "Total training time: 205.48 seconds.\n",
      "-- Epoch 2443\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.674970, T: 417474498, Avg. loss: 0.065230\n",
      "Total training time: 205.56 seconds.\n",
      "-- Epoch 2444\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.672295, T: 417645384, Avg. loss: 0.065229\n",
      "Total training time: 205.64 seconds.\n",
      "-- Epoch 2445\n",
      "Norm: 13.69, NNZs: 30, Bias: -121.669623, T: 417816270, Avg. loss: 0.065227\n",
      "Total training time: 205.72 seconds.\n",
      "-- Epoch 2446\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.666951, T: 417987156, Avg. loss: 0.065226\n",
      "Total training time: 205.80 seconds.\n",
      "-- Epoch 2447\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.664279, T: 418158042, Avg. loss: 0.065224\n",
      "Total training time: 205.88 seconds.\n",
      "-- Epoch 2448\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.661610, T: 418328928, Avg. loss: 0.065223\n",
      "Total training time: 205.97 seconds.\n",
      "-- Epoch 2449\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.658945, T: 418499814, Avg. loss: 0.065222\n",
      "Total training time: 206.05 seconds.\n",
      "-- Epoch 2450\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.656279, T: 418670700, Avg. loss: 0.065220\n",
      "Total training time: 206.13 seconds.\n",
      "-- Epoch 2451\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.653610, T: 418841586, Avg. loss: 0.065219\n",
      "Total training time: 206.21 seconds.\n",
      "-- Epoch 2452\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.650945, T: 419012472, Avg. loss: 0.065217\n",
      "Total training time: 206.30 seconds.\n",
      "-- Epoch 2453\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.648283, T: 419183358, Avg. loss: 0.065216\n",
      "Total training time: 206.38 seconds.\n",
      "-- Epoch 2454\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.645622, T: 419354244, Avg. loss: 0.065214\n",
      "Total training time: 206.46 seconds.\n",
      "-- Epoch 2455\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.642963, T: 419525130, Avg. loss: 0.065213\n",
      "Total training time: 206.54 seconds.\n",
      "-- Epoch 2456\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.640304, T: 419696016, Avg. loss: 0.065211\n",
      "Total training time: 206.62 seconds.\n",
      "-- Epoch 2457\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.637647, T: 419866902, Avg. loss: 0.065210\n",
      "Total training time: 206.70 seconds.\n",
      "-- Epoch 2458\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.634990, T: 420037788, Avg. loss: 0.065208\n",
      "Total training time: 206.79 seconds.\n",
      "-- Epoch 2459\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.632332, T: 420208674, Avg. loss: 0.065207\n",
      "Total training time: 206.87 seconds.\n",
      "-- Epoch 2460\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.629675, T: 420379560, Avg. loss: 0.065205\n",
      "Total training time: 206.95 seconds.\n",
      "-- Epoch 2461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.68, NNZs: 30, Bias: -121.627023, T: 420550446, Avg. loss: 0.065204\n",
      "Total training time: 207.04 seconds.\n",
      "-- Epoch 2462\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.624369, T: 420721332, Avg. loss: 0.065202\n",
      "Total training time: 207.12 seconds.\n",
      "-- Epoch 2463\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.621715, T: 420892218, Avg. loss: 0.065201\n",
      "Total training time: 207.20 seconds.\n",
      "-- Epoch 2464\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.619064, T: 421063104, Avg. loss: 0.065199\n",
      "Total training time: 207.28 seconds.\n",
      "-- Epoch 2465\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.616418, T: 421233990, Avg. loss: 0.065198\n",
      "Total training time: 207.36 seconds.\n",
      "-- Epoch 2466\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.613769, T: 421404876, Avg. loss: 0.065196\n",
      "Total training time: 207.44 seconds.\n",
      "-- Epoch 2467\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.611120, T: 421575762, Avg. loss: 0.065195\n",
      "Total training time: 207.52 seconds.\n",
      "-- Epoch 2468\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.608474, T: 421746648, Avg. loss: 0.065193\n",
      "Total training time: 207.61 seconds.\n",
      "-- Epoch 2469\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.605829, T: 421917534, Avg. loss: 0.065192\n",
      "Total training time: 207.68 seconds.\n",
      "-- Epoch 2470\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.603185, T: 422088420, Avg. loss: 0.065190\n",
      "Total training time: 207.77 seconds.\n",
      "-- Epoch 2471\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.600542, T: 422259306, Avg. loss: 0.065189\n",
      "Total training time: 207.85 seconds.\n",
      "-- Epoch 2472\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.597900, T: 422430192, Avg. loss: 0.065187\n",
      "Total training time: 207.93 seconds.\n",
      "-- Epoch 2473\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.595258, T: 422601078, Avg. loss: 0.065186\n",
      "Total training time: 208.01 seconds.\n",
      "-- Epoch 2474\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.592617, T: 422771964, Avg. loss: 0.065185\n",
      "Total training time: 208.10 seconds.\n",
      "-- Epoch 2475\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.589977, T: 422942850, Avg. loss: 0.065183\n",
      "Total training time: 208.18 seconds.\n",
      "-- Epoch 2476\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.587339, T: 423113736, Avg. loss: 0.065182\n",
      "Total training time: 208.26 seconds.\n",
      "-- Epoch 2477\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.584704, T: 423284622, Avg. loss: 0.065180\n",
      "Total training time: 208.35 seconds.\n",
      "-- Epoch 2478\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.582068, T: 423455508, Avg. loss: 0.065179\n",
      "Total training time: 208.43 seconds.\n",
      "-- Epoch 2479\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.579430, T: 423626394, Avg. loss: 0.065177\n",
      "Total training time: 208.51 seconds.\n",
      "-- Epoch 2480\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.576793, T: 423797280, Avg. loss: 0.065176\n",
      "Total training time: 208.60 seconds.\n",
      "-- Epoch 2481\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.574161, T: 423968166, Avg. loss: 0.065174\n",
      "Total training time: 208.68 seconds.\n",
      "-- Epoch 2482\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.571530, T: 424139052, Avg. loss: 0.065173\n",
      "Total training time: 208.77 seconds.\n",
      "-- Epoch 2483\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.568899, T: 424309938, Avg. loss: 0.065171\n",
      "Total training time: 208.85 seconds.\n",
      "-- Epoch 2484\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.566271, T: 424480824, Avg. loss: 0.065170\n",
      "Total training time: 208.93 seconds.\n",
      "-- Epoch 2485\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.563641, T: 424651710, Avg. loss: 0.065168\n",
      "Total training time: 209.01 seconds.\n",
      "-- Epoch 2486\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.561013, T: 424822596, Avg. loss: 0.065167\n",
      "Total training time: 209.09 seconds.\n",
      "-- Epoch 2487\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.558386, T: 424993482, Avg. loss: 0.065165\n",
      "Total training time: 209.17 seconds.\n",
      "-- Epoch 2488\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.555759, T: 425164368, Avg. loss: 0.065164\n",
      "Total training time: 209.25 seconds.\n",
      "-- Epoch 2489\n",
      "Norm: 13.68, NNZs: 30, Bias: -121.553132, T: 425335254, Avg. loss: 0.065162\n",
      "Total training time: 209.33 seconds.\n",
      "-- Epoch 2490\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.550506, T: 425506140, Avg. loss: 0.065161\n",
      "Total training time: 209.42 seconds.\n",
      "-- Epoch 2491\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.547883, T: 425677026, Avg. loss: 0.065160\n",
      "Total training time: 209.50 seconds.\n",
      "-- Epoch 2492\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.545260, T: 425847912, Avg. loss: 0.065158\n",
      "Total training time: 209.58 seconds.\n",
      "-- Epoch 2493\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.542640, T: 426018798, Avg. loss: 0.065157\n",
      "Total training time: 209.66 seconds.\n",
      "-- Epoch 2494\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.540018, T: 426189684, Avg. loss: 0.065155\n",
      "Total training time: 209.74 seconds.\n",
      "-- Epoch 2495\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.537400, T: 426360570, Avg. loss: 0.065154\n",
      "Total training time: 209.82 seconds.\n",
      "-- Epoch 2496\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.534781, T: 426531456, Avg. loss: 0.065152\n",
      "Total training time: 209.90 seconds.\n",
      "-- Epoch 2497\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.532167, T: 426702342, Avg. loss: 0.065151\n",
      "Total training time: 209.98 seconds.\n",
      "-- Epoch 2498\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.529551, T: 426873228, Avg. loss: 0.065149\n",
      "Total training time: 210.07 seconds.\n",
      "-- Epoch 2499\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.526936, T: 427044114, Avg. loss: 0.065148\n",
      "Total training time: 210.15 seconds.\n",
      "-- Epoch 2500\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.524323, T: 427215000, Avg. loss: 0.065146\n",
      "Total training time: 210.23 seconds.\n",
      "-- Epoch 2501\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.521709, T: 427385886, Avg. loss: 0.065145\n",
      "Total training time: 210.31 seconds.\n",
      "-- Epoch 2502\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.519100, T: 427556772, Avg. loss: 0.065144\n",
      "Total training time: 210.39 seconds.\n",
      "-- Epoch 2503\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.516488, T: 427727658, Avg. loss: 0.065142\n",
      "Total training time: 210.47 seconds.\n",
      "-- Epoch 2504\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.513881, T: 427898544, Avg. loss: 0.065141\n",
      "Total training time: 210.56 seconds.\n",
      "-- Epoch 2505\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.511274, T: 428069430, Avg. loss: 0.065139\n",
      "Total training time: 210.64 seconds.\n",
      "-- Epoch 2506\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.508667, T: 428240316, Avg. loss: 0.065138\n",
      "Total training time: 210.72 seconds.\n",
      "-- Epoch 2507\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.506062, T: 428411202, Avg. loss: 0.065136\n",
      "Total training time: 210.80 seconds.\n",
      "-- Epoch 2508\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.503456, T: 428582088, Avg. loss: 0.065135\n",
      "Total training time: 210.88 seconds.\n",
      "-- Epoch 2509\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.500856, T: 428752974, Avg. loss: 0.065133\n",
      "Total training time: 210.97 seconds.\n",
      "-- Epoch 2510\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.498252, T: 428923860, Avg. loss: 0.065132\n",
      "Total training time: 211.05 seconds.\n",
      "-- Epoch 2511\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.495654, T: 429094746, Avg. loss: 0.065130\n",
      "Total training time: 211.13 seconds.\n",
      "-- Epoch 2512\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.493055, T: 429265632, Avg. loss: 0.065129\n",
      "Total training time: 211.21 seconds.\n",
      "-- Epoch 2513\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.490456, T: 429436518, Avg. loss: 0.065128\n",
      "Total training time: 211.29 seconds.\n",
      "-- Epoch 2514\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.487859, T: 429607404, Avg. loss: 0.065126\n",
      "Total training time: 211.37 seconds.\n",
      "-- Epoch 2515\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.485260, T: 429778290, Avg. loss: 0.065125\n",
      "Total training time: 211.45 seconds.\n",
      "-- Epoch 2516\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.482663, T: 429949176, Avg. loss: 0.065123\n",
      "Total training time: 211.54 seconds.\n",
      "-- Epoch 2517\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.480067, T: 430120062, Avg. loss: 0.065122\n",
      "Total training time: 211.62 seconds.\n",
      "-- Epoch 2518\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.477471, T: 430290948, Avg. loss: 0.065120\n",
      "Total training time: 211.70 seconds.\n",
      "-- Epoch 2519\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.474877, T: 430461834, Avg. loss: 0.065119\n",
      "Total training time: 211.78 seconds.\n",
      "-- Epoch 2520\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.472284, T: 430632720, Avg. loss: 0.065117\n",
      "Total training time: 211.86 seconds.\n",
      "-- Epoch 2521\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.469694, T: 430803606, Avg. loss: 0.065116\n",
      "Total training time: 211.94 seconds.\n",
      "-- Epoch 2522\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.467104, T: 430974492, Avg. loss: 0.065115\n",
      "Total training time: 212.03 seconds.\n",
      "-- Epoch 2523\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.464516, T: 431145378, Avg. loss: 0.065113\n",
      "Total training time: 212.11 seconds.\n",
      "-- Epoch 2524\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.461926, T: 431316264, Avg. loss: 0.065112\n",
      "Total training time: 212.19 seconds.\n",
      "-- Epoch 2525\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.459339, T: 431487150, Avg. loss: 0.065110\n",
      "Total training time: 212.27 seconds.\n",
      "-- Epoch 2526\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.456754, T: 431658036, Avg. loss: 0.065109\n",
      "Total training time: 212.35 seconds.\n",
      "-- Epoch 2527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.67, NNZs: 30, Bias: -121.454169, T: 431828922, Avg. loss: 0.065107\n",
      "Total training time: 212.43 seconds.\n",
      "-- Epoch 2528\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.451586, T: 431999808, Avg. loss: 0.065106\n",
      "Total training time: 212.51 seconds.\n",
      "-- Epoch 2529\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.449003, T: 432170694, Avg. loss: 0.065104\n",
      "Total training time: 212.60 seconds.\n",
      "-- Epoch 2530\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.446422, T: 432341580, Avg. loss: 0.065103\n",
      "Total training time: 212.68 seconds.\n",
      "-- Epoch 2531\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.443844, T: 432512466, Avg. loss: 0.065102\n",
      "Total training time: 212.76 seconds.\n",
      "-- Epoch 2532\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.441265, T: 432683352, Avg. loss: 0.065100\n",
      "Total training time: 212.84 seconds.\n",
      "-- Epoch 2533\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.438688, T: 432854238, Avg. loss: 0.065099\n",
      "Total training time: 212.92 seconds.\n",
      "-- Epoch 2534\n",
      "Norm: 13.67, NNZs: 30, Bias: -121.436109, T: 433025124, Avg. loss: 0.065097\n",
      "Total training time: 213.01 seconds.\n",
      "-- Epoch 2535\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.433537, T: 433196010, Avg. loss: 0.065096\n",
      "Total training time: 213.09 seconds.\n",
      "-- Epoch 2536\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.430961, T: 433366896, Avg. loss: 0.065094\n",
      "Total training time: 213.17 seconds.\n",
      "-- Epoch 2537\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.428387, T: 433537782, Avg. loss: 0.065093\n",
      "Total training time: 213.25 seconds.\n",
      "-- Epoch 2538\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.425811, T: 433708668, Avg. loss: 0.065091\n",
      "Total training time: 213.33 seconds.\n",
      "-- Epoch 2539\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.423239, T: 433879554, Avg. loss: 0.065090\n",
      "Total training time: 213.41 seconds.\n",
      "-- Epoch 2540\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.420666, T: 434050440, Avg. loss: 0.065089\n",
      "Total training time: 213.50 seconds.\n",
      "-- Epoch 2541\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.418095, T: 434221326, Avg. loss: 0.065087\n",
      "Total training time: 213.58 seconds.\n",
      "-- Epoch 2542\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.415523, T: 434392212, Avg. loss: 0.065086\n",
      "Total training time: 213.66 seconds.\n",
      "-- Epoch 2543\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.412957, T: 434563098, Avg. loss: 0.065084\n",
      "Total training time: 213.74 seconds.\n",
      "-- Epoch 2544\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.410389, T: 434733984, Avg. loss: 0.065083\n",
      "Total training time: 213.82 seconds.\n",
      "-- Epoch 2545\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.407821, T: 434904870, Avg. loss: 0.065081\n",
      "Total training time: 213.90 seconds.\n",
      "-- Epoch 2546\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.405253, T: 435075756, Avg. loss: 0.065080\n",
      "Total training time: 213.99 seconds.\n",
      "-- Epoch 2547\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.402692, T: 435246642, Avg. loss: 0.065079\n",
      "Total training time: 214.07 seconds.\n",
      "-- Epoch 2548\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.400127, T: 435417528, Avg. loss: 0.065077\n",
      "Total training time: 214.15 seconds.\n",
      "-- Epoch 2549\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.397564, T: 435588414, Avg. loss: 0.065076\n",
      "Total training time: 214.23 seconds.\n",
      "-- Epoch 2550\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.395001, T: 435759300, Avg. loss: 0.065074\n",
      "Total training time: 214.31 seconds.\n",
      "-- Epoch 2551\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.392444, T: 435930186, Avg. loss: 0.065073\n",
      "Total training time: 214.39 seconds.\n",
      "-- Epoch 2552\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.389882, T: 436101072, Avg. loss: 0.065071\n",
      "Total training time: 214.48 seconds.\n",
      "-- Epoch 2553\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.387322, T: 436271958, Avg. loss: 0.065070\n",
      "Total training time: 214.56 seconds.\n",
      "-- Epoch 2554\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.384764, T: 436442844, Avg. loss: 0.065069\n",
      "Total training time: 214.64 seconds.\n",
      "-- Epoch 2555\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.382208, T: 436613730, Avg. loss: 0.065067\n",
      "Total training time: 214.72 seconds.\n",
      "-- Epoch 2556\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.379654, T: 436784616, Avg. loss: 0.065066\n",
      "Total training time: 214.81 seconds.\n",
      "-- Epoch 2557\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.377098, T: 436955502, Avg. loss: 0.065064\n",
      "Total training time: 214.89 seconds.\n",
      "-- Epoch 2558\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.374545, T: 437126388, Avg. loss: 0.065063\n",
      "Total training time: 214.97 seconds.\n",
      "-- Epoch 2559\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.371993, T: 437297274, Avg. loss: 0.065062\n",
      "Total training time: 215.05 seconds.\n",
      "-- Epoch 2560\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.369442, T: 437468160, Avg. loss: 0.065060\n",
      "Total training time: 215.13 seconds.\n",
      "-- Epoch 2561\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.366890, T: 437639046, Avg. loss: 0.065059\n",
      "Total training time: 215.21 seconds.\n",
      "-- Epoch 2562\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.364342, T: 437809932, Avg. loss: 0.065057\n",
      "Total training time: 215.29 seconds.\n",
      "-- Epoch 2563\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.361795, T: 437980818, Avg. loss: 0.065056\n",
      "Total training time: 215.37 seconds.\n",
      "-- Epoch 2564\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.359248, T: 438151704, Avg. loss: 0.065054\n",
      "Total training time: 215.46 seconds.\n",
      "-- Epoch 2565\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.356703, T: 438322590, Avg. loss: 0.065053\n",
      "Total training time: 215.54 seconds.\n",
      "-- Epoch 2566\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.354160, T: 438493476, Avg. loss: 0.065052\n",
      "Total training time: 215.62 seconds.\n",
      "-- Epoch 2567\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.351615, T: 438664362, Avg. loss: 0.065050\n",
      "Total training time: 215.70 seconds.\n",
      "-- Epoch 2568\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.349069, T: 438835248, Avg. loss: 0.065049\n",
      "Total training time: 215.78 seconds.\n",
      "-- Epoch 2569\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.346526, T: 439006134, Avg. loss: 0.065047\n",
      "Total training time: 215.86 seconds.\n",
      "-- Epoch 2570\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.343985, T: 439177020, Avg. loss: 0.065046\n",
      "Total training time: 215.94 seconds.\n",
      "-- Epoch 2571\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.341447, T: 439347906, Avg. loss: 0.065044\n",
      "Total training time: 216.03 seconds.\n",
      "-- Epoch 2572\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.338908, T: 439518792, Avg. loss: 0.065043\n",
      "Total training time: 216.11 seconds.\n",
      "-- Epoch 2573\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.336370, T: 439689678, Avg. loss: 0.065042\n",
      "Total training time: 216.19 seconds.\n",
      "-- Epoch 2574\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.333834, T: 439860564, Avg. loss: 0.065040\n",
      "Total training time: 216.27 seconds.\n",
      "-- Epoch 2575\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.331296, T: 440031450, Avg. loss: 0.065039\n",
      "Total training time: 216.35 seconds.\n",
      "-- Epoch 2576\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.328759, T: 440202336, Avg. loss: 0.065037\n",
      "Total training time: 216.43 seconds.\n",
      "-- Epoch 2577\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.326225, T: 440373222, Avg. loss: 0.065036\n",
      "Total training time: 216.52 seconds.\n",
      "-- Epoch 2578\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.323691, T: 440544108, Avg. loss: 0.065035\n",
      "Total training time: 216.60 seconds.\n",
      "-- Epoch 2579\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.321156, T: 440714994, Avg. loss: 0.065033\n",
      "Total training time: 216.68 seconds.\n",
      "-- Epoch 2580\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.318625, T: 440885880, Avg. loss: 0.065032\n",
      "Total training time: 216.76 seconds.\n",
      "-- Epoch 2581\n",
      "Norm: 13.66, NNZs: 30, Bias: -121.316096, T: 441056766, Avg. loss: 0.065030\n",
      "Total training time: 216.84 seconds.\n",
      "-- Epoch 2582\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.313566, T: 441227652, Avg. loss: 0.065029\n",
      "Total training time: 216.93 seconds.\n",
      "-- Epoch 2583\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.311037, T: 441398538, Avg. loss: 0.065028\n",
      "Total training time: 217.01 seconds.\n",
      "-- Epoch 2584\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.308511, T: 441569424, Avg. loss: 0.065026\n",
      "Total training time: 217.09 seconds.\n",
      "-- Epoch 2585\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.305984, T: 441740310, Avg. loss: 0.065025\n",
      "Total training time: 217.17 seconds.\n",
      "-- Epoch 2586\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.303460, T: 441911196, Avg. loss: 0.065023\n",
      "Total training time: 217.25 seconds.\n",
      "-- Epoch 2587\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.300935, T: 442082082, Avg. loss: 0.065022\n",
      "Total training time: 217.34 seconds.\n",
      "-- Epoch 2588\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.298412, T: 442252968, Avg. loss: 0.065020\n",
      "Total training time: 217.42 seconds.\n",
      "-- Epoch 2589\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.295891, T: 442423854, Avg. loss: 0.065019\n",
      "Total training time: 217.50 seconds.\n",
      "-- Epoch 2590\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.293369, T: 442594740, Avg. loss: 0.065018\n",
      "Total training time: 217.58 seconds.\n",
      "-- Epoch 2591\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.290849, T: 442765626, Avg. loss: 0.065016\n",
      "Total training time: 217.67 seconds.\n",
      "-- Epoch 2592\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.288329, T: 442936512, Avg. loss: 0.065015\n",
      "Total training time: 217.75 seconds.\n",
      "-- Epoch 2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.65, NNZs: 30, Bias: -121.285814, T: 443107398, Avg. loss: 0.065013\n",
      "Total training time: 217.83 seconds.\n",
      "-- Epoch 2594\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.283296, T: 443278284, Avg. loss: 0.065012\n",
      "Total training time: 217.91 seconds.\n",
      "-- Epoch 2595\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.280782, T: 443449170, Avg. loss: 0.065011\n",
      "Total training time: 217.99 seconds.\n",
      "-- Epoch 2596\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.278265, T: 443620056, Avg. loss: 0.065009\n",
      "Total training time: 218.08 seconds.\n",
      "-- Epoch 2597\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.275751, T: 443790942, Avg. loss: 0.065008\n",
      "Total training time: 218.16 seconds.\n",
      "-- Epoch 2598\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.273240, T: 443961828, Avg. loss: 0.065006\n",
      "Total training time: 218.24 seconds.\n",
      "-- Epoch 2599\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.270727, T: 444132714, Avg. loss: 0.065005\n",
      "Total training time: 218.32 seconds.\n",
      "-- Epoch 2600\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.268212, T: 444303600, Avg. loss: 0.065004\n",
      "Total training time: 218.40 seconds.\n",
      "-- Epoch 2601\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.265702, T: 444474486, Avg. loss: 0.065002\n",
      "Total training time: 218.49 seconds.\n",
      "-- Epoch 2602\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.263194, T: 444645372, Avg. loss: 0.065001\n",
      "Total training time: 218.57 seconds.\n",
      "-- Epoch 2603\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.260687, T: 444816258, Avg. loss: 0.064999\n",
      "Total training time: 218.65 seconds.\n",
      "-- Epoch 2604\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.258180, T: 444987144, Avg. loss: 0.064998\n",
      "Total training time: 218.73 seconds.\n",
      "-- Epoch 2605\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.255673, T: 445158030, Avg. loss: 0.064997\n",
      "Total training time: 218.81 seconds.\n",
      "-- Epoch 2606\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.253167, T: 445328916, Avg. loss: 0.064995\n",
      "Total training time: 218.89 seconds.\n",
      "-- Epoch 2607\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.250661, T: 445499802, Avg. loss: 0.064994\n",
      "Total training time: 218.98 seconds.\n",
      "-- Epoch 2608\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.248156, T: 445670688, Avg. loss: 0.064992\n",
      "Total training time: 219.06 seconds.\n",
      "-- Epoch 2609\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.245652, T: 445841574, Avg. loss: 0.064991\n",
      "Total training time: 219.14 seconds.\n",
      "-- Epoch 2610\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.243151, T: 446012460, Avg. loss: 0.064990\n",
      "Total training time: 219.22 seconds.\n",
      "-- Epoch 2611\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.240650, T: 446183346, Avg. loss: 0.064988\n",
      "Total training time: 219.30 seconds.\n",
      "-- Epoch 2612\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.238150, T: 446354232, Avg. loss: 0.064987\n",
      "Total training time: 219.38 seconds.\n",
      "-- Epoch 2613\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.235652, T: 446525118, Avg. loss: 0.064986\n",
      "Total training time: 219.47 seconds.\n",
      "-- Epoch 2614\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.233156, T: 446696004, Avg. loss: 0.064984\n",
      "Total training time: 219.55 seconds.\n",
      "-- Epoch 2615\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.230660, T: 446866890, Avg. loss: 0.064983\n",
      "Total training time: 219.64 seconds.\n",
      "-- Epoch 2616\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.228162, T: 447037776, Avg. loss: 0.064981\n",
      "Total training time: 219.72 seconds.\n",
      "-- Epoch 2617\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.225668, T: 447208662, Avg. loss: 0.064980\n",
      "Total training time: 219.80 seconds.\n",
      "-- Epoch 2618\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.223175, T: 447379548, Avg. loss: 0.064979\n",
      "Total training time: 219.89 seconds.\n",
      "-- Epoch 2619\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.220682, T: 447550434, Avg. loss: 0.064977\n",
      "Total training time: 219.97 seconds.\n",
      "-- Epoch 2620\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.218190, T: 447721320, Avg. loss: 0.064976\n",
      "Total training time: 220.05 seconds.\n",
      "-- Epoch 2621\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.215701, T: 447892206, Avg. loss: 0.064974\n",
      "Total training time: 220.13 seconds.\n",
      "-- Epoch 2622\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.213209, T: 448063092, Avg. loss: 0.064973\n",
      "Total training time: 220.21 seconds.\n",
      "-- Epoch 2623\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.210721, T: 448233978, Avg. loss: 0.064972\n",
      "Total training time: 220.29 seconds.\n",
      "-- Epoch 2624\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.208232, T: 448404864, Avg. loss: 0.064970\n",
      "Total training time: 220.38 seconds.\n",
      "-- Epoch 2625\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.205744, T: 448575750, Avg. loss: 0.064969\n",
      "Total training time: 220.45 seconds.\n",
      "-- Epoch 2626\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.203262, T: 448746636, Avg. loss: 0.064967\n",
      "Total training time: 220.54 seconds.\n",
      "-- Epoch 2627\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.200776, T: 448917522, Avg. loss: 0.064966\n",
      "Total training time: 220.62 seconds.\n",
      "-- Epoch 2628\n",
      "Norm: 13.65, NNZs: 30, Bias: -121.198293, T: 449088408, Avg. loss: 0.064965\n",
      "Total training time: 220.70 seconds.\n",
      "-- Epoch 2629\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.195810, T: 449259294, Avg. loss: 0.064963\n",
      "Total training time: 220.78 seconds.\n",
      "-- Epoch 2630\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.193326, T: 449430180, Avg. loss: 0.064962\n",
      "Total training time: 220.86 seconds.\n",
      "-- Epoch 2631\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.190843, T: 449601066, Avg. loss: 0.064961\n",
      "Total training time: 220.94 seconds.\n",
      "-- Epoch 2632\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.188365, T: 449771952, Avg. loss: 0.064959\n",
      "Total training time: 221.03 seconds.\n",
      "-- Epoch 2633\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.185886, T: 449942838, Avg. loss: 0.064958\n",
      "Total training time: 221.11 seconds.\n",
      "-- Epoch 2634\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.183408, T: 450113724, Avg. loss: 0.064956\n",
      "Total training time: 221.19 seconds.\n",
      "-- Epoch 2635\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.180928, T: 450284610, Avg. loss: 0.064955\n",
      "Total training time: 221.27 seconds.\n",
      "-- Epoch 2636\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.178452, T: 450455496, Avg. loss: 0.064954\n",
      "Total training time: 221.35 seconds.\n",
      "-- Epoch 2637\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.175977, T: 450626382, Avg. loss: 0.064952\n",
      "Total training time: 221.44 seconds.\n",
      "-- Epoch 2638\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.173500, T: 450797268, Avg. loss: 0.064951\n",
      "Total training time: 221.52 seconds.\n",
      "-- Epoch 2639\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.171024, T: 450968154, Avg. loss: 0.064949\n",
      "Total training time: 221.60 seconds.\n",
      "-- Epoch 2640\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.168551, T: 451139040, Avg. loss: 0.064948\n",
      "Total training time: 221.69 seconds.\n",
      "-- Epoch 2641\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.166078, T: 451309926, Avg. loss: 0.064947\n",
      "Total training time: 221.77 seconds.\n",
      "-- Epoch 2642\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.163607, T: 451480812, Avg. loss: 0.064945\n",
      "Total training time: 221.85 seconds.\n",
      "-- Epoch 2643\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.161137, T: 451651698, Avg. loss: 0.064944\n",
      "Total training time: 221.94 seconds.\n",
      "-- Epoch 2644\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.158669, T: 451822584, Avg. loss: 0.064943\n",
      "Total training time: 222.02 seconds.\n",
      "-- Epoch 2645\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.156201, T: 451993470, Avg. loss: 0.064941\n",
      "Total training time: 222.10 seconds.\n",
      "-- Epoch 2646\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.153734, T: 452164356, Avg. loss: 0.064940\n",
      "Total training time: 222.19 seconds.\n",
      "-- Epoch 2647\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.151268, T: 452335242, Avg. loss: 0.064938\n",
      "Total training time: 222.27 seconds.\n",
      "-- Epoch 2648\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.148802, T: 452506128, Avg. loss: 0.064937\n",
      "Total training time: 222.35 seconds.\n",
      "-- Epoch 2649\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.146338, T: 452677014, Avg. loss: 0.064936\n",
      "Total training time: 222.43 seconds.\n",
      "-- Epoch 2650\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.143874, T: 452847900, Avg. loss: 0.064934\n",
      "Total training time: 222.52 seconds.\n",
      "-- Epoch 2651\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.141412, T: 453018786, Avg. loss: 0.064933\n",
      "Total training time: 222.60 seconds.\n",
      "-- Epoch 2652\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.138948, T: 453189672, Avg. loss: 0.064932\n",
      "Total training time: 222.68 seconds.\n",
      "-- Epoch 2653\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.136488, T: 453360558, Avg. loss: 0.064930\n",
      "Total training time: 222.76 seconds.\n",
      "-- Epoch 2654\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.134025, T: 453531444, Avg. loss: 0.064929\n",
      "Total training time: 222.84 seconds.\n",
      "-- Epoch 2655\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.131568, T: 453702330, Avg. loss: 0.064928\n",
      "Total training time: 222.93 seconds.\n",
      "-- Epoch 2656\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.129109, T: 453873216, Avg. loss: 0.064926\n",
      "Total training time: 223.01 seconds.\n",
      "-- Epoch 2657\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.126651, T: 454044102, Avg. loss: 0.064925\n",
      "Total training time: 223.09 seconds.\n",
      "-- Epoch 2658\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.124195, T: 454214988, Avg. loss: 0.064923\n",
      "Total training time: 223.18 seconds.\n",
      "-- Epoch 2659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.64, NNZs: 30, Bias: -121.121739, T: 454385874, Avg. loss: 0.064922\n",
      "Total training time: 223.26 seconds.\n",
      "-- Epoch 2660\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.119284, T: 454556760, Avg. loss: 0.064921\n",
      "Total training time: 223.34 seconds.\n",
      "-- Epoch 2661\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.116828, T: 454727646, Avg. loss: 0.064919\n",
      "Total training time: 223.42 seconds.\n",
      "-- Epoch 2662\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.114376, T: 454898532, Avg. loss: 0.064918\n",
      "Total training time: 223.51 seconds.\n",
      "-- Epoch 2663\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.111923, T: 455069418, Avg. loss: 0.064917\n",
      "Total training time: 223.59 seconds.\n",
      "-- Epoch 2664\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.109471, T: 455240304, Avg. loss: 0.064915\n",
      "Total training time: 223.67 seconds.\n",
      "-- Epoch 2665\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.107022, T: 455411190, Avg. loss: 0.064914\n",
      "Total training time: 223.76 seconds.\n",
      "-- Epoch 2666\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.104571, T: 455582076, Avg. loss: 0.064912\n",
      "Total training time: 223.84 seconds.\n",
      "-- Epoch 2667\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.102124, T: 455752962, Avg. loss: 0.064911\n",
      "Total training time: 223.92 seconds.\n",
      "-- Epoch 2668\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.099678, T: 455923848, Avg. loss: 0.064910\n",
      "Total training time: 224.00 seconds.\n",
      "-- Epoch 2669\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.097233, T: 456094734, Avg. loss: 0.064908\n",
      "Total training time: 224.09 seconds.\n",
      "-- Epoch 2670\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.094788, T: 456265620, Avg. loss: 0.064907\n",
      "Total training time: 224.17 seconds.\n",
      "-- Epoch 2671\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.092344, T: 456436506, Avg. loss: 0.064906\n",
      "Total training time: 224.25 seconds.\n",
      "-- Epoch 2672\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.089901, T: 456607392, Avg. loss: 0.064904\n",
      "Total training time: 224.33 seconds.\n",
      "-- Epoch 2673\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.087458, T: 456778278, Avg. loss: 0.064903\n",
      "Total training time: 224.42 seconds.\n",
      "-- Epoch 2674\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.085017, T: 456949164, Avg. loss: 0.064902\n",
      "Total training time: 224.50 seconds.\n",
      "-- Epoch 2675\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.082576, T: 457120050, Avg. loss: 0.064900\n",
      "Total training time: 224.58 seconds.\n",
      "-- Epoch 2676\n",
      "Norm: 13.64, NNZs: 30, Bias: -121.080137, T: 457290936, Avg. loss: 0.064899\n",
      "Total training time: 224.67 seconds.\n",
      "-- Epoch 2677\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.077699, T: 457461822, Avg. loss: 0.064898\n",
      "Total training time: 224.75 seconds.\n",
      "-- Epoch 2678\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.075263, T: 457632708, Avg. loss: 0.064896\n",
      "Total training time: 224.83 seconds.\n",
      "-- Epoch 2679\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.072825, T: 457803594, Avg. loss: 0.064895\n",
      "Total training time: 224.91 seconds.\n",
      "-- Epoch 2680\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.070387, T: 457974480, Avg. loss: 0.064893\n",
      "Total training time: 225.00 seconds.\n",
      "-- Epoch 2681\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.067955, T: 458145366, Avg. loss: 0.064892\n",
      "Total training time: 225.08 seconds.\n",
      "-- Epoch 2682\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.065519, T: 458316252, Avg. loss: 0.064891\n",
      "Total training time: 225.16 seconds.\n",
      "-- Epoch 2683\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.063087, T: 458487138, Avg. loss: 0.064889\n",
      "Total training time: 225.25 seconds.\n",
      "-- Epoch 2684\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.060654, T: 458658024, Avg. loss: 0.064888\n",
      "Total training time: 225.33 seconds.\n",
      "-- Epoch 2685\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.058223, T: 458828910, Avg. loss: 0.064887\n",
      "Total training time: 225.41 seconds.\n",
      "-- Epoch 2686\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.055793, T: 458999796, Avg. loss: 0.064885\n",
      "Total training time: 225.50 seconds.\n",
      "-- Epoch 2687\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.053363, T: 459170682, Avg. loss: 0.064884\n",
      "Total training time: 225.58 seconds.\n",
      "-- Epoch 2688\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.050937, T: 459341568, Avg. loss: 0.064883\n",
      "Total training time: 225.66 seconds.\n",
      "-- Epoch 2689\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.048509, T: 459512454, Avg. loss: 0.064881\n",
      "Total training time: 225.74 seconds.\n",
      "-- Epoch 2690\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.046084, T: 459683340, Avg. loss: 0.064880\n",
      "Total training time: 225.83 seconds.\n",
      "-- Epoch 2691\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.043658, T: 459854226, Avg. loss: 0.064879\n",
      "Total training time: 225.91 seconds.\n",
      "-- Epoch 2692\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.041231, T: 460025112, Avg. loss: 0.064877\n",
      "Total training time: 225.99 seconds.\n",
      "-- Epoch 2693\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.038805, T: 460195998, Avg. loss: 0.064876\n",
      "Total training time: 226.07 seconds.\n",
      "-- Epoch 2694\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.036381, T: 460366884, Avg. loss: 0.064874\n",
      "Total training time: 226.15 seconds.\n",
      "-- Epoch 2695\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.033959, T: 460537770, Avg. loss: 0.064873\n",
      "Total training time: 226.23 seconds.\n",
      "-- Epoch 2696\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.031540, T: 460708656, Avg. loss: 0.064872\n",
      "Total training time: 226.31 seconds.\n",
      "-- Epoch 2697\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.029120, T: 460879542, Avg. loss: 0.064870\n",
      "Total training time: 226.40 seconds.\n",
      "-- Epoch 2698\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.026700, T: 461050428, Avg. loss: 0.064869\n",
      "Total training time: 226.48 seconds.\n",
      "-- Epoch 2699\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.024282, T: 461221314, Avg. loss: 0.064868\n",
      "Total training time: 226.56 seconds.\n",
      "-- Epoch 2700\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.021863, T: 461392200, Avg. loss: 0.064866\n",
      "Total training time: 226.64 seconds.\n",
      "-- Epoch 2701\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.019450, T: 461563086, Avg. loss: 0.064865\n",
      "Total training time: 226.72 seconds.\n",
      "-- Epoch 2702\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.017036, T: 461733972, Avg. loss: 0.064864\n",
      "Total training time: 226.81 seconds.\n",
      "-- Epoch 2703\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.014622, T: 461904858, Avg. loss: 0.064862\n",
      "Total training time: 226.89 seconds.\n",
      "-- Epoch 2704\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.012208, T: 462075744, Avg. loss: 0.064861\n",
      "Total training time: 226.97 seconds.\n",
      "-- Epoch 2705\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.009796, T: 462246630, Avg. loss: 0.064860\n",
      "Total training time: 227.05 seconds.\n",
      "-- Epoch 2706\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.007383, T: 462417516, Avg. loss: 0.064858\n",
      "Total training time: 227.13 seconds.\n",
      "-- Epoch 2707\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.004971, T: 462588402, Avg. loss: 0.064857\n",
      "Total training time: 227.21 seconds.\n",
      "-- Epoch 2708\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.002559, T: 462759288, Avg. loss: 0.064856\n",
      "Total training time: 227.29 seconds.\n",
      "-- Epoch 2709\n",
      "Norm: 13.63, NNZs: 30, Bias: -121.000151, T: 462930174, Avg. loss: 0.064854\n",
      "Total training time: 227.37 seconds.\n",
      "-- Epoch 2710\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.997743, T: 463101060, Avg. loss: 0.064853\n",
      "Total training time: 227.46 seconds.\n",
      "-- Epoch 2711\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.995336, T: 463271946, Avg. loss: 0.064852\n",
      "Total training time: 227.54 seconds.\n",
      "-- Epoch 2712\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.992929, T: 463442832, Avg. loss: 0.064850\n",
      "Total training time: 227.62 seconds.\n",
      "-- Epoch 2713\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.990522, T: 463613718, Avg. loss: 0.064849\n",
      "Total training time: 227.70 seconds.\n",
      "-- Epoch 2714\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.988118, T: 463784604, Avg. loss: 0.064848\n",
      "Total training time: 227.78 seconds.\n",
      "-- Epoch 2715\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.985715, T: 463955490, Avg. loss: 0.064846\n",
      "Total training time: 227.87 seconds.\n",
      "-- Epoch 2716\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.983311, T: 464126376, Avg. loss: 0.064845\n",
      "Total training time: 227.95 seconds.\n",
      "-- Epoch 2717\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.980909, T: 464297262, Avg. loss: 0.064844\n",
      "Total training time: 228.03 seconds.\n",
      "-- Epoch 2718\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.978507, T: 464468148, Avg. loss: 0.064842\n",
      "Total training time: 228.11 seconds.\n",
      "-- Epoch 2719\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.976108, T: 464639034, Avg. loss: 0.064841\n",
      "Total training time: 228.19 seconds.\n",
      "-- Epoch 2720\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.973706, T: 464809920, Avg. loss: 0.064840\n",
      "Total training time: 228.27 seconds.\n",
      "-- Epoch 2721\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.971309, T: 464980806, Avg. loss: 0.064838\n",
      "Total training time: 228.35 seconds.\n",
      "-- Epoch 2722\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.968909, T: 465151692, Avg. loss: 0.064837\n",
      "Total training time: 228.43 seconds.\n",
      "-- Epoch 2723\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.966509, T: 465322578, Avg. loss: 0.064836\n",
      "Total training time: 228.52 seconds.\n",
      "-- Epoch 2724\n",
      "Norm: 13.63, NNZs: 30, Bias: -120.964112, T: 465493464, Avg. loss: 0.064834\n",
      "Total training time: 228.60 seconds.\n",
      "-- Epoch 2725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.62, NNZs: 30, Bias: -120.961717, T: 465664350, Avg. loss: 0.064833\n",
      "Total training time: 228.68 seconds.\n",
      "-- Epoch 2726\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.959324, T: 465835236, Avg. loss: 0.064832\n",
      "Total training time: 228.76 seconds.\n",
      "-- Epoch 2727\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.956931, T: 466006122, Avg. loss: 0.064830\n",
      "Total training time: 228.84 seconds.\n",
      "-- Epoch 2728\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.954537, T: 466177008, Avg. loss: 0.064829\n",
      "Total training time: 228.93 seconds.\n",
      "-- Epoch 2729\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.952144, T: 466347894, Avg. loss: 0.064828\n",
      "Total training time: 229.01 seconds.\n",
      "-- Epoch 2730\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.949753, T: 466518780, Avg. loss: 0.064826\n",
      "Total training time: 229.09 seconds.\n",
      "-- Epoch 2731\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.947362, T: 466689666, Avg. loss: 0.064825\n",
      "Total training time: 229.17 seconds.\n",
      "-- Epoch 2732\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.944972, T: 466860552, Avg. loss: 0.064824\n",
      "Total training time: 229.25 seconds.\n",
      "-- Epoch 2733\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.942585, T: 467031438, Avg. loss: 0.064822\n",
      "Total training time: 229.34 seconds.\n",
      "-- Epoch 2734\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.940197, T: 467202324, Avg. loss: 0.064821\n",
      "Total training time: 229.42 seconds.\n",
      "-- Epoch 2735\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.937811, T: 467373210, Avg. loss: 0.064820\n",
      "Total training time: 229.50 seconds.\n",
      "-- Epoch 2736\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.935427, T: 467544096, Avg. loss: 0.064818\n",
      "Total training time: 229.58 seconds.\n",
      "-- Epoch 2737\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.933043, T: 467714982, Avg. loss: 0.064817\n",
      "Total training time: 229.66 seconds.\n",
      "-- Epoch 2738\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.930658, T: 467885868, Avg. loss: 0.064816\n",
      "Total training time: 229.74 seconds.\n",
      "-- Epoch 2739\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.928273, T: 468056754, Avg. loss: 0.064814\n",
      "Total training time: 229.82 seconds.\n",
      "-- Epoch 2740\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.925891, T: 468227640, Avg. loss: 0.064813\n",
      "Total training time: 229.90 seconds.\n",
      "-- Epoch 2741\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.923509, T: 468398526, Avg. loss: 0.064812\n",
      "Total training time: 229.99 seconds.\n",
      "-- Epoch 2742\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.921130, T: 468569412, Avg. loss: 0.064810\n",
      "Total training time: 230.07 seconds.\n",
      "-- Epoch 2743\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.918751, T: 468740298, Avg. loss: 0.064809\n",
      "Total training time: 230.15 seconds.\n",
      "-- Epoch 2744\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.916372, T: 468911184, Avg. loss: 0.064808\n",
      "Total training time: 230.23 seconds.\n",
      "-- Epoch 2745\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.913994, T: 469082070, Avg. loss: 0.064806\n",
      "Total training time: 230.31 seconds.\n",
      "-- Epoch 2746\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.911618, T: 469252956, Avg. loss: 0.064805\n",
      "Total training time: 230.39 seconds.\n",
      "-- Epoch 2747\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.909242, T: 469423842, Avg. loss: 0.064804\n",
      "Total training time: 230.47 seconds.\n",
      "-- Epoch 2748\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.906866, T: 469594728, Avg. loss: 0.064802\n",
      "Total training time: 230.55 seconds.\n",
      "-- Epoch 2749\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.904492, T: 469765614, Avg. loss: 0.064801\n",
      "Total training time: 230.64 seconds.\n",
      "-- Epoch 2750\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.902120, T: 469936500, Avg. loss: 0.064800\n",
      "Total training time: 230.72 seconds.\n",
      "-- Epoch 2751\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.899748, T: 470107386, Avg. loss: 0.064798\n",
      "Total training time: 230.80 seconds.\n",
      "-- Epoch 2752\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.897376, T: 470278272, Avg. loss: 0.064797\n",
      "Total training time: 230.88 seconds.\n",
      "-- Epoch 2753\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.895005, T: 470449158, Avg. loss: 0.064796\n",
      "Total training time: 230.96 seconds.\n",
      "-- Epoch 2754\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.892636, T: 470620044, Avg. loss: 0.064794\n",
      "Total training time: 231.04 seconds.\n",
      "-- Epoch 2755\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.890266, T: 470790930, Avg. loss: 0.064793\n",
      "Total training time: 231.12 seconds.\n",
      "-- Epoch 2756\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.887900, T: 470961816, Avg. loss: 0.064792\n",
      "Total training time: 231.20 seconds.\n",
      "-- Epoch 2757\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.885533, T: 471132702, Avg. loss: 0.064790\n",
      "Total training time: 231.29 seconds.\n",
      "-- Epoch 2758\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.883166, T: 471303588, Avg. loss: 0.064789\n",
      "Total training time: 231.37 seconds.\n",
      "-- Epoch 2759\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.880800, T: 471474474, Avg. loss: 0.064788\n",
      "Total training time: 231.45 seconds.\n",
      "-- Epoch 2760\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.878435, T: 471645360, Avg. loss: 0.064787\n",
      "Total training time: 231.53 seconds.\n",
      "-- Epoch 2761\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.876070, T: 471816246, Avg. loss: 0.064785\n",
      "Total training time: 231.62 seconds.\n",
      "-- Epoch 2762\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.873707, T: 471987132, Avg. loss: 0.064784\n",
      "Total training time: 231.70 seconds.\n",
      "-- Epoch 2763\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.871345, T: 472158018, Avg. loss: 0.064783\n",
      "Total training time: 231.78 seconds.\n",
      "-- Epoch 2764\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.868983, T: 472328904, Avg. loss: 0.064781\n",
      "Total training time: 231.86 seconds.\n",
      "-- Epoch 2765\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.866623, T: 472499790, Avg. loss: 0.064780\n",
      "Total training time: 231.95 seconds.\n",
      "-- Epoch 2766\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.864264, T: 472670676, Avg. loss: 0.064779\n",
      "Total training time: 232.03 seconds.\n",
      "-- Epoch 2767\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.861905, T: 472841562, Avg. loss: 0.064777\n",
      "Total training time: 232.11 seconds.\n",
      "-- Epoch 2768\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.859547, T: 473012448, Avg. loss: 0.064776\n",
      "Total training time: 232.19 seconds.\n",
      "-- Epoch 2769\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.857190, T: 473183334, Avg. loss: 0.064775\n",
      "Total training time: 232.27 seconds.\n",
      "-- Epoch 2770\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.854834, T: 473354220, Avg. loss: 0.064773\n",
      "Total training time: 232.38 seconds.\n",
      "-- Epoch 2771\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.852480, T: 473525106, Avg. loss: 0.064772\n",
      "Total training time: 232.46 seconds.\n",
      "-- Epoch 2772\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.850126, T: 473695992, Avg. loss: 0.064771\n",
      "Total training time: 232.54 seconds.\n",
      "-- Epoch 2773\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.847771, T: 473866878, Avg. loss: 0.064769\n",
      "Total training time: 232.63 seconds.\n",
      "-- Epoch 2774\n",
      "Norm: 13.62, NNZs: 30, Bias: -120.845418, T: 474037764, Avg. loss: 0.064768\n",
      "Total training time: 232.71 seconds.\n",
      "-- Epoch 2775\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.843067, T: 474208650, Avg. loss: 0.064767\n",
      "Total training time: 232.79 seconds.\n",
      "-- Epoch 2776\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.840717, T: 474379536, Avg. loss: 0.064766\n",
      "Total training time: 232.87 seconds.\n",
      "-- Epoch 2777\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.838367, T: 474550422, Avg. loss: 0.064764\n",
      "Total training time: 232.95 seconds.\n",
      "-- Epoch 2778\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.836017, T: 474721308, Avg. loss: 0.064763\n",
      "Total training time: 233.03 seconds.\n",
      "-- Epoch 2779\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.833671, T: 474892194, Avg. loss: 0.064762\n",
      "Total training time: 233.12 seconds.\n",
      "-- Epoch 2780\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.831323, T: 475063080, Avg. loss: 0.064760\n",
      "Total training time: 233.20 seconds.\n",
      "-- Epoch 2781\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.828977, T: 475233966, Avg. loss: 0.064759\n",
      "Total training time: 233.28 seconds.\n",
      "-- Epoch 2782\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.826632, T: 475404852, Avg. loss: 0.064758\n",
      "Total training time: 233.36 seconds.\n",
      "-- Epoch 2783\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.824285, T: 475575738, Avg. loss: 0.064756\n",
      "Total training time: 233.45 seconds.\n",
      "-- Epoch 2784\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.821942, T: 475746624, Avg. loss: 0.064755\n",
      "Total training time: 233.53 seconds.\n",
      "-- Epoch 2785\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.819599, T: 475917510, Avg. loss: 0.064754\n",
      "Total training time: 233.61 seconds.\n",
      "-- Epoch 2786\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.817259, T: 476088396, Avg. loss: 0.064752\n",
      "Total training time: 233.69 seconds.\n",
      "-- Epoch 2787\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.814916, T: 476259282, Avg. loss: 0.064751\n",
      "Total training time: 233.77 seconds.\n",
      "-- Epoch 2788\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.812576, T: 476430168, Avg. loss: 0.064750\n",
      "Total training time: 233.85 seconds.\n",
      "-- Epoch 2789\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.810237, T: 476601054, Avg. loss: 0.064749\n",
      "Total training time: 233.94 seconds.\n",
      "-- Epoch 2790\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.807895, T: 476771940, Avg. loss: 0.064747\n",
      "Total training time: 234.02 seconds.\n",
      "-- Epoch 2791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.61, NNZs: 30, Bias: -120.805555, T: 476942826, Avg. loss: 0.064746\n",
      "Total training time: 234.10 seconds.\n",
      "-- Epoch 2792\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.803217, T: 477113712, Avg. loss: 0.064745\n",
      "Total training time: 234.18 seconds.\n",
      "-- Epoch 2793\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.800880, T: 477284598, Avg. loss: 0.064743\n",
      "Total training time: 234.26 seconds.\n",
      "-- Epoch 2794\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.798545, T: 477455484, Avg. loss: 0.064742\n",
      "Total training time: 234.37 seconds.\n",
      "-- Epoch 2795\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.796211, T: 477626370, Avg. loss: 0.064741\n",
      "Total training time: 234.47 seconds.\n",
      "-- Epoch 2796\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.793879, T: 477797256, Avg. loss: 0.064739\n",
      "Total training time: 234.55 seconds.\n",
      "-- Epoch 2797\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.791543, T: 477968142, Avg. loss: 0.064738\n",
      "Total training time: 234.64 seconds.\n",
      "-- Epoch 2798\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.789211, T: 478139028, Avg. loss: 0.064737\n",
      "Total training time: 234.72 seconds.\n",
      "-- Epoch 2799\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.786880, T: 478309914, Avg. loss: 0.064736\n",
      "Total training time: 234.81 seconds.\n",
      "-- Epoch 2800\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.784549, T: 478480800, Avg. loss: 0.064734\n",
      "Total training time: 234.90 seconds.\n",
      "-- Epoch 2801\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.782217, T: 478651686, Avg. loss: 0.064733\n",
      "Total training time: 234.98 seconds.\n",
      "-- Epoch 2802\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.779890, T: 478822572, Avg. loss: 0.064732\n",
      "Total training time: 235.07 seconds.\n",
      "-- Epoch 2803\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.777562, T: 478993458, Avg. loss: 0.064730\n",
      "Total training time: 235.16 seconds.\n",
      "-- Epoch 2804\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.775233, T: 479164344, Avg. loss: 0.064729\n",
      "Total training time: 235.24 seconds.\n",
      "-- Epoch 2805\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.772905, T: 479335230, Avg. loss: 0.064728\n",
      "Total training time: 235.33 seconds.\n",
      "-- Epoch 2806\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.770580, T: 479506116, Avg. loss: 0.064726\n",
      "Total training time: 235.41 seconds.\n",
      "-- Epoch 2807\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.768254, T: 479677002, Avg. loss: 0.064725\n",
      "Total training time: 235.49 seconds.\n",
      "-- Epoch 2808\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.765931, T: 479847888, Avg. loss: 0.064724\n",
      "Total training time: 235.57 seconds.\n",
      "-- Epoch 2809\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.763606, T: 480018774, Avg. loss: 0.064723\n",
      "Total training time: 235.66 seconds.\n",
      "-- Epoch 2810\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.761285, T: 480189660, Avg. loss: 0.064721\n",
      "Total training time: 235.74 seconds.\n",
      "-- Epoch 2811\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.758965, T: 480360546, Avg. loss: 0.064720\n",
      "Total training time: 235.82 seconds.\n",
      "-- Epoch 2812\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.756643, T: 480531432, Avg. loss: 0.064719\n",
      "Total training time: 235.90 seconds.\n",
      "-- Epoch 2813\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.754324, T: 480702318, Avg. loss: 0.064717\n",
      "Total training time: 235.98 seconds.\n",
      "-- Epoch 2814\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.752004, T: 480873204, Avg. loss: 0.064716\n",
      "Total training time: 236.06 seconds.\n",
      "-- Epoch 2815\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.749688, T: 481044090, Avg. loss: 0.064715\n",
      "Total training time: 236.14 seconds.\n",
      "-- Epoch 2816\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.747370, T: 481214976, Avg. loss: 0.064714\n",
      "Total training time: 236.22 seconds.\n",
      "-- Epoch 2817\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.745054, T: 481385862, Avg. loss: 0.064712\n",
      "Total training time: 236.30 seconds.\n",
      "-- Epoch 2818\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.742738, T: 481556748, Avg. loss: 0.064711\n",
      "Total training time: 236.39 seconds.\n",
      "-- Epoch 2819\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.740425, T: 481727634, Avg. loss: 0.064710\n",
      "Total training time: 236.47 seconds.\n",
      "-- Epoch 2820\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.738115, T: 481898520, Avg. loss: 0.064708\n",
      "Total training time: 236.55 seconds.\n",
      "-- Epoch 2821\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.735803, T: 482069406, Avg. loss: 0.064707\n",
      "Total training time: 236.63 seconds.\n",
      "-- Epoch 2822\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.733492, T: 482240292, Avg. loss: 0.064706\n",
      "Total training time: 236.71 seconds.\n",
      "-- Epoch 2823\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.731179, T: 482411178, Avg. loss: 0.064705\n",
      "Total training time: 236.80 seconds.\n",
      "-- Epoch 2824\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.728869, T: 482582064, Avg. loss: 0.064703\n",
      "Total training time: 236.88 seconds.\n",
      "-- Epoch 2825\n",
      "Norm: 13.61, NNZs: 30, Bias: -120.726559, T: 482752950, Avg. loss: 0.064702\n",
      "Total training time: 236.96 seconds.\n",
      "-- Epoch 2826\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.724250, T: 482923836, Avg. loss: 0.064701\n",
      "Total training time: 237.04 seconds.\n",
      "-- Epoch 2827\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.721944, T: 483094722, Avg. loss: 0.064699\n",
      "Total training time: 237.12 seconds.\n",
      "-- Epoch 2828\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.719637, T: 483265608, Avg. loss: 0.064698\n",
      "Total training time: 237.20 seconds.\n",
      "-- Epoch 2829\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.717330, T: 483436494, Avg. loss: 0.064697\n",
      "Total training time: 237.29 seconds.\n",
      "-- Epoch 2830\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.715027, T: 483607380, Avg. loss: 0.064696\n",
      "Total training time: 237.37 seconds.\n",
      "-- Epoch 2831\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.712721, T: 483778266, Avg. loss: 0.064694\n",
      "Total training time: 237.45 seconds.\n",
      "-- Epoch 2832\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.710417, T: 483949152, Avg. loss: 0.064693\n",
      "Total training time: 237.54 seconds.\n",
      "-- Epoch 2833\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.708114, T: 484120038, Avg. loss: 0.064692\n",
      "Total training time: 237.62 seconds.\n",
      "-- Epoch 2834\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.705809, T: 484290924, Avg. loss: 0.064690\n",
      "Total training time: 237.70 seconds.\n",
      "-- Epoch 2835\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.703507, T: 484461810, Avg. loss: 0.064689\n",
      "Total training time: 237.78 seconds.\n",
      "-- Epoch 2836\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.701208, T: 484632696, Avg. loss: 0.064688\n",
      "Total training time: 237.86 seconds.\n",
      "-- Epoch 2837\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.698907, T: 484803582, Avg. loss: 0.064687\n",
      "Total training time: 237.94 seconds.\n",
      "-- Epoch 2838\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.696608, T: 484974468, Avg. loss: 0.064685\n",
      "Total training time: 238.02 seconds.\n",
      "-- Epoch 2839\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.694309, T: 485145354, Avg. loss: 0.064684\n",
      "Total training time: 238.11 seconds.\n",
      "-- Epoch 2840\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.692012, T: 485316240, Avg. loss: 0.064683\n",
      "Total training time: 238.19 seconds.\n",
      "-- Epoch 2841\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.689715, T: 485487126, Avg. loss: 0.064681\n",
      "Total training time: 238.27 seconds.\n",
      "-- Epoch 2842\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.687420, T: 485658012, Avg. loss: 0.064680\n",
      "Total training time: 238.36 seconds.\n",
      "-- Epoch 2843\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.685125, T: 485828898, Avg. loss: 0.064679\n",
      "Total training time: 238.44 seconds.\n",
      "-- Epoch 2844\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.682832, T: 485999784, Avg. loss: 0.064678\n",
      "Total training time: 238.52 seconds.\n",
      "-- Epoch 2845\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.680538, T: 486170670, Avg. loss: 0.064676\n",
      "Total training time: 238.60 seconds.\n",
      "-- Epoch 2846\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.678248, T: 486341556, Avg. loss: 0.064675\n",
      "Total training time: 238.69 seconds.\n",
      "-- Epoch 2847\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.675958, T: 486512442, Avg. loss: 0.064674\n",
      "Total training time: 238.77 seconds.\n",
      "-- Epoch 2848\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.673670, T: 486683328, Avg. loss: 0.064673\n",
      "Total training time: 238.85 seconds.\n",
      "-- Epoch 2849\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.671380, T: 486854214, Avg. loss: 0.064671\n",
      "Total training time: 238.93 seconds.\n",
      "-- Epoch 2850\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.669090, T: 487025100, Avg. loss: 0.064670\n",
      "Total training time: 239.01 seconds.\n",
      "-- Epoch 2851\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.666802, T: 487195986, Avg. loss: 0.064669\n",
      "Total training time: 239.10 seconds.\n",
      "-- Epoch 2852\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.664514, T: 487366872, Avg. loss: 0.064667\n",
      "Total training time: 239.18 seconds.\n",
      "-- Epoch 2853\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.662226, T: 487537758, Avg. loss: 0.064666\n",
      "Total training time: 239.26 seconds.\n",
      "-- Epoch 2854\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.659939, T: 487708644, Avg. loss: 0.064665\n",
      "Total training time: 239.34 seconds.\n",
      "-- Epoch 2855\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.657655, T: 487879530, Avg. loss: 0.064664\n",
      "Total training time: 239.42 seconds.\n",
      "-- Epoch 2856\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.655369, T: 488050416, Avg. loss: 0.064662\n",
      "Total training time: 239.50 seconds.\n",
      "-- Epoch 2857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.60, NNZs: 30, Bias: -120.653087, T: 488221302, Avg. loss: 0.064661\n",
      "Total training time: 239.59 seconds.\n",
      "-- Epoch 2858\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.650803, T: 488392188, Avg. loss: 0.064660\n",
      "Total training time: 239.67 seconds.\n",
      "-- Epoch 2859\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.648522, T: 488563074, Avg. loss: 0.064659\n",
      "Total training time: 239.75 seconds.\n",
      "-- Epoch 2860\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.646240, T: 488733960, Avg. loss: 0.064657\n",
      "Total training time: 239.83 seconds.\n",
      "-- Epoch 2861\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.643961, T: 488904846, Avg. loss: 0.064656\n",
      "Total training time: 239.92 seconds.\n",
      "-- Epoch 2862\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.641681, T: 489075732, Avg. loss: 0.064655\n",
      "Total training time: 240.00 seconds.\n",
      "-- Epoch 2863\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.639402, T: 489246618, Avg. loss: 0.064653\n",
      "Total training time: 240.08 seconds.\n",
      "-- Epoch 2864\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.637122, T: 489417504, Avg. loss: 0.064652\n",
      "Total training time: 240.16 seconds.\n",
      "-- Epoch 2865\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.634844, T: 489588390, Avg. loss: 0.064651\n",
      "Total training time: 240.24 seconds.\n",
      "-- Epoch 2866\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.632570, T: 489759276, Avg. loss: 0.064650\n",
      "Total training time: 240.33 seconds.\n",
      "-- Epoch 2867\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.630295, T: 489930162, Avg. loss: 0.064648\n",
      "Total training time: 240.41 seconds.\n",
      "-- Epoch 2868\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.628022, T: 490101048, Avg. loss: 0.064647\n",
      "Total training time: 240.49 seconds.\n",
      "-- Epoch 2869\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.625749, T: 490271934, Avg. loss: 0.064646\n",
      "Total training time: 240.57 seconds.\n",
      "-- Epoch 2870\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.623476, T: 490442820, Avg. loss: 0.064645\n",
      "Total training time: 240.66 seconds.\n",
      "-- Epoch 2871\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.621205, T: 490613706, Avg. loss: 0.064643\n",
      "Total training time: 240.74 seconds.\n",
      "-- Epoch 2872\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.618935, T: 490784592, Avg. loss: 0.064642\n",
      "Total training time: 240.82 seconds.\n",
      "-- Epoch 2873\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.616664, T: 490955478, Avg. loss: 0.064641\n",
      "Total training time: 240.90 seconds.\n",
      "-- Epoch 2874\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.614394, T: 491126364, Avg. loss: 0.064640\n",
      "Total training time: 240.98 seconds.\n",
      "-- Epoch 2875\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.612126, T: 491297250, Avg. loss: 0.064638\n",
      "Total training time: 241.06 seconds.\n",
      "-- Epoch 2876\n",
      "Norm: 13.60, NNZs: 30, Bias: -120.609858, T: 491468136, Avg. loss: 0.064637\n",
      "Total training time: 241.15 seconds.\n",
      "-- Epoch 2877\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.607590, T: 491639022, Avg. loss: 0.064636\n",
      "Total training time: 241.22 seconds.\n",
      "-- Epoch 2878\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.605323, T: 491809908, Avg. loss: 0.064635\n",
      "Total training time: 241.31 seconds.\n",
      "-- Epoch 2879\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.603057, T: 491980794, Avg. loss: 0.064633\n",
      "Total training time: 241.39 seconds.\n",
      "-- Epoch 2880\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.600792, T: 492151680, Avg. loss: 0.064632\n",
      "Total training time: 241.47 seconds.\n",
      "-- Epoch 2881\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.598528, T: 492322566, Avg. loss: 0.064631\n",
      "Total training time: 241.55 seconds.\n",
      "-- Epoch 2882\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.596263, T: 492493452, Avg. loss: 0.064629\n",
      "Total training time: 241.63 seconds.\n",
      "-- Epoch 2883\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.594003, T: 492664338, Avg. loss: 0.064628\n",
      "Total training time: 241.71 seconds.\n",
      "-- Epoch 2884\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.591739, T: 492835224, Avg. loss: 0.064627\n",
      "Total training time: 241.79 seconds.\n",
      "-- Epoch 2885\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.589478, T: 493006110, Avg. loss: 0.064626\n",
      "Total training time: 241.88 seconds.\n",
      "-- Epoch 2886\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.587217, T: 493176996, Avg. loss: 0.064624\n",
      "Total training time: 241.96 seconds.\n",
      "-- Epoch 2887\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.584958, T: 493347882, Avg. loss: 0.064623\n",
      "Total training time: 242.04 seconds.\n",
      "-- Epoch 2888\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.582700, T: 493518768, Avg. loss: 0.064622\n",
      "Total training time: 242.12 seconds.\n",
      "-- Epoch 2889\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.580445, T: 493689654, Avg. loss: 0.064621\n",
      "Total training time: 242.20 seconds.\n",
      "-- Epoch 2890\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.578188, T: 493860540, Avg. loss: 0.064619\n",
      "Total training time: 242.29 seconds.\n",
      "-- Epoch 2891\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.575930, T: 494031426, Avg. loss: 0.064618\n",
      "Total training time: 242.37 seconds.\n",
      "-- Epoch 2892\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.573675, T: 494202312, Avg. loss: 0.064617\n",
      "Total training time: 242.45 seconds.\n",
      "-- Epoch 2893\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.571422, T: 494373198, Avg. loss: 0.064616\n",
      "Total training time: 242.54 seconds.\n",
      "-- Epoch 2894\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.569165, T: 494544084, Avg. loss: 0.064614\n",
      "Total training time: 242.62 seconds.\n",
      "-- Epoch 2895\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.566911, T: 494714970, Avg. loss: 0.064613\n",
      "Total training time: 242.71 seconds.\n",
      "-- Epoch 2896\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.564657, T: 494885856, Avg. loss: 0.064612\n",
      "Total training time: 242.79 seconds.\n",
      "-- Epoch 2897\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.562406, T: 495056742, Avg. loss: 0.064611\n",
      "Total training time: 242.87 seconds.\n",
      "-- Epoch 2898\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.560155, T: 495227628, Avg. loss: 0.064609\n",
      "Total training time: 242.95 seconds.\n",
      "-- Epoch 2899\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.557906, T: 495398514, Avg. loss: 0.064608\n",
      "Total training time: 243.04 seconds.\n",
      "-- Epoch 2900\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.555657, T: 495569400, Avg. loss: 0.064607\n",
      "Total training time: 243.12 seconds.\n",
      "-- Epoch 2901\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.553410, T: 495740286, Avg. loss: 0.064606\n",
      "Total training time: 243.20 seconds.\n",
      "-- Epoch 2902\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.551163, T: 495911172, Avg. loss: 0.064604\n",
      "Total training time: 243.29 seconds.\n",
      "-- Epoch 2903\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.548918, T: 496082058, Avg. loss: 0.064603\n",
      "Total training time: 243.37 seconds.\n",
      "-- Epoch 2904\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.546671, T: 496252944, Avg. loss: 0.064602\n",
      "Total training time: 243.45 seconds.\n",
      "-- Epoch 2905\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.544424, T: 496423830, Avg. loss: 0.064601\n",
      "Total training time: 243.53 seconds.\n",
      "-- Epoch 2906\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.542179, T: 496594716, Avg. loss: 0.064599\n",
      "Total training time: 243.61 seconds.\n",
      "-- Epoch 2907\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.539935, T: 496765602, Avg. loss: 0.064598\n",
      "Total training time: 243.70 seconds.\n",
      "-- Epoch 2908\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.537692, T: 496936488, Avg. loss: 0.064597\n",
      "Total training time: 243.78 seconds.\n",
      "-- Epoch 2909\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.535450, T: 497107374, Avg. loss: 0.064596\n",
      "Total training time: 243.86 seconds.\n",
      "-- Epoch 2910\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.533208, T: 497278260, Avg. loss: 0.064594\n",
      "Total training time: 243.94 seconds.\n",
      "-- Epoch 2911\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.530968, T: 497449146, Avg. loss: 0.064593\n",
      "Total training time: 244.03 seconds.\n",
      "-- Epoch 2912\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.528728, T: 497620032, Avg. loss: 0.064592\n",
      "Total training time: 244.11 seconds.\n",
      "-- Epoch 2913\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.526488, T: 497790918, Avg. loss: 0.064591\n",
      "Total training time: 244.19 seconds.\n",
      "-- Epoch 2914\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.524249, T: 497961804, Avg. loss: 0.064589\n",
      "Total training time: 244.27 seconds.\n",
      "-- Epoch 2915\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.522009, T: 498132690, Avg. loss: 0.064588\n",
      "Total training time: 244.35 seconds.\n",
      "-- Epoch 2916\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.519774, T: 498303576, Avg. loss: 0.064587\n",
      "Total training time: 244.43 seconds.\n",
      "-- Epoch 2917\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.517538, T: 498474462, Avg. loss: 0.064586\n",
      "Total training time: 244.52 seconds.\n",
      "-- Epoch 2918\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.515304, T: 498645348, Avg. loss: 0.064584\n",
      "Total training time: 244.60 seconds.\n",
      "-- Epoch 2919\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.513069, T: 498816234, Avg. loss: 0.064583\n",
      "Total training time: 244.68 seconds.\n",
      "-- Epoch 2920\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.510835, T: 498987120, Avg. loss: 0.064582\n",
      "Total training time: 244.77 seconds.\n",
      "-- Epoch 2921\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.508606, T: 499158006, Avg. loss: 0.064581\n",
      "Total training time: 244.85 seconds.\n",
      "-- Epoch 2922\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.506373, T: 499328892, Avg. loss: 0.064579\n",
      "Total training time: 244.93 seconds.\n",
      "-- Epoch 2923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.59, NNZs: 30, Bias: -120.504144, T: 499499778, Avg. loss: 0.064578\n",
      "Total training time: 245.01 seconds.\n",
      "-- Epoch 2924\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.501912, T: 499670664, Avg. loss: 0.064577\n",
      "Total training time: 245.09 seconds.\n",
      "-- Epoch 2925\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.499683, T: 499841550, Avg. loss: 0.064576\n",
      "Total training time: 245.17 seconds.\n",
      "-- Epoch 2926\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.497452, T: 500012436, Avg. loss: 0.064574\n",
      "Total training time: 245.26 seconds.\n",
      "-- Epoch 2927\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.495224, T: 500183322, Avg. loss: 0.064573\n",
      "Total training time: 245.34 seconds.\n",
      "-- Epoch 2928\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.492996, T: 500354208, Avg. loss: 0.064572\n",
      "Total training time: 245.42 seconds.\n",
      "-- Epoch 2929\n",
      "Norm: 13.59, NNZs: 30, Bias: -120.490769, T: 500525094, Avg. loss: 0.064571\n",
      "Total training time: 245.51 seconds.\n",
      "-- Epoch 2930\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.488542, T: 500695980, Avg. loss: 0.064570\n",
      "Total training time: 245.59 seconds.\n",
      "-- Epoch 2931\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.486316, T: 500866866, Avg. loss: 0.064568\n",
      "Total training time: 245.67 seconds.\n",
      "-- Epoch 2932\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.484090, T: 501037752, Avg. loss: 0.064567\n",
      "Total training time: 245.75 seconds.\n",
      "-- Epoch 2933\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.481865, T: 501208638, Avg. loss: 0.064566\n",
      "Total training time: 245.83 seconds.\n",
      "-- Epoch 2934\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.479641, T: 501379524, Avg. loss: 0.064565\n",
      "Total training time: 245.92 seconds.\n",
      "-- Epoch 2935\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.477419, T: 501550410, Avg. loss: 0.064563\n",
      "Total training time: 246.00 seconds.\n",
      "-- Epoch 2936\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.475197, T: 501721296, Avg. loss: 0.064562\n",
      "Total training time: 246.08 seconds.\n",
      "-- Epoch 2937\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.472975, T: 501892182, Avg. loss: 0.064561\n",
      "Total training time: 246.16 seconds.\n",
      "-- Epoch 2938\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.470755, T: 502063068, Avg. loss: 0.064560\n",
      "Total training time: 246.24 seconds.\n",
      "-- Epoch 2939\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.468534, T: 502233954, Avg. loss: 0.064558\n",
      "Total training time: 246.32 seconds.\n",
      "-- Epoch 2940\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.466316, T: 502404840, Avg. loss: 0.064557\n",
      "Total training time: 246.40 seconds.\n",
      "-- Epoch 2941\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.464096, T: 502575726, Avg. loss: 0.064556\n",
      "Total training time: 246.48 seconds.\n",
      "-- Epoch 2942\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.461879, T: 502746612, Avg. loss: 0.064555\n",
      "Total training time: 246.57 seconds.\n",
      "-- Epoch 2943\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.459664, T: 502917498, Avg. loss: 0.064553\n",
      "Total training time: 246.65 seconds.\n",
      "-- Epoch 2944\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.457450, T: 503088384, Avg. loss: 0.064552\n",
      "Total training time: 246.73 seconds.\n",
      "-- Epoch 2945\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.455236, T: 503259270, Avg. loss: 0.064551\n",
      "Total training time: 246.82 seconds.\n",
      "-- Epoch 2946\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.453021, T: 503430156, Avg. loss: 0.064550\n",
      "Total training time: 246.90 seconds.\n",
      "-- Epoch 2947\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.450810, T: 503601042, Avg. loss: 0.064549\n",
      "Total training time: 246.98 seconds.\n",
      "-- Epoch 2948\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.448598, T: 503771928, Avg. loss: 0.064547\n",
      "Total training time: 247.06 seconds.\n",
      "-- Epoch 2949\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.446388, T: 503942814, Avg. loss: 0.064546\n",
      "Total training time: 247.14 seconds.\n",
      "-- Epoch 2950\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.444176, T: 504113700, Avg. loss: 0.064545\n",
      "Total training time: 247.23 seconds.\n",
      "-- Epoch 2951\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.441966, T: 504284586, Avg. loss: 0.064544\n",
      "Total training time: 247.31 seconds.\n",
      "-- Epoch 2952\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.439757, T: 504455472, Avg. loss: 0.064542\n",
      "Total training time: 247.39 seconds.\n",
      "-- Epoch 2953\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.437548, T: 504626358, Avg. loss: 0.064541\n",
      "Total training time: 247.47 seconds.\n",
      "-- Epoch 2954\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.435340, T: 504797244, Avg. loss: 0.064540\n",
      "Total training time: 247.55 seconds.\n",
      "-- Epoch 2955\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.433133, T: 504968130, Avg. loss: 0.064539\n",
      "Total training time: 247.64 seconds.\n",
      "-- Epoch 2956\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.430927, T: 505139016, Avg. loss: 0.064537\n",
      "Total training time: 247.72 seconds.\n",
      "-- Epoch 2957\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.428720, T: 505309902, Avg. loss: 0.064536\n",
      "Total training time: 247.80 seconds.\n",
      "-- Epoch 2958\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.426514, T: 505480788, Avg. loss: 0.064535\n",
      "Total training time: 247.88 seconds.\n",
      "-- Epoch 2959\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.424312, T: 505651674, Avg. loss: 0.064534\n",
      "Total training time: 247.96 seconds.\n",
      "-- Epoch 2960\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.422108, T: 505822560, Avg. loss: 0.064533\n",
      "Total training time: 248.04 seconds.\n",
      "-- Epoch 2961\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.419908, T: 505993446, Avg. loss: 0.064531\n",
      "Total training time: 248.13 seconds.\n",
      "-- Epoch 2962\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.417705, T: 506164332, Avg. loss: 0.064530\n",
      "Total training time: 248.21 seconds.\n",
      "-- Epoch 2963\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.415502, T: 506335218, Avg. loss: 0.064529\n",
      "Total training time: 248.29 seconds.\n",
      "-- Epoch 2964\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.413301, T: 506506104, Avg. loss: 0.064528\n",
      "Total training time: 248.40 seconds.\n",
      "-- Epoch 2965\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.411100, T: 506676990, Avg. loss: 0.064526\n",
      "Total training time: 248.49 seconds.\n",
      "-- Epoch 2966\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.408900, T: 506847876, Avg. loss: 0.064525\n",
      "Total training time: 248.58 seconds.\n",
      "-- Epoch 2967\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.406703, T: 507018762, Avg. loss: 0.064524\n",
      "Total training time: 248.66 seconds.\n",
      "-- Epoch 2968\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.404504, T: 507189648, Avg. loss: 0.064523\n",
      "Total training time: 248.77 seconds.\n",
      "-- Epoch 2969\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.402309, T: 507360534, Avg. loss: 0.064522\n",
      "Total training time: 248.86 seconds.\n",
      "-- Epoch 2970\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.400113, T: 507531420, Avg. loss: 0.064520\n",
      "Total training time: 248.94 seconds.\n",
      "-- Epoch 2971\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.397919, T: 507702306, Avg. loss: 0.064519\n",
      "Total training time: 249.02 seconds.\n",
      "-- Epoch 2972\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.395725, T: 507873192, Avg. loss: 0.064518\n",
      "Total training time: 249.11 seconds.\n",
      "-- Epoch 2973\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.393534, T: 508044078, Avg. loss: 0.064517\n",
      "Total training time: 249.19 seconds.\n",
      "-- Epoch 2974\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.391342, T: 508214964, Avg. loss: 0.064515\n",
      "Total training time: 249.27 seconds.\n",
      "-- Epoch 2975\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.389149, T: 508385850, Avg. loss: 0.064514\n",
      "Total training time: 249.35 seconds.\n",
      "-- Epoch 2976\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.386956, T: 508556736, Avg. loss: 0.064513\n",
      "Total training time: 249.43 seconds.\n",
      "-- Epoch 2977\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.384765, T: 508727622, Avg. loss: 0.064512\n",
      "Total training time: 249.52 seconds.\n",
      "-- Epoch 2978\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.382574, T: 508898508, Avg. loss: 0.064511\n",
      "Total training time: 249.60 seconds.\n",
      "-- Epoch 2979\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.380386, T: 509069394, Avg. loss: 0.064509\n",
      "Total training time: 249.68 seconds.\n",
      "-- Epoch 2980\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.378196, T: 509240280, Avg. loss: 0.064508\n",
      "Total training time: 249.77 seconds.\n",
      "-- Epoch 2981\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.376008, T: 509411166, Avg. loss: 0.064507\n",
      "Total training time: 249.85 seconds.\n",
      "-- Epoch 2982\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.373821, T: 509582052, Avg. loss: 0.064506\n",
      "Total training time: 249.93 seconds.\n",
      "-- Epoch 2983\n",
      "Norm: 13.58, NNZs: 30, Bias: -120.371636, T: 509752938, Avg. loss: 0.064504\n",
      "Total training time: 250.01 seconds.\n",
      "-- Epoch 2984\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.369450, T: 509923824, Avg. loss: 0.064503\n",
      "Total training time: 250.09 seconds.\n",
      "-- Epoch 2985\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.367264, T: 510094710, Avg. loss: 0.064502\n",
      "Total training time: 250.17 seconds.\n",
      "-- Epoch 2986\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.365080, T: 510265596, Avg. loss: 0.064501\n",
      "Total training time: 250.26 seconds.\n",
      "-- Epoch 2987\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.362896, T: 510436482, Avg. loss: 0.064500\n",
      "Total training time: 250.34 seconds.\n",
      "-- Epoch 2988\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.360713, T: 510607368, Avg. loss: 0.064498\n",
      "Total training time: 250.42 seconds.\n",
      "-- Epoch 2989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.57, NNZs: 30, Bias: -120.358531, T: 510778254, Avg. loss: 0.064497\n",
      "Total training time: 250.50 seconds.\n",
      "-- Epoch 2990\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.356348, T: 510949140, Avg. loss: 0.064496\n",
      "Total training time: 250.58 seconds.\n",
      "-- Epoch 2991\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.354166, T: 511120026, Avg. loss: 0.064495\n",
      "Total training time: 250.67 seconds.\n",
      "-- Epoch 2992\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.351987, T: 511290912, Avg. loss: 0.064494\n",
      "Total training time: 250.75 seconds.\n",
      "-- Epoch 2993\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.349809, T: 511461798, Avg. loss: 0.064492\n",
      "Total training time: 250.83 seconds.\n",
      "-- Epoch 2994\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.347630, T: 511632684, Avg. loss: 0.064491\n",
      "Total training time: 250.91 seconds.\n",
      "-- Epoch 2995\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.345452, T: 511803570, Avg. loss: 0.064490\n",
      "Total training time: 250.99 seconds.\n",
      "-- Epoch 2996\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.343275, T: 511974456, Avg. loss: 0.064489\n",
      "Total training time: 251.07 seconds.\n",
      "-- Epoch 2997\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.341098, T: 512145342, Avg. loss: 0.064488\n",
      "Total training time: 251.16 seconds.\n",
      "-- Epoch 2998\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.338926, T: 512316228, Avg. loss: 0.064486\n",
      "Total training time: 251.24 seconds.\n",
      "-- Epoch 2999\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.336752, T: 512487114, Avg. loss: 0.064485\n",
      "Total training time: 251.32 seconds.\n",
      "-- Epoch 3000\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.334578, T: 512658000, Avg. loss: 0.064484\n",
      "Total training time: 251.40 seconds.\n",
      "-- Epoch 3001\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.332405, T: 512828886, Avg. loss: 0.064483\n",
      "Total training time: 251.48 seconds.\n",
      "-- Epoch 3002\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.330231, T: 512999772, Avg. loss: 0.064481\n",
      "Total training time: 251.57 seconds.\n",
      "-- Epoch 3003\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.328061, T: 513170658, Avg. loss: 0.064480\n",
      "Total training time: 251.65 seconds.\n",
      "-- Epoch 3004\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.325890, T: 513341544, Avg. loss: 0.064479\n",
      "Total training time: 251.73 seconds.\n",
      "-- Epoch 3005\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.323722, T: 513512430, Avg. loss: 0.064478\n",
      "Total training time: 251.81 seconds.\n",
      "-- Epoch 3006\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.321553, T: 513683316, Avg. loss: 0.064477\n",
      "Total training time: 251.89 seconds.\n",
      "-- Epoch 3007\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.319384, T: 513854202, Avg. loss: 0.064475\n",
      "Total training time: 251.97 seconds.\n",
      "-- Epoch 3008\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.317217, T: 514025088, Avg. loss: 0.064474\n",
      "Total training time: 252.05 seconds.\n",
      "-- Epoch 3009\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.315050, T: 514195974, Avg. loss: 0.064473\n",
      "Total training time: 252.13 seconds.\n",
      "-- Epoch 3010\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.312882, T: 514366860, Avg. loss: 0.064472\n",
      "Total training time: 252.21 seconds.\n",
      "-- Epoch 3011\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.310717, T: 514537746, Avg. loss: 0.064471\n",
      "Total training time: 252.30 seconds.\n",
      "-- Epoch 3012\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.308552, T: 514708632, Avg. loss: 0.064469\n",
      "Total training time: 252.38 seconds.\n",
      "-- Epoch 3013\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.306388, T: 514879518, Avg. loss: 0.064468\n",
      "Total training time: 252.46 seconds.\n",
      "-- Epoch 3014\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.304226, T: 515050404, Avg. loss: 0.064467\n",
      "Total training time: 252.54 seconds.\n",
      "-- Epoch 3015\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.302064, T: 515221290, Avg. loss: 0.064466\n",
      "Total training time: 252.62 seconds.\n",
      "-- Epoch 3016\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.299900, T: 515392176, Avg. loss: 0.064465\n",
      "Total training time: 252.70 seconds.\n",
      "-- Epoch 3017\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.297739, T: 515563062, Avg. loss: 0.064463\n",
      "Total training time: 252.78 seconds.\n",
      "-- Epoch 3018\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.295577, T: 515733948, Avg. loss: 0.064462\n",
      "Total training time: 252.86 seconds.\n",
      "-- Epoch 3019\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.293416, T: 515904834, Avg. loss: 0.064461\n",
      "Total training time: 252.94 seconds.\n",
      "-- Epoch 3020\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.291255, T: 516075720, Avg. loss: 0.064460\n",
      "Total training time: 253.02 seconds.\n",
      "-- Epoch 3021\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.289097, T: 516246606, Avg. loss: 0.064459\n",
      "Total training time: 253.10 seconds.\n",
      "-- Epoch 3022\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.286939, T: 516417492, Avg. loss: 0.064457\n",
      "Total training time: 253.19 seconds.\n",
      "-- Epoch 3023\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.284782, T: 516588378, Avg. loss: 0.064456\n",
      "Total training time: 253.27 seconds.\n",
      "-- Epoch 3024\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.282627, T: 516759264, Avg. loss: 0.064455\n",
      "Total training time: 253.35 seconds.\n",
      "-- Epoch 3025\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.280471, T: 516930150, Avg. loss: 0.064454\n",
      "Total training time: 253.43 seconds.\n",
      "-- Epoch 3026\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.278317, T: 517101036, Avg. loss: 0.064453\n",
      "Total training time: 253.51 seconds.\n",
      "-- Epoch 3027\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.276162, T: 517271922, Avg. loss: 0.064451\n",
      "Total training time: 253.59 seconds.\n",
      "-- Epoch 3028\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.274007, T: 517442808, Avg. loss: 0.064450\n",
      "Total training time: 253.68 seconds.\n",
      "-- Epoch 3029\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.271854, T: 517613694, Avg. loss: 0.064449\n",
      "Total training time: 253.76 seconds.\n",
      "-- Epoch 3030\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.269702, T: 517784580, Avg. loss: 0.064448\n",
      "Total training time: 253.84 seconds.\n",
      "-- Epoch 3031\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.267550, T: 517955466, Avg. loss: 0.064447\n",
      "Total training time: 253.92 seconds.\n",
      "-- Epoch 3032\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.265398, T: 518126352, Avg. loss: 0.064445\n",
      "Total training time: 254.00 seconds.\n",
      "-- Epoch 3033\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.263250, T: 518297238, Avg. loss: 0.064444\n",
      "Total training time: 254.08 seconds.\n",
      "-- Epoch 3034\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.261100, T: 518468124, Avg. loss: 0.064443\n",
      "Total training time: 254.16 seconds.\n",
      "-- Epoch 3035\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.258953, T: 518639010, Avg. loss: 0.064442\n",
      "Total training time: 254.25 seconds.\n",
      "-- Epoch 3036\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.256805, T: 518809896, Avg. loss: 0.064441\n",
      "Total training time: 254.33 seconds.\n",
      "-- Epoch 3037\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.254658, T: 518980782, Avg. loss: 0.064439\n",
      "Total training time: 254.41 seconds.\n",
      "-- Epoch 3038\n",
      "Norm: 13.57, NNZs: 30, Bias: -120.252512, T: 519151668, Avg. loss: 0.064438\n",
      "Total training time: 254.49 seconds.\n",
      "-- Epoch 3039\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.250367, T: 519322554, Avg. loss: 0.064437\n",
      "Total training time: 254.57 seconds.\n",
      "-- Epoch 3040\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.248222, T: 519493440, Avg. loss: 0.064436\n",
      "Total training time: 254.65 seconds.\n",
      "-- Epoch 3041\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.246079, T: 519664326, Avg. loss: 0.064435\n",
      "Total training time: 254.74 seconds.\n",
      "-- Epoch 3042\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.243935, T: 519835212, Avg. loss: 0.064433\n",
      "Total training time: 254.82 seconds.\n",
      "-- Epoch 3043\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.241795, T: 520006098, Avg. loss: 0.064432\n",
      "Total training time: 254.90 seconds.\n",
      "-- Epoch 3044\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.239654, T: 520176984, Avg. loss: 0.064431\n",
      "Total training time: 254.98 seconds.\n",
      "-- Epoch 3045\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.237513, T: 520347870, Avg. loss: 0.064430\n",
      "Total training time: 255.06 seconds.\n",
      "-- Epoch 3046\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.235374, T: 520518756, Avg. loss: 0.064429\n",
      "Total training time: 255.14 seconds.\n",
      "-- Epoch 3047\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.233234, T: 520689642, Avg. loss: 0.064428\n",
      "Total training time: 255.23 seconds.\n",
      "-- Epoch 3048\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.231095, T: 520860528, Avg. loss: 0.064426\n",
      "Total training time: 255.31 seconds.\n",
      "-- Epoch 3049\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.228959, T: 521031414, Avg. loss: 0.064425\n",
      "Total training time: 255.39 seconds.\n",
      "-- Epoch 3050\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.226821, T: 521202300, Avg. loss: 0.064424\n",
      "Total training time: 255.47 seconds.\n",
      "-- Epoch 3051\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.224682, T: 521373186, Avg. loss: 0.064423\n",
      "Total training time: 255.55 seconds.\n",
      "-- Epoch 3052\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.222545, T: 521544072, Avg. loss: 0.064422\n",
      "Total training time: 255.64 seconds.\n",
      "-- Epoch 3053\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.220407, T: 521714958, Avg. loss: 0.064420\n",
      "Total training time: 255.72 seconds.\n",
      "-- Epoch 3054\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.218272, T: 521885844, Avg. loss: 0.064419\n",
      "Total training time: 255.80 seconds.\n",
      "-- Epoch 3055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.56, NNZs: 30, Bias: -120.216136, T: 522056730, Avg. loss: 0.064418\n",
      "Total training time: 255.88 seconds.\n",
      "-- Epoch 3056\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.214004, T: 522227616, Avg. loss: 0.064417\n",
      "Total training time: 255.96 seconds.\n",
      "-- Epoch 3057\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.211871, T: 522398502, Avg. loss: 0.064416\n",
      "Total training time: 256.04 seconds.\n",
      "-- Epoch 3058\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.209739, T: 522569388, Avg. loss: 0.064414\n",
      "Total training time: 256.12 seconds.\n",
      "-- Epoch 3059\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.207608, T: 522740274, Avg. loss: 0.064413\n",
      "Total training time: 256.20 seconds.\n",
      "-- Epoch 3060\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.205477, T: 522911160, Avg. loss: 0.064412\n",
      "Total training time: 256.29 seconds.\n",
      "-- Epoch 3061\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.203346, T: 523082046, Avg. loss: 0.064411\n",
      "Total training time: 256.37 seconds.\n",
      "-- Epoch 3062\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.201214, T: 523252932, Avg. loss: 0.064410\n",
      "Total training time: 256.45 seconds.\n",
      "-- Epoch 3063\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.199087, T: 523423818, Avg. loss: 0.064409\n",
      "Total training time: 256.53 seconds.\n",
      "-- Epoch 3064\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.196958, T: 523594704, Avg. loss: 0.064407\n",
      "Total training time: 256.62 seconds.\n",
      "-- Epoch 3065\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.194830, T: 523765590, Avg. loss: 0.064406\n",
      "Total training time: 256.70 seconds.\n",
      "-- Epoch 3066\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.192705, T: 523936476, Avg. loss: 0.064405\n",
      "Total training time: 256.78 seconds.\n",
      "-- Epoch 3067\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.190579, T: 524107362, Avg. loss: 0.064404\n",
      "Total training time: 256.86 seconds.\n",
      "-- Epoch 3068\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.188455, T: 524278248, Avg. loss: 0.064403\n",
      "Total training time: 256.95 seconds.\n",
      "-- Epoch 3069\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.186330, T: 524449134, Avg. loss: 0.064401\n",
      "Total training time: 257.03 seconds.\n",
      "-- Epoch 3070\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.184208, T: 524620020, Avg. loss: 0.064400\n",
      "Total training time: 257.11 seconds.\n",
      "-- Epoch 3071\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.182083, T: 524790906, Avg. loss: 0.064399\n",
      "Total training time: 257.19 seconds.\n",
      "-- Epoch 3072\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.179960, T: 524961792, Avg. loss: 0.064398\n",
      "Total training time: 257.28 seconds.\n",
      "-- Epoch 3073\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.177839, T: 525132678, Avg. loss: 0.064397\n",
      "Total training time: 257.36 seconds.\n",
      "-- Epoch 3074\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.175720, T: 525303564, Avg. loss: 0.064396\n",
      "Total training time: 257.44 seconds.\n",
      "-- Epoch 3075\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.173599, T: 525474450, Avg. loss: 0.064394\n",
      "Total training time: 257.53 seconds.\n",
      "-- Epoch 3076\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.171479, T: 525645336, Avg. loss: 0.064393\n",
      "Total training time: 257.61 seconds.\n",
      "-- Epoch 3077\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.169362, T: 525816222, Avg. loss: 0.064392\n",
      "Total training time: 257.69 seconds.\n",
      "-- Epoch 3078\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.167245, T: 525987108, Avg. loss: 0.064391\n",
      "Total training time: 257.77 seconds.\n",
      "-- Epoch 3079\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.165127, T: 526157994, Avg. loss: 0.064390\n",
      "Total training time: 257.86 seconds.\n",
      "-- Epoch 3080\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.163011, T: 526328880, Avg. loss: 0.064388\n",
      "Total training time: 257.94 seconds.\n",
      "-- Epoch 3081\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.160895, T: 526499766, Avg. loss: 0.064387\n",
      "Total training time: 258.02 seconds.\n",
      "-- Epoch 3082\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.158779, T: 526670652, Avg. loss: 0.064386\n",
      "Total training time: 258.10 seconds.\n",
      "-- Epoch 3083\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.156666, T: 526841538, Avg. loss: 0.064385\n",
      "Total training time: 258.18 seconds.\n",
      "-- Epoch 3084\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.154550, T: 527012424, Avg. loss: 0.064384\n",
      "Total training time: 258.26 seconds.\n",
      "-- Epoch 3085\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.152436, T: 527183310, Avg. loss: 0.064383\n",
      "Total training time: 258.35 seconds.\n",
      "-- Epoch 3086\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.150324, T: 527354196, Avg. loss: 0.064381\n",
      "Total training time: 258.43 seconds.\n",
      "-- Epoch 3087\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.148211, T: 527525082, Avg. loss: 0.064380\n",
      "Total training time: 258.54 seconds.\n",
      "-- Epoch 3088\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.146100, T: 527695968, Avg. loss: 0.064379\n",
      "Total training time: 258.62 seconds.\n",
      "-- Epoch 3089\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.143989, T: 527866854, Avg. loss: 0.064378\n",
      "Total training time: 258.70 seconds.\n",
      "-- Epoch 3090\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.141877, T: 528037740, Avg. loss: 0.064377\n",
      "Total training time: 258.79 seconds.\n",
      "-- Epoch 3091\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.139769, T: 528208626, Avg. loss: 0.064376\n",
      "Total training time: 258.87 seconds.\n",
      "-- Epoch 3092\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.137660, T: 528379512, Avg. loss: 0.064374\n",
      "Total training time: 258.95 seconds.\n",
      "-- Epoch 3093\n",
      "Norm: 13.56, NNZs: 30, Bias: -120.135553, T: 528550398, Avg. loss: 0.064373\n",
      "Total training time: 259.03 seconds.\n",
      "-- Epoch 3094\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.133447, T: 528721284, Avg. loss: 0.064372\n",
      "Total training time: 259.12 seconds.\n",
      "-- Epoch 3095\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.131341, T: 528892170, Avg. loss: 0.064371\n",
      "Total training time: 259.20 seconds.\n",
      "-- Epoch 3096\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.129235, T: 529063056, Avg. loss: 0.064370\n",
      "Total training time: 259.28 seconds.\n",
      "-- Epoch 3097\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.127130, T: 529233942, Avg. loss: 0.064369\n",
      "Total training time: 259.36 seconds.\n",
      "-- Epoch 3098\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.125027, T: 529404828, Avg. loss: 0.064367\n",
      "Total training time: 259.44 seconds.\n",
      "-- Epoch 3099\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.122923, T: 529575714, Avg. loss: 0.064366\n",
      "Total training time: 259.52 seconds.\n",
      "-- Epoch 3100\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.120820, T: 529746600, Avg. loss: 0.064365\n",
      "Total training time: 259.61 seconds.\n",
      "-- Epoch 3101\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.118718, T: 529917486, Avg. loss: 0.064364\n",
      "Total training time: 259.69 seconds.\n",
      "-- Epoch 3102\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.116617, T: 530088372, Avg. loss: 0.064363\n",
      "Total training time: 259.77 seconds.\n",
      "-- Epoch 3103\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.114517, T: 530259258, Avg. loss: 0.064362\n",
      "Total training time: 259.85 seconds.\n",
      "-- Epoch 3104\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.112417, T: 530430144, Avg. loss: 0.064360\n",
      "Total training time: 259.94 seconds.\n",
      "-- Epoch 3105\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.110318, T: 530601030, Avg. loss: 0.064359\n",
      "Total training time: 260.02 seconds.\n",
      "-- Epoch 3106\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.108219, T: 530771916, Avg. loss: 0.064358\n",
      "Total training time: 260.10 seconds.\n",
      "-- Epoch 3107\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.106121, T: 530942802, Avg. loss: 0.064357\n",
      "Total training time: 260.18 seconds.\n",
      "-- Epoch 3108\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.104024, T: 531113688, Avg. loss: 0.064356\n",
      "Total training time: 260.26 seconds.\n",
      "-- Epoch 3109\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.101927, T: 531284574, Avg. loss: 0.064355\n",
      "Total training time: 260.34 seconds.\n",
      "-- Epoch 3110\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.099831, T: 531455460, Avg. loss: 0.064353\n",
      "Total training time: 260.42 seconds.\n",
      "-- Epoch 3111\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.097735, T: 531626346, Avg. loss: 0.064352\n",
      "Total training time: 260.51 seconds.\n",
      "-- Epoch 3112\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.095640, T: 531797232, Avg. loss: 0.064351\n",
      "Total training time: 260.59 seconds.\n",
      "-- Epoch 3113\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.093546, T: 531968118, Avg. loss: 0.064350\n",
      "Total training time: 260.67 seconds.\n",
      "-- Epoch 3114\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.091452, T: 532139004, Avg. loss: 0.064349\n",
      "Total training time: 260.75 seconds.\n",
      "-- Epoch 3115\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.089359, T: 532309890, Avg. loss: 0.064348\n",
      "Total training time: 260.84 seconds.\n",
      "-- Epoch 3116\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.087268, T: 532480776, Avg. loss: 0.064346\n",
      "Total training time: 260.92 seconds.\n",
      "-- Epoch 3117\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.085177, T: 532651662, Avg. loss: 0.064345\n",
      "Total training time: 261.00 seconds.\n",
      "-- Epoch 3118\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.083088, T: 532822548, Avg. loss: 0.064344\n",
      "Total training time: 261.08 seconds.\n",
      "-- Epoch 3119\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.080998, T: 532993434, Avg. loss: 0.064343\n",
      "Total training time: 261.16 seconds.\n",
      "-- Epoch 3120\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.078908, T: 533164320, Avg. loss: 0.064342\n",
      "Total training time: 261.24 seconds.\n",
      "-- Epoch 3121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.55, NNZs: 30, Bias: -120.076820, T: 533335206, Avg. loss: 0.064341\n",
      "Total training time: 261.33 seconds.\n",
      "-- Epoch 3122\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.074733, T: 533506092, Avg. loss: 0.064339\n",
      "Total training time: 261.41 seconds.\n",
      "-- Epoch 3123\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.072647, T: 533676978, Avg. loss: 0.064338\n",
      "Total training time: 261.49 seconds.\n",
      "-- Epoch 3124\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.070560, T: 533847864, Avg. loss: 0.064337\n",
      "Total training time: 261.58 seconds.\n",
      "-- Epoch 3125\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.068475, T: 534018750, Avg. loss: 0.064336\n",
      "Total training time: 261.66 seconds.\n",
      "-- Epoch 3126\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.066389, T: 534189636, Avg. loss: 0.064335\n",
      "Total training time: 261.74 seconds.\n",
      "-- Epoch 3127\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.064305, T: 534360522, Avg. loss: 0.064334\n",
      "Total training time: 261.82 seconds.\n",
      "-- Epoch 3128\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.062223, T: 534531408, Avg. loss: 0.064332\n",
      "Total training time: 261.90 seconds.\n",
      "-- Epoch 3129\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.060139, T: 534702294, Avg. loss: 0.064331\n",
      "Total training time: 261.98 seconds.\n",
      "-- Epoch 3130\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.058056, T: 534873180, Avg. loss: 0.064330\n",
      "Total training time: 262.06 seconds.\n",
      "-- Epoch 3131\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.055972, T: 535044066, Avg. loss: 0.064329\n",
      "Total training time: 262.15 seconds.\n",
      "-- Epoch 3132\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.053892, T: 535214952, Avg. loss: 0.064328\n",
      "Total training time: 262.23 seconds.\n",
      "-- Epoch 3133\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.051810, T: 535385838, Avg. loss: 0.064327\n",
      "Total training time: 262.31 seconds.\n",
      "-- Epoch 3134\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.049729, T: 535556724, Avg. loss: 0.064326\n",
      "Total training time: 262.39 seconds.\n",
      "-- Epoch 3135\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.047649, T: 535727610, Avg. loss: 0.064324\n",
      "Total training time: 262.48 seconds.\n",
      "-- Epoch 3136\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.045569, T: 535898496, Avg. loss: 0.064323\n",
      "Total training time: 262.56 seconds.\n",
      "-- Epoch 3137\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.043492, T: 536069382, Avg. loss: 0.064322\n",
      "Total training time: 262.64 seconds.\n",
      "-- Epoch 3138\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.041416, T: 536240268, Avg. loss: 0.064321\n",
      "Total training time: 262.73 seconds.\n",
      "-- Epoch 3139\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.039341, T: 536411154, Avg. loss: 0.064320\n",
      "Total training time: 262.81 seconds.\n",
      "-- Epoch 3140\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.037264, T: 536582040, Avg. loss: 0.064319\n",
      "Total training time: 262.89 seconds.\n",
      "-- Epoch 3141\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.035189, T: 536752926, Avg. loss: 0.064317\n",
      "Total training time: 262.98 seconds.\n",
      "-- Epoch 3142\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.033115, T: 536923812, Avg. loss: 0.064316\n",
      "Total training time: 263.06 seconds.\n",
      "-- Epoch 3143\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.031041, T: 537094698, Avg. loss: 0.064315\n",
      "Total training time: 263.14 seconds.\n",
      "-- Epoch 3144\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.028968, T: 537265584, Avg. loss: 0.064314\n",
      "Total training time: 263.22 seconds.\n",
      "-- Epoch 3145\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.026896, T: 537436470, Avg. loss: 0.064313\n",
      "Total training time: 263.31 seconds.\n",
      "-- Epoch 3146\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.024826, T: 537607356, Avg. loss: 0.064312\n",
      "Total training time: 263.39 seconds.\n",
      "-- Epoch 3147\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.022754, T: 537778242, Avg. loss: 0.064311\n",
      "Total training time: 263.47 seconds.\n",
      "-- Epoch 3148\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.020684, T: 537949128, Avg. loss: 0.064309\n",
      "Total training time: 263.55 seconds.\n",
      "-- Epoch 3149\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.018615, T: 538120014, Avg. loss: 0.064308\n",
      "Total training time: 263.64 seconds.\n",
      "-- Epoch 3150\n",
      "Norm: 13.55, NNZs: 30, Bias: -120.016545, T: 538290900, Avg. loss: 0.064307\n",
      "Total training time: 263.72 seconds.\n",
      "-- Epoch 3151\n",
      "Norm: 13.54, NNZs: 30, Bias: -120.014475, T: 538461786, Avg. loss: 0.064306\n",
      "Total training time: 263.80 seconds.\n",
      "-- Epoch 3152\n",
      "Norm: 13.54, NNZs: 30, Bias: -120.012407, T: 538632672, Avg. loss: 0.064305\n",
      "Total training time: 263.89 seconds.\n",
      "-- Epoch 3153\n",
      "Norm: 13.54, NNZs: 30, Bias: -120.010338, T: 538803558, Avg. loss: 0.064304\n",
      "Total training time: 263.97 seconds.\n",
      "-- Epoch 3154\n",
      "Norm: 13.54, NNZs: 30, Bias: -120.008272, T: 538974444, Avg. loss: 0.064302\n",
      "Total training time: 264.05 seconds.\n",
      "-- Epoch 3155\n",
      "Norm: 13.54, NNZs: 30, Bias: -120.006207, T: 539145330, Avg. loss: 0.064301\n",
      "Total training time: 264.14 seconds.\n",
      "-- Epoch 3156\n",
      "Norm: 13.54, NNZs: 30, Bias: -120.004142, T: 539316216, Avg. loss: 0.064300\n",
      "Total training time: 264.22 seconds.\n",
      "-- Epoch 3157\n",
      "Norm: 13.54, NNZs: 30, Bias: -120.002078, T: 539487102, Avg. loss: 0.064299\n",
      "Total training time: 264.31 seconds.\n",
      "-- Epoch 3158\n",
      "Norm: 13.54, NNZs: 30, Bias: -120.000013, T: 539657988, Avg. loss: 0.064298\n",
      "Total training time: 264.39 seconds.\n",
      "-- Epoch 3159\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.997949, T: 539828874, Avg. loss: 0.064297\n",
      "Total training time: 264.47 seconds.\n",
      "-- Epoch 3160\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.995888, T: 539999760, Avg. loss: 0.064296\n",
      "Total training time: 264.56 seconds.\n",
      "-- Epoch 3161\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.993826, T: 540170646, Avg. loss: 0.064294\n",
      "Total training time: 264.64 seconds.\n",
      "-- Epoch 3162\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.991767, T: 540341532, Avg. loss: 0.064293\n",
      "Total training time: 264.73 seconds.\n",
      "-- Epoch 3163\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.989707, T: 540512418, Avg. loss: 0.064292\n",
      "Total training time: 264.82 seconds.\n",
      "-- Epoch 3164\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.987646, T: 540683304, Avg. loss: 0.064291\n",
      "Total training time: 264.90 seconds.\n",
      "-- Epoch 3165\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.985587, T: 540854190, Avg. loss: 0.064290\n",
      "Total training time: 264.98 seconds.\n",
      "-- Epoch 3166\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.983529, T: 541025076, Avg. loss: 0.064289\n",
      "Total training time: 265.07 seconds.\n",
      "-- Epoch 3167\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.981472, T: 541195962, Avg. loss: 0.064288\n",
      "Total training time: 265.15 seconds.\n",
      "-- Epoch 3168\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.979414, T: 541366848, Avg. loss: 0.064286\n",
      "Total training time: 265.24 seconds.\n",
      "-- Epoch 3169\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.977356, T: 541537734, Avg. loss: 0.064285\n",
      "Total training time: 265.32 seconds.\n",
      "-- Epoch 3170\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.975301, T: 541708620, Avg. loss: 0.064284\n",
      "Total training time: 265.41 seconds.\n",
      "-- Epoch 3171\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.973247, T: 541879506, Avg. loss: 0.064283\n",
      "Total training time: 265.49 seconds.\n",
      "-- Epoch 3172\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.971193, T: 542050392, Avg. loss: 0.064282\n",
      "Total training time: 265.57 seconds.\n",
      "-- Epoch 3173\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.969140, T: 542221278, Avg. loss: 0.064281\n",
      "Total training time: 265.66 seconds.\n",
      "-- Epoch 3174\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.967086, T: 542392164, Avg. loss: 0.064280\n",
      "Total training time: 265.74 seconds.\n",
      "-- Epoch 3175\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.965032, T: 542563050, Avg. loss: 0.064278\n",
      "Total training time: 265.82 seconds.\n",
      "-- Epoch 3176\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.962980, T: 542733936, Avg. loss: 0.064277\n",
      "Total training time: 265.91 seconds.\n",
      "-- Epoch 3177\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.960928, T: 542904822, Avg. loss: 0.064276\n",
      "Total training time: 265.99 seconds.\n",
      "-- Epoch 3178\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.958875, T: 543075708, Avg. loss: 0.064275\n",
      "Total training time: 266.08 seconds.\n",
      "-- Epoch 3179\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.956824, T: 543246594, Avg. loss: 0.064274\n",
      "Total training time: 266.16 seconds.\n",
      "-- Epoch 3180\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.954775, T: 543417480, Avg. loss: 0.064273\n",
      "Total training time: 266.25 seconds.\n",
      "-- Epoch 3181\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.952727, T: 543588366, Avg. loss: 0.064272\n",
      "Total training time: 266.33 seconds.\n",
      "-- Epoch 3182\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.950679, T: 543759252, Avg. loss: 0.064270\n",
      "Total training time: 266.41 seconds.\n",
      "-- Epoch 3183\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.948631, T: 543930138, Avg. loss: 0.064269\n",
      "Total training time: 266.50 seconds.\n",
      "-- Epoch 3184\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.946584, T: 544101024, Avg. loss: 0.064268\n",
      "Total training time: 266.60 seconds.\n",
      "-- Epoch 3185\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.944538, T: 544271910, Avg. loss: 0.064267\n",
      "Total training time: 266.70 seconds.\n",
      "-- Epoch 3186\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.942492, T: 544442796, Avg. loss: 0.064266\n",
      "Total training time: 266.79 seconds.\n",
      "-- Epoch 3187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.54, NNZs: 30, Bias: -119.940447, T: 544613682, Avg. loss: 0.064265\n",
      "Total training time: 266.88 seconds.\n",
      "-- Epoch 3188\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.938403, T: 544784568, Avg. loss: 0.064264\n",
      "Total training time: 266.96 seconds.\n",
      "-- Epoch 3189\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.936361, T: 544955454, Avg. loss: 0.064263\n",
      "Total training time: 267.05 seconds.\n",
      "-- Epoch 3190\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.934319, T: 545126340, Avg. loss: 0.064261\n",
      "Total training time: 267.15 seconds.\n",
      "-- Epoch 3191\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.932275, T: 545297226, Avg. loss: 0.064260\n",
      "Total training time: 267.24 seconds.\n",
      "-- Epoch 3192\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.930233, T: 545468112, Avg. loss: 0.064259\n",
      "Total training time: 267.35 seconds.\n",
      "-- Epoch 3193\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.928191, T: 545638998, Avg. loss: 0.064258\n",
      "Total training time: 267.43 seconds.\n",
      "-- Epoch 3194\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.926152, T: 545809884, Avg. loss: 0.064257\n",
      "Total training time: 267.52 seconds.\n",
      "-- Epoch 3195\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.924114, T: 545980770, Avg. loss: 0.064256\n",
      "Total training time: 267.60 seconds.\n",
      "-- Epoch 3196\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.922076, T: 546151656, Avg. loss: 0.064255\n",
      "Total training time: 267.69 seconds.\n",
      "-- Epoch 3197\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.920038, T: 546322542, Avg. loss: 0.064253\n",
      "Total training time: 267.77 seconds.\n",
      "-- Epoch 3198\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.918000, T: 546493428, Avg. loss: 0.064252\n",
      "Total training time: 267.87 seconds.\n",
      "-- Epoch 3199\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.915963, T: 546664314, Avg. loss: 0.064251\n",
      "Total training time: 267.96 seconds.\n",
      "-- Epoch 3200\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.913926, T: 546835200, Avg. loss: 0.064250\n",
      "Total training time: 268.05 seconds.\n",
      "-- Epoch 3201\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.911891, T: 547006086, Avg. loss: 0.064249\n",
      "Total training time: 268.14 seconds.\n",
      "-- Epoch 3202\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.909857, T: 547176972, Avg. loss: 0.064248\n",
      "Total training time: 268.23 seconds.\n",
      "-- Epoch 3203\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.907822, T: 547347858, Avg. loss: 0.064247\n",
      "Total training time: 268.32 seconds.\n",
      "-- Epoch 3204\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.905788, T: 547518744, Avg. loss: 0.064246\n",
      "Total training time: 268.40 seconds.\n",
      "-- Epoch 3205\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.903755, T: 547689630, Avg. loss: 0.064244\n",
      "Total training time: 268.48 seconds.\n",
      "-- Epoch 3206\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.901722, T: 547860516, Avg. loss: 0.064243\n",
      "Total training time: 268.57 seconds.\n",
      "-- Epoch 3207\n",
      "Norm: 13.54, NNZs: 30, Bias: -119.899689, T: 548031402, Avg. loss: 0.064242\n",
      "Total training time: 268.65 seconds.\n",
      "-- Epoch 3208\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.897657, T: 548202288, Avg. loss: 0.064241\n",
      "Total training time: 268.74 seconds.\n",
      "-- Epoch 3209\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.895628, T: 548373174, Avg. loss: 0.064240\n",
      "Total training time: 268.82 seconds.\n",
      "-- Epoch 3210\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.893599, T: 548544060, Avg. loss: 0.064239\n",
      "Total training time: 268.90 seconds.\n",
      "-- Epoch 3211\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.891570, T: 548714946, Avg. loss: 0.064238\n",
      "Total training time: 268.98 seconds.\n",
      "-- Epoch 3212\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.889540, T: 548885832, Avg. loss: 0.064236\n",
      "Total training time: 269.06 seconds.\n",
      "-- Epoch 3213\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.887512, T: 549056718, Avg. loss: 0.064235\n",
      "Total training time: 269.14 seconds.\n",
      "-- Epoch 3214\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.885484, T: 549227604, Avg. loss: 0.064234\n",
      "Total training time: 269.22 seconds.\n",
      "-- Epoch 3215\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.883456, T: 549398490, Avg. loss: 0.064233\n",
      "Total training time: 269.30 seconds.\n",
      "-- Epoch 3216\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.881428, T: 549569376, Avg. loss: 0.064232\n",
      "Total training time: 269.39 seconds.\n",
      "-- Epoch 3217\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.879402, T: 549740262, Avg. loss: 0.064231\n",
      "Total training time: 269.47 seconds.\n",
      "-- Epoch 3218\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.877376, T: 549911148, Avg. loss: 0.064230\n",
      "Total training time: 269.55 seconds.\n",
      "-- Epoch 3219\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.875352, T: 550082034, Avg. loss: 0.064229\n",
      "Total training time: 269.63 seconds.\n",
      "-- Epoch 3220\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.873328, T: 550252920, Avg. loss: 0.064227\n",
      "Total training time: 269.71 seconds.\n",
      "-- Epoch 3221\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.871306, T: 550423806, Avg. loss: 0.064226\n",
      "Total training time: 269.79 seconds.\n",
      "-- Epoch 3222\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.869282, T: 550594692, Avg. loss: 0.064225\n",
      "Total training time: 269.88 seconds.\n",
      "-- Epoch 3223\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.867261, T: 550765578, Avg. loss: 0.064224\n",
      "Total training time: 269.96 seconds.\n",
      "-- Epoch 3224\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.865240, T: 550936464, Avg. loss: 0.064223\n",
      "Total training time: 270.04 seconds.\n",
      "-- Epoch 3225\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.863219, T: 551107350, Avg. loss: 0.064222\n",
      "Total training time: 270.13 seconds.\n",
      "-- Epoch 3226\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.861199, T: 551278236, Avg. loss: 0.064221\n",
      "Total training time: 270.21 seconds.\n",
      "-- Epoch 3227\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.859179, T: 551449122, Avg. loss: 0.064220\n",
      "Total training time: 270.29 seconds.\n",
      "-- Epoch 3228\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.857160, T: 551620008, Avg. loss: 0.064218\n",
      "Total training time: 270.38 seconds.\n",
      "-- Epoch 3229\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.855142, T: 551790894, Avg. loss: 0.064217\n",
      "Total training time: 270.46 seconds.\n",
      "-- Epoch 3230\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.853125, T: 551961780, Avg. loss: 0.064216\n",
      "Total training time: 270.55 seconds.\n",
      "-- Epoch 3231\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.851109, T: 552132666, Avg. loss: 0.064215\n",
      "Total training time: 270.64 seconds.\n",
      "-- Epoch 3232\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.849092, T: 552303552, Avg. loss: 0.064214\n",
      "Total training time: 270.72 seconds.\n",
      "-- Epoch 3233\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.847074, T: 552474438, Avg. loss: 0.064213\n",
      "Total training time: 270.80 seconds.\n",
      "-- Epoch 3234\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.845058, T: 552645324, Avg. loss: 0.064212\n",
      "Total training time: 270.89 seconds.\n",
      "-- Epoch 3235\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.843044, T: 552816210, Avg. loss: 0.064211\n",
      "Total training time: 270.97 seconds.\n",
      "-- Epoch 3236\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.841031, T: 552987096, Avg. loss: 0.064210\n",
      "Total training time: 271.06 seconds.\n",
      "-- Epoch 3237\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.839018, T: 553157982, Avg. loss: 0.064208\n",
      "Total training time: 271.15 seconds.\n",
      "-- Epoch 3238\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.837006, T: 553328868, Avg. loss: 0.064207\n",
      "Total training time: 271.23 seconds.\n",
      "-- Epoch 3239\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.834994, T: 553499754, Avg. loss: 0.064206\n",
      "Total training time: 271.32 seconds.\n",
      "-- Epoch 3240\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.832983, T: 553670640, Avg. loss: 0.064205\n",
      "Total training time: 271.40 seconds.\n",
      "-- Epoch 3241\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.830972, T: 553841526, Avg. loss: 0.064204\n",
      "Total training time: 271.49 seconds.\n",
      "-- Epoch 3242\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.828962, T: 554012412, Avg. loss: 0.064203\n",
      "Total training time: 271.58 seconds.\n",
      "-- Epoch 3243\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.826955, T: 554183298, Avg. loss: 0.064202\n",
      "Total training time: 271.68 seconds.\n",
      "-- Epoch 3244\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.824946, T: 554354184, Avg. loss: 0.064201\n",
      "Total training time: 271.77 seconds.\n",
      "-- Epoch 3245\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.822937, T: 554525070, Avg. loss: 0.064199\n",
      "Total training time: 271.86 seconds.\n",
      "-- Epoch 3246\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.820927, T: 554695956, Avg. loss: 0.064198\n",
      "Total training time: 271.94 seconds.\n",
      "-- Epoch 3247\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.818920, T: 554866842, Avg. loss: 0.064197\n",
      "Total training time: 272.03 seconds.\n",
      "-- Epoch 3248\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.816914, T: 555037728, Avg. loss: 0.064196\n",
      "Total training time: 272.13 seconds.\n",
      "-- Epoch 3249\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.814910, T: 555208614, Avg. loss: 0.064195\n",
      "Total training time: 272.24 seconds.\n",
      "-- Epoch 3250\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.812904, T: 555379500, Avg. loss: 0.064194\n",
      "Total training time: 272.33 seconds.\n",
      "-- Epoch 3251\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.810901, T: 555550386, Avg. loss: 0.064193\n",
      "Total training time: 272.42 seconds.\n",
      "-- Epoch 3252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.53, NNZs: 30, Bias: -119.808896, T: 555721272, Avg. loss: 0.064192\n",
      "Total training time: 272.50 seconds.\n",
      "-- Epoch 3253\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.806894, T: 555892158, Avg. loss: 0.064191\n",
      "Total training time: 272.59 seconds.\n",
      "-- Epoch 3254\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.804890, T: 556063044, Avg. loss: 0.064189\n",
      "Total training time: 272.67 seconds.\n",
      "-- Epoch 3255\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.802889, T: 556233930, Avg. loss: 0.064188\n",
      "Total training time: 272.76 seconds.\n",
      "-- Epoch 3256\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.800888, T: 556404816, Avg. loss: 0.064187\n",
      "Total training time: 272.84 seconds.\n",
      "-- Epoch 3257\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.798887, T: 556575702, Avg. loss: 0.064186\n",
      "Total training time: 272.93 seconds.\n",
      "-- Epoch 3258\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.796887, T: 556746588, Avg. loss: 0.064185\n",
      "Total training time: 273.01 seconds.\n",
      "-- Epoch 3259\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.794888, T: 556917474, Avg. loss: 0.064184\n",
      "Total training time: 273.09 seconds.\n",
      "-- Epoch 3260\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.792890, T: 557088360, Avg. loss: 0.064183\n",
      "Total training time: 273.17 seconds.\n",
      "-- Epoch 3261\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.790890, T: 557259246, Avg. loss: 0.064182\n",
      "Total training time: 273.25 seconds.\n",
      "-- Epoch 3262\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.788893, T: 557430132, Avg. loss: 0.064181\n",
      "Total training time: 273.34 seconds.\n",
      "-- Epoch 3263\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.786897, T: 557601018, Avg. loss: 0.064179\n",
      "Total training time: 273.42 seconds.\n",
      "-- Epoch 3264\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.784902, T: 557771904, Avg. loss: 0.064178\n",
      "Total training time: 273.51 seconds.\n",
      "-- Epoch 3265\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.782906, T: 557942790, Avg. loss: 0.064177\n",
      "Total training time: 273.59 seconds.\n",
      "-- Epoch 3266\n",
      "Norm: 13.53, NNZs: 30, Bias: -119.780911, T: 558113676, Avg. loss: 0.064176\n",
      "Total training time: 273.67 seconds.\n",
      "-- Epoch 3267\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.778916, T: 558284562, Avg. loss: 0.064175\n",
      "Total training time: 273.76 seconds.\n",
      "-- Epoch 3268\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.776922, T: 558455448, Avg. loss: 0.064174\n",
      "Total training time: 273.84 seconds.\n",
      "-- Epoch 3269\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.774929, T: 558626334, Avg. loss: 0.064173\n",
      "Total training time: 273.92 seconds.\n",
      "-- Epoch 3270\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.772936, T: 558797220, Avg. loss: 0.064172\n",
      "Total training time: 274.00 seconds.\n",
      "-- Epoch 3271\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.770943, T: 558968106, Avg. loss: 0.064171\n",
      "Total training time: 274.09 seconds.\n",
      "-- Epoch 3272\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.768951, T: 559138992, Avg. loss: 0.064169\n",
      "Total training time: 274.17 seconds.\n",
      "-- Epoch 3273\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.766961, T: 559309878, Avg. loss: 0.064168\n",
      "Total training time: 274.25 seconds.\n",
      "-- Epoch 3274\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.764972, T: 559480764, Avg. loss: 0.064167\n",
      "Total training time: 274.34 seconds.\n",
      "-- Epoch 3275\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.762983, T: 559651650, Avg. loss: 0.064166\n",
      "Total training time: 274.43 seconds.\n",
      "-- Epoch 3276\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.760996, T: 559822536, Avg. loss: 0.064165\n",
      "Total training time: 274.51 seconds.\n",
      "-- Epoch 3277\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.759007, T: 559993422, Avg. loss: 0.064164\n",
      "Total training time: 274.60 seconds.\n",
      "-- Epoch 3278\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.757020, T: 560164308, Avg. loss: 0.064163\n",
      "Total training time: 274.69 seconds.\n",
      "-- Epoch 3279\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.755033, T: 560335194, Avg. loss: 0.064162\n",
      "Total training time: 274.78 seconds.\n",
      "-- Epoch 3280\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.753048, T: 560506080, Avg. loss: 0.064161\n",
      "Total training time: 274.87 seconds.\n",
      "-- Epoch 3281\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.751063, T: 560676966, Avg. loss: 0.064160\n",
      "Total training time: 274.96 seconds.\n",
      "-- Epoch 3282\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.749076, T: 560847852, Avg. loss: 0.064158\n",
      "Total training time: 275.05 seconds.\n",
      "-- Epoch 3283\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.747092, T: 561018738, Avg. loss: 0.064157\n",
      "Total training time: 275.15 seconds.\n",
      "-- Epoch 3284\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.745108, T: 561189624, Avg. loss: 0.064156\n",
      "Total training time: 275.24 seconds.\n",
      "-- Epoch 3285\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.743124, T: 561360510, Avg. loss: 0.064155\n",
      "Total training time: 275.33 seconds.\n",
      "-- Epoch 3286\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.741141, T: 561531396, Avg. loss: 0.064154\n",
      "Total training time: 275.42 seconds.\n",
      "-- Epoch 3287\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.739159, T: 561702282, Avg. loss: 0.064153\n",
      "Total training time: 275.52 seconds.\n",
      "-- Epoch 3288\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.737177, T: 561873168, Avg. loss: 0.064152\n",
      "Total training time: 275.61 seconds.\n",
      "-- Epoch 3289\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.735197, T: 562044054, Avg. loss: 0.064151\n",
      "Total training time: 275.70 seconds.\n",
      "-- Epoch 3290\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.733218, T: 562214940, Avg. loss: 0.064150\n",
      "Total training time: 275.79 seconds.\n",
      "-- Epoch 3291\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.731237, T: 562385826, Avg. loss: 0.064149\n",
      "Total training time: 275.87 seconds.\n",
      "-- Epoch 3292\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.729258, T: 562556712, Avg. loss: 0.064147\n",
      "Total training time: 275.95 seconds.\n",
      "-- Epoch 3293\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.727281, T: 562727598, Avg. loss: 0.064146\n",
      "Total training time: 276.03 seconds.\n",
      "-- Epoch 3294\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.725303, T: 562898484, Avg. loss: 0.064145\n",
      "Total training time: 276.11 seconds.\n",
      "-- Epoch 3295\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.723326, T: 563069370, Avg. loss: 0.064144\n",
      "Total training time: 276.20 seconds.\n",
      "-- Epoch 3296\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.721349, T: 563240256, Avg. loss: 0.064143\n",
      "Total training time: 276.28 seconds.\n",
      "-- Epoch 3297\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.719374, T: 563411142, Avg. loss: 0.064142\n",
      "Total training time: 276.37 seconds.\n",
      "-- Epoch 3298\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.717398, T: 563582028, Avg. loss: 0.064141\n",
      "Total training time: 276.45 seconds.\n",
      "-- Epoch 3299\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.715423, T: 563752914, Avg. loss: 0.064140\n",
      "Total training time: 276.54 seconds.\n",
      "-- Epoch 3300\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.713448, T: 563923800, Avg. loss: 0.064139\n",
      "Total training time: 276.63 seconds.\n",
      "-- Epoch 3301\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.711475, T: 564094686, Avg. loss: 0.064138\n",
      "Total training time: 276.71 seconds.\n",
      "-- Epoch 3302\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.709500, T: 564265572, Avg. loss: 0.064136\n",
      "Total training time: 276.79 seconds.\n",
      "-- Epoch 3303\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.707526, T: 564436458, Avg. loss: 0.064135\n",
      "Total training time: 276.87 seconds.\n",
      "-- Epoch 3304\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.705553, T: 564607344, Avg. loss: 0.064134\n",
      "Total training time: 276.95 seconds.\n",
      "-- Epoch 3305\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.703582, T: 564778230, Avg. loss: 0.064133\n",
      "Total training time: 277.04 seconds.\n",
      "-- Epoch 3306\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.701611, T: 564949116, Avg. loss: 0.064132\n",
      "Total training time: 277.12 seconds.\n",
      "-- Epoch 3307\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.699642, T: 565120002, Avg. loss: 0.064131\n",
      "Total training time: 277.21 seconds.\n",
      "-- Epoch 3308\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.697672, T: 565290888, Avg. loss: 0.064130\n",
      "Total training time: 277.29 seconds.\n",
      "-- Epoch 3309\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.695704, T: 565461774, Avg. loss: 0.064129\n",
      "Total training time: 277.37 seconds.\n",
      "-- Epoch 3310\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.693736, T: 565632660, Avg. loss: 0.064128\n",
      "Total training time: 277.45 seconds.\n",
      "-- Epoch 3311\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.691769, T: 565803546, Avg. loss: 0.064127\n",
      "Total training time: 277.54 seconds.\n",
      "-- Epoch 3312\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.689802, T: 565974432, Avg. loss: 0.064126\n",
      "Total training time: 277.62 seconds.\n",
      "-- Epoch 3313\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.687835, T: 566145318, Avg. loss: 0.064124\n",
      "Total training time: 277.71 seconds.\n",
      "-- Epoch 3314\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.685871, T: 566316204, Avg. loss: 0.064123\n",
      "Total training time: 277.79 seconds.\n",
      "-- Epoch 3315\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.683906, T: 566487090, Avg. loss: 0.064122\n",
      "Total training time: 277.87 seconds.\n",
      "-- Epoch 3316\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.681942, T: 566657976, Avg. loss: 0.064121\n",
      "Total training time: 277.96 seconds.\n",
      "-- Epoch 3317\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.679978, T: 566828862, Avg. loss: 0.064120\n",
      "Total training time: 278.04 seconds.\n",
      "-- Epoch 3318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.52, NNZs: 30, Bias: -119.678013, T: 566999748, Avg. loss: 0.064119\n",
      "Total training time: 278.12 seconds.\n",
      "-- Epoch 3319\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.676051, T: 567170634, Avg. loss: 0.064118\n",
      "Total training time: 278.20 seconds.\n",
      "-- Epoch 3320\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.674089, T: 567341520, Avg. loss: 0.064117\n",
      "Total training time: 278.29 seconds.\n",
      "-- Epoch 3321\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.672128, T: 567512406, Avg. loss: 0.064116\n",
      "Total training time: 278.37 seconds.\n",
      "-- Epoch 3322\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.670167, T: 567683292, Avg. loss: 0.064115\n",
      "Total training time: 278.46 seconds.\n",
      "-- Epoch 3323\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.668205, T: 567854178, Avg. loss: 0.064114\n",
      "Total training time: 278.54 seconds.\n",
      "-- Epoch 3324\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.666244, T: 568025064, Avg. loss: 0.064112\n",
      "Total training time: 278.63 seconds.\n",
      "-- Epoch 3325\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.664284, T: 568195950, Avg. loss: 0.064111\n",
      "Total training time: 278.71 seconds.\n",
      "-- Epoch 3326\n",
      "Norm: 13.52, NNZs: 30, Bias: -119.662325, T: 568366836, Avg. loss: 0.064110\n",
      "Total training time: 278.79 seconds.\n",
      "-- Epoch 3327\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.660366, T: 568537722, Avg. loss: 0.064109\n",
      "Total training time: 278.88 seconds.\n",
      "-- Epoch 3328\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.658408, T: 568708608, Avg. loss: 0.064108\n",
      "Total training time: 278.96 seconds.\n",
      "-- Epoch 3329\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.656450, T: 568879494, Avg. loss: 0.064107\n",
      "Total training time: 279.04 seconds.\n",
      "-- Epoch 3330\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.654494, T: 569050380, Avg. loss: 0.064106\n",
      "Total training time: 279.12 seconds.\n",
      "-- Epoch 3331\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.652539, T: 569221266, Avg. loss: 0.064105\n",
      "Total training time: 279.21 seconds.\n",
      "-- Epoch 3332\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.650584, T: 569392152, Avg. loss: 0.064104\n",
      "Total training time: 279.29 seconds.\n",
      "-- Epoch 3333\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.648630, T: 569563038, Avg. loss: 0.064103\n",
      "Total training time: 279.37 seconds.\n",
      "-- Epoch 3334\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.646675, T: 569733924, Avg. loss: 0.064102\n",
      "Total training time: 279.45 seconds.\n",
      "-- Epoch 3335\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.644721, T: 569904810, Avg. loss: 0.064100\n",
      "Total training time: 279.53 seconds.\n",
      "-- Epoch 3336\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.642768, T: 570075696, Avg. loss: 0.064099\n",
      "Total training time: 279.62 seconds.\n",
      "-- Epoch 3337\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.640818, T: 570246582, Avg. loss: 0.064098\n",
      "Total training time: 279.70 seconds.\n",
      "-- Epoch 3338\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.638866, T: 570417468, Avg. loss: 0.064097\n",
      "Total training time: 279.78 seconds.\n",
      "-- Epoch 3339\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.636918, T: 570588354, Avg. loss: 0.064096\n",
      "Total training time: 279.87 seconds.\n",
      "-- Epoch 3340\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.634967, T: 570759240, Avg. loss: 0.064095\n",
      "Total training time: 279.95 seconds.\n",
      "-- Epoch 3341\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.633019, T: 570930126, Avg. loss: 0.064094\n",
      "Total training time: 280.04 seconds.\n",
      "-- Epoch 3342\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.631069, T: 571101012, Avg. loss: 0.064093\n",
      "Total training time: 280.12 seconds.\n",
      "-- Epoch 3343\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.629120, T: 571271898, Avg. loss: 0.064092\n",
      "Total training time: 280.20 seconds.\n",
      "-- Epoch 3344\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.627172, T: 571442784, Avg. loss: 0.064091\n",
      "Total training time: 280.28 seconds.\n",
      "-- Epoch 3345\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.625223, T: 571613670, Avg. loss: 0.064090\n",
      "Total training time: 280.36 seconds.\n",
      "-- Epoch 3346\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.623278, T: 571784556, Avg. loss: 0.064089\n",
      "Total training time: 280.45 seconds.\n",
      "-- Epoch 3347\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.621330, T: 571955442, Avg. loss: 0.064087\n",
      "Total training time: 280.53 seconds.\n",
      "-- Epoch 3348\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.619384, T: 572126328, Avg. loss: 0.064086\n",
      "Total training time: 280.62 seconds.\n",
      "-- Epoch 3349\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.617440, T: 572297214, Avg. loss: 0.064085\n",
      "Total training time: 280.71 seconds.\n",
      "-- Epoch 3350\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.615494, T: 572468100, Avg. loss: 0.064084\n",
      "Total training time: 280.80 seconds.\n",
      "-- Epoch 3351\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.613549, T: 572638986, Avg. loss: 0.064083\n",
      "Total training time: 280.88 seconds.\n",
      "-- Epoch 3352\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.611606, T: 572809872, Avg. loss: 0.064082\n",
      "Total training time: 280.97 seconds.\n",
      "-- Epoch 3353\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.609664, T: 572980758, Avg. loss: 0.064081\n",
      "Total training time: 281.05 seconds.\n",
      "-- Epoch 3354\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.607720, T: 573151644, Avg. loss: 0.064080\n",
      "Total training time: 281.13 seconds.\n",
      "-- Epoch 3355\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.605777, T: 573322530, Avg. loss: 0.064079\n",
      "Total training time: 281.21 seconds.\n",
      "-- Epoch 3356\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.603836, T: 573493416, Avg. loss: 0.064078\n",
      "Total training time: 281.29 seconds.\n",
      "-- Epoch 3357\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.601895, T: 573664302, Avg. loss: 0.064077\n",
      "Total training time: 281.37 seconds.\n",
      "-- Epoch 3358\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.599957, T: 573835188, Avg. loss: 0.064076\n",
      "Total training time: 281.46 seconds.\n",
      "-- Epoch 3359\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.598018, T: 574006074, Avg. loss: 0.064075\n",
      "Total training time: 281.54 seconds.\n",
      "-- Epoch 3360\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.596079, T: 574176960, Avg. loss: 0.064073\n",
      "Total training time: 281.62 seconds.\n",
      "-- Epoch 3361\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.594141, T: 574347846, Avg. loss: 0.064072\n",
      "Total training time: 281.70 seconds.\n",
      "-- Epoch 3362\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.592201, T: 574518732, Avg. loss: 0.064071\n",
      "Total training time: 281.78 seconds.\n",
      "-- Epoch 3363\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.590264, T: 574689618, Avg. loss: 0.064070\n",
      "Total training time: 281.87 seconds.\n",
      "-- Epoch 3364\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.588328, T: 574860504, Avg. loss: 0.064069\n",
      "Total training time: 281.95 seconds.\n",
      "-- Epoch 3365\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.586393, T: 575031390, Avg. loss: 0.064068\n",
      "Total training time: 282.04 seconds.\n",
      "-- Epoch 3366\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.584457, T: 575202276, Avg. loss: 0.064067\n",
      "Total training time: 282.12 seconds.\n",
      "-- Epoch 3367\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.582524, T: 575373162, Avg. loss: 0.064066\n",
      "Total training time: 282.20 seconds.\n",
      "-- Epoch 3368\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.580591, T: 575544048, Avg. loss: 0.064065\n",
      "Total training time: 282.28 seconds.\n",
      "-- Epoch 3369\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.578657, T: 575714934, Avg. loss: 0.064064\n",
      "Total training time: 282.37 seconds.\n",
      "-- Epoch 3370\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.576722, T: 575885820, Avg. loss: 0.064063\n",
      "Total training time: 282.45 seconds.\n",
      "-- Epoch 3371\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.574790, T: 576056706, Avg. loss: 0.064062\n",
      "Total training time: 282.53 seconds.\n",
      "-- Epoch 3372\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.572860, T: 576227592, Avg. loss: 0.064061\n",
      "Total training time: 282.62 seconds.\n",
      "-- Epoch 3373\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.570929, T: 576398478, Avg. loss: 0.064060\n",
      "Total training time: 282.70 seconds.\n",
      "-- Epoch 3374\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.568998, T: 576569364, Avg. loss: 0.064058\n",
      "Total training time: 282.78 seconds.\n",
      "-- Epoch 3375\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.567066, T: 576740250, Avg. loss: 0.064057\n",
      "Total training time: 282.87 seconds.\n",
      "-- Epoch 3376\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.565140, T: 576911136, Avg. loss: 0.064056\n",
      "Total training time: 282.95 seconds.\n",
      "-- Epoch 3377\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.563210, T: 577082022, Avg. loss: 0.064055\n",
      "Total training time: 283.03 seconds.\n",
      "-- Epoch 3378\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.561282, T: 577252908, Avg. loss: 0.064054\n",
      "Total training time: 283.11 seconds.\n",
      "-- Epoch 3379\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.559355, T: 577423794, Avg. loss: 0.064053\n",
      "Total training time: 283.19 seconds.\n",
      "-- Epoch 3380\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.557428, T: 577594680, Avg. loss: 0.064052\n",
      "Total training time: 283.28 seconds.\n",
      "-- Epoch 3381\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.555502, T: 577765566, Avg. loss: 0.064051\n",
      "Total training time: 283.36 seconds.\n",
      "-- Epoch 3382\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.553576, T: 577936452, Avg. loss: 0.064050\n",
      "Total training time: 283.44 seconds.\n",
      "-- Epoch 3383\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.551651, T: 578107338, Avg. loss: 0.064049\n",
      "Total training time: 283.52 seconds.\n",
      "-- Epoch 3384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.51, NNZs: 30, Bias: -119.549726, T: 578278224, Avg. loss: 0.064048\n",
      "Total training time: 283.60 seconds.\n",
      "-- Epoch 3385\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.547802, T: 578449110, Avg. loss: 0.064047\n",
      "Total training time: 283.68 seconds.\n",
      "-- Epoch 3386\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.545878, T: 578619996, Avg. loss: 0.064046\n",
      "Total training time: 283.76 seconds.\n",
      "-- Epoch 3387\n",
      "Norm: 13.51, NNZs: 30, Bias: -119.543955, T: 578790882, Avg. loss: 0.064045\n",
      "Total training time: 283.85 seconds.\n",
      "-- Epoch 3388\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.542032, T: 578961768, Avg. loss: 0.064043\n",
      "Total training time: 283.94 seconds.\n",
      "-- Epoch 3389\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.540110, T: 579132654, Avg. loss: 0.064042\n",
      "Total training time: 284.03 seconds.\n",
      "-- Epoch 3390\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.538191, T: 579303540, Avg. loss: 0.064041\n",
      "Total training time: 284.13 seconds.\n",
      "-- Epoch 3391\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.536271, T: 579474426, Avg. loss: 0.064040\n",
      "Total training time: 284.21 seconds.\n",
      "-- Epoch 3392\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.534350, T: 579645312, Avg. loss: 0.064039\n",
      "Total training time: 284.30 seconds.\n",
      "-- Epoch 3393\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.532430, T: 579816198, Avg. loss: 0.064038\n",
      "Total training time: 284.38 seconds.\n",
      "-- Epoch 3394\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.530511, T: 579987084, Avg. loss: 0.064037\n",
      "Total training time: 284.47 seconds.\n",
      "-- Epoch 3395\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.528593, T: 580157970, Avg. loss: 0.064036\n",
      "Total training time: 284.55 seconds.\n",
      "-- Epoch 3396\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.526676, T: 580328856, Avg. loss: 0.064035\n",
      "Total training time: 284.63 seconds.\n",
      "-- Epoch 3397\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.524760, T: 580499742, Avg. loss: 0.064034\n",
      "Total training time: 284.72 seconds.\n",
      "-- Epoch 3398\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.522844, T: 580670628, Avg. loss: 0.064033\n",
      "Total training time: 284.80 seconds.\n",
      "-- Epoch 3399\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.520928, T: 580841514, Avg. loss: 0.064032\n",
      "Total training time: 284.88 seconds.\n",
      "-- Epoch 3400\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.519013, T: 581012400, Avg. loss: 0.064031\n",
      "Total training time: 284.96 seconds.\n",
      "-- Epoch 3401\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.517096, T: 581183286, Avg. loss: 0.064030\n",
      "Total training time: 285.04 seconds.\n",
      "-- Epoch 3402\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.515182, T: 581354172, Avg. loss: 0.064029\n",
      "Total training time: 285.12 seconds.\n",
      "-- Epoch 3403\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.513268, T: 581525058, Avg. loss: 0.064027\n",
      "Total training time: 285.21 seconds.\n",
      "-- Epoch 3404\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.511356, T: 581695944, Avg. loss: 0.064026\n",
      "Total training time: 285.28 seconds.\n",
      "-- Epoch 3405\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.509444, T: 581866830, Avg. loss: 0.064025\n",
      "Total training time: 285.37 seconds.\n",
      "-- Epoch 3406\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.507532, T: 582037716, Avg. loss: 0.064024\n",
      "Total training time: 285.45 seconds.\n",
      "-- Epoch 3407\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.505621, T: 582208602, Avg. loss: 0.064023\n",
      "Total training time: 285.53 seconds.\n",
      "-- Epoch 3408\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.503710, T: 582379488, Avg. loss: 0.064022\n",
      "Total training time: 285.61 seconds.\n",
      "-- Epoch 3409\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.501800, T: 582550374, Avg. loss: 0.064021\n",
      "Total training time: 285.69 seconds.\n",
      "-- Epoch 3410\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.499890, T: 582721260, Avg. loss: 0.064020\n",
      "Total training time: 285.78 seconds.\n",
      "-- Epoch 3411\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.497980, T: 582892146, Avg. loss: 0.064019\n",
      "Total training time: 285.86 seconds.\n",
      "-- Epoch 3412\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.496071, T: 583063032, Avg. loss: 0.064018\n",
      "Total training time: 285.94 seconds.\n",
      "-- Epoch 3413\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.494163, T: 583233918, Avg. loss: 0.064017\n",
      "Total training time: 286.02 seconds.\n",
      "-- Epoch 3414\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.492255, T: 583404804, Avg. loss: 0.064016\n",
      "Total training time: 286.10 seconds.\n",
      "-- Epoch 3415\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.490348, T: 583575690, Avg. loss: 0.064015\n",
      "Total training time: 286.18 seconds.\n",
      "-- Epoch 3416\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.488442, T: 583746576, Avg. loss: 0.064014\n",
      "Total training time: 286.26 seconds.\n",
      "-- Epoch 3417\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.486535, T: 583917462, Avg. loss: 0.064013\n",
      "Total training time: 286.35 seconds.\n",
      "-- Epoch 3418\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.484629, T: 584088348, Avg. loss: 0.064012\n",
      "Total training time: 286.43 seconds.\n",
      "-- Epoch 3419\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.482722, T: 584259234, Avg. loss: 0.064011\n",
      "Total training time: 286.51 seconds.\n",
      "-- Epoch 3420\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.480817, T: 584430120, Avg. loss: 0.064009\n",
      "Total training time: 286.60 seconds.\n",
      "-- Epoch 3421\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.478913, T: 584601006, Avg. loss: 0.064008\n",
      "Total training time: 286.68 seconds.\n",
      "-- Epoch 3422\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.477009, T: 584771892, Avg. loss: 0.064007\n",
      "Total training time: 286.76 seconds.\n",
      "-- Epoch 3423\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.475106, T: 584942778, Avg. loss: 0.064006\n",
      "Total training time: 286.85 seconds.\n",
      "-- Epoch 3424\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.473205, T: 585113664, Avg. loss: 0.064005\n",
      "Total training time: 286.93 seconds.\n",
      "-- Epoch 3425\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.471303, T: 585284550, Avg. loss: 0.064004\n",
      "Total training time: 287.01 seconds.\n",
      "-- Epoch 3426\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.469402, T: 585455436, Avg. loss: 0.064003\n",
      "Total training time: 287.09 seconds.\n",
      "-- Epoch 3427\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.467502, T: 585626322, Avg. loss: 0.064002\n",
      "Total training time: 287.17 seconds.\n",
      "-- Epoch 3428\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.465601, T: 585797208, Avg. loss: 0.064001\n",
      "Total training time: 287.25 seconds.\n",
      "-- Epoch 3429\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.463702, T: 585968094, Avg. loss: 0.064000\n",
      "Total training time: 287.33 seconds.\n",
      "-- Epoch 3430\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.461803, T: 586138980, Avg. loss: 0.063999\n",
      "Total training time: 287.42 seconds.\n",
      "-- Epoch 3431\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.459905, T: 586309866, Avg. loss: 0.063998\n",
      "Total training time: 287.50 seconds.\n",
      "-- Epoch 3432\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.458008, T: 586480752, Avg. loss: 0.063997\n",
      "Total training time: 287.58 seconds.\n",
      "-- Epoch 3433\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.456110, T: 586651638, Avg. loss: 0.063996\n",
      "Total training time: 287.66 seconds.\n",
      "-- Epoch 3434\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.454215, T: 586822524, Avg. loss: 0.063995\n",
      "Total training time: 287.75 seconds.\n",
      "-- Epoch 3435\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.452317, T: 586993410, Avg. loss: 0.063994\n",
      "Total training time: 287.83 seconds.\n",
      "-- Epoch 3436\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.450421, T: 587164296, Avg. loss: 0.063993\n",
      "Total training time: 287.91 seconds.\n",
      "-- Epoch 3437\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.448527, T: 587335182, Avg. loss: 0.063992\n",
      "Total training time: 287.99 seconds.\n",
      "-- Epoch 3438\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.446633, T: 587506068, Avg. loss: 0.063990\n",
      "Total training time: 288.07 seconds.\n",
      "-- Epoch 3439\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.444739, T: 587676954, Avg. loss: 0.063989\n",
      "Total training time: 288.15 seconds.\n",
      "-- Epoch 3440\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.442845, T: 587847840, Avg. loss: 0.063988\n",
      "Total training time: 288.23 seconds.\n",
      "-- Epoch 3441\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.440953, T: 588018726, Avg. loss: 0.063987\n",
      "Total training time: 288.31 seconds.\n",
      "-- Epoch 3442\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.439062, T: 588189612, Avg. loss: 0.063986\n",
      "Total training time: 288.40 seconds.\n",
      "-- Epoch 3443\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.437170, T: 588360498, Avg. loss: 0.063985\n",
      "Total training time: 288.48 seconds.\n",
      "-- Epoch 3444\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.435279, T: 588531384, Avg. loss: 0.063984\n",
      "Total training time: 288.56 seconds.\n",
      "-- Epoch 3445\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.433389, T: 588702270, Avg. loss: 0.063983\n",
      "Total training time: 288.64 seconds.\n",
      "-- Epoch 3446\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.431499, T: 588873156, Avg. loss: 0.063982\n",
      "Total training time: 288.72 seconds.\n",
      "-- Epoch 3447\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.429610, T: 589044042, Avg. loss: 0.063981\n",
      "Total training time: 288.81 seconds.\n",
      "-- Epoch 3448\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.427723, T: 589214928, Avg. loss: 0.063980\n",
      "Total training time: 288.89 seconds.\n",
      "-- Epoch 3449\n",
      "Norm: 13.50, NNZs: 30, Bias: -119.425835, T: 589385814, Avg. loss: 0.063979\n",
      "Total training time: 288.97 seconds.\n",
      "-- Epoch 3450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.49, NNZs: 30, Bias: -119.423949, T: 589556700, Avg. loss: 0.063978\n",
      "Total training time: 289.05 seconds.\n",
      "-- Epoch 3451\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.422062, T: 589727586, Avg. loss: 0.063977\n",
      "Total training time: 289.13 seconds.\n",
      "-- Epoch 3452\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.420177, T: 589898472, Avg. loss: 0.063976\n",
      "Total training time: 289.22 seconds.\n",
      "-- Epoch 3453\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.418291, T: 590069358, Avg. loss: 0.063975\n",
      "Total training time: 289.30 seconds.\n",
      "-- Epoch 3454\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.416406, T: 590240244, Avg. loss: 0.063974\n",
      "Total training time: 289.38 seconds.\n",
      "-- Epoch 3455\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.414522, T: 590411130, Avg. loss: 0.063973\n",
      "Total training time: 289.46 seconds.\n",
      "-- Epoch 3456\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.412639, T: 590582016, Avg. loss: 0.063972\n",
      "Total training time: 289.55 seconds.\n",
      "-- Epoch 3457\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.410755, T: 590752902, Avg. loss: 0.063971\n",
      "Total training time: 289.63 seconds.\n",
      "-- Epoch 3458\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.408872, T: 590923788, Avg. loss: 0.063970\n",
      "Total training time: 289.71 seconds.\n",
      "-- Epoch 3459\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.406989, T: 591094674, Avg. loss: 0.063968\n",
      "Total training time: 289.79 seconds.\n",
      "-- Epoch 3460\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.405107, T: 591265560, Avg. loss: 0.063967\n",
      "Total training time: 289.87 seconds.\n",
      "-- Epoch 3461\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.403226, T: 591436446, Avg. loss: 0.063966\n",
      "Total training time: 289.96 seconds.\n",
      "-- Epoch 3462\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.401345, T: 591607332, Avg. loss: 0.063965\n",
      "Total training time: 290.04 seconds.\n",
      "-- Epoch 3463\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.399465, T: 591778218, Avg. loss: 0.063964\n",
      "Total training time: 290.12 seconds.\n",
      "-- Epoch 3464\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.397585, T: 591949104, Avg. loss: 0.063963\n",
      "Total training time: 290.20 seconds.\n",
      "-- Epoch 3465\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.395703, T: 592119990, Avg. loss: 0.063962\n",
      "Total training time: 290.28 seconds.\n",
      "-- Epoch 3466\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.393826, T: 592290876, Avg. loss: 0.063961\n",
      "Total training time: 290.37 seconds.\n",
      "-- Epoch 3467\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.391948, T: 592461762, Avg. loss: 0.063960\n",
      "Total training time: 290.45 seconds.\n",
      "-- Epoch 3468\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.390070, T: 592632648, Avg. loss: 0.063959\n",
      "Total training time: 290.53 seconds.\n",
      "-- Epoch 3469\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.388192, T: 592803534, Avg. loss: 0.063958\n",
      "Total training time: 290.61 seconds.\n",
      "-- Epoch 3470\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.386317, T: 592974420, Avg. loss: 0.063957\n",
      "Total training time: 290.70 seconds.\n",
      "-- Epoch 3471\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.384441, T: 593145306, Avg. loss: 0.063956\n",
      "Total training time: 290.78 seconds.\n",
      "-- Epoch 3472\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.382566, T: 593316192, Avg. loss: 0.063955\n",
      "Total training time: 290.87 seconds.\n",
      "-- Epoch 3473\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.380691, T: 593487078, Avg. loss: 0.063954\n",
      "Total training time: 290.96 seconds.\n",
      "-- Epoch 3474\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.378816, T: 593657964, Avg. loss: 0.063953\n",
      "Total training time: 291.05 seconds.\n",
      "-- Epoch 3475\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.376944, T: 593828850, Avg. loss: 0.063952\n",
      "Total training time: 291.14 seconds.\n",
      "-- Epoch 3476\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.375070, T: 593999736, Avg. loss: 0.063951\n",
      "Total training time: 291.23 seconds.\n",
      "-- Epoch 3477\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.373197, T: 594170622, Avg. loss: 0.063950\n",
      "Total training time: 291.32 seconds.\n",
      "-- Epoch 3478\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.371324, T: 594341508, Avg. loss: 0.063949\n",
      "Total training time: 291.40 seconds.\n",
      "-- Epoch 3479\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.369452, T: 594512394, Avg. loss: 0.063948\n",
      "Total training time: 291.49 seconds.\n",
      "-- Epoch 3480\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.367580, T: 594683280, Avg. loss: 0.063947\n",
      "Total training time: 291.57 seconds.\n",
      "-- Epoch 3481\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.365710, T: 594854166, Avg. loss: 0.063946\n",
      "Total training time: 291.65 seconds.\n",
      "-- Epoch 3482\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.363838, T: 595025052, Avg. loss: 0.063945\n",
      "Total training time: 291.74 seconds.\n",
      "-- Epoch 3483\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.361968, T: 595195938, Avg. loss: 0.063943\n",
      "Total training time: 291.83 seconds.\n",
      "-- Epoch 3484\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.360099, T: 595366824, Avg. loss: 0.063942\n",
      "Total training time: 291.91 seconds.\n",
      "-- Epoch 3485\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.358231, T: 595537710, Avg. loss: 0.063941\n",
      "Total training time: 291.99 seconds.\n",
      "-- Epoch 3486\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.356364, T: 595708596, Avg. loss: 0.063940\n",
      "Total training time: 292.08 seconds.\n",
      "-- Epoch 3487\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.354496, T: 595879482, Avg. loss: 0.063939\n",
      "Total training time: 292.16 seconds.\n",
      "-- Epoch 3488\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.352628, T: 596050368, Avg. loss: 0.063938\n",
      "Total training time: 292.25 seconds.\n",
      "-- Epoch 3489\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.350763, T: 596221254, Avg. loss: 0.063937\n",
      "Total training time: 292.33 seconds.\n",
      "-- Epoch 3490\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.348898, T: 596392140, Avg. loss: 0.063936\n",
      "Total training time: 292.41 seconds.\n",
      "-- Epoch 3491\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.347033, T: 596563026, Avg. loss: 0.063935\n",
      "Total training time: 292.49 seconds.\n",
      "-- Epoch 3492\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.345167, T: 596733912, Avg. loss: 0.063934\n",
      "Total training time: 292.58 seconds.\n",
      "-- Epoch 3493\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.343302, T: 596904798, Avg. loss: 0.063933\n",
      "Total training time: 292.66 seconds.\n",
      "-- Epoch 3494\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.341437, T: 597075684, Avg. loss: 0.063932\n",
      "Total training time: 292.75 seconds.\n",
      "-- Epoch 3495\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.339573, T: 597246570, Avg. loss: 0.063931\n",
      "Total training time: 292.83 seconds.\n",
      "-- Epoch 3496\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.337710, T: 597417456, Avg. loss: 0.063930\n",
      "Total training time: 292.91 seconds.\n",
      "-- Epoch 3497\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.335847, T: 597588342, Avg. loss: 0.063929\n",
      "Total training time: 293.00 seconds.\n",
      "-- Epoch 3498\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.333986, T: 597759228, Avg. loss: 0.063928\n",
      "Total training time: 293.12 seconds.\n",
      "-- Epoch 3499\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.332124, T: 597930114, Avg. loss: 0.063927\n",
      "Total training time: 293.24 seconds.\n",
      "-- Epoch 3500\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.330262, T: 598101000, Avg. loss: 0.063926\n",
      "Total training time: 293.32 seconds.\n",
      "-- Epoch 3501\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.328403, T: 598271886, Avg. loss: 0.063925\n",
      "Total training time: 293.40 seconds.\n",
      "-- Epoch 3502\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.326542, T: 598442772, Avg. loss: 0.063924\n",
      "Total training time: 293.48 seconds.\n",
      "-- Epoch 3503\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.324683, T: 598613658, Avg. loss: 0.063923\n",
      "Total training time: 293.57 seconds.\n",
      "-- Epoch 3504\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.322825, T: 598784544, Avg. loss: 0.063922\n",
      "Total training time: 293.65 seconds.\n",
      "-- Epoch 3505\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.320968, T: 598955430, Avg. loss: 0.063921\n",
      "Total training time: 293.73 seconds.\n",
      "-- Epoch 3506\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.319111, T: 599126316, Avg. loss: 0.063920\n",
      "Total training time: 293.81 seconds.\n",
      "-- Epoch 3507\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.317255, T: 599297202, Avg. loss: 0.063919\n",
      "Total training time: 293.89 seconds.\n",
      "-- Epoch 3508\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.315399, T: 599468088, Avg. loss: 0.063918\n",
      "Total training time: 293.97 seconds.\n",
      "-- Epoch 3509\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.313542, T: 599638974, Avg. loss: 0.063917\n",
      "Total training time: 294.04 seconds.\n",
      "-- Epoch 3510\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.311686, T: 599809860, Avg. loss: 0.063916\n",
      "Total training time: 294.12 seconds.\n",
      "-- Epoch 3511\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.309832, T: 599980746, Avg. loss: 0.063915\n",
      "Total training time: 294.20 seconds.\n",
      "-- Epoch 3512\n",
      "Norm: 13.49, NNZs: 30, Bias: -119.307979, T: 600151632, Avg. loss: 0.063914\n",
      "Total training time: 294.28 seconds.\n",
      "-- Epoch 3513\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.306126, T: 600322518, Avg. loss: 0.063912\n",
      "Total training time: 294.36 seconds.\n",
      "-- Epoch 3514\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.304275, T: 600493404, Avg. loss: 0.063911\n",
      "Total training time: 294.43 seconds.\n",
      "-- Epoch 3515\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.302421, T: 600664290, Avg. loss: 0.063910\n",
      "Total training time: 294.51 seconds.\n",
      "-- Epoch 3516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.48, NNZs: 30, Bias: -119.300570, T: 600835176, Avg. loss: 0.063909\n",
      "Total training time: 294.59 seconds.\n",
      "-- Epoch 3517\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.298719, T: 601006062, Avg. loss: 0.063908\n",
      "Total training time: 294.67 seconds.\n",
      "-- Epoch 3518\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.296868, T: 601176948, Avg. loss: 0.063907\n",
      "Total training time: 294.75 seconds.\n",
      "-- Epoch 3519\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.295016, T: 601347834, Avg. loss: 0.063906\n",
      "Total training time: 294.83 seconds.\n",
      "-- Epoch 3520\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.293167, T: 601518720, Avg. loss: 0.063905\n",
      "Total training time: 294.91 seconds.\n",
      "-- Epoch 3521\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.291318, T: 601689606, Avg. loss: 0.063904\n",
      "Total training time: 294.99 seconds.\n",
      "-- Epoch 3522\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.289468, T: 601860492, Avg. loss: 0.063903\n",
      "Total training time: 295.06 seconds.\n",
      "-- Epoch 3523\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.287620, T: 602031378, Avg. loss: 0.063902\n",
      "Total training time: 295.14 seconds.\n",
      "-- Epoch 3524\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.285771, T: 602202264, Avg. loss: 0.063901\n",
      "Total training time: 295.22 seconds.\n",
      "-- Epoch 3525\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.283924, T: 602373150, Avg. loss: 0.063900\n",
      "Total training time: 295.29 seconds.\n",
      "-- Epoch 3526\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.282078, T: 602544036, Avg. loss: 0.063899\n",
      "Total training time: 295.37 seconds.\n",
      "-- Epoch 3527\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.280232, T: 602714922, Avg. loss: 0.063898\n",
      "Total training time: 295.45 seconds.\n",
      "-- Epoch 3528\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.278386, T: 602885808, Avg. loss: 0.063897\n",
      "Total training time: 295.53 seconds.\n",
      "-- Epoch 3529\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.276541, T: 603056694, Avg. loss: 0.063896\n",
      "Total training time: 295.61 seconds.\n",
      "-- Epoch 3530\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.274697, T: 603227580, Avg. loss: 0.063895\n",
      "Total training time: 295.69 seconds.\n",
      "-- Epoch 3531\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.272853, T: 603398466, Avg. loss: 0.063894\n",
      "Total training time: 295.76 seconds.\n",
      "-- Epoch 3532\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.271010, T: 603569352, Avg. loss: 0.063893\n",
      "Total training time: 295.84 seconds.\n",
      "-- Epoch 3533\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.269167, T: 603740238, Avg. loss: 0.063892\n",
      "Total training time: 295.91 seconds.\n",
      "-- Epoch 3534\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.267326, T: 603911124, Avg. loss: 0.063891\n",
      "Total training time: 295.99 seconds.\n",
      "-- Epoch 3535\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.265484, T: 604082010, Avg. loss: 0.063890\n",
      "Total training time: 296.07 seconds.\n",
      "-- Epoch 3536\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.263643, T: 604252896, Avg. loss: 0.063889\n",
      "Total training time: 296.14 seconds.\n",
      "-- Epoch 3537\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.261802, T: 604423782, Avg. loss: 0.063888\n",
      "Total training time: 296.22 seconds.\n",
      "-- Epoch 3538\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.259962, T: 604594668, Avg. loss: 0.063887\n",
      "Total training time: 296.30 seconds.\n",
      "-- Epoch 3539\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.258122, T: 604765554, Avg. loss: 0.063886\n",
      "Total training time: 296.38 seconds.\n",
      "-- Epoch 3540\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.256284, T: 604936440, Avg. loss: 0.063885\n",
      "Total training time: 296.45 seconds.\n",
      "-- Epoch 3541\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.254445, T: 605107326, Avg. loss: 0.063884\n",
      "Total training time: 296.53 seconds.\n",
      "-- Epoch 3542\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.252606, T: 605278212, Avg. loss: 0.063883\n",
      "Total training time: 296.61 seconds.\n",
      "-- Epoch 3543\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.250768, T: 605449098, Avg. loss: 0.063882\n",
      "Total training time: 296.69 seconds.\n",
      "-- Epoch 3544\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.248931, T: 605619984, Avg. loss: 0.063881\n",
      "Total training time: 296.77 seconds.\n",
      "-- Epoch 3545\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.247094, T: 605790870, Avg. loss: 0.063880\n",
      "Total training time: 296.84 seconds.\n",
      "-- Epoch 3546\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.245259, T: 605961756, Avg. loss: 0.063879\n",
      "Total training time: 296.92 seconds.\n",
      "-- Epoch 3547\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.243424, T: 606132642, Avg. loss: 0.063878\n",
      "Total training time: 297.00 seconds.\n",
      "-- Epoch 3548\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.241588, T: 606303528, Avg. loss: 0.063877\n",
      "Total training time: 297.08 seconds.\n",
      "-- Epoch 3549\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.239755, T: 606474414, Avg. loss: 0.063876\n",
      "Total training time: 297.15 seconds.\n",
      "-- Epoch 3550\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.237922, T: 606645300, Avg. loss: 0.063875\n",
      "Total training time: 297.23 seconds.\n",
      "-- Epoch 3551\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.236089, T: 606816186, Avg. loss: 0.063874\n",
      "Total training time: 297.31 seconds.\n",
      "-- Epoch 3552\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.234255, T: 606987072, Avg. loss: 0.063873\n",
      "Total training time: 297.39 seconds.\n",
      "-- Epoch 3553\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.232422, T: 607157958, Avg. loss: 0.063872\n",
      "Total training time: 297.47 seconds.\n",
      "-- Epoch 3554\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.230591, T: 607328844, Avg. loss: 0.063871\n",
      "Total training time: 297.55 seconds.\n",
      "-- Epoch 3555\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.228760, T: 607499730, Avg. loss: 0.063870\n",
      "Total training time: 297.63 seconds.\n",
      "-- Epoch 3556\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.226929, T: 607670616, Avg. loss: 0.063869\n",
      "Total training time: 297.70 seconds.\n",
      "-- Epoch 3557\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.225098, T: 607841502, Avg. loss: 0.063868\n",
      "Total training time: 297.78 seconds.\n",
      "-- Epoch 3558\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.223270, T: 608012388, Avg. loss: 0.063867\n",
      "Total training time: 297.86 seconds.\n",
      "-- Epoch 3559\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.221440, T: 608183274, Avg. loss: 0.063865\n",
      "Total training time: 297.94 seconds.\n",
      "-- Epoch 3560\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.219613, T: 608354160, Avg. loss: 0.063864\n",
      "Total training time: 298.01 seconds.\n",
      "-- Epoch 3561\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.217784, T: 608525046, Avg. loss: 0.063863\n",
      "Total training time: 298.09 seconds.\n",
      "-- Epoch 3562\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.215957, T: 608695932, Avg. loss: 0.063862\n",
      "Total training time: 298.17 seconds.\n",
      "-- Epoch 3563\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.214130, T: 608866818, Avg. loss: 0.063861\n",
      "Total training time: 298.24 seconds.\n",
      "-- Epoch 3564\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.212303, T: 609037704, Avg. loss: 0.063860\n",
      "Total training time: 298.32 seconds.\n",
      "-- Epoch 3565\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.210477, T: 609208590, Avg. loss: 0.063859\n",
      "Total training time: 298.40 seconds.\n",
      "-- Epoch 3566\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.208651, T: 609379476, Avg. loss: 0.063858\n",
      "Total training time: 298.48 seconds.\n",
      "-- Epoch 3567\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.206826, T: 609550362, Avg. loss: 0.063857\n",
      "Total training time: 298.56 seconds.\n",
      "-- Epoch 3568\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.205001, T: 609721248, Avg. loss: 0.063856\n",
      "Total training time: 298.63 seconds.\n",
      "-- Epoch 3569\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.203177, T: 609892134, Avg. loss: 0.063855\n",
      "Total training time: 298.71 seconds.\n",
      "-- Epoch 3570\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.201353, T: 610063020, Avg. loss: 0.063854\n",
      "Total training time: 298.79 seconds.\n",
      "-- Epoch 3571\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.199530, T: 610233906, Avg. loss: 0.063853\n",
      "Total training time: 298.86 seconds.\n",
      "-- Epoch 3572\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.197707, T: 610404792, Avg. loss: 0.063852\n",
      "Total training time: 298.94 seconds.\n",
      "-- Epoch 3573\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.195884, T: 610575678, Avg. loss: 0.063851\n",
      "Total training time: 299.02 seconds.\n",
      "-- Epoch 3574\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.194062, T: 610746564, Avg. loss: 0.063850\n",
      "Total training time: 299.10 seconds.\n",
      "-- Epoch 3575\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.192242, T: 610917450, Avg. loss: 0.063849\n",
      "Total training time: 299.17 seconds.\n",
      "-- Epoch 3576\n",
      "Norm: 13.48, NNZs: 30, Bias: -119.190421, T: 611088336, Avg. loss: 0.063848\n",
      "Total training time: 299.25 seconds.\n",
      "-- Epoch 3577\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.188601, T: 611259222, Avg. loss: 0.063847\n",
      "Total training time: 299.33 seconds.\n",
      "-- Epoch 3578\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.186782, T: 611430108, Avg. loss: 0.063846\n",
      "Total training time: 299.40 seconds.\n",
      "-- Epoch 3579\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.184963, T: 611600994, Avg. loss: 0.063845\n",
      "Total training time: 299.48 seconds.\n",
      "-- Epoch 3580\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.183143, T: 611771880, Avg. loss: 0.063844\n",
      "Total training time: 299.56 seconds.\n",
      "-- Epoch 3581\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.181324, T: 611942766, Avg. loss: 0.063843\n",
      "Total training time: 299.63 seconds.\n",
      "-- Epoch 3582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.47, NNZs: 30, Bias: -119.179507, T: 612113652, Avg. loss: 0.063842\n",
      "Total training time: 299.71 seconds.\n",
      "-- Epoch 3583\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.177691, T: 612284538, Avg. loss: 0.063841\n",
      "Total training time: 299.79 seconds.\n",
      "-- Epoch 3584\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.175874, T: 612455424, Avg. loss: 0.063840\n",
      "Total training time: 299.86 seconds.\n",
      "-- Epoch 3585\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.174059, T: 612626310, Avg. loss: 0.063839\n",
      "Total training time: 299.94 seconds.\n",
      "-- Epoch 3586\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.172245, T: 612797196, Avg. loss: 0.063838\n",
      "Total training time: 300.02 seconds.\n",
      "-- Epoch 3587\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.170431, T: 612968082, Avg. loss: 0.063837\n",
      "Total training time: 300.09 seconds.\n",
      "-- Epoch 3588\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.168617, T: 613138968, Avg. loss: 0.063836\n",
      "Total training time: 300.17 seconds.\n",
      "-- Epoch 3589\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.166802, T: 613309854, Avg. loss: 0.063835\n",
      "Total training time: 300.25 seconds.\n",
      "-- Epoch 3590\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.164989, T: 613480740, Avg. loss: 0.063834\n",
      "Total training time: 300.33 seconds.\n",
      "-- Epoch 3591\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.163177, T: 613651626, Avg. loss: 0.063833\n",
      "Total training time: 300.41 seconds.\n",
      "-- Epoch 3592\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.161364, T: 613822512, Avg. loss: 0.063832\n",
      "Total training time: 300.48 seconds.\n",
      "-- Epoch 3593\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.159552, T: 613993398, Avg. loss: 0.063831\n",
      "Total training time: 300.56 seconds.\n",
      "-- Epoch 3594\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.157739, T: 614164284, Avg. loss: 0.063830\n",
      "Total training time: 300.64 seconds.\n",
      "-- Epoch 3595\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.155928, T: 614335170, Avg. loss: 0.063829\n",
      "Total training time: 300.72 seconds.\n",
      "-- Epoch 3596\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.154117, T: 614506056, Avg. loss: 0.063828\n",
      "Total training time: 300.80 seconds.\n",
      "-- Epoch 3597\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.152309, T: 614676942, Avg. loss: 0.063827\n",
      "Total training time: 300.88 seconds.\n",
      "-- Epoch 3598\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.150501, T: 614847828, Avg. loss: 0.063826\n",
      "Total training time: 300.96 seconds.\n",
      "-- Epoch 3599\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.148692, T: 615018714, Avg. loss: 0.063825\n",
      "Total training time: 301.04 seconds.\n",
      "-- Epoch 3600\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.146883, T: 615189600, Avg. loss: 0.063824\n",
      "Total training time: 301.12 seconds.\n",
      "-- Epoch 3601\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.145076, T: 615360486, Avg. loss: 0.063823\n",
      "Total training time: 301.19 seconds.\n",
      "-- Epoch 3602\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.143268, T: 615531372, Avg. loss: 0.063822\n",
      "Total training time: 301.27 seconds.\n",
      "-- Epoch 3603\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.141462, T: 615702258, Avg. loss: 0.063821\n",
      "Total training time: 301.35 seconds.\n",
      "-- Epoch 3604\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.139655, T: 615873144, Avg. loss: 0.063820\n",
      "Total training time: 301.42 seconds.\n",
      "-- Epoch 3605\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.137849, T: 616044030, Avg. loss: 0.063819\n",
      "Total training time: 301.50 seconds.\n",
      "-- Epoch 3606\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.136043, T: 616214916, Avg. loss: 0.063818\n",
      "Total training time: 301.58 seconds.\n",
      "-- Epoch 3607\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.134239, T: 616385802, Avg. loss: 0.063817\n",
      "Total training time: 301.66 seconds.\n",
      "-- Epoch 3608\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.132435, T: 616556688, Avg. loss: 0.063816\n",
      "Total training time: 301.74 seconds.\n",
      "-- Epoch 3609\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.130632, T: 616727574, Avg. loss: 0.063815\n",
      "Total training time: 301.82 seconds.\n",
      "-- Epoch 3610\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.128830, T: 616898460, Avg. loss: 0.063814\n",
      "Total training time: 301.89 seconds.\n",
      "-- Epoch 3611\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.127028, T: 617069346, Avg. loss: 0.063813\n",
      "Total training time: 301.97 seconds.\n",
      "-- Epoch 3612\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.125225, T: 617240232, Avg. loss: 0.063812\n",
      "Total training time: 302.05 seconds.\n",
      "-- Epoch 3613\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.123425, T: 617411118, Avg. loss: 0.063811\n",
      "Total training time: 302.13 seconds.\n",
      "-- Epoch 3614\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.121624, T: 617582004, Avg. loss: 0.063810\n",
      "Total training time: 302.20 seconds.\n",
      "-- Epoch 3615\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.119825, T: 617752890, Avg. loss: 0.063809\n",
      "Total training time: 302.28 seconds.\n",
      "-- Epoch 3616\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.118025, T: 617923776, Avg. loss: 0.063808\n",
      "Total training time: 302.36 seconds.\n",
      "-- Epoch 3617\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.116226, T: 618094662, Avg. loss: 0.063807\n",
      "Total training time: 302.43 seconds.\n",
      "-- Epoch 3618\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.114425, T: 618265548, Avg. loss: 0.063806\n",
      "Total training time: 302.51 seconds.\n",
      "-- Epoch 3619\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.112626, T: 618436434, Avg. loss: 0.063805\n",
      "Total training time: 302.59 seconds.\n",
      "-- Epoch 3620\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.110828, T: 618607320, Avg. loss: 0.063804\n",
      "Total training time: 302.66 seconds.\n",
      "-- Epoch 3621\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.109028, T: 618778206, Avg. loss: 0.063803\n",
      "Total training time: 302.74 seconds.\n",
      "-- Epoch 3622\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.107230, T: 618949092, Avg. loss: 0.063802\n",
      "Total training time: 302.83 seconds.\n",
      "-- Epoch 3623\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.105432, T: 619119978, Avg. loss: 0.063801\n",
      "Total training time: 302.91 seconds.\n",
      "-- Epoch 3624\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.103637, T: 619290864, Avg. loss: 0.063800\n",
      "Total training time: 302.99 seconds.\n",
      "-- Epoch 3625\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.101841, T: 619461750, Avg. loss: 0.063799\n",
      "Total training time: 303.07 seconds.\n",
      "-- Epoch 3626\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.100046, T: 619632636, Avg. loss: 0.063798\n",
      "Total training time: 303.15 seconds.\n",
      "-- Epoch 3627\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.098252, T: 619803522, Avg. loss: 0.063797\n",
      "Total training time: 303.23 seconds.\n",
      "-- Epoch 3628\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.096457, T: 619974408, Avg. loss: 0.063796\n",
      "Total training time: 303.31 seconds.\n",
      "-- Epoch 3629\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.094664, T: 620145294, Avg. loss: 0.063795\n",
      "Total training time: 303.39 seconds.\n",
      "-- Epoch 3630\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.092871, T: 620316180, Avg. loss: 0.063794\n",
      "Total training time: 303.46 seconds.\n",
      "-- Epoch 3631\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.091078, T: 620487066, Avg. loss: 0.063793\n",
      "Total training time: 303.54 seconds.\n",
      "-- Epoch 3632\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.089287, T: 620657952, Avg. loss: 0.063792\n",
      "Total training time: 303.62 seconds.\n",
      "-- Epoch 3633\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.087494, T: 620828838, Avg. loss: 0.063791\n",
      "Total training time: 303.70 seconds.\n",
      "-- Epoch 3634\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.085705, T: 620999724, Avg. loss: 0.063790\n",
      "Total training time: 303.78 seconds.\n",
      "-- Epoch 3635\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.083914, T: 621170610, Avg. loss: 0.063789\n",
      "Total training time: 303.85 seconds.\n",
      "-- Epoch 3636\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.082125, T: 621341496, Avg. loss: 0.063788\n",
      "Total training time: 303.93 seconds.\n",
      "-- Epoch 3637\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.080335, T: 621512382, Avg. loss: 0.063787\n",
      "Total training time: 304.01 seconds.\n",
      "-- Epoch 3638\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.078544, T: 621683268, Avg. loss: 0.063786\n",
      "Total training time: 304.08 seconds.\n",
      "-- Epoch 3639\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.076754, T: 621854154, Avg. loss: 0.063785\n",
      "Total training time: 304.16 seconds.\n",
      "-- Epoch 3640\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.074967, T: 622025040, Avg. loss: 0.063784\n",
      "Total training time: 304.24 seconds.\n",
      "-- Epoch 3641\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.073179, T: 622195926, Avg. loss: 0.063783\n",
      "Total training time: 304.31 seconds.\n",
      "-- Epoch 3642\n",
      "Norm: 13.47, NNZs: 30, Bias: -119.071393, T: 622366812, Avg. loss: 0.063782\n",
      "Total training time: 304.39 seconds.\n",
      "-- Epoch 3643\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.069608, T: 622537698, Avg. loss: 0.063781\n",
      "Total training time: 304.47 seconds.\n",
      "-- Epoch 3644\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.067821, T: 622708584, Avg. loss: 0.063780\n",
      "Total training time: 304.54 seconds.\n",
      "-- Epoch 3645\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.066035, T: 622879470, Avg. loss: 0.063779\n",
      "Total training time: 304.63 seconds.\n",
      "-- Epoch 3646\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.064249, T: 623050356, Avg. loss: 0.063778\n",
      "Total training time: 304.71 seconds.\n",
      "-- Epoch 3647\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.062465, T: 623221242, Avg. loss: 0.063777\n",
      "Total training time: 304.79 seconds.\n",
      "-- Epoch 3648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.46, NNZs: 30, Bias: -119.060681, T: 623392128, Avg. loss: 0.063776\n",
      "Total training time: 304.86 seconds.\n",
      "-- Epoch 3649\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.058898, T: 623563014, Avg. loss: 0.063775\n",
      "Total training time: 304.94 seconds.\n",
      "-- Epoch 3650\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.057114, T: 623733900, Avg. loss: 0.063774\n",
      "Total training time: 305.01 seconds.\n",
      "-- Epoch 3651\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.055332, T: 623904786, Avg. loss: 0.063773\n",
      "Total training time: 305.09 seconds.\n",
      "-- Epoch 3652\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.053550, T: 624075672, Avg. loss: 0.063772\n",
      "Total training time: 305.17 seconds.\n",
      "-- Epoch 3653\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.051769, T: 624246558, Avg. loss: 0.063771\n",
      "Total training time: 305.25 seconds.\n",
      "-- Epoch 3654\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.049988, T: 624417444, Avg. loss: 0.063770\n",
      "Total training time: 305.33 seconds.\n",
      "-- Epoch 3655\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.048208, T: 624588330, Avg. loss: 0.063769\n",
      "Total training time: 305.40 seconds.\n",
      "-- Epoch 3656\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.046427, T: 624759216, Avg. loss: 0.063768\n",
      "Total training time: 305.48 seconds.\n",
      "-- Epoch 3657\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.044649, T: 624930102, Avg. loss: 0.063767\n",
      "Total training time: 305.56 seconds.\n",
      "-- Epoch 3658\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.042869, T: 625100988, Avg. loss: 0.063766\n",
      "Total training time: 305.63 seconds.\n",
      "-- Epoch 3659\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.041089, T: 625271874, Avg. loss: 0.063765\n",
      "Total training time: 305.71 seconds.\n",
      "-- Epoch 3660\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.039312, T: 625442760, Avg. loss: 0.063764\n",
      "Total training time: 305.79 seconds.\n",
      "-- Epoch 3661\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.037534, T: 625613646, Avg. loss: 0.063763\n",
      "Total training time: 305.87 seconds.\n",
      "-- Epoch 3662\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.035757, T: 625784532, Avg. loss: 0.063762\n",
      "Total training time: 305.94 seconds.\n",
      "-- Epoch 3663\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.033980, T: 625955418, Avg. loss: 0.063761\n",
      "Total training time: 306.02 seconds.\n",
      "-- Epoch 3664\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.032205, T: 626126304, Avg. loss: 0.063760\n",
      "Total training time: 306.10 seconds.\n",
      "-- Epoch 3665\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.030430, T: 626297190, Avg. loss: 0.063759\n",
      "Total training time: 306.18 seconds.\n",
      "-- Epoch 3666\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.028656, T: 626468076, Avg. loss: 0.063759\n",
      "Total training time: 306.26 seconds.\n",
      "-- Epoch 3667\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.026882, T: 626638962, Avg. loss: 0.063758\n",
      "Total training time: 306.33 seconds.\n",
      "-- Epoch 3668\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.025108, T: 626809848, Avg. loss: 0.063757\n",
      "Total training time: 306.41 seconds.\n",
      "-- Epoch 3669\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.023334, T: 626980734, Avg. loss: 0.063756\n",
      "Total training time: 306.49 seconds.\n",
      "-- Epoch 3670\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.021561, T: 627151620, Avg. loss: 0.063755\n",
      "Total training time: 306.56 seconds.\n",
      "-- Epoch 3671\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.019787, T: 627322506, Avg. loss: 0.063754\n",
      "Total training time: 306.64 seconds.\n",
      "-- Epoch 3672\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.018015, T: 627493392, Avg. loss: 0.063753\n",
      "Total training time: 306.72 seconds.\n",
      "-- Epoch 3673\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.016243, T: 627664278, Avg. loss: 0.063752\n",
      "Total training time: 306.80 seconds.\n",
      "-- Epoch 3674\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.014471, T: 627835164, Avg. loss: 0.063751\n",
      "Total training time: 306.87 seconds.\n",
      "-- Epoch 3675\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.012700, T: 628006050, Avg. loss: 0.063750\n",
      "Total training time: 306.95 seconds.\n",
      "-- Epoch 3676\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.010929, T: 628176936, Avg. loss: 0.063749\n",
      "Total training time: 307.03 seconds.\n",
      "-- Epoch 3677\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.009157, T: 628347822, Avg. loss: 0.063748\n",
      "Total training time: 307.12 seconds.\n",
      "-- Epoch 3678\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.007389, T: 628518708, Avg. loss: 0.063747\n",
      "Total training time: 307.20 seconds.\n",
      "-- Epoch 3679\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.005621, T: 628689594, Avg. loss: 0.063746\n",
      "Total training time: 307.28 seconds.\n",
      "-- Epoch 3680\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.003853, T: 628860480, Avg. loss: 0.063745\n",
      "Total training time: 307.36 seconds.\n",
      "-- Epoch 3681\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.002084, T: 629031366, Avg. loss: 0.063744\n",
      "Total training time: 307.45 seconds.\n",
      "-- Epoch 3682\n",
      "Norm: 13.46, NNZs: 30, Bias: -119.000316, T: 629202252, Avg. loss: 0.063743\n",
      "Total training time: 307.53 seconds.\n",
      "-- Epoch 3683\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.998549, T: 629373138, Avg. loss: 0.063742\n",
      "Total training time: 307.61 seconds.\n",
      "-- Epoch 3684\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.996783, T: 629544024, Avg. loss: 0.063741\n",
      "Total training time: 307.71 seconds.\n",
      "-- Epoch 3685\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.995017, T: 629714910, Avg. loss: 0.063740\n",
      "Total training time: 307.80 seconds.\n",
      "-- Epoch 3686\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.993250, T: 629885796, Avg. loss: 0.063739\n",
      "Total training time: 307.89 seconds.\n",
      "-- Epoch 3687\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.991485, T: 630056682, Avg. loss: 0.063738\n",
      "Total training time: 307.97 seconds.\n",
      "-- Epoch 3688\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.989720, T: 630227568, Avg. loss: 0.063737\n",
      "Total training time: 308.05 seconds.\n",
      "-- Epoch 3689\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.987955, T: 630398454, Avg. loss: 0.063736\n",
      "Total training time: 308.13 seconds.\n",
      "-- Epoch 3690\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.986192, T: 630569340, Avg. loss: 0.063735\n",
      "Total training time: 308.21 seconds.\n",
      "-- Epoch 3691\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.984428, T: 630740226, Avg. loss: 0.063734\n",
      "Total training time: 308.28 seconds.\n",
      "-- Epoch 3692\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.982667, T: 630911112, Avg. loss: 0.063733\n",
      "Total training time: 308.36 seconds.\n",
      "-- Epoch 3693\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.980905, T: 631081998, Avg. loss: 0.063732\n",
      "Total training time: 308.44 seconds.\n",
      "-- Epoch 3694\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.979143, T: 631252884, Avg. loss: 0.063731\n",
      "Total training time: 308.52 seconds.\n",
      "-- Epoch 3695\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.977382, T: 631423770, Avg. loss: 0.063730\n",
      "Total training time: 308.60 seconds.\n",
      "-- Epoch 3696\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.975621, T: 631594656, Avg. loss: 0.063729\n",
      "Total training time: 308.67 seconds.\n",
      "-- Epoch 3697\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.973862, T: 631765542, Avg. loss: 0.063728\n",
      "Total training time: 308.76 seconds.\n",
      "-- Epoch 3698\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.972104, T: 631936428, Avg. loss: 0.063727\n",
      "Total training time: 308.84 seconds.\n",
      "-- Epoch 3699\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.970344, T: 632107314, Avg. loss: 0.063726\n",
      "Total training time: 308.92 seconds.\n",
      "-- Epoch 3700\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.968585, T: 632278200, Avg. loss: 0.063725\n",
      "Total training time: 309.01 seconds.\n",
      "-- Epoch 3701\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.966827, T: 632449086, Avg. loss: 0.063724\n",
      "Total training time: 309.08 seconds.\n",
      "-- Epoch 3702\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.965070, T: 632619972, Avg. loss: 0.063723\n",
      "Total training time: 309.16 seconds.\n",
      "-- Epoch 3703\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.963312, T: 632790858, Avg. loss: 0.063722\n",
      "Total training time: 309.24 seconds.\n",
      "-- Epoch 3704\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.961555, T: 632961744, Avg. loss: 0.063721\n",
      "Total training time: 309.31 seconds.\n",
      "-- Epoch 3705\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.959798, T: 633132630, Avg. loss: 0.063720\n",
      "Total training time: 309.39 seconds.\n",
      "-- Epoch 3706\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.958041, T: 633303516, Avg. loss: 0.063719\n",
      "Total training time: 309.46 seconds.\n",
      "-- Epoch 3707\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.956285, T: 633474402, Avg. loss: 0.063718\n",
      "Total training time: 309.54 seconds.\n",
      "-- Epoch 3708\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.954531, T: 633645288, Avg. loss: 0.063717\n",
      "Total training time: 309.62 seconds.\n",
      "-- Epoch 3709\n",
      "Norm: 13.46, NNZs: 30, Bias: -118.952776, T: 633816174, Avg. loss: 0.063716\n",
      "Total training time: 309.70 seconds.\n",
      "-- Epoch 3710\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.951020, T: 633987060, Avg. loss: 0.063715\n",
      "Total training time: 309.78 seconds.\n",
      "-- Epoch 3711\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.949267, T: 634157946, Avg. loss: 0.063714\n",
      "Total training time: 309.86 seconds.\n",
      "-- Epoch 3712\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.947513, T: 634328832, Avg. loss: 0.063714\n",
      "Total training time: 309.94 seconds.\n",
      "-- Epoch 3713\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.945761, T: 634499718, Avg. loss: 0.063713\n",
      "Total training time: 310.01 seconds.\n",
      "-- Epoch 3714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.45, NNZs: 30, Bias: -118.944009, T: 634670604, Avg. loss: 0.063712\n",
      "Total training time: 310.09 seconds.\n",
      "-- Epoch 3715\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.942256, T: 634841490, Avg. loss: 0.063711\n",
      "Total training time: 310.17 seconds.\n",
      "-- Epoch 3716\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.940506, T: 635012376, Avg. loss: 0.063710\n",
      "Total training time: 310.25 seconds.\n",
      "-- Epoch 3717\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.938755, T: 635183262, Avg. loss: 0.063709\n",
      "Total training time: 310.32 seconds.\n",
      "-- Epoch 3718\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.937004, T: 635354148, Avg. loss: 0.063708\n",
      "Total training time: 310.40 seconds.\n",
      "-- Epoch 3719\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.935253, T: 635525034, Avg. loss: 0.063707\n",
      "Total training time: 310.47 seconds.\n",
      "-- Epoch 3720\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.933504, T: 635695920, Avg. loss: 0.063706\n",
      "Total training time: 310.55 seconds.\n",
      "-- Epoch 3721\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.931754, T: 635866806, Avg. loss: 0.063705\n",
      "Total training time: 310.63 seconds.\n",
      "-- Epoch 3722\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.930006, T: 636037692, Avg. loss: 0.063704\n",
      "Total training time: 310.71 seconds.\n",
      "-- Epoch 3723\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.928259, T: 636208578, Avg. loss: 0.063703\n",
      "Total training time: 310.78 seconds.\n",
      "-- Epoch 3724\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.926511, T: 636379464, Avg. loss: 0.063702\n",
      "Total training time: 310.86 seconds.\n",
      "-- Epoch 3725\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.924764, T: 636550350, Avg. loss: 0.063701\n",
      "Total training time: 310.93 seconds.\n",
      "-- Epoch 3726\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.923019, T: 636721236, Avg. loss: 0.063700\n",
      "Total training time: 311.01 seconds.\n",
      "-- Epoch 3727\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.921273, T: 636892122, Avg. loss: 0.063699\n",
      "Total training time: 311.09 seconds.\n",
      "-- Epoch 3728\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.919526, T: 637063008, Avg. loss: 0.063698\n",
      "Total training time: 311.18 seconds.\n",
      "-- Epoch 3729\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.917780, T: 637233894, Avg. loss: 0.063697\n",
      "Total training time: 311.27 seconds.\n",
      "-- Epoch 3730\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.916035, T: 637404780, Avg. loss: 0.063696\n",
      "Total training time: 311.36 seconds.\n",
      "-- Epoch 3731\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.914292, T: 637575666, Avg. loss: 0.063695\n",
      "Total training time: 311.44 seconds.\n",
      "-- Epoch 3732\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.912548, T: 637746552, Avg. loss: 0.063694\n",
      "Total training time: 311.52 seconds.\n",
      "-- Epoch 3733\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.910805, T: 637917438, Avg. loss: 0.063693\n",
      "Total training time: 311.60 seconds.\n",
      "-- Epoch 3734\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.909063, T: 638088324, Avg. loss: 0.063692\n",
      "Total training time: 311.69 seconds.\n",
      "-- Epoch 3735\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.907321, T: 638259210, Avg. loss: 0.063691\n",
      "Total training time: 311.78 seconds.\n",
      "-- Epoch 3736\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.905580, T: 638430096, Avg. loss: 0.063690\n",
      "Total training time: 311.87 seconds.\n",
      "-- Epoch 3737\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.903838, T: 638600982, Avg. loss: 0.063689\n",
      "Total training time: 311.95 seconds.\n",
      "-- Epoch 3738\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.902097, T: 638771868, Avg. loss: 0.063688\n",
      "Total training time: 312.03 seconds.\n",
      "-- Epoch 3739\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.900357, T: 638942754, Avg. loss: 0.063687\n",
      "Total training time: 312.12 seconds.\n",
      "-- Epoch 3740\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.898616, T: 639113640, Avg. loss: 0.063686\n",
      "Total training time: 312.20 seconds.\n",
      "-- Epoch 3741\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.896877, T: 639284526, Avg. loss: 0.063685\n",
      "Total training time: 312.28 seconds.\n",
      "-- Epoch 3742\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.895138, T: 639455412, Avg. loss: 0.063684\n",
      "Total training time: 312.36 seconds.\n",
      "-- Epoch 3743\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.893400, T: 639626298, Avg. loss: 0.063683\n",
      "Total training time: 312.45 seconds.\n",
      "-- Epoch 3744\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.891661, T: 639797184, Avg. loss: 0.063683\n",
      "Total training time: 312.54 seconds.\n",
      "-- Epoch 3745\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.889924, T: 639968070, Avg. loss: 0.063682\n",
      "Total training time: 312.62 seconds.\n",
      "-- Epoch 3746\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.888187, T: 640138956, Avg. loss: 0.063681\n",
      "Total training time: 312.71 seconds.\n",
      "-- Epoch 3747\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.886450, T: 640309842, Avg. loss: 0.063680\n",
      "Total training time: 312.79 seconds.\n",
      "-- Epoch 3748\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.884714, T: 640480728, Avg. loss: 0.063679\n",
      "Total training time: 312.87 seconds.\n",
      "-- Epoch 3749\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.882978, T: 640651614, Avg. loss: 0.063678\n",
      "Total training time: 312.96 seconds.\n",
      "-- Epoch 3750\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.881243, T: 640822500, Avg. loss: 0.063677\n",
      "Total training time: 313.04 seconds.\n",
      "-- Epoch 3751\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.879509, T: 640993386, Avg. loss: 0.063676\n",
      "Total training time: 313.13 seconds.\n",
      "-- Epoch 3752\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.877776, T: 641164272, Avg. loss: 0.063675\n",
      "Total training time: 313.22 seconds.\n",
      "-- Epoch 3753\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.876042, T: 641335158, Avg. loss: 0.063674\n",
      "Total training time: 313.33 seconds.\n",
      "-- Epoch 3754\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.874309, T: 641506044, Avg. loss: 0.063673\n",
      "Total training time: 313.43 seconds.\n",
      "-- Epoch 3755\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.872577, T: 641676930, Avg. loss: 0.063672\n",
      "Total training time: 313.52 seconds.\n",
      "-- Epoch 3756\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.870844, T: 641847816, Avg. loss: 0.063671\n",
      "Total training time: 313.61 seconds.\n",
      "-- Epoch 3757\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.869113, T: 642018702, Avg. loss: 0.063670\n",
      "Total training time: 313.71 seconds.\n",
      "-- Epoch 3758\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.867382, T: 642189588, Avg. loss: 0.063669\n",
      "Total training time: 313.81 seconds.\n",
      "-- Epoch 3759\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.865650, T: 642360474, Avg. loss: 0.063668\n",
      "Total training time: 313.89 seconds.\n",
      "-- Epoch 3760\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.863920, T: 642531360, Avg. loss: 0.063667\n",
      "Total training time: 313.97 seconds.\n",
      "-- Epoch 3761\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.862190, T: 642702246, Avg. loss: 0.063666\n",
      "Total training time: 314.06 seconds.\n",
      "-- Epoch 3762\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.860460, T: 642873132, Avg. loss: 0.063665\n",
      "Total training time: 314.15 seconds.\n",
      "-- Epoch 3763\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.858732, T: 643044018, Avg. loss: 0.063664\n",
      "Total training time: 314.24 seconds.\n",
      "-- Epoch 3764\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.857002, T: 643214904, Avg. loss: 0.063663\n",
      "Total training time: 314.32 seconds.\n",
      "-- Epoch 3765\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.855273, T: 643385790, Avg. loss: 0.063662\n",
      "Total training time: 314.41 seconds.\n",
      "-- Epoch 3766\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.853546, T: 643556676, Avg. loss: 0.063661\n",
      "Total training time: 314.51 seconds.\n",
      "-- Epoch 3767\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.851819, T: 643727562, Avg. loss: 0.063660\n",
      "Total training time: 314.60 seconds.\n",
      "-- Epoch 3768\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.850092, T: 643898448, Avg. loss: 0.063659\n",
      "Total training time: 314.68 seconds.\n",
      "-- Epoch 3769\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.848367, T: 644069334, Avg. loss: 0.063659\n",
      "Total training time: 314.76 seconds.\n",
      "-- Epoch 3770\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.846640, T: 644240220, Avg. loss: 0.063658\n",
      "Total training time: 314.84 seconds.\n",
      "-- Epoch 3771\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.844914, T: 644411106, Avg. loss: 0.063657\n",
      "Total training time: 314.92 seconds.\n",
      "-- Epoch 3772\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.843189, T: 644581992, Avg. loss: 0.063656\n",
      "Total training time: 315.00 seconds.\n",
      "-- Epoch 3773\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.841463, T: 644752878, Avg. loss: 0.063655\n",
      "Total training time: 315.09 seconds.\n",
      "-- Epoch 3774\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.839738, T: 644923764, Avg. loss: 0.063654\n",
      "Total training time: 315.17 seconds.\n",
      "-- Epoch 3775\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.838013, T: 645094650, Avg. loss: 0.063653\n",
      "Total training time: 315.26 seconds.\n",
      "-- Epoch 3776\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.836290, T: 645265536, Avg. loss: 0.063652\n",
      "Total training time: 315.34 seconds.\n",
      "-- Epoch 3777\n",
      "Norm: 13.45, NNZs: 30, Bias: -118.834569, T: 645436422, Avg. loss: 0.063651\n",
      "Total training time: 315.41 seconds.\n",
      "-- Epoch 3778\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.832847, T: 645607308, Avg. loss: 0.063650\n",
      "Total training time: 315.49 seconds.\n",
      "-- Epoch 3779\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.831124, T: 645778194, Avg. loss: 0.063649\n",
      "Total training time: 315.57 seconds.\n",
      "-- Epoch 3780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.44, NNZs: 30, Bias: -118.829404, T: 645949080, Avg. loss: 0.063648\n",
      "Total training time: 315.65 seconds.\n",
      "-- Epoch 3781\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.827683, T: 646119966, Avg. loss: 0.063647\n",
      "Total training time: 315.72 seconds.\n",
      "-- Epoch 3782\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.825963, T: 646290852, Avg. loss: 0.063646\n",
      "Total training time: 315.80 seconds.\n",
      "-- Epoch 3783\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.824242, T: 646461738, Avg. loss: 0.063645\n",
      "Total training time: 315.87 seconds.\n",
      "-- Epoch 3784\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.822522, T: 646632624, Avg. loss: 0.063644\n",
      "Total training time: 315.95 seconds.\n",
      "-- Epoch 3785\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.820802, T: 646803510, Avg. loss: 0.063643\n",
      "Total training time: 316.02 seconds.\n",
      "-- Epoch 3786\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.819083, T: 646974396, Avg. loss: 0.063642\n",
      "Total training time: 316.10 seconds.\n",
      "-- Epoch 3787\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.817365, T: 647145282, Avg. loss: 0.063641\n",
      "Total training time: 316.17 seconds.\n",
      "-- Epoch 3788\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.815647, T: 647316168, Avg. loss: 0.063640\n",
      "Total training time: 316.25 seconds.\n",
      "-- Epoch 3789\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.813929, T: 647487054, Avg. loss: 0.063639\n",
      "Total training time: 316.32 seconds.\n",
      "-- Epoch 3790\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.812212, T: 647657940, Avg. loss: 0.063638\n",
      "Total training time: 316.40 seconds.\n",
      "-- Epoch 3791\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.810497, T: 647828826, Avg. loss: 0.063638\n",
      "Total training time: 316.47 seconds.\n",
      "-- Epoch 3792\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.808781, T: 647999712, Avg. loss: 0.063637\n",
      "Total training time: 316.55 seconds.\n",
      "-- Epoch 3793\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.807066, T: 648170598, Avg. loss: 0.063636\n",
      "Total training time: 316.63 seconds.\n",
      "-- Epoch 3794\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.805352, T: 648341484, Avg. loss: 0.063635\n",
      "Total training time: 316.70 seconds.\n",
      "-- Epoch 3795\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.803636, T: 648512370, Avg. loss: 0.063634\n",
      "Total training time: 316.78 seconds.\n",
      "-- Epoch 3796\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.801922, T: 648683256, Avg. loss: 0.063633\n",
      "Total training time: 316.86 seconds.\n",
      "-- Epoch 3797\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.800209, T: 648854142, Avg. loss: 0.063632\n",
      "Total training time: 316.93 seconds.\n",
      "-- Epoch 3798\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.798497, T: 649025028, Avg. loss: 0.063631\n",
      "Total training time: 317.01 seconds.\n",
      "-- Epoch 3799\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.796784, T: 649195914, Avg. loss: 0.063630\n",
      "Total training time: 317.08 seconds.\n",
      "-- Epoch 3800\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.795071, T: 649366800, Avg. loss: 0.063629\n",
      "Total training time: 317.16 seconds.\n",
      "-- Epoch 3801\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.793360, T: 649537686, Avg. loss: 0.063628\n",
      "Total training time: 317.23 seconds.\n",
      "-- Epoch 3802\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.791649, T: 649708572, Avg. loss: 0.063627\n",
      "Total training time: 317.31 seconds.\n",
      "-- Epoch 3803\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.789937, T: 649879458, Avg. loss: 0.063626\n",
      "Total training time: 317.40 seconds.\n",
      "-- Epoch 3804\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.788226, T: 650050344, Avg. loss: 0.063625\n",
      "Total training time: 317.48 seconds.\n",
      "-- Epoch 3805\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.786517, T: 650221230, Avg. loss: 0.063624\n",
      "Total training time: 317.56 seconds.\n",
      "-- Epoch 3806\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.784809, T: 650392116, Avg. loss: 0.063623\n",
      "Total training time: 317.63 seconds.\n",
      "-- Epoch 3807\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.783100, T: 650563002, Avg. loss: 0.063622\n",
      "Total training time: 317.71 seconds.\n",
      "-- Epoch 3808\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.781392, T: 650733888, Avg. loss: 0.063621\n",
      "Total training time: 317.79 seconds.\n",
      "-- Epoch 3809\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.779684, T: 650904774, Avg. loss: 0.063620\n",
      "Total training time: 317.86 seconds.\n",
      "-- Epoch 3810\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.777976, T: 651075660, Avg. loss: 0.063619\n",
      "Total training time: 317.94 seconds.\n",
      "-- Epoch 3811\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.776269, T: 651246546, Avg. loss: 0.063619\n",
      "Total training time: 318.02 seconds.\n",
      "-- Epoch 3812\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.774562, T: 651417432, Avg. loss: 0.063618\n",
      "Total training time: 318.09 seconds.\n",
      "-- Epoch 3813\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.772856, T: 651588318, Avg. loss: 0.063617\n",
      "Total training time: 318.17 seconds.\n",
      "-- Epoch 3814\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.771151, T: 651759204, Avg. loss: 0.063616\n",
      "Total training time: 318.24 seconds.\n",
      "-- Epoch 3815\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.769445, T: 651930090, Avg. loss: 0.063615\n",
      "Total training time: 318.32 seconds.\n",
      "-- Epoch 3816\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.767739, T: 652100976, Avg. loss: 0.063614\n",
      "Total training time: 318.39 seconds.\n",
      "-- Epoch 3817\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.766035, T: 652271862, Avg. loss: 0.063613\n",
      "Total training time: 318.47 seconds.\n",
      "-- Epoch 3818\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.764331, T: 652442748, Avg. loss: 0.063612\n",
      "Total training time: 318.55 seconds.\n",
      "-- Epoch 3819\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.762630, T: 652613634, Avg. loss: 0.063611\n",
      "Total training time: 318.63 seconds.\n",
      "-- Epoch 3820\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.760927, T: 652784520, Avg. loss: 0.063610\n",
      "Total training time: 318.70 seconds.\n",
      "-- Epoch 3821\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.759224, T: 652955406, Avg. loss: 0.063609\n",
      "Total training time: 318.77 seconds.\n",
      "-- Epoch 3822\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.757522, T: 653126292, Avg. loss: 0.063608\n",
      "Total training time: 318.85 seconds.\n",
      "-- Epoch 3823\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.755820, T: 653297178, Avg. loss: 0.063607\n",
      "Total training time: 318.92 seconds.\n",
      "-- Epoch 3824\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.754118, T: 653468064, Avg. loss: 0.063606\n",
      "Total training time: 319.00 seconds.\n",
      "-- Epoch 3825\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.752417, T: 653638950, Avg. loss: 0.063605\n",
      "Total training time: 319.07 seconds.\n",
      "-- Epoch 3826\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.750716, T: 653809836, Avg. loss: 0.063604\n",
      "Total training time: 319.15 seconds.\n",
      "-- Epoch 3827\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.749015, T: 653980722, Avg. loss: 0.063603\n",
      "Total training time: 319.22 seconds.\n",
      "-- Epoch 3828\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.747315, T: 654151608, Avg. loss: 0.063602\n",
      "Total training time: 319.30 seconds.\n",
      "-- Epoch 3829\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.745617, T: 654322494, Avg. loss: 0.063602\n",
      "Total training time: 319.37 seconds.\n",
      "-- Epoch 3830\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.743918, T: 654493380, Avg. loss: 0.063601\n",
      "Total training time: 319.47 seconds.\n",
      "-- Epoch 3831\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.742219, T: 654664266, Avg. loss: 0.063600\n",
      "Total training time: 319.56 seconds.\n",
      "-- Epoch 3832\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.740521, T: 654835152, Avg. loss: 0.063599\n",
      "Total training time: 319.65 seconds.\n",
      "-- Epoch 3833\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.738823, T: 655006038, Avg. loss: 0.063598\n",
      "Total training time: 319.76 seconds.\n",
      "-- Epoch 3834\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.737127, T: 655176924, Avg. loss: 0.063597\n",
      "Total training time: 319.87 seconds.\n",
      "-- Epoch 3835\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.735431, T: 655347810, Avg. loss: 0.063596\n",
      "Total training time: 319.96 seconds.\n",
      "-- Epoch 3836\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.733736, T: 655518696, Avg. loss: 0.063595\n",
      "Total training time: 320.05 seconds.\n",
      "-- Epoch 3837\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.732041, T: 655689582, Avg. loss: 0.063594\n",
      "Total training time: 320.13 seconds.\n",
      "-- Epoch 3838\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.730347, T: 655860468, Avg. loss: 0.063593\n",
      "Total training time: 320.20 seconds.\n",
      "-- Epoch 3839\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.728652, T: 656031354, Avg. loss: 0.063592\n",
      "Total training time: 320.29 seconds.\n",
      "-- Epoch 3840\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.726959, T: 656202240, Avg. loss: 0.063591\n",
      "Total training time: 320.38 seconds.\n",
      "-- Epoch 3841\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.725264, T: 656373126, Avg. loss: 0.063590\n",
      "Total training time: 320.45 seconds.\n",
      "-- Epoch 3842\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.723572, T: 656544012, Avg. loss: 0.063589\n",
      "Total training time: 320.53 seconds.\n",
      "-- Epoch 3843\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.721879, T: 656714898, Avg. loss: 0.063588\n",
      "Total training time: 320.61 seconds.\n",
      "-- Epoch 3844\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.720186, T: 656885784, Avg. loss: 0.063587\n",
      "Total training time: 320.70 seconds.\n",
      "-- Epoch 3845\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.718495, T: 657056670, Avg. loss: 0.063586\n",
      "Total training time: 320.78 seconds.\n",
      "-- Epoch 3846\n",
      "Norm: 13.44, NNZs: 30, Bias: -118.716804, T: 657227556, Avg. loss: 0.063586\n",
      "Total training time: 320.86 seconds.\n",
      "-- Epoch 3847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.43, NNZs: 30, Bias: -118.715112, T: 657398442, Avg. loss: 0.063585\n",
      "Total training time: 320.94 seconds.\n",
      "-- Epoch 3848\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.713422, T: 657569328, Avg. loss: 0.063584\n",
      "Total training time: 321.01 seconds.\n",
      "-- Epoch 3849\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.711732, T: 657740214, Avg. loss: 0.063583\n",
      "Total training time: 321.09 seconds.\n",
      "-- Epoch 3850\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.710043, T: 657911100, Avg. loss: 0.063582\n",
      "Total training time: 321.17 seconds.\n",
      "-- Epoch 3851\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.708353, T: 658081986, Avg. loss: 0.063581\n",
      "Total training time: 321.24 seconds.\n",
      "-- Epoch 3852\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.706665, T: 658252872, Avg. loss: 0.063580\n",
      "Total training time: 321.32 seconds.\n",
      "-- Epoch 3853\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.704978, T: 658423758, Avg. loss: 0.063579\n",
      "Total training time: 321.40 seconds.\n",
      "-- Epoch 3854\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.703290, T: 658594644, Avg. loss: 0.063578\n",
      "Total training time: 321.47 seconds.\n",
      "-- Epoch 3855\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.701602, T: 658765530, Avg. loss: 0.063577\n",
      "Total training time: 321.55 seconds.\n",
      "-- Epoch 3856\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.699915, T: 658936416, Avg. loss: 0.063576\n",
      "Total training time: 321.62 seconds.\n",
      "-- Epoch 3857\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.698228, T: 659107302, Avg. loss: 0.063575\n",
      "Total training time: 321.70 seconds.\n",
      "-- Epoch 3858\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.696542, T: 659278188, Avg. loss: 0.063574\n",
      "Total training time: 321.77 seconds.\n",
      "-- Epoch 3859\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.694856, T: 659449074, Avg. loss: 0.063573\n",
      "Total training time: 321.85 seconds.\n",
      "-- Epoch 3860\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.693171, T: 659619960, Avg. loss: 0.063572\n",
      "Total training time: 321.92 seconds.\n",
      "-- Epoch 3861\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.691485, T: 659790846, Avg. loss: 0.063572\n",
      "Total training time: 322.00 seconds.\n",
      "-- Epoch 3862\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.689802, T: 659961732, Avg. loss: 0.063571\n",
      "Total training time: 322.08 seconds.\n",
      "-- Epoch 3863\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.688117, T: 660132618, Avg. loss: 0.063570\n",
      "Total training time: 322.17 seconds.\n",
      "-- Epoch 3864\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.686432, T: 660303504, Avg. loss: 0.063569\n",
      "Total training time: 322.25 seconds.\n",
      "-- Epoch 3865\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.684749, T: 660474390, Avg. loss: 0.063568\n",
      "Total training time: 322.33 seconds.\n",
      "-- Epoch 3866\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.683066, T: 660645276, Avg. loss: 0.063567\n",
      "Total training time: 322.40 seconds.\n",
      "-- Epoch 3867\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.681383, T: 660816162, Avg. loss: 0.063566\n",
      "Total training time: 322.48 seconds.\n",
      "-- Epoch 3868\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.679700, T: 660987048, Avg. loss: 0.063565\n",
      "Total training time: 322.56 seconds.\n",
      "-- Epoch 3869\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.678018, T: 661157934, Avg. loss: 0.063564\n",
      "Total training time: 322.63 seconds.\n",
      "-- Epoch 3870\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.676337, T: 661328820, Avg. loss: 0.063563\n",
      "Total training time: 322.71 seconds.\n",
      "-- Epoch 3871\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.674657, T: 661499706, Avg. loss: 0.063562\n",
      "Total training time: 322.78 seconds.\n",
      "-- Epoch 3872\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.672977, T: 661670592, Avg. loss: 0.063561\n",
      "Total training time: 322.86 seconds.\n",
      "-- Epoch 3873\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.671298, T: 661841478, Avg. loss: 0.063560\n",
      "Total training time: 322.93 seconds.\n",
      "-- Epoch 3874\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.669618, T: 662012364, Avg. loss: 0.063559\n",
      "Total training time: 323.01 seconds.\n",
      "-- Epoch 3875\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.667939, T: 662183250, Avg. loss: 0.063558\n",
      "Total training time: 323.08 seconds.\n",
      "-- Epoch 3876\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.666261, T: 662354136, Avg. loss: 0.063558\n",
      "Total training time: 323.16 seconds.\n",
      "-- Epoch 3877\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.664584, T: 662525022, Avg. loss: 0.063557\n",
      "Total training time: 323.23 seconds.\n",
      "-- Epoch 3878\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.662906, T: 662695908, Avg. loss: 0.063556\n",
      "Total training time: 323.31 seconds.\n",
      "-- Epoch 3879\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.661230, T: 662866794, Avg. loss: 0.063555\n",
      "Total training time: 323.39 seconds.\n",
      "-- Epoch 3880\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.659554, T: 663037680, Avg. loss: 0.063554\n",
      "Total training time: 323.46 seconds.\n",
      "-- Epoch 3881\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.657878, T: 663208566, Avg. loss: 0.063553\n",
      "Total training time: 323.54 seconds.\n",
      "-- Epoch 3882\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.656203, T: 663379452, Avg. loss: 0.063552\n",
      "Total training time: 323.62 seconds.\n",
      "-- Epoch 3883\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.654527, T: 663550338, Avg. loss: 0.063551\n",
      "Total training time: 323.69 seconds.\n",
      "-- Epoch 3884\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.652851, T: 663721224, Avg. loss: 0.063550\n",
      "Total training time: 323.77 seconds.\n",
      "-- Epoch 3885\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.651178, T: 663892110, Avg. loss: 0.063549\n",
      "Total training time: 323.85 seconds.\n",
      "-- Epoch 3886\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.649505, T: 664062996, Avg. loss: 0.063548\n",
      "Total training time: 323.93 seconds.\n",
      "-- Epoch 3887\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.647832, T: 664233882, Avg. loss: 0.063547\n",
      "Total training time: 324.01 seconds.\n",
      "-- Epoch 3888\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.646160, T: 664404768, Avg. loss: 0.063546\n",
      "Total training time: 324.09 seconds.\n",
      "-- Epoch 3889\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.644486, T: 664575654, Avg. loss: 0.063545\n",
      "Total training time: 324.17 seconds.\n",
      "-- Epoch 3890\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.642815, T: 664746540, Avg. loss: 0.063545\n",
      "Total training time: 324.25 seconds.\n",
      "-- Epoch 3891\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.641144, T: 664917426, Avg. loss: 0.063544\n",
      "Total training time: 324.32 seconds.\n",
      "-- Epoch 3892\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.639472, T: 665088312, Avg. loss: 0.063543\n",
      "Total training time: 324.40 seconds.\n",
      "-- Epoch 3893\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.637801, T: 665259198, Avg. loss: 0.063542\n",
      "Total training time: 324.48 seconds.\n",
      "-- Epoch 3894\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.636130, T: 665430084, Avg. loss: 0.063541\n",
      "Total training time: 324.56 seconds.\n",
      "-- Epoch 3895\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.634459, T: 665600970, Avg. loss: 0.063540\n",
      "Total training time: 324.64 seconds.\n",
      "-- Epoch 3896\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.632788, T: 665771856, Avg. loss: 0.063539\n",
      "Total training time: 324.71 seconds.\n",
      "-- Epoch 3897\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.631119, T: 665942742, Avg. loss: 0.063538\n",
      "Total training time: 324.80 seconds.\n",
      "-- Epoch 3898\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.629450, T: 666113628, Avg. loss: 0.063537\n",
      "Total training time: 324.88 seconds.\n",
      "-- Epoch 3899\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.627783, T: 666284514, Avg. loss: 0.063536\n",
      "Total training time: 324.95 seconds.\n",
      "-- Epoch 3900\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.626116, T: 666455400, Avg. loss: 0.063535\n",
      "Total training time: 325.03 seconds.\n",
      "-- Epoch 3901\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.624448, T: 666626286, Avg. loss: 0.063534\n",
      "Total training time: 325.11 seconds.\n",
      "-- Epoch 3902\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.622781, T: 666797172, Avg. loss: 0.063533\n",
      "Total training time: 325.20 seconds.\n",
      "-- Epoch 3903\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.621115, T: 666968058, Avg. loss: 0.063533\n",
      "Total training time: 325.27 seconds.\n",
      "-- Epoch 3904\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.619449, T: 667138944, Avg. loss: 0.063532\n",
      "Total training time: 325.35 seconds.\n",
      "-- Epoch 3905\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.617783, T: 667309830, Avg. loss: 0.063531\n",
      "Total training time: 325.42 seconds.\n",
      "-- Epoch 3906\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.616118, T: 667480716, Avg. loss: 0.063530\n",
      "Total training time: 325.50 seconds.\n",
      "-- Epoch 3907\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.614453, T: 667651602, Avg. loss: 0.063529\n",
      "Total training time: 325.58 seconds.\n",
      "-- Epoch 3908\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.612790, T: 667822488, Avg. loss: 0.063528\n",
      "Total training time: 325.65 seconds.\n",
      "-- Epoch 3909\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.611127, T: 667993374, Avg. loss: 0.063527\n",
      "Total training time: 325.73 seconds.\n",
      "-- Epoch 3910\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.609464, T: 668164260, Avg. loss: 0.063526\n",
      "Total training time: 325.80 seconds.\n",
      "-- Epoch 3911\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.607801, T: 668335146, Avg. loss: 0.063525\n",
      "Total training time: 325.88 seconds.\n",
      "-- Epoch 3912\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.606139, T: 668506032, Avg. loss: 0.063524\n",
      "Total training time: 325.96 seconds.\n",
      "-- Epoch 3913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.43, NNZs: 30, Bias: -118.604477, T: 668676918, Avg. loss: 0.063523\n",
      "Total training time: 326.06 seconds.\n",
      "-- Epoch 3914\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.602815, T: 668847804, Avg. loss: 0.063522\n",
      "Total training time: 326.15 seconds.\n",
      "-- Epoch 3915\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.601154, T: 669018690, Avg. loss: 0.063521\n",
      "Total training time: 326.24 seconds.\n",
      "-- Epoch 3916\n",
      "Norm: 13.43, NNZs: 30, Bias: -118.599495, T: 669189576, Avg. loss: 0.063521\n",
      "Total training time: 326.32 seconds.\n",
      "-- Epoch 3917\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.597835, T: 669360462, Avg. loss: 0.063520\n",
      "Total training time: 326.40 seconds.\n",
      "-- Epoch 3918\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.596176, T: 669531348, Avg. loss: 0.063519\n",
      "Total training time: 326.49 seconds.\n",
      "-- Epoch 3919\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.594516, T: 669702234, Avg. loss: 0.063518\n",
      "Total training time: 326.58 seconds.\n",
      "-- Epoch 3920\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.592856, T: 669873120, Avg. loss: 0.063517\n",
      "Total training time: 326.67 seconds.\n",
      "-- Epoch 3921\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.591196, T: 670044006, Avg. loss: 0.063516\n",
      "Total training time: 326.75 seconds.\n",
      "-- Epoch 3922\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.589537, T: 670214892, Avg. loss: 0.063515\n",
      "Total training time: 326.84 seconds.\n",
      "-- Epoch 3923\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.587879, T: 670385778, Avg. loss: 0.063514\n",
      "Total training time: 326.92 seconds.\n",
      "-- Epoch 3924\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.586222, T: 670556664, Avg. loss: 0.063513\n",
      "Total training time: 327.02 seconds.\n",
      "-- Epoch 3925\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.584564, T: 670727550, Avg. loss: 0.063512\n",
      "Total training time: 327.11 seconds.\n",
      "-- Epoch 3926\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.582909, T: 670898436, Avg. loss: 0.063511\n",
      "Total training time: 327.20 seconds.\n",
      "-- Epoch 3927\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.581252, T: 671069322, Avg. loss: 0.063510\n",
      "Total training time: 327.28 seconds.\n",
      "-- Epoch 3928\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.579595, T: 671240208, Avg. loss: 0.063509\n",
      "Total training time: 327.37 seconds.\n",
      "-- Epoch 3929\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.577940, T: 671411094, Avg. loss: 0.063509\n",
      "Total training time: 327.45 seconds.\n",
      "-- Epoch 3930\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.576286, T: 671581980, Avg. loss: 0.063508\n",
      "Total training time: 327.54 seconds.\n",
      "-- Epoch 3931\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.574631, T: 671752866, Avg. loss: 0.063507\n",
      "Total training time: 327.63 seconds.\n",
      "-- Epoch 3932\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.572977, T: 671923752, Avg. loss: 0.063506\n",
      "Total training time: 327.71 seconds.\n",
      "-- Epoch 3933\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.571324, T: 672094638, Avg. loss: 0.063505\n",
      "Total training time: 327.79 seconds.\n",
      "-- Epoch 3934\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.569669, T: 672265524, Avg. loss: 0.063504\n",
      "Total training time: 327.87 seconds.\n",
      "-- Epoch 3935\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.568016, T: 672436410, Avg. loss: 0.063503\n",
      "Total training time: 327.96 seconds.\n",
      "-- Epoch 3936\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.566365, T: 672607296, Avg. loss: 0.063502\n",
      "Total training time: 328.05 seconds.\n",
      "-- Epoch 3937\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.564713, T: 672778182, Avg. loss: 0.063501\n",
      "Total training time: 328.13 seconds.\n",
      "-- Epoch 3938\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.563061, T: 672949068, Avg. loss: 0.063500\n",
      "Total training time: 328.21 seconds.\n",
      "-- Epoch 3939\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.561411, T: 673119954, Avg. loss: 0.063499\n",
      "Total training time: 328.30 seconds.\n",
      "-- Epoch 3940\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.559761, T: 673290840, Avg. loss: 0.063498\n",
      "Total training time: 328.38 seconds.\n",
      "-- Epoch 3941\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.558111, T: 673461726, Avg. loss: 0.063498\n",
      "Total training time: 328.47 seconds.\n",
      "-- Epoch 3942\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.556461, T: 673632612, Avg. loss: 0.063497\n",
      "Total training time: 328.55 seconds.\n",
      "-- Epoch 3943\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.554811, T: 673803498, Avg. loss: 0.063496\n",
      "Total training time: 328.63 seconds.\n",
      "-- Epoch 3944\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.553162, T: 673974384, Avg. loss: 0.063495\n",
      "Total training time: 328.72 seconds.\n",
      "-- Epoch 3945\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.551513, T: 674145270, Avg. loss: 0.063494\n",
      "Total training time: 328.80 seconds.\n",
      "-- Epoch 3946\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.549865, T: 674316156, Avg. loss: 0.063493\n",
      "Total training time: 328.89 seconds.\n",
      "-- Epoch 3947\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.548217, T: 674487042, Avg. loss: 0.063492\n",
      "Total training time: 328.97 seconds.\n",
      "-- Epoch 3948\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.546570, T: 674657928, Avg. loss: 0.063491\n",
      "Total training time: 329.05 seconds.\n",
      "-- Epoch 3949\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.544923, T: 674828814, Avg. loss: 0.063490\n",
      "Total training time: 329.14 seconds.\n",
      "-- Epoch 3950\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.543277, T: 674999700, Avg. loss: 0.063489\n",
      "Total training time: 329.22 seconds.\n",
      "-- Epoch 3951\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.541631, T: 675170586, Avg. loss: 0.063488\n",
      "Total training time: 329.30 seconds.\n",
      "-- Epoch 3952\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.539986, T: 675341472, Avg. loss: 0.063488\n",
      "Total training time: 329.39 seconds.\n",
      "-- Epoch 3953\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.538340, T: 675512358, Avg. loss: 0.063487\n",
      "Total training time: 329.47 seconds.\n",
      "-- Epoch 3954\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.536696, T: 675683244, Avg. loss: 0.063486\n",
      "Total training time: 329.56 seconds.\n",
      "-- Epoch 3955\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.535051, T: 675854130, Avg. loss: 0.063485\n",
      "Total training time: 329.64 seconds.\n",
      "-- Epoch 3956\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.533406, T: 676025016, Avg. loss: 0.063484\n",
      "Total training time: 329.72 seconds.\n",
      "-- Epoch 3957\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.531763, T: 676195902, Avg. loss: 0.063483\n",
      "Total training time: 329.80 seconds.\n",
      "-- Epoch 3958\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.530120, T: 676366788, Avg. loss: 0.063482\n",
      "Total training time: 329.89 seconds.\n",
      "-- Epoch 3959\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.528476, T: 676537674, Avg. loss: 0.063481\n",
      "Total training time: 329.97 seconds.\n",
      "-- Epoch 3960\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.526833, T: 676708560, Avg. loss: 0.063480\n",
      "Total training time: 330.05 seconds.\n",
      "-- Epoch 3961\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.525192, T: 676879446, Avg. loss: 0.063479\n",
      "Total training time: 330.13 seconds.\n",
      "-- Epoch 3962\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.523551, T: 677050332, Avg. loss: 0.063478\n",
      "Total training time: 330.22 seconds.\n",
      "-- Epoch 3963\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.521910, T: 677221218, Avg. loss: 0.063478\n",
      "Total training time: 330.30 seconds.\n",
      "-- Epoch 3964\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.520270, T: 677392104, Avg. loss: 0.063477\n",
      "Total training time: 330.39 seconds.\n",
      "-- Epoch 3965\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.518629, T: 677562990, Avg. loss: 0.063476\n",
      "Total training time: 330.47 seconds.\n",
      "-- Epoch 3966\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.516990, T: 677733876, Avg. loss: 0.063475\n",
      "Total training time: 330.56 seconds.\n",
      "-- Epoch 3967\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.515351, T: 677904762, Avg. loss: 0.063474\n",
      "Total training time: 330.64 seconds.\n",
      "-- Epoch 3968\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.513712, T: 678075648, Avg. loss: 0.063473\n",
      "Total training time: 330.72 seconds.\n",
      "-- Epoch 3969\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.512073, T: 678246534, Avg. loss: 0.063472\n",
      "Total training time: 330.80 seconds.\n",
      "-- Epoch 3970\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.510435, T: 678417420, Avg. loss: 0.063471\n",
      "Total training time: 330.88 seconds.\n",
      "-- Epoch 3971\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.508797, T: 678588306, Avg. loss: 0.063470\n",
      "Total training time: 330.97 seconds.\n",
      "-- Epoch 3972\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.507160, T: 678759192, Avg. loss: 0.063469\n",
      "Total training time: 331.05 seconds.\n",
      "-- Epoch 3973\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.505522, T: 678930078, Avg. loss: 0.063468\n",
      "Total training time: 331.13 seconds.\n",
      "-- Epoch 3974\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.503885, T: 679100964, Avg. loss: 0.063468\n",
      "Total training time: 331.22 seconds.\n",
      "-- Epoch 3975\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.502248, T: 679271850, Avg. loss: 0.063467\n",
      "Total training time: 331.30 seconds.\n",
      "-- Epoch 3976\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.500612, T: 679442736, Avg. loss: 0.063466\n",
      "Total training time: 331.38 seconds.\n",
      "-- Epoch 3977\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.498976, T: 679613622, Avg. loss: 0.063465\n",
      "Total training time: 331.47 seconds.\n",
      "-- Epoch 3978\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.497341, T: 679784508, Avg. loss: 0.063464\n",
      "Total training time: 331.56 seconds.\n",
      "-- Epoch 3979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.42, NNZs: 30, Bias: -118.495706, T: 679955394, Avg. loss: 0.063463\n",
      "Total training time: 331.65 seconds.\n",
      "-- Epoch 3980\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.494071, T: 680126280, Avg. loss: 0.063462\n",
      "Total training time: 331.74 seconds.\n",
      "-- Epoch 3981\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.492437, T: 680297166, Avg. loss: 0.063461\n",
      "Total training time: 331.83 seconds.\n",
      "-- Epoch 3982\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.490804, T: 680468052, Avg. loss: 0.063460\n",
      "Total training time: 331.92 seconds.\n",
      "-- Epoch 3983\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.489172, T: 680638938, Avg. loss: 0.063459\n",
      "Total training time: 332.01 seconds.\n",
      "-- Epoch 3984\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.487540, T: 680809824, Avg. loss: 0.063458\n",
      "Total training time: 332.10 seconds.\n",
      "-- Epoch 3985\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.485908, T: 680980710, Avg. loss: 0.063458\n",
      "Total training time: 332.18 seconds.\n",
      "-- Epoch 3986\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.484276, T: 681151596, Avg. loss: 0.063457\n",
      "Total training time: 332.27 seconds.\n",
      "-- Epoch 3987\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.482645, T: 681322482, Avg. loss: 0.063456\n",
      "Total training time: 332.36 seconds.\n",
      "-- Epoch 3988\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.481013, T: 681493368, Avg. loss: 0.063455\n",
      "Total training time: 332.44 seconds.\n",
      "-- Epoch 3989\n",
      "Norm: 13.42, NNZs: 30, Bias: -118.479384, T: 681664254, Avg. loss: 0.063454\n",
      "Total training time: 332.53 seconds.\n",
      "-- Epoch 3990\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.477753, T: 681835140, Avg. loss: 0.063453\n",
      "Total training time: 332.61 seconds.\n",
      "-- Epoch 3991\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.476123, T: 682006026, Avg. loss: 0.063452\n",
      "Total training time: 332.70 seconds.\n",
      "-- Epoch 3992\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.474495, T: 682176912, Avg. loss: 0.063451\n",
      "Total training time: 332.79 seconds.\n",
      "-- Epoch 3993\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.472867, T: 682347798, Avg. loss: 0.063450\n",
      "Total training time: 332.88 seconds.\n",
      "-- Epoch 3994\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.471239, T: 682518684, Avg. loss: 0.063449\n",
      "Total training time: 332.98 seconds.\n",
      "-- Epoch 3995\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.469611, T: 682689570, Avg. loss: 0.063449\n",
      "Total training time: 333.06 seconds.\n",
      "-- Epoch 3996\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.467983, T: 682860456, Avg. loss: 0.063448\n",
      "Total training time: 333.15 seconds.\n",
      "-- Epoch 3997\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.466357, T: 683031342, Avg. loss: 0.063447\n",
      "Total training time: 333.24 seconds.\n",
      "-- Epoch 3998\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.464731, T: 683202228, Avg. loss: 0.063446\n",
      "Total training time: 333.33 seconds.\n",
      "-- Epoch 3999\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.463105, T: 683373114, Avg. loss: 0.063445\n",
      "Total training time: 333.43 seconds.\n",
      "-- Epoch 4000\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.461479, T: 683544000, Avg. loss: 0.063444\n",
      "Total training time: 333.53 seconds.\n",
      "-- Epoch 4001\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.459853, T: 683714886, Avg. loss: 0.063443\n",
      "Total training time: 333.62 seconds.\n",
      "-- Epoch 4002\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.458229, T: 683885772, Avg. loss: 0.063442\n",
      "Total training time: 333.71 seconds.\n",
      "-- Epoch 4003\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.456605, T: 684056658, Avg. loss: 0.063441\n",
      "Total training time: 333.79 seconds.\n",
      "-- Epoch 4004\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.454981, T: 684227544, Avg. loss: 0.063440\n",
      "Total training time: 333.88 seconds.\n",
      "-- Epoch 4005\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.453357, T: 684398430, Avg. loss: 0.063440\n",
      "Total training time: 333.99 seconds.\n",
      "-- Epoch 4006\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.451734, T: 684569316, Avg. loss: 0.063439\n",
      "Total training time: 334.07 seconds.\n",
      "-- Epoch 4007\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.450111, T: 684740202, Avg. loss: 0.063438\n",
      "Total training time: 334.16 seconds.\n",
      "-- Epoch 4008\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.448489, T: 684911088, Avg. loss: 0.063437\n",
      "Total training time: 334.25 seconds.\n",
      "-- Epoch 4009\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.446866, T: 685081974, Avg. loss: 0.063436\n",
      "Total training time: 334.34 seconds.\n",
      "-- Epoch 4010\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.445245, T: 685252860, Avg. loss: 0.063435\n",
      "Total training time: 334.43 seconds.\n",
      "-- Epoch 4011\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.443624, T: 685423746, Avg. loss: 0.063434\n",
      "Total training time: 334.51 seconds.\n",
      "-- Epoch 4012\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.442004, T: 685594632, Avg. loss: 0.063433\n",
      "Total training time: 334.61 seconds.\n",
      "-- Epoch 4013\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.440384, T: 685765518, Avg. loss: 0.063432\n",
      "Total training time: 334.70 seconds.\n",
      "-- Epoch 4014\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.438764, T: 685936404, Avg. loss: 0.063431\n",
      "Total training time: 334.78 seconds.\n",
      "-- Epoch 4015\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.437144, T: 686107290, Avg. loss: 0.063431\n",
      "Total training time: 334.86 seconds.\n",
      "-- Epoch 4016\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.435524, T: 686278176, Avg. loss: 0.063430\n",
      "Total training time: 334.93 seconds.\n",
      "-- Epoch 4017\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.433905, T: 686449062, Avg. loss: 0.063429\n",
      "Total training time: 335.02 seconds.\n",
      "-- Epoch 4018\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.432286, T: 686619948, Avg. loss: 0.063428\n",
      "Total training time: 335.09 seconds.\n",
      "-- Epoch 4019\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.430669, T: 686790834, Avg. loss: 0.063427\n",
      "Total training time: 335.17 seconds.\n",
      "-- Epoch 4020\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.429051, T: 686961720, Avg. loss: 0.063426\n",
      "Total training time: 335.24 seconds.\n",
      "-- Epoch 4021\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.427434, T: 687132606, Avg. loss: 0.063425\n",
      "Total training time: 335.32 seconds.\n",
      "-- Epoch 4022\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.425817, T: 687303492, Avg. loss: 0.063424\n",
      "Total training time: 335.39 seconds.\n",
      "-- Epoch 4023\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.424201, T: 687474378, Avg. loss: 0.063423\n",
      "Total training time: 335.47 seconds.\n",
      "-- Epoch 4024\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.422585, T: 687645264, Avg. loss: 0.063422\n",
      "Total training time: 335.55 seconds.\n",
      "-- Epoch 4025\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.420969, T: 687816150, Avg. loss: 0.063422\n",
      "Total training time: 335.62 seconds.\n",
      "-- Epoch 4026\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.419355, T: 687987036, Avg. loss: 0.063421\n",
      "Total training time: 335.70 seconds.\n",
      "-- Epoch 4027\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.417739, T: 688157922, Avg. loss: 0.063420\n",
      "Total training time: 335.77 seconds.\n",
      "-- Epoch 4028\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.416125, T: 688328808, Avg. loss: 0.063419\n",
      "Total training time: 335.85 seconds.\n",
      "-- Epoch 4029\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.414511, T: 688499694, Avg. loss: 0.063418\n",
      "Total training time: 335.92 seconds.\n",
      "-- Epoch 4030\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.412897, T: 688670580, Avg. loss: 0.063417\n",
      "Total training time: 336.00 seconds.\n",
      "-- Epoch 4031\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.411284, T: 688841466, Avg. loss: 0.063416\n",
      "Total training time: 336.07 seconds.\n",
      "-- Epoch 4032\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.409671, T: 689012352, Avg. loss: 0.063415\n",
      "Total training time: 336.15 seconds.\n",
      "-- Epoch 4033\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.408058, T: 689183238, Avg. loss: 0.063414\n",
      "Total training time: 336.22 seconds.\n",
      "-- Epoch 4034\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.406447, T: 689354124, Avg. loss: 0.063414\n",
      "Total training time: 336.30 seconds.\n",
      "-- Epoch 4035\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.404836, T: 689525010, Avg. loss: 0.063413\n",
      "Total training time: 336.37 seconds.\n",
      "-- Epoch 4036\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.403226, T: 689695896, Avg. loss: 0.063412\n",
      "Total training time: 336.45 seconds.\n",
      "-- Epoch 4037\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.401614, T: 689866782, Avg. loss: 0.063411\n",
      "Total training time: 336.52 seconds.\n",
      "-- Epoch 4038\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.400002, T: 690037668, Avg. loss: 0.063410\n",
      "Total training time: 336.60 seconds.\n",
      "-- Epoch 4039\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.398392, T: 690208554, Avg. loss: 0.063409\n",
      "Total training time: 336.67 seconds.\n",
      "-- Epoch 4040\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.396782, T: 690379440, Avg. loss: 0.063408\n",
      "Total training time: 336.75 seconds.\n",
      "-- Epoch 4041\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.395174, T: 690550326, Avg. loss: 0.063407\n",
      "Total training time: 336.83 seconds.\n",
      "-- Epoch 4042\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.393565, T: 690721212, Avg. loss: 0.063406\n",
      "Total training time: 336.90 seconds.\n",
      "-- Epoch 4043\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.391958, T: 690892098, Avg. loss: 0.063405\n",
      "Total training time: 336.98 seconds.\n",
      "-- Epoch 4044\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.390350, T: 691062984, Avg. loss: 0.063405\n",
      "Total training time: 337.05 seconds.\n",
      "-- Epoch 4045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.41, NNZs: 30, Bias: -118.388742, T: 691233870, Avg. loss: 0.063404\n",
      "Total training time: 337.13 seconds.\n",
      "-- Epoch 4046\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.387135, T: 691404756, Avg. loss: 0.063403\n",
      "Total training time: 337.20 seconds.\n",
      "-- Epoch 4047\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.385528, T: 691575642, Avg. loss: 0.063402\n",
      "Total training time: 337.28 seconds.\n",
      "-- Epoch 4048\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.383923, T: 691746528, Avg. loss: 0.063401\n",
      "Total training time: 337.35 seconds.\n",
      "-- Epoch 4049\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.382316, T: 691917414, Avg. loss: 0.063400\n",
      "Total training time: 337.43 seconds.\n",
      "-- Epoch 4050\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.380711, T: 692088300, Avg. loss: 0.063399\n",
      "Total training time: 337.50 seconds.\n",
      "-- Epoch 4051\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.379106, T: 692259186, Avg. loss: 0.063398\n",
      "Total training time: 337.58 seconds.\n",
      "-- Epoch 4052\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.377501, T: 692430072, Avg. loss: 0.063397\n",
      "Total training time: 337.66 seconds.\n",
      "-- Epoch 4053\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.375897, T: 692600958, Avg. loss: 0.063397\n",
      "Total training time: 337.73 seconds.\n",
      "-- Epoch 4054\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.374293, T: 692771844, Avg. loss: 0.063396\n",
      "Total training time: 337.81 seconds.\n",
      "-- Epoch 4055\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.372689, T: 692942730, Avg. loss: 0.063395\n",
      "Total training time: 337.88 seconds.\n",
      "-- Epoch 4056\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.371086, T: 693113616, Avg. loss: 0.063394\n",
      "Total training time: 337.95 seconds.\n",
      "-- Epoch 4057\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.369483, T: 693284502, Avg. loss: 0.063393\n",
      "Total training time: 338.03 seconds.\n",
      "-- Epoch 4058\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.367880, T: 693455388, Avg. loss: 0.063392\n",
      "Total training time: 338.11 seconds.\n",
      "-- Epoch 4059\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.366278, T: 693626274, Avg. loss: 0.063391\n",
      "Total training time: 338.18 seconds.\n",
      "-- Epoch 4060\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.364677, T: 693797160, Avg. loss: 0.063390\n",
      "Total training time: 338.26 seconds.\n",
      "-- Epoch 4061\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.363074, T: 693968046, Avg. loss: 0.063389\n",
      "Total training time: 338.33 seconds.\n",
      "-- Epoch 4062\n",
      "Norm: 13.41, NNZs: 30, Bias: -118.361474, T: 694138932, Avg. loss: 0.063389\n",
      "Total training time: 338.41 seconds.\n",
      "-- Epoch 4063\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.359874, T: 694309818, Avg. loss: 0.063388\n",
      "Total training time: 338.48 seconds.\n",
      "-- Epoch 4064\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.358275, T: 694480704, Avg. loss: 0.063387\n",
      "Total training time: 338.56 seconds.\n",
      "-- Epoch 4065\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.356677, T: 694651590, Avg. loss: 0.063386\n",
      "Total training time: 338.63 seconds.\n",
      "-- Epoch 4066\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.355077, T: 694822476, Avg. loss: 0.063385\n",
      "Total training time: 338.71 seconds.\n",
      "-- Epoch 4067\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.353479, T: 694993362, Avg. loss: 0.063384\n",
      "Total training time: 338.78 seconds.\n",
      "-- Epoch 4068\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.351882, T: 695164248, Avg. loss: 0.063383\n",
      "Total training time: 338.86 seconds.\n",
      "-- Epoch 4069\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.350284, T: 695335134, Avg. loss: 0.063382\n",
      "Total training time: 338.93 seconds.\n",
      "-- Epoch 4070\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.348687, T: 695506020, Avg. loss: 0.063382\n",
      "Total training time: 339.01 seconds.\n",
      "-- Epoch 4071\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.347091, T: 695676906, Avg. loss: 0.063381\n",
      "Total training time: 339.08 seconds.\n",
      "-- Epoch 4072\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.345493, T: 695847792, Avg. loss: 0.063380\n",
      "Total training time: 339.16 seconds.\n",
      "-- Epoch 4073\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.343897, T: 696018678, Avg. loss: 0.063379\n",
      "Total training time: 339.23 seconds.\n",
      "-- Epoch 4074\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.342300, T: 696189564, Avg. loss: 0.063378\n",
      "Total training time: 339.31 seconds.\n",
      "-- Epoch 4075\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.340706, T: 696360450, Avg. loss: 0.063377\n",
      "Total training time: 339.38 seconds.\n",
      "-- Epoch 4076\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.339110, T: 696531336, Avg. loss: 0.063376\n",
      "Total training time: 339.46 seconds.\n",
      "-- Epoch 4077\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.337515, T: 696702222, Avg. loss: 0.063375\n",
      "Total training time: 339.53 seconds.\n",
      "-- Epoch 4078\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.335921, T: 696873108, Avg. loss: 0.063374\n",
      "Total training time: 339.61 seconds.\n",
      "-- Epoch 4079\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.334327, T: 697043994, Avg. loss: 0.063374\n",
      "Total training time: 339.68 seconds.\n",
      "-- Epoch 4080\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.332734, T: 697214880, Avg. loss: 0.063373\n",
      "Total training time: 339.76 seconds.\n",
      "-- Epoch 4081\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.331141, T: 697385766, Avg. loss: 0.063372\n",
      "Total training time: 339.83 seconds.\n",
      "-- Epoch 4082\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.329547, T: 697556652, Avg. loss: 0.063371\n",
      "Total training time: 339.91 seconds.\n",
      "-- Epoch 4083\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.327955, T: 697727538, Avg. loss: 0.063370\n",
      "Total training time: 339.98 seconds.\n",
      "-- Epoch 4084\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.326363, T: 697898424, Avg. loss: 0.063369\n",
      "Total training time: 340.06 seconds.\n",
      "-- Epoch 4085\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.324770, T: 698069310, Avg. loss: 0.063368\n",
      "Total training time: 340.13 seconds.\n",
      "-- Epoch 4086\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.323179, T: 698240196, Avg. loss: 0.063367\n",
      "Total training time: 340.20 seconds.\n",
      "-- Epoch 4087\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.321588, T: 698411082, Avg. loss: 0.063366\n",
      "Total training time: 340.28 seconds.\n",
      "-- Epoch 4088\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.319997, T: 698581968, Avg. loss: 0.063366\n",
      "Total training time: 340.35 seconds.\n",
      "-- Epoch 4089\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.318408, T: 698752854, Avg. loss: 0.063365\n",
      "Total training time: 340.43 seconds.\n",
      "-- Epoch 4090\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.316819, T: 698923740, Avg. loss: 0.063364\n",
      "Total training time: 340.50 seconds.\n",
      "-- Epoch 4091\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.315229, T: 699094626, Avg. loss: 0.063363\n",
      "Total training time: 340.58 seconds.\n",
      "-- Epoch 4092\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.313640, T: 699265512, Avg. loss: 0.063362\n",
      "Total training time: 340.65 seconds.\n",
      "-- Epoch 4093\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.312051, T: 699436398, Avg. loss: 0.063361\n",
      "Total training time: 340.73 seconds.\n",
      "-- Epoch 4094\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.310463, T: 699607284, Avg. loss: 0.063360\n",
      "Total training time: 340.81 seconds.\n",
      "-- Epoch 4095\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.308876, T: 699778170, Avg. loss: 0.063359\n",
      "Total training time: 340.88 seconds.\n",
      "-- Epoch 4096\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.307289, T: 699949056, Avg. loss: 0.063359\n",
      "Total training time: 340.95 seconds.\n",
      "-- Epoch 4097\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.305703, T: 700119942, Avg. loss: 0.063358\n",
      "Total training time: 341.04 seconds.\n",
      "-- Epoch 4098\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.304116, T: 700290828, Avg. loss: 0.063357\n",
      "Total training time: 341.11 seconds.\n",
      "-- Epoch 4099\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.302530, T: 700461714, Avg. loss: 0.063356\n",
      "Total training time: 341.19 seconds.\n",
      "-- Epoch 4100\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.300944, T: 700632600, Avg. loss: 0.063355\n",
      "Total training time: 341.26 seconds.\n",
      "-- Epoch 4101\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.299359, T: 700803486, Avg. loss: 0.063354\n",
      "Total training time: 341.34 seconds.\n",
      "-- Epoch 4102\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.297774, T: 700974372, Avg. loss: 0.063353\n",
      "Total training time: 341.42 seconds.\n",
      "-- Epoch 4103\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.296190, T: 701145258, Avg. loss: 0.063352\n",
      "Total training time: 341.49 seconds.\n",
      "-- Epoch 4104\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.294606, T: 701316144, Avg. loss: 0.063352\n",
      "Total training time: 341.57 seconds.\n",
      "-- Epoch 4105\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.293022, T: 701487030, Avg. loss: 0.063351\n",
      "Total training time: 341.64 seconds.\n",
      "-- Epoch 4106\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.291439, T: 701657916, Avg. loss: 0.063350\n",
      "Total training time: 341.72 seconds.\n",
      "-- Epoch 4107\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.289856, T: 701828802, Avg. loss: 0.063349\n",
      "Total training time: 341.79 seconds.\n",
      "-- Epoch 4108\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.288275, T: 701999688, Avg. loss: 0.063348\n",
      "Total training time: 341.87 seconds.\n",
      "-- Epoch 4109\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.286693, T: 702170574, Avg. loss: 0.063347\n",
      "Total training time: 341.94 seconds.\n",
      "-- Epoch 4110\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.285112, T: 702341460, Avg. loss: 0.063346\n",
      "Total training time: 342.02 seconds.\n",
      "-- Epoch 4111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.40, NNZs: 30, Bias: -118.283529, T: 702512346, Avg. loss: 0.063345\n",
      "Total training time: 342.09 seconds.\n",
      "-- Epoch 4112\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.281949, T: 702683232, Avg. loss: 0.063345\n",
      "Total training time: 342.17 seconds.\n",
      "-- Epoch 4113\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.280369, T: 702854118, Avg. loss: 0.063344\n",
      "Total training time: 342.24 seconds.\n",
      "-- Epoch 4114\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.278788, T: 703025004, Avg. loss: 0.063343\n",
      "Total training time: 342.32 seconds.\n",
      "-- Epoch 4115\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.277209, T: 703195890, Avg. loss: 0.063342\n",
      "Total training time: 342.39 seconds.\n",
      "-- Epoch 4116\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.275630, T: 703366776, Avg. loss: 0.063341\n",
      "Total training time: 342.47 seconds.\n",
      "-- Epoch 4117\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.274052, T: 703537662, Avg. loss: 0.063340\n",
      "Total training time: 342.55 seconds.\n",
      "-- Epoch 4118\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.272474, T: 703708548, Avg. loss: 0.063339\n",
      "Total training time: 342.62 seconds.\n",
      "-- Epoch 4119\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.270896, T: 703879434, Avg. loss: 0.063338\n",
      "Total training time: 342.69 seconds.\n",
      "-- Epoch 4120\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.269318, T: 704050320, Avg. loss: 0.063338\n",
      "Total training time: 342.77 seconds.\n",
      "-- Epoch 4121\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.267741, T: 704221206, Avg. loss: 0.063337\n",
      "Total training time: 342.84 seconds.\n",
      "-- Epoch 4122\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.266164, T: 704392092, Avg. loss: 0.063336\n",
      "Total training time: 342.92 seconds.\n",
      "-- Epoch 4123\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.264586, T: 704562978, Avg. loss: 0.063335\n",
      "Total training time: 342.99 seconds.\n",
      "-- Epoch 4124\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.263009, T: 704733864, Avg. loss: 0.063334\n",
      "Total training time: 343.07 seconds.\n",
      "-- Epoch 4125\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.261433, T: 704904750, Avg. loss: 0.063333\n",
      "Total training time: 343.14 seconds.\n",
      "-- Epoch 4126\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.259857, T: 705075636, Avg. loss: 0.063332\n",
      "Total training time: 343.22 seconds.\n",
      "-- Epoch 4127\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.258282, T: 705246522, Avg. loss: 0.063331\n",
      "Total training time: 343.29 seconds.\n",
      "-- Epoch 4128\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.256708, T: 705417408, Avg. loss: 0.063331\n",
      "Total training time: 343.37 seconds.\n",
      "-- Epoch 4129\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.255133, T: 705588294, Avg. loss: 0.063330\n",
      "Total training time: 343.44 seconds.\n",
      "-- Epoch 4130\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.253558, T: 705759180, Avg. loss: 0.063329\n",
      "Total training time: 343.52 seconds.\n",
      "-- Epoch 4131\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.251985, T: 705930066, Avg. loss: 0.063328\n",
      "Total training time: 343.59 seconds.\n",
      "-- Epoch 4132\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.250411, T: 706100952, Avg. loss: 0.063327\n",
      "Total training time: 343.67 seconds.\n",
      "-- Epoch 4133\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.248837, T: 706271838, Avg. loss: 0.063326\n",
      "Total training time: 343.75 seconds.\n",
      "-- Epoch 4134\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.247264, T: 706442724, Avg. loss: 0.063325\n",
      "Total training time: 343.82 seconds.\n",
      "-- Epoch 4135\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.245692, T: 706613610, Avg. loss: 0.063324\n",
      "Total training time: 343.90 seconds.\n",
      "-- Epoch 4136\n",
      "Norm: 13.40, NNZs: 30, Bias: -118.244120, T: 706784496, Avg. loss: 0.063324\n",
      "Total training time: 343.97 seconds.\n",
      "-- Epoch 4137\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.242548, T: 706955382, Avg. loss: 0.063323\n",
      "Total training time: 344.05 seconds.\n",
      "-- Epoch 4138\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.240977, T: 707126268, Avg. loss: 0.063322\n",
      "Total training time: 344.12 seconds.\n",
      "-- Epoch 4139\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.239407, T: 707297154, Avg. loss: 0.063321\n",
      "Total training time: 344.20 seconds.\n",
      "-- Epoch 4140\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.237836, T: 707468040, Avg. loss: 0.063320\n",
      "Total training time: 344.28 seconds.\n",
      "-- Epoch 4141\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.236267, T: 707638926, Avg. loss: 0.063319\n",
      "Total training time: 344.35 seconds.\n",
      "-- Epoch 4142\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.234696, T: 707809812, Avg. loss: 0.063318\n",
      "Total training time: 344.43 seconds.\n",
      "-- Epoch 4143\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.233127, T: 707980698, Avg. loss: 0.063317\n",
      "Total training time: 344.50 seconds.\n",
      "-- Epoch 4144\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.231559, T: 708151584, Avg. loss: 0.063317\n",
      "Total training time: 344.58 seconds.\n",
      "-- Epoch 4145\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.229991, T: 708322470, Avg. loss: 0.063316\n",
      "Total training time: 344.65 seconds.\n",
      "-- Epoch 4146\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.228424, T: 708493356, Avg. loss: 0.063315\n",
      "Total training time: 344.73 seconds.\n",
      "-- Epoch 4147\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.226857, T: 708664242, Avg. loss: 0.063314\n",
      "Total training time: 344.80 seconds.\n",
      "-- Epoch 4148\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.225289, T: 708835128, Avg. loss: 0.063313\n",
      "Total training time: 344.88 seconds.\n",
      "-- Epoch 4149\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.223723, T: 709006014, Avg. loss: 0.063312\n",
      "Total training time: 344.96 seconds.\n",
      "-- Epoch 4150\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.222157, T: 709176900, Avg. loss: 0.063311\n",
      "Total training time: 345.04 seconds.\n",
      "-- Epoch 4151\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.220592, T: 709347786, Avg. loss: 0.063311\n",
      "Total training time: 345.11 seconds.\n",
      "-- Epoch 4152\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.219026, T: 709518672, Avg. loss: 0.063310\n",
      "Total training time: 345.19 seconds.\n",
      "-- Epoch 4153\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.217460, T: 709689558, Avg. loss: 0.063309\n",
      "Total training time: 345.26 seconds.\n",
      "-- Epoch 4154\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.215895, T: 709860444, Avg. loss: 0.063308\n",
      "Total training time: 345.34 seconds.\n",
      "-- Epoch 4155\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.214331, T: 710031330, Avg. loss: 0.063307\n",
      "Total training time: 345.41 seconds.\n",
      "-- Epoch 4156\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.212767, T: 710202216, Avg. loss: 0.063306\n",
      "Total training time: 345.49 seconds.\n",
      "-- Epoch 4157\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.211203, T: 710373102, Avg. loss: 0.063305\n",
      "Total training time: 345.57 seconds.\n",
      "-- Epoch 4158\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.209640, T: 710543988, Avg. loss: 0.063304\n",
      "Total training time: 345.64 seconds.\n",
      "-- Epoch 4159\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.208077, T: 710714874, Avg. loss: 0.063304\n",
      "Total training time: 345.72 seconds.\n",
      "-- Epoch 4160\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.206515, T: 710885760, Avg. loss: 0.063303\n",
      "Total training time: 345.79 seconds.\n",
      "-- Epoch 4161\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.204953, T: 711056646, Avg. loss: 0.063302\n",
      "Total training time: 345.87 seconds.\n",
      "-- Epoch 4162\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.203391, T: 711227532, Avg. loss: 0.063301\n",
      "Total training time: 345.94 seconds.\n",
      "-- Epoch 4163\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.201830, T: 711398418, Avg. loss: 0.063300\n",
      "Total training time: 346.02 seconds.\n",
      "-- Epoch 4164\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.200269, T: 711569304, Avg. loss: 0.063299\n",
      "Total training time: 346.09 seconds.\n",
      "-- Epoch 4165\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.198709, T: 711740190, Avg. loss: 0.063298\n",
      "Total training time: 346.17 seconds.\n",
      "-- Epoch 4166\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.197148, T: 711911076, Avg. loss: 0.063298\n",
      "Total training time: 346.24 seconds.\n",
      "-- Epoch 4167\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.195588, T: 712081962, Avg. loss: 0.063297\n",
      "Total training time: 346.31 seconds.\n",
      "-- Epoch 4168\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.194027, T: 712252848, Avg. loss: 0.063296\n",
      "Total training time: 346.39 seconds.\n",
      "-- Epoch 4169\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.192468, T: 712423734, Avg. loss: 0.063295\n",
      "Total training time: 346.46 seconds.\n",
      "-- Epoch 4170\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.190909, T: 712594620, Avg. loss: 0.063294\n",
      "Total training time: 346.54 seconds.\n",
      "-- Epoch 4171\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.189349, T: 712765506, Avg. loss: 0.063293\n",
      "Total training time: 346.62 seconds.\n",
      "-- Epoch 4172\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.187791, T: 712936392, Avg. loss: 0.063292\n",
      "Total training time: 346.69 seconds.\n",
      "-- Epoch 4173\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.186233, T: 713107278, Avg. loss: 0.063291\n",
      "Total training time: 346.77 seconds.\n",
      "-- Epoch 4174\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.184676, T: 713278164, Avg. loss: 0.063291\n",
      "Total training time: 346.84 seconds.\n",
      "-- Epoch 4175\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.183118, T: 713449050, Avg. loss: 0.063290\n",
      "Total training time: 346.92 seconds.\n",
      "-- Epoch 4176\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.181562, T: 713619936, Avg. loss: 0.063289\n",
      "Total training time: 346.99 seconds.\n",
      "-- Epoch 4177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.39, NNZs: 30, Bias: -118.180006, T: 713790822, Avg. loss: 0.063288\n",
      "Total training time: 347.07 seconds.\n",
      "-- Epoch 4178\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.178450, T: 713961708, Avg. loss: 0.063287\n",
      "Total training time: 347.14 seconds.\n",
      "-- Epoch 4179\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.176894, T: 714132594, Avg. loss: 0.063286\n",
      "Total training time: 347.21 seconds.\n",
      "-- Epoch 4180\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.175339, T: 714303480, Avg. loss: 0.063285\n",
      "Total training time: 347.29 seconds.\n",
      "-- Epoch 4181\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.173784, T: 714474366, Avg. loss: 0.063285\n",
      "Total training time: 347.36 seconds.\n",
      "-- Epoch 4182\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.172230, T: 714645252, Avg. loss: 0.063284\n",
      "Total training time: 347.44 seconds.\n",
      "-- Epoch 4183\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.170676, T: 714816138, Avg. loss: 0.063283\n",
      "Total training time: 347.52 seconds.\n",
      "-- Epoch 4184\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.169122, T: 714987024, Avg. loss: 0.063282\n",
      "Total training time: 347.59 seconds.\n",
      "-- Epoch 4185\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.167569, T: 715157910, Avg. loss: 0.063281\n",
      "Total training time: 347.67 seconds.\n",
      "-- Epoch 4186\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.166016, T: 715328796, Avg. loss: 0.063280\n",
      "Total training time: 347.74 seconds.\n",
      "-- Epoch 4187\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.164464, T: 715499682, Avg. loss: 0.063279\n",
      "Total training time: 347.82 seconds.\n",
      "-- Epoch 4188\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.162911, T: 715670568, Avg. loss: 0.063279\n",
      "Total training time: 347.89 seconds.\n",
      "-- Epoch 4189\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.161359, T: 715841454, Avg. loss: 0.063278\n",
      "Total training time: 347.97 seconds.\n",
      "-- Epoch 4190\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.159809, T: 716012340, Avg. loss: 0.063277\n",
      "Total training time: 348.04 seconds.\n",
      "-- Epoch 4191\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.158257, T: 716183226, Avg. loss: 0.063276\n",
      "Total training time: 348.12 seconds.\n",
      "-- Epoch 4192\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.156707, T: 716354112, Avg. loss: 0.063275\n",
      "Total training time: 348.19 seconds.\n",
      "-- Epoch 4193\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.155157, T: 716524998, Avg. loss: 0.063274\n",
      "Total training time: 348.26 seconds.\n",
      "-- Epoch 4194\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.153607, T: 716695884, Avg. loss: 0.063273\n",
      "Total training time: 348.34 seconds.\n",
      "-- Epoch 4195\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.152057, T: 716866770, Avg. loss: 0.063273\n",
      "Total training time: 348.41 seconds.\n",
      "-- Epoch 4196\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.150507, T: 717037656, Avg. loss: 0.063272\n",
      "Total training time: 348.49 seconds.\n",
      "-- Epoch 4197\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.148959, T: 717208542, Avg. loss: 0.063271\n",
      "Total training time: 348.57 seconds.\n",
      "-- Epoch 4198\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.147410, T: 717379428, Avg. loss: 0.063270\n",
      "Total training time: 348.64 seconds.\n",
      "-- Epoch 4199\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.145862, T: 717550314, Avg. loss: 0.063269\n",
      "Total training time: 348.72 seconds.\n",
      "-- Epoch 4200\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.144314, T: 717721200, Avg. loss: 0.063268\n",
      "Total training time: 348.79 seconds.\n",
      "-- Epoch 4201\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.142766, T: 717892086, Avg. loss: 0.063267\n",
      "Total training time: 348.87 seconds.\n",
      "-- Epoch 4202\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.141220, T: 718062972, Avg. loss: 0.063267\n",
      "Total training time: 348.94 seconds.\n",
      "-- Epoch 4203\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.139673, T: 718233858, Avg. loss: 0.063266\n",
      "Total training time: 349.02 seconds.\n",
      "-- Epoch 4204\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.138127, T: 718404744, Avg. loss: 0.063265\n",
      "Total training time: 349.09 seconds.\n",
      "-- Epoch 4205\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.136581, T: 718575630, Avg. loss: 0.063264\n",
      "Total training time: 349.17 seconds.\n",
      "-- Epoch 4206\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.135036, T: 718746516, Avg. loss: 0.063263\n",
      "Total training time: 349.24 seconds.\n",
      "-- Epoch 4207\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.133492, T: 718917402, Avg. loss: 0.063262\n",
      "Total training time: 349.32 seconds.\n",
      "-- Epoch 4208\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.131947, T: 719088288, Avg. loss: 0.063261\n",
      "Total training time: 349.39 seconds.\n",
      "-- Epoch 4209\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.130404, T: 719259174, Avg. loss: 0.063261\n",
      "Total training time: 349.47 seconds.\n",
      "-- Epoch 4210\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.128860, T: 719430060, Avg. loss: 0.063260\n",
      "Total training time: 349.55 seconds.\n",
      "-- Epoch 4211\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.127317, T: 719600946, Avg. loss: 0.063259\n",
      "Total training time: 349.62 seconds.\n",
      "-- Epoch 4212\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.125772, T: 719771832, Avg. loss: 0.063258\n",
      "Total training time: 349.70 seconds.\n",
      "-- Epoch 4213\n",
      "Norm: 13.39, NNZs: 30, Bias: -118.124229, T: 719942718, Avg. loss: 0.063257\n",
      "Total training time: 349.77 seconds.\n",
      "-- Epoch 4214\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.122687, T: 720113604, Avg. loss: 0.063256\n",
      "Total training time: 349.85 seconds.\n",
      "-- Epoch 4215\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.121144, T: 720284490, Avg. loss: 0.063255\n",
      "Total training time: 349.92 seconds.\n",
      "-- Epoch 4216\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.119603, T: 720455376, Avg. loss: 0.063255\n",
      "Total training time: 350.00 seconds.\n",
      "-- Epoch 4217\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.118063, T: 720626262, Avg. loss: 0.063254\n",
      "Total training time: 350.07 seconds.\n",
      "-- Epoch 4218\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.116522, T: 720797148, Avg. loss: 0.063253\n",
      "Total training time: 350.15 seconds.\n",
      "-- Epoch 4219\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.114982, T: 720968034, Avg. loss: 0.063252\n",
      "Total training time: 350.22 seconds.\n",
      "-- Epoch 4220\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.113442, T: 721138920, Avg. loss: 0.063251\n",
      "Total training time: 350.30 seconds.\n",
      "-- Epoch 4221\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.111903, T: 721309806, Avg. loss: 0.063250\n",
      "Total training time: 350.37 seconds.\n",
      "-- Epoch 4222\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.110363, T: 721480692, Avg. loss: 0.063249\n",
      "Total training time: 350.45 seconds.\n",
      "-- Epoch 4223\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.108824, T: 721651578, Avg. loss: 0.063249\n",
      "Total training time: 350.53 seconds.\n",
      "-- Epoch 4224\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.107286, T: 721822464, Avg. loss: 0.063248\n",
      "Total training time: 350.60 seconds.\n",
      "-- Epoch 4225\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.105748, T: 721993350, Avg. loss: 0.063247\n",
      "Total training time: 350.68 seconds.\n",
      "-- Epoch 4226\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.104210, T: 722164236, Avg. loss: 0.063246\n",
      "Total training time: 350.75 seconds.\n",
      "-- Epoch 4227\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.102673, T: 722335122, Avg. loss: 0.063245\n",
      "Total training time: 350.83 seconds.\n",
      "-- Epoch 4228\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.101135, T: 722506008, Avg. loss: 0.063244\n",
      "Total training time: 350.90 seconds.\n",
      "-- Epoch 4229\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.099599, T: 722676894, Avg. loss: 0.063244\n",
      "Total training time: 350.98 seconds.\n",
      "-- Epoch 4230\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.098063, T: 722847780, Avg. loss: 0.063243\n",
      "Total training time: 351.05 seconds.\n",
      "-- Epoch 4231\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.096527, T: 723018666, Avg. loss: 0.063242\n",
      "Total training time: 351.12 seconds.\n",
      "-- Epoch 4232\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.094991, T: 723189552, Avg. loss: 0.063241\n",
      "Total training time: 351.20 seconds.\n",
      "-- Epoch 4233\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.093456, T: 723360438, Avg. loss: 0.063240\n",
      "Total training time: 351.27 seconds.\n",
      "-- Epoch 4234\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.091920, T: 723531324, Avg. loss: 0.063239\n",
      "Total training time: 351.35 seconds.\n",
      "-- Epoch 4235\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.090386, T: 723702210, Avg. loss: 0.063238\n",
      "Total training time: 351.42 seconds.\n",
      "-- Epoch 4236\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.088852, T: 723873096, Avg. loss: 0.063238\n",
      "Total training time: 351.50 seconds.\n",
      "-- Epoch 4237\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.087319, T: 724043982, Avg. loss: 0.063237\n",
      "Total training time: 351.58 seconds.\n",
      "-- Epoch 4238\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.085785, T: 724214868, Avg. loss: 0.063236\n",
      "Total training time: 351.65 seconds.\n",
      "-- Epoch 4239\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.084251, T: 724385754, Avg. loss: 0.063235\n",
      "Total training time: 351.73 seconds.\n",
      "-- Epoch 4240\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.082718, T: 724556640, Avg. loss: 0.063234\n",
      "Total training time: 351.80 seconds.\n",
      "-- Epoch 4241\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.081186, T: 724727526, Avg. loss: 0.063233\n",
      "Total training time: 351.88 seconds.\n",
      "-- Epoch 4242\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.079654, T: 724898412, Avg. loss: 0.063232\n",
      "Total training time: 351.95 seconds.\n",
      "-- Epoch 4243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.38, NNZs: 30, Bias: -118.078122, T: 725069298, Avg. loss: 0.063232\n",
      "Total training time: 352.03 seconds.\n",
      "-- Epoch 4244\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.076591, T: 725240184, Avg. loss: 0.063231\n",
      "Total training time: 352.11 seconds.\n",
      "-- Epoch 4245\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.075060, T: 725411070, Avg. loss: 0.063230\n",
      "Total training time: 352.18 seconds.\n",
      "-- Epoch 4246\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.073530, T: 725581956, Avg. loss: 0.063229\n",
      "Total training time: 352.26 seconds.\n",
      "-- Epoch 4247\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.071999, T: 725752842, Avg. loss: 0.063228\n",
      "Total training time: 352.33 seconds.\n",
      "-- Epoch 4248\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.070469, T: 725923728, Avg. loss: 0.063227\n",
      "Total training time: 352.41 seconds.\n",
      "-- Epoch 4249\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.068940, T: 726094614, Avg. loss: 0.063227\n",
      "Total training time: 352.48 seconds.\n",
      "-- Epoch 4250\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.067411, T: 726265500, Avg. loss: 0.063226\n",
      "Total training time: 352.56 seconds.\n",
      "-- Epoch 4251\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.065883, T: 726436386, Avg. loss: 0.063225\n",
      "Total training time: 352.64 seconds.\n",
      "-- Epoch 4252\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.064355, T: 726607272, Avg. loss: 0.063224\n",
      "Total training time: 352.71 seconds.\n",
      "-- Epoch 4253\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.062825, T: 726778158, Avg. loss: 0.063223\n",
      "Total training time: 352.79 seconds.\n",
      "-- Epoch 4254\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.061297, T: 726949044, Avg. loss: 0.063222\n",
      "Total training time: 352.86 seconds.\n",
      "-- Epoch 4255\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.059771, T: 727119930, Avg. loss: 0.063221\n",
      "Total training time: 352.94 seconds.\n",
      "-- Epoch 4256\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.058244, T: 727290816, Avg. loss: 0.063221\n",
      "Total training time: 353.01 seconds.\n",
      "-- Epoch 4257\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.056717, T: 727461702, Avg. loss: 0.063220\n",
      "Total training time: 353.08 seconds.\n",
      "-- Epoch 4258\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.055191, T: 727632588, Avg. loss: 0.063219\n",
      "Total training time: 353.16 seconds.\n",
      "-- Epoch 4259\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.053664, T: 727803474, Avg. loss: 0.063218\n",
      "Total training time: 353.23 seconds.\n",
      "-- Epoch 4260\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.052138, T: 727974360, Avg. loss: 0.063217\n",
      "Total training time: 353.31 seconds.\n",
      "-- Epoch 4261\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.050614, T: 728145246, Avg. loss: 0.063216\n",
      "Total training time: 353.39 seconds.\n",
      "-- Epoch 4262\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.049090, T: 728316132, Avg. loss: 0.063216\n",
      "Total training time: 353.46 seconds.\n",
      "-- Epoch 4263\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.047565, T: 728487018, Avg. loss: 0.063215\n",
      "Total training time: 353.54 seconds.\n",
      "-- Epoch 4264\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.046041, T: 728657904, Avg. loss: 0.063214\n",
      "Total training time: 353.61 seconds.\n",
      "-- Epoch 4265\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.044518, T: 728828790, Avg. loss: 0.063213\n",
      "Total training time: 353.69 seconds.\n",
      "-- Epoch 4266\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.042993, T: 728999676, Avg. loss: 0.063212\n",
      "Total training time: 353.76 seconds.\n",
      "-- Epoch 4267\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.041471, T: 729170562, Avg. loss: 0.063211\n",
      "Total training time: 353.84 seconds.\n",
      "-- Epoch 4268\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.039948, T: 729341448, Avg. loss: 0.063210\n",
      "Total training time: 353.91 seconds.\n",
      "-- Epoch 4269\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.038426, T: 729512334, Avg. loss: 0.063210\n",
      "Total training time: 353.99 seconds.\n",
      "-- Epoch 4270\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.036905, T: 729683220, Avg. loss: 0.063209\n",
      "Total training time: 354.06 seconds.\n",
      "-- Epoch 4271\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.035383, T: 729854106, Avg. loss: 0.063208\n",
      "Total training time: 354.14 seconds.\n",
      "-- Epoch 4272\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.033862, T: 730024992, Avg. loss: 0.063207\n",
      "Total training time: 354.22 seconds.\n",
      "-- Epoch 4273\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.032342, T: 730195878, Avg. loss: 0.063206\n",
      "Total training time: 354.29 seconds.\n",
      "-- Epoch 4274\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.030821, T: 730366764, Avg. loss: 0.063205\n",
      "Total training time: 354.38 seconds.\n",
      "-- Epoch 4275\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.029300, T: 730537650, Avg. loss: 0.063205\n",
      "Total training time: 354.45 seconds.\n",
      "-- Epoch 4276\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.027780, T: 730708536, Avg. loss: 0.063204\n",
      "Total training time: 354.53 seconds.\n",
      "-- Epoch 4277\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.026260, T: 730879422, Avg. loss: 0.063203\n",
      "Total training time: 354.61 seconds.\n",
      "-- Epoch 4278\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.024741, T: 731050308, Avg. loss: 0.063202\n",
      "Total training time: 354.69 seconds.\n",
      "-- Epoch 4279\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.023222, T: 731221194, Avg. loss: 0.063201\n",
      "Total training time: 354.77 seconds.\n",
      "-- Epoch 4280\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.021705, T: 731392080, Avg. loss: 0.063200\n",
      "Total training time: 354.85 seconds.\n",
      "-- Epoch 4281\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.020187, T: 731562966, Avg. loss: 0.063200\n",
      "Total training time: 354.93 seconds.\n",
      "-- Epoch 4282\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.018668, T: 731733852, Avg. loss: 0.063199\n",
      "Total training time: 355.00 seconds.\n",
      "-- Epoch 4283\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.017151, T: 731904738, Avg. loss: 0.063198\n",
      "Total training time: 355.08 seconds.\n",
      "-- Epoch 4284\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.015634, T: 732075624, Avg. loss: 0.063197\n",
      "Total training time: 355.16 seconds.\n",
      "-- Epoch 4285\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.014118, T: 732246510, Avg. loss: 0.063196\n",
      "Total training time: 355.24 seconds.\n",
      "-- Epoch 4286\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.012600, T: 732417396, Avg. loss: 0.063195\n",
      "Total training time: 355.31 seconds.\n",
      "-- Epoch 4287\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.011084, T: 732588282, Avg. loss: 0.063194\n",
      "Total training time: 355.38 seconds.\n",
      "-- Epoch 4288\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.009569, T: 732759168, Avg. loss: 0.063194\n",
      "Total training time: 355.46 seconds.\n",
      "-- Epoch 4289\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.008053, T: 732930054, Avg. loss: 0.063193\n",
      "Total training time: 355.54 seconds.\n",
      "-- Epoch 4290\n",
      "Norm: 13.38, NNZs: 30, Bias: -118.006538, T: 733100940, Avg. loss: 0.063192\n",
      "Total training time: 355.61 seconds.\n",
      "-- Epoch 4291\n",
      "Norm: 13.37, NNZs: 30, Bias: -118.005024, T: 733271826, Avg. loss: 0.063191\n",
      "Total training time: 355.68 seconds.\n",
      "-- Epoch 4292\n",
      "Norm: 13.37, NNZs: 30, Bias: -118.003509, T: 733442712, Avg. loss: 0.063190\n",
      "Total training time: 355.76 seconds.\n",
      "-- Epoch 4293\n",
      "Norm: 13.37, NNZs: 30, Bias: -118.001997, T: 733613598, Avg. loss: 0.063189\n",
      "Total training time: 355.83 seconds.\n",
      "-- Epoch 4294\n",
      "Norm: 13.37, NNZs: 30, Bias: -118.000483, T: 733784484, Avg. loss: 0.063189\n",
      "Total training time: 355.91 seconds.\n",
      "-- Epoch 4295\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.998970, T: 733955370, Avg. loss: 0.063188\n",
      "Total training time: 355.98 seconds.\n",
      "-- Epoch 4296\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.997458, T: 734126256, Avg. loss: 0.063187\n",
      "Total training time: 356.06 seconds.\n",
      "-- Epoch 4297\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.995946, T: 734297142, Avg. loss: 0.063186\n",
      "Total training time: 356.13 seconds.\n",
      "-- Epoch 4298\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.994434, T: 734468028, Avg. loss: 0.063185\n",
      "Total training time: 356.20 seconds.\n",
      "-- Epoch 4299\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.992922, T: 734638914, Avg. loss: 0.063184\n",
      "Total training time: 356.28 seconds.\n",
      "-- Epoch 4300\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.991412, T: 734809800, Avg. loss: 0.063184\n",
      "Total training time: 356.35 seconds.\n",
      "-- Epoch 4301\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.989900, T: 734980686, Avg. loss: 0.063183\n",
      "Total training time: 356.43 seconds.\n",
      "-- Epoch 4302\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.988390, T: 735151572, Avg. loss: 0.063182\n",
      "Total training time: 356.50 seconds.\n",
      "-- Epoch 4303\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.986880, T: 735322458, Avg. loss: 0.063181\n",
      "Total training time: 356.58 seconds.\n",
      "-- Epoch 4304\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.985370, T: 735493344, Avg. loss: 0.063180\n",
      "Total training time: 356.66 seconds.\n",
      "-- Epoch 4305\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.983860, T: 735664230, Avg. loss: 0.063179\n",
      "Total training time: 356.73 seconds.\n",
      "-- Epoch 4306\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.982351, T: 735835116, Avg. loss: 0.063179\n",
      "Total training time: 356.81 seconds.\n",
      "-- Epoch 4307\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.980842, T: 736006002, Avg. loss: 0.063178\n",
      "Total training time: 356.91 seconds.\n",
      "-- Epoch 4308\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.979333, T: 736176888, Avg. loss: 0.063177\n",
      "Total training time: 356.98 seconds.\n",
      "-- Epoch 4309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.37, NNZs: 30, Bias: -117.977825, T: 736347774, Avg. loss: 0.063176\n",
      "Total training time: 357.06 seconds.\n",
      "-- Epoch 4310\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.976317, T: 736518660, Avg. loss: 0.063175\n",
      "Total training time: 357.13 seconds.\n",
      "-- Epoch 4311\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.974810, T: 736689546, Avg. loss: 0.063174\n",
      "Total training time: 357.21 seconds.\n",
      "-- Epoch 4312\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.973303, T: 736860432, Avg. loss: 0.063174\n",
      "Total training time: 357.28 seconds.\n",
      "-- Epoch 4313\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.971797, T: 737031318, Avg. loss: 0.063173\n",
      "Total training time: 357.36 seconds.\n",
      "-- Epoch 4314\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.970291, T: 737202204, Avg. loss: 0.063172\n",
      "Total training time: 357.43 seconds.\n",
      "-- Epoch 4315\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.968785, T: 737373090, Avg. loss: 0.063171\n",
      "Total training time: 357.51 seconds.\n",
      "-- Epoch 4316\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.967279, T: 737543976, Avg. loss: 0.063170\n",
      "Total training time: 357.58 seconds.\n",
      "-- Epoch 4317\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.965775, T: 737714862, Avg. loss: 0.063169\n",
      "Total training time: 357.66 seconds.\n",
      "-- Epoch 4318\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.964269, T: 737885748, Avg. loss: 0.063169\n",
      "Total training time: 357.73 seconds.\n",
      "-- Epoch 4319\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.962765, T: 738056634, Avg. loss: 0.063168\n",
      "Total training time: 357.81 seconds.\n",
      "-- Epoch 4320\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.961261, T: 738227520, Avg. loss: 0.063167\n",
      "Total training time: 357.88 seconds.\n",
      "-- Epoch 4321\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.959757, T: 738398406, Avg. loss: 0.063166\n",
      "Total training time: 357.96 seconds.\n",
      "-- Epoch 4322\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.958253, T: 738569292, Avg. loss: 0.063165\n",
      "Total training time: 358.03 seconds.\n",
      "-- Epoch 4323\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.956750, T: 738740178, Avg. loss: 0.063164\n",
      "Total training time: 358.11 seconds.\n",
      "-- Epoch 4324\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.955249, T: 738911064, Avg. loss: 0.063164\n",
      "Total training time: 358.18 seconds.\n",
      "-- Epoch 4325\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.953746, T: 739081950, Avg. loss: 0.063163\n",
      "Total training time: 358.26 seconds.\n",
      "-- Epoch 4326\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.952244, T: 739252836, Avg. loss: 0.063162\n",
      "Total training time: 358.33 seconds.\n",
      "-- Epoch 4327\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.950741, T: 739423722, Avg. loss: 0.063161\n",
      "Total training time: 358.41 seconds.\n",
      "-- Epoch 4328\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.949239, T: 739594608, Avg. loss: 0.063160\n",
      "Total training time: 358.48 seconds.\n",
      "-- Epoch 4329\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.947739, T: 739765494, Avg. loss: 0.063159\n",
      "Total training time: 358.56 seconds.\n",
      "-- Epoch 4330\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.946238, T: 739936380, Avg. loss: 0.063159\n",
      "Total training time: 358.64 seconds.\n",
      "-- Epoch 4331\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.944738, T: 740107266, Avg. loss: 0.063158\n",
      "Total training time: 358.71 seconds.\n",
      "-- Epoch 4332\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.943238, T: 740278152, Avg. loss: 0.063157\n",
      "Total training time: 358.79 seconds.\n",
      "-- Epoch 4333\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.941739, T: 740449038, Avg. loss: 0.063156\n",
      "Total training time: 358.86 seconds.\n",
      "-- Epoch 4334\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.940240, T: 740619924, Avg. loss: 0.063155\n",
      "Total training time: 358.94 seconds.\n",
      "-- Epoch 4335\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.938741, T: 740790810, Avg. loss: 0.063154\n",
      "Total training time: 359.01 seconds.\n",
      "-- Epoch 4336\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.937242, T: 740961696, Avg. loss: 0.063154\n",
      "Total training time: 359.09 seconds.\n",
      "-- Epoch 4337\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.935743, T: 741132582, Avg. loss: 0.063153\n",
      "Total training time: 359.16 seconds.\n",
      "-- Epoch 4338\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.934245, T: 741303468, Avg. loss: 0.063152\n",
      "Total training time: 359.24 seconds.\n",
      "-- Epoch 4339\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.932748, T: 741474354, Avg. loss: 0.063151\n",
      "Total training time: 359.31 seconds.\n",
      "-- Epoch 4340\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.931250, T: 741645240, Avg. loss: 0.063150\n",
      "Total training time: 359.39 seconds.\n",
      "-- Epoch 4341\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.929753, T: 741816126, Avg. loss: 0.063149\n",
      "Total training time: 359.46 seconds.\n",
      "-- Epoch 4342\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.928257, T: 741987012, Avg. loss: 0.063149\n",
      "Total training time: 359.54 seconds.\n",
      "-- Epoch 4343\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.926761, T: 742157898, Avg. loss: 0.063148\n",
      "Total training time: 359.62 seconds.\n",
      "-- Epoch 4344\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.925265, T: 742328784, Avg. loss: 0.063147\n",
      "Total training time: 359.69 seconds.\n",
      "-- Epoch 4345\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.923770, T: 742499670, Avg. loss: 0.063146\n",
      "Total training time: 359.76 seconds.\n",
      "-- Epoch 4346\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.922275, T: 742670556, Avg. loss: 0.063145\n",
      "Total training time: 359.84 seconds.\n",
      "-- Epoch 4347\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.920781, T: 742841442, Avg. loss: 0.063144\n",
      "Total training time: 359.91 seconds.\n",
      "-- Epoch 4348\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.919286, T: 743012328, Avg. loss: 0.063144\n",
      "Total training time: 359.99 seconds.\n",
      "-- Epoch 4349\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.917792, T: 743183214, Avg. loss: 0.063143\n",
      "Total training time: 360.06 seconds.\n",
      "-- Epoch 4350\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.916298, T: 743354100, Avg. loss: 0.063142\n",
      "Total training time: 360.14 seconds.\n",
      "-- Epoch 4351\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.914804, T: 743524986, Avg. loss: 0.063141\n",
      "Total training time: 360.21 seconds.\n",
      "-- Epoch 4352\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.913311, T: 743695872, Avg. loss: 0.063140\n",
      "Total training time: 360.29 seconds.\n",
      "-- Epoch 4353\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.911820, T: 743866758, Avg. loss: 0.063140\n",
      "Total training time: 360.36 seconds.\n",
      "-- Epoch 4354\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.910327, T: 744037644, Avg. loss: 0.063139\n",
      "Total training time: 360.43 seconds.\n",
      "-- Epoch 4355\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.908835, T: 744208530, Avg. loss: 0.063138\n",
      "Total training time: 360.51 seconds.\n",
      "-- Epoch 4356\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.907343, T: 744379416, Avg. loss: 0.063137\n",
      "Total training time: 360.59 seconds.\n",
      "-- Epoch 4357\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.905853, T: 744550302, Avg. loss: 0.063136\n",
      "Total training time: 360.66 seconds.\n",
      "-- Epoch 4358\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.904363, T: 744721188, Avg. loss: 0.063135\n",
      "Total training time: 360.74 seconds.\n",
      "-- Epoch 4359\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.902873, T: 744892074, Avg. loss: 0.063135\n",
      "Total training time: 360.81 seconds.\n",
      "-- Epoch 4360\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.901382, T: 745062960, Avg. loss: 0.063134\n",
      "Total training time: 360.89 seconds.\n",
      "-- Epoch 4361\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.899892, T: 745233846, Avg. loss: 0.063133\n",
      "Total training time: 360.96 seconds.\n",
      "-- Epoch 4362\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.898402, T: 745404732, Avg. loss: 0.063132\n",
      "Total training time: 361.03 seconds.\n",
      "-- Epoch 4363\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.896912, T: 745575618, Avg. loss: 0.063131\n",
      "Total training time: 361.11 seconds.\n",
      "-- Epoch 4364\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.895422, T: 745746504, Avg. loss: 0.063130\n",
      "Total training time: 361.19 seconds.\n",
      "-- Epoch 4365\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.893934, T: 745917390, Avg. loss: 0.063130\n",
      "Total training time: 361.26 seconds.\n",
      "-- Epoch 4366\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.892445, T: 746088276, Avg. loss: 0.063129\n",
      "Total training time: 361.34 seconds.\n",
      "-- Epoch 4367\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.890958, T: 746259162, Avg. loss: 0.063128\n",
      "Total training time: 361.41 seconds.\n",
      "-- Epoch 4368\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.889470, T: 746430048, Avg. loss: 0.063127\n",
      "Total training time: 361.49 seconds.\n",
      "-- Epoch 4369\n",
      "Norm: 13.37, NNZs: 30, Bias: -117.887982, T: 746600934, Avg. loss: 0.063126\n",
      "Total training time: 361.56 seconds.\n",
      "-- Epoch 4370\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.886496, T: 746771820, Avg. loss: 0.063125\n",
      "Total training time: 361.64 seconds.\n",
      "-- Epoch 4371\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.885010, T: 746942706, Avg. loss: 0.063125\n",
      "Total training time: 361.71 seconds.\n",
      "-- Epoch 4372\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.883523, T: 747113592, Avg. loss: 0.063124\n",
      "Total training time: 361.79 seconds.\n",
      "-- Epoch 4373\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.882037, T: 747284478, Avg. loss: 0.063123\n",
      "Total training time: 361.86 seconds.\n",
      "-- Epoch 4374\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.880552, T: 747455364, Avg. loss: 0.063122\n",
      "Total training time: 361.94 seconds.\n",
      "-- Epoch 4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.36, NNZs: 30, Bias: -117.879067, T: 747626250, Avg. loss: 0.063121\n",
      "Total training time: 362.01 seconds.\n",
      "-- Epoch 4376\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.877582, T: 747797136, Avg. loss: 0.063121\n",
      "Total training time: 362.09 seconds.\n",
      "-- Epoch 4377\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.876098, T: 747968022, Avg. loss: 0.063120\n",
      "Total training time: 362.16 seconds.\n",
      "-- Epoch 4378\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.874615, T: 748138908, Avg. loss: 0.063119\n",
      "Total training time: 362.24 seconds.\n",
      "-- Epoch 4379\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.873131, T: 748309794, Avg. loss: 0.063118\n",
      "Total training time: 362.31 seconds.\n",
      "-- Epoch 4380\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.871647, T: 748480680, Avg. loss: 0.063117\n",
      "Total training time: 362.38 seconds.\n",
      "-- Epoch 4381\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.870164, T: 748651566, Avg. loss: 0.063116\n",
      "Total training time: 362.46 seconds.\n",
      "-- Epoch 4382\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.868682, T: 748822452, Avg. loss: 0.063116\n",
      "Total training time: 362.54 seconds.\n",
      "-- Epoch 4383\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.867198, T: 748993338, Avg. loss: 0.063115\n",
      "Total training time: 362.62 seconds.\n",
      "-- Epoch 4384\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.865716, T: 749164224, Avg. loss: 0.063114\n",
      "Total training time: 362.69 seconds.\n",
      "-- Epoch 4385\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.864234, T: 749335110, Avg. loss: 0.063113\n",
      "Total training time: 362.77 seconds.\n",
      "-- Epoch 4386\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.862752, T: 749505996, Avg. loss: 0.063112\n",
      "Total training time: 362.84 seconds.\n",
      "-- Epoch 4387\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.861271, T: 749676882, Avg. loss: 0.063112\n",
      "Total training time: 362.92 seconds.\n",
      "-- Epoch 4388\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.859790, T: 749847768, Avg. loss: 0.063111\n",
      "Total training time: 362.99 seconds.\n",
      "-- Epoch 4389\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.858310, T: 750018654, Avg. loss: 0.063110\n",
      "Total training time: 363.06 seconds.\n",
      "-- Epoch 4390\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.856831, T: 750189540, Avg. loss: 0.063109\n",
      "Total training time: 363.14 seconds.\n",
      "-- Epoch 4391\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.855350, T: 750360426, Avg. loss: 0.063108\n",
      "Total training time: 363.21 seconds.\n",
      "-- Epoch 4392\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.853870, T: 750531312, Avg. loss: 0.063107\n",
      "Total training time: 363.29 seconds.\n",
      "-- Epoch 4393\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.852391, T: 750702198, Avg. loss: 0.063107\n",
      "Total training time: 363.37 seconds.\n",
      "-- Epoch 4394\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.850913, T: 750873084, Avg. loss: 0.063106\n",
      "Total training time: 363.44 seconds.\n",
      "-- Epoch 4395\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.849434, T: 751043970, Avg. loss: 0.063105\n",
      "Total training time: 363.52 seconds.\n",
      "-- Epoch 4396\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.847956, T: 751214856, Avg. loss: 0.063104\n",
      "Total training time: 363.60 seconds.\n",
      "-- Epoch 4397\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.846479, T: 751385742, Avg. loss: 0.063103\n",
      "Total training time: 363.67 seconds.\n",
      "-- Epoch 4398\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.845001, T: 751556628, Avg. loss: 0.063103\n",
      "Total training time: 363.74 seconds.\n",
      "-- Epoch 4399\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.843524, T: 751727514, Avg. loss: 0.063102\n",
      "Total training time: 363.82 seconds.\n",
      "-- Epoch 4400\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.842047, T: 751898400, Avg. loss: 0.063101\n",
      "Total training time: 363.90 seconds.\n",
      "-- Epoch 4401\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.840571, T: 752069286, Avg. loss: 0.063100\n",
      "Total training time: 363.97 seconds.\n",
      "-- Epoch 4402\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.839096, T: 752240172, Avg. loss: 0.063099\n",
      "Total training time: 364.05 seconds.\n",
      "-- Epoch 4403\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.837622, T: 752411058, Avg. loss: 0.063098\n",
      "Total training time: 364.12 seconds.\n",
      "-- Epoch 4404\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.836147, T: 752581944, Avg. loss: 0.063098\n",
      "Total training time: 364.20 seconds.\n",
      "-- Epoch 4405\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.834672, T: 752752830, Avg. loss: 0.063097\n",
      "Total training time: 364.27 seconds.\n",
      "-- Epoch 4406\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.833198, T: 752923716, Avg. loss: 0.063096\n",
      "Total training time: 364.35 seconds.\n",
      "-- Epoch 4407\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.831723, T: 753094602, Avg. loss: 0.063095\n",
      "Total training time: 364.42 seconds.\n",
      "-- Epoch 4408\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.830250, T: 753265488, Avg. loss: 0.063094\n",
      "Total training time: 364.50 seconds.\n",
      "-- Epoch 4409\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.828775, T: 753436374, Avg. loss: 0.063094\n",
      "Total training time: 364.58 seconds.\n",
      "-- Epoch 4410\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.827303, T: 753607260, Avg. loss: 0.063093\n",
      "Total training time: 364.65 seconds.\n",
      "-- Epoch 4411\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.825830, T: 753778146, Avg. loss: 0.063092\n",
      "Total training time: 364.73 seconds.\n",
      "-- Epoch 4412\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.824358, T: 753949032, Avg. loss: 0.063091\n",
      "Total training time: 364.80 seconds.\n",
      "-- Epoch 4413\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.822886, T: 754119918, Avg. loss: 0.063090\n",
      "Total training time: 364.87 seconds.\n",
      "-- Epoch 4414\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.821414, T: 754290804, Avg. loss: 0.063089\n",
      "Total training time: 364.95 seconds.\n",
      "-- Epoch 4415\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.819942, T: 754461690, Avg. loss: 0.063089\n",
      "Total training time: 365.03 seconds.\n",
      "-- Epoch 4416\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.818471, T: 754632576, Avg. loss: 0.063088\n",
      "Total training time: 365.10 seconds.\n",
      "-- Epoch 4417\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.817000, T: 754803462, Avg. loss: 0.063087\n",
      "Total training time: 365.18 seconds.\n",
      "-- Epoch 4418\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.815531, T: 754974348, Avg. loss: 0.063086\n",
      "Total training time: 365.25 seconds.\n",
      "-- Epoch 4419\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.814061, T: 755145234, Avg. loss: 0.063085\n",
      "Total training time: 365.33 seconds.\n",
      "-- Epoch 4420\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.812591, T: 755316120, Avg. loss: 0.063085\n",
      "Total training time: 365.41 seconds.\n",
      "-- Epoch 4421\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.811122, T: 755487006, Avg. loss: 0.063084\n",
      "Total training time: 365.48 seconds.\n",
      "-- Epoch 4422\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.809653, T: 755657892, Avg. loss: 0.063083\n",
      "Total training time: 365.56 seconds.\n",
      "-- Epoch 4423\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.808185, T: 755828778, Avg. loss: 0.063082\n",
      "Total training time: 365.64 seconds.\n",
      "-- Epoch 4424\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.806716, T: 755999664, Avg. loss: 0.063081\n",
      "Total training time: 365.72 seconds.\n",
      "-- Epoch 4425\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.805247, T: 756170550, Avg. loss: 0.063080\n",
      "Total training time: 365.79 seconds.\n",
      "-- Epoch 4426\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.803779, T: 756341436, Avg. loss: 0.063080\n",
      "Total training time: 365.87 seconds.\n",
      "-- Epoch 4427\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.802310, T: 756512322, Avg. loss: 0.063079\n",
      "Total training time: 365.94 seconds.\n",
      "-- Epoch 4428\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.800843, T: 756683208, Avg. loss: 0.063078\n",
      "Total training time: 366.02 seconds.\n",
      "-- Epoch 4429\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.799376, T: 756854094, Avg. loss: 0.063077\n",
      "Total training time: 366.09 seconds.\n",
      "-- Epoch 4430\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.797909, T: 757024980, Avg. loss: 0.063076\n",
      "Total training time: 366.17 seconds.\n",
      "-- Epoch 4431\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.796443, T: 757195866, Avg. loss: 0.063076\n",
      "Total training time: 366.24 seconds.\n",
      "-- Epoch 4432\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.794977, T: 757366752, Avg. loss: 0.063075\n",
      "Total training time: 366.32 seconds.\n",
      "-- Epoch 4433\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.793511, T: 757537638, Avg. loss: 0.063074\n",
      "Total training time: 366.39 seconds.\n",
      "-- Epoch 4434\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.792047, T: 757708524, Avg. loss: 0.063073\n",
      "Total training time: 366.47 seconds.\n",
      "-- Epoch 4435\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.790582, T: 757879410, Avg. loss: 0.063072\n",
      "Total training time: 366.55 seconds.\n",
      "-- Epoch 4436\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.789118, T: 758050296, Avg. loss: 0.063072\n",
      "Total training time: 366.62 seconds.\n",
      "-- Epoch 4437\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.787654, T: 758221182, Avg. loss: 0.063071\n",
      "Total training time: 366.70 seconds.\n",
      "-- Epoch 4438\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.786190, T: 758392068, Avg. loss: 0.063070\n",
      "Total training time: 366.77 seconds.\n",
      "-- Epoch 4439\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.784726, T: 758562954, Avg. loss: 0.063069\n",
      "Total training time: 366.85 seconds.\n",
      "-- Epoch 4440\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.783263, T: 758733840, Avg. loss: 0.063068\n",
      "Total training time: 366.92 seconds.\n",
      "-- Epoch 4441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.36, NNZs: 30, Bias: -117.781801, T: 758904726, Avg. loss: 0.063068\n",
      "Total training time: 367.00 seconds.\n",
      "-- Epoch 4442\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.780338, T: 759075612, Avg. loss: 0.063067\n",
      "Total training time: 367.07 seconds.\n",
      "-- Epoch 4443\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.778876, T: 759246498, Avg. loss: 0.063066\n",
      "Total training time: 367.15 seconds.\n",
      "-- Epoch 4444\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.777414, T: 759417384, Avg. loss: 0.063065\n",
      "Total training time: 367.22 seconds.\n",
      "-- Epoch 4445\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.775952, T: 759588270, Avg. loss: 0.063064\n",
      "Total training time: 367.30 seconds.\n",
      "-- Epoch 4446\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.774490, T: 759759156, Avg. loss: 0.063063\n",
      "Total training time: 367.37 seconds.\n",
      "-- Epoch 4447\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.773028, T: 759930042, Avg. loss: 0.063063\n",
      "Total training time: 367.45 seconds.\n",
      "-- Epoch 4448\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.771567, T: 760100928, Avg. loss: 0.063062\n",
      "Total training time: 367.52 seconds.\n",
      "-- Epoch 4449\n",
      "Norm: 13.36, NNZs: 30, Bias: -117.770107, T: 760271814, Avg. loss: 0.063061\n",
      "Total training time: 367.60 seconds.\n",
      "-- Epoch 4450\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.768648, T: 760442700, Avg. loss: 0.063060\n",
      "Total training time: 367.67 seconds.\n",
      "-- Epoch 4451\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.767189, T: 760613586, Avg. loss: 0.063059\n",
      "Total training time: 367.75 seconds.\n",
      "-- Epoch 4452\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.765731, T: 760784472, Avg. loss: 0.063059\n",
      "Total training time: 367.82 seconds.\n",
      "-- Epoch 4453\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.764272, T: 760955358, Avg. loss: 0.063058\n",
      "Total training time: 367.90 seconds.\n",
      "-- Epoch 4454\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.762813, T: 761126244, Avg. loss: 0.063057\n",
      "Total training time: 367.97 seconds.\n",
      "-- Epoch 4455\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.761355, T: 761297130, Avg. loss: 0.063056\n",
      "Total training time: 368.05 seconds.\n",
      "-- Epoch 4456\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.759897, T: 761468016, Avg. loss: 0.063055\n",
      "Total training time: 368.13 seconds.\n",
      "-- Epoch 4457\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.758439, T: 761638902, Avg. loss: 0.063055\n",
      "Total training time: 368.20 seconds.\n",
      "-- Epoch 4458\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.756982, T: 761809788, Avg. loss: 0.063054\n",
      "Total training time: 368.27 seconds.\n",
      "-- Epoch 4459\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.755525, T: 761980674, Avg. loss: 0.063053\n",
      "Total training time: 368.35 seconds.\n",
      "-- Epoch 4460\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.754069, T: 762151560, Avg. loss: 0.063052\n",
      "Total training time: 368.43 seconds.\n",
      "-- Epoch 4461\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.752613, T: 762322446, Avg. loss: 0.063051\n",
      "Total training time: 368.50 seconds.\n",
      "-- Epoch 4462\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.751157, T: 762493332, Avg. loss: 0.063051\n",
      "Total training time: 368.58 seconds.\n",
      "-- Epoch 4463\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.749701, T: 762664218, Avg. loss: 0.063050\n",
      "Total training time: 368.65 seconds.\n",
      "-- Epoch 4464\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.748246, T: 762835104, Avg. loss: 0.063049\n",
      "Total training time: 368.73 seconds.\n",
      "-- Epoch 4465\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.746793, T: 763005990, Avg. loss: 0.063048\n",
      "Total training time: 368.80 seconds.\n",
      "-- Epoch 4466\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.745337, T: 763176876, Avg. loss: 0.063047\n",
      "Total training time: 368.88 seconds.\n",
      "-- Epoch 4467\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.743883, T: 763347762, Avg. loss: 0.063047\n",
      "Total training time: 368.95 seconds.\n",
      "-- Epoch 4468\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.742428, T: 763518648, Avg. loss: 0.063046\n",
      "Total training time: 369.03 seconds.\n",
      "-- Epoch 4469\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.740975, T: 763689534, Avg. loss: 0.063045\n",
      "Total training time: 369.10 seconds.\n",
      "-- Epoch 4470\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.739522, T: 763860420, Avg. loss: 0.063044\n",
      "Total training time: 369.18 seconds.\n",
      "-- Epoch 4471\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.738070, T: 764031306, Avg. loss: 0.063043\n",
      "Total training time: 369.25 seconds.\n",
      "-- Epoch 4472\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.736617, T: 764202192, Avg. loss: 0.063043\n",
      "Total training time: 369.33 seconds.\n",
      "-- Epoch 4473\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.735164, T: 764373078, Avg. loss: 0.063042\n",
      "Total training time: 369.40 seconds.\n",
      "-- Epoch 4474\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.733713, T: 764543964, Avg. loss: 0.063041\n",
      "Total training time: 369.48 seconds.\n",
      "-- Epoch 4475\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.732261, T: 764714850, Avg. loss: 0.063040\n",
      "Total training time: 369.55 seconds.\n",
      "-- Epoch 4476\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.730810, T: 764885736, Avg. loss: 0.063039\n",
      "Total training time: 369.63 seconds.\n",
      "-- Epoch 4477\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.729359, T: 765056622, Avg. loss: 0.063038\n",
      "Total training time: 369.70 seconds.\n",
      "-- Epoch 4478\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.727908, T: 765227508, Avg. loss: 0.063038\n",
      "Total training time: 369.78 seconds.\n",
      "-- Epoch 4479\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.726457, T: 765398394, Avg. loss: 0.063037\n",
      "Total training time: 369.85 seconds.\n",
      "-- Epoch 4480\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.725007, T: 765569280, Avg. loss: 0.063036\n",
      "Total training time: 369.93 seconds.\n",
      "-- Epoch 4481\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.723557, T: 765740166, Avg. loss: 0.063035\n",
      "Total training time: 370.00 seconds.\n",
      "-- Epoch 4482\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.722107, T: 765911052, Avg. loss: 0.063034\n",
      "Total training time: 370.08 seconds.\n",
      "-- Epoch 4483\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.720659, T: 766081938, Avg. loss: 0.063034\n",
      "Total training time: 370.15 seconds.\n",
      "-- Epoch 4484\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.719210, T: 766252824, Avg. loss: 0.063033\n",
      "Total training time: 370.23 seconds.\n",
      "-- Epoch 4485\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.717762, T: 766423710, Avg. loss: 0.063032\n",
      "Total training time: 370.30 seconds.\n",
      "-- Epoch 4486\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.716314, T: 766594596, Avg. loss: 0.063031\n",
      "Total training time: 370.38 seconds.\n",
      "-- Epoch 4487\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.714865, T: 766765482, Avg. loss: 0.063030\n",
      "Total training time: 370.45 seconds.\n",
      "-- Epoch 4488\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.713419, T: 766936368, Avg. loss: 0.063030\n",
      "Total training time: 370.53 seconds.\n",
      "-- Epoch 4489\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.711972, T: 767107254, Avg. loss: 0.063029\n",
      "Total training time: 370.61 seconds.\n",
      "-- Epoch 4490\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.710526, T: 767278140, Avg. loss: 0.063028\n",
      "Total training time: 370.68 seconds.\n",
      "-- Epoch 4491\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.709080, T: 767449026, Avg. loss: 0.063027\n",
      "Total training time: 370.75 seconds.\n",
      "-- Epoch 4492\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.707635, T: 767619912, Avg. loss: 0.063026\n",
      "Total training time: 370.83 seconds.\n",
      "-- Epoch 4493\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.706189, T: 767790798, Avg. loss: 0.063026\n",
      "Total training time: 370.91 seconds.\n",
      "-- Epoch 4494\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.704744, T: 767961684, Avg. loss: 0.063025\n",
      "Total training time: 370.99 seconds.\n",
      "-- Epoch 4495\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.703299, T: 768132570, Avg. loss: 0.063024\n",
      "Total training time: 371.06 seconds.\n",
      "-- Epoch 4496\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.701854, T: 768303456, Avg. loss: 0.063023\n",
      "Total training time: 371.14 seconds.\n",
      "-- Epoch 4497\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.700411, T: 768474342, Avg. loss: 0.063022\n",
      "Total training time: 371.21 seconds.\n",
      "-- Epoch 4498\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.698967, T: 768645228, Avg. loss: 0.063022\n",
      "Total training time: 371.29 seconds.\n",
      "-- Epoch 4499\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.697524, T: 768816114, Avg. loss: 0.063021\n",
      "Total training time: 371.36 seconds.\n",
      "-- Epoch 4500\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.696081, T: 768987000, Avg. loss: 0.063020\n",
      "Total training time: 371.44 seconds.\n",
      "-- Epoch 4501\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.694638, T: 769157886, Avg. loss: 0.063019\n",
      "Total training time: 371.51 seconds.\n",
      "-- Epoch 4502\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.693196, T: 769328772, Avg. loss: 0.063018\n",
      "Total training time: 371.59 seconds.\n",
      "-- Epoch 4503\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.691754, T: 769499658, Avg. loss: 0.063018\n",
      "Total training time: 371.67 seconds.\n",
      "-- Epoch 4504\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.690311, T: 769670544, Avg. loss: 0.063017\n",
      "Total training time: 371.74 seconds.\n",
      "-- Epoch 4505\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.688869, T: 769841430, Avg. loss: 0.063016\n",
      "Total training time: 371.82 seconds.\n",
      "-- Epoch 4506\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.687428, T: 770012316, Avg. loss: 0.063015\n",
      "Total training time: 371.89 seconds.\n",
      "-- Epoch 4507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.35, NNZs: 30, Bias: -117.685987, T: 770183202, Avg. loss: 0.063014\n",
      "Total training time: 371.97 seconds.\n",
      "-- Epoch 4508\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.684546, T: 770354088, Avg. loss: 0.063014\n",
      "Total training time: 372.04 seconds.\n",
      "-- Epoch 4509\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.683106, T: 770524974, Avg. loss: 0.063013\n",
      "Total training time: 372.12 seconds.\n",
      "-- Epoch 4510\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.681666, T: 770695860, Avg. loss: 0.063012\n",
      "Total training time: 372.20 seconds.\n",
      "-- Epoch 4511\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.680226, T: 770866746, Avg. loss: 0.063011\n",
      "Total training time: 372.27 seconds.\n",
      "-- Epoch 4512\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.678786, T: 771037632, Avg. loss: 0.063010\n",
      "Total training time: 372.35 seconds.\n",
      "-- Epoch 4513\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.677346, T: 771208518, Avg. loss: 0.063010\n",
      "Total training time: 372.43 seconds.\n",
      "-- Epoch 4514\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.675908, T: 771379404, Avg. loss: 0.063009\n",
      "Total training time: 372.50 seconds.\n",
      "-- Epoch 4515\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.674470, T: 771550290, Avg. loss: 0.063008\n",
      "Total training time: 372.58 seconds.\n",
      "-- Epoch 4516\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.673032, T: 771721176, Avg. loss: 0.063007\n",
      "Total training time: 372.65 seconds.\n",
      "-- Epoch 4517\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.671594, T: 771892062, Avg. loss: 0.063007\n",
      "Total training time: 372.73 seconds.\n",
      "-- Epoch 4518\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.670156, T: 772062948, Avg. loss: 0.063006\n",
      "Total training time: 372.81 seconds.\n",
      "-- Epoch 4519\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.668717, T: 772233834, Avg. loss: 0.063005\n",
      "Total training time: 372.91 seconds.\n",
      "-- Epoch 4520\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.667280, T: 772404720, Avg. loss: 0.063004\n",
      "Total training time: 372.98 seconds.\n",
      "-- Epoch 4521\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.665844, T: 772575606, Avg. loss: 0.063003\n",
      "Total training time: 373.07 seconds.\n",
      "-- Epoch 4522\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.664408, T: 772746492, Avg. loss: 0.063003\n",
      "Total training time: 373.16 seconds.\n",
      "-- Epoch 4523\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.662972, T: 772917378, Avg. loss: 0.063002\n",
      "Total training time: 373.24 seconds.\n",
      "-- Epoch 4524\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.661536, T: 773088264, Avg. loss: 0.063001\n",
      "Total training time: 373.33 seconds.\n",
      "-- Epoch 4525\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.660101, T: 773259150, Avg. loss: 0.063000\n",
      "Total training time: 373.42 seconds.\n",
      "-- Epoch 4526\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.658665, T: 773430036, Avg. loss: 0.062999\n",
      "Total training time: 373.50 seconds.\n",
      "-- Epoch 4527\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.657230, T: 773600922, Avg. loss: 0.062999\n",
      "Total training time: 373.57 seconds.\n",
      "-- Epoch 4528\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.655795, T: 773771808, Avg. loss: 0.062998\n",
      "Total training time: 373.65 seconds.\n",
      "-- Epoch 4529\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.654362, T: 773942694, Avg. loss: 0.062997\n",
      "Total training time: 373.73 seconds.\n",
      "-- Epoch 4530\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.652928, T: 774113580, Avg. loss: 0.062996\n",
      "Total training time: 373.82 seconds.\n",
      "-- Epoch 4531\n",
      "Norm: 13.35, NNZs: 30, Bias: -117.651494, T: 774284466, Avg. loss: 0.062995\n",
      "Total training time: 373.91 seconds.\n",
      "-- Epoch 4532\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.650060, T: 774455352, Avg. loss: 0.062995\n",
      "Total training time: 374.01 seconds.\n",
      "-- Epoch 4533\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.648627, T: 774626238, Avg. loss: 0.062994\n",
      "Total training time: 374.11 seconds.\n",
      "-- Epoch 4534\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.647195, T: 774797124, Avg. loss: 0.062993\n",
      "Total training time: 374.20 seconds.\n",
      "-- Epoch 4535\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.645763, T: 774968010, Avg. loss: 0.062992\n",
      "Total training time: 374.27 seconds.\n",
      "-- Epoch 4536\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.644331, T: 775138896, Avg. loss: 0.062991\n",
      "Total training time: 374.35 seconds.\n",
      "-- Epoch 4537\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.642900, T: 775309782, Avg. loss: 0.062991\n",
      "Total training time: 374.42 seconds.\n",
      "-- Epoch 4538\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.641469, T: 775480668, Avg. loss: 0.062990\n",
      "Total training time: 374.50 seconds.\n",
      "-- Epoch 4539\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.640039, T: 775651554, Avg. loss: 0.062989\n",
      "Total training time: 374.58 seconds.\n",
      "-- Epoch 4540\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.638608, T: 775822440, Avg. loss: 0.062988\n",
      "Total training time: 374.65 seconds.\n",
      "-- Epoch 4541\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.637177, T: 775993326, Avg. loss: 0.062987\n",
      "Total training time: 374.74 seconds.\n",
      "-- Epoch 4542\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.635747, T: 776164212, Avg. loss: 0.062987\n",
      "Total training time: 374.83 seconds.\n",
      "-- Epoch 4543\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.634316, T: 776335098, Avg. loss: 0.062986\n",
      "Total training time: 374.91 seconds.\n",
      "-- Epoch 4544\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.632887, T: 776505984, Avg. loss: 0.062985\n",
      "Total training time: 374.98 seconds.\n",
      "-- Epoch 4545\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.631458, T: 776676870, Avg. loss: 0.062984\n",
      "Total training time: 375.06 seconds.\n",
      "-- Epoch 4546\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.630030, T: 776847756, Avg. loss: 0.062984\n",
      "Total training time: 375.13 seconds.\n",
      "-- Epoch 4547\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.628602, T: 777018642, Avg. loss: 0.062983\n",
      "Total training time: 375.22 seconds.\n",
      "-- Epoch 4548\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.627174, T: 777189528, Avg. loss: 0.062982\n",
      "Total training time: 375.32 seconds.\n",
      "-- Epoch 4549\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.625747, T: 777360414, Avg. loss: 0.062981\n",
      "Total training time: 375.41 seconds.\n",
      "-- Epoch 4550\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.624320, T: 777531300, Avg. loss: 0.062980\n",
      "Total training time: 375.50 seconds.\n",
      "-- Epoch 4551\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.622893, T: 777702186, Avg. loss: 0.062980\n",
      "Total training time: 375.59 seconds.\n",
      "-- Epoch 4552\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.621467, T: 777873072, Avg. loss: 0.062979\n",
      "Total training time: 375.68 seconds.\n",
      "-- Epoch 4553\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.620040, T: 778043958, Avg. loss: 0.062978\n",
      "Total training time: 375.77 seconds.\n",
      "-- Epoch 4554\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.618615, T: 778214844, Avg. loss: 0.062977\n",
      "Total training time: 375.86 seconds.\n",
      "-- Epoch 4555\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.617189, T: 778385730, Avg. loss: 0.062976\n",
      "Total training time: 375.93 seconds.\n",
      "-- Epoch 4556\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.615764, T: 778556616, Avg. loss: 0.062976\n",
      "Total training time: 376.01 seconds.\n",
      "-- Epoch 4557\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.614338, T: 778727502, Avg. loss: 0.062975\n",
      "Total training time: 376.08 seconds.\n",
      "-- Epoch 4558\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.612913, T: 778898388, Avg. loss: 0.062974\n",
      "Total training time: 376.16 seconds.\n",
      "-- Epoch 4559\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.611488, T: 779069274, Avg. loss: 0.062973\n",
      "Total training time: 376.23 seconds.\n",
      "-- Epoch 4560\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.610064, T: 779240160, Avg. loss: 0.062972\n",
      "Total training time: 376.31 seconds.\n",
      "-- Epoch 4561\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.608639, T: 779411046, Avg. loss: 0.062972\n",
      "Total training time: 376.38 seconds.\n",
      "-- Epoch 4562\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.607216, T: 779581932, Avg. loss: 0.062971\n",
      "Total training time: 376.46 seconds.\n",
      "-- Epoch 4563\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.605792, T: 779752818, Avg. loss: 0.062970\n",
      "Total training time: 376.53 seconds.\n",
      "-- Epoch 4564\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.604369, T: 779923704, Avg. loss: 0.062969\n",
      "Total training time: 376.61 seconds.\n",
      "-- Epoch 4565\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.602946, T: 780094590, Avg. loss: 0.062969\n",
      "Total training time: 376.68 seconds.\n",
      "-- Epoch 4566\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.601524, T: 780265476, Avg. loss: 0.062968\n",
      "Total training time: 376.76 seconds.\n",
      "-- Epoch 4567\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.600101, T: 780436362, Avg. loss: 0.062967\n",
      "Total training time: 376.83 seconds.\n",
      "-- Epoch 4568\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.598680, T: 780607248, Avg. loss: 0.062966\n",
      "Total training time: 376.91 seconds.\n",
      "-- Epoch 4569\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.597259, T: 780778134, Avg. loss: 0.062965\n",
      "Total training time: 376.98 seconds.\n",
      "-- Epoch 4570\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.595838, T: 780949020, Avg. loss: 0.062965\n",
      "Total training time: 377.06 seconds.\n",
      "-- Epoch 4571\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.594417, T: 781119906, Avg. loss: 0.062964\n",
      "Total training time: 377.13 seconds.\n",
      "-- Epoch 4572\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.592996, T: 781290792, Avg. loss: 0.062963\n",
      "Total training time: 377.21 seconds.\n",
      "-- Epoch 4573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.34, NNZs: 30, Bias: -117.591576, T: 781461678, Avg. loss: 0.062962\n",
      "Total training time: 377.28 seconds.\n",
      "-- Epoch 4574\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.590156, T: 781632564, Avg. loss: 0.062961\n",
      "Total training time: 377.36 seconds.\n",
      "-- Epoch 4575\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.588737, T: 781803450, Avg. loss: 0.062961\n",
      "Total training time: 377.44 seconds.\n",
      "-- Epoch 4576\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.587318, T: 781974336, Avg. loss: 0.062960\n",
      "Total training time: 377.52 seconds.\n",
      "-- Epoch 4577\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.585899, T: 782145222, Avg. loss: 0.062959\n",
      "Total training time: 377.59 seconds.\n",
      "-- Epoch 4578\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.584481, T: 782316108, Avg. loss: 0.062958\n",
      "Total training time: 377.67 seconds.\n",
      "-- Epoch 4579\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.583063, T: 782486994, Avg. loss: 0.062958\n",
      "Total training time: 377.74 seconds.\n",
      "-- Epoch 4580\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.581644, T: 782657880, Avg. loss: 0.062957\n",
      "Total training time: 377.82 seconds.\n",
      "-- Epoch 4581\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.580226, T: 782828766, Avg. loss: 0.062956\n",
      "Total training time: 377.90 seconds.\n",
      "-- Epoch 4582\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.578810, T: 782999652, Avg. loss: 0.062955\n",
      "Total training time: 377.97 seconds.\n",
      "-- Epoch 4583\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.577393, T: 783170538, Avg. loss: 0.062954\n",
      "Total training time: 378.05 seconds.\n",
      "-- Epoch 4584\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.575978, T: 783341424, Avg. loss: 0.062954\n",
      "Total training time: 378.12 seconds.\n",
      "-- Epoch 4585\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.574560, T: 783512310, Avg. loss: 0.062953\n",
      "Total training time: 378.20 seconds.\n",
      "-- Epoch 4586\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.573144, T: 783683196, Avg. loss: 0.062952\n",
      "Total training time: 378.27 seconds.\n",
      "-- Epoch 4587\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.571728, T: 783854082, Avg. loss: 0.062951\n",
      "Total training time: 378.35 seconds.\n",
      "-- Epoch 4588\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.570313, T: 784024968, Avg. loss: 0.062950\n",
      "Total training time: 378.42 seconds.\n",
      "-- Epoch 4589\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.568897, T: 784195854, Avg. loss: 0.062950\n",
      "Total training time: 378.51 seconds.\n",
      "-- Epoch 4590\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.567482, T: 784366740, Avg. loss: 0.062949\n",
      "Total training time: 378.59 seconds.\n",
      "-- Epoch 4591\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.566067, T: 784537626, Avg. loss: 0.062948\n",
      "Total training time: 378.67 seconds.\n",
      "-- Epoch 4592\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.564653, T: 784708512, Avg. loss: 0.062947\n",
      "Total training time: 378.75 seconds.\n",
      "-- Epoch 4593\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.563239, T: 784879398, Avg. loss: 0.062947\n",
      "Total training time: 378.82 seconds.\n",
      "-- Epoch 4594\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.561826, T: 785050284, Avg. loss: 0.062946\n",
      "Total training time: 378.90 seconds.\n",
      "-- Epoch 4595\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.560413, T: 785221170, Avg. loss: 0.062945\n",
      "Total training time: 378.97 seconds.\n",
      "-- Epoch 4596\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.559000, T: 785392056, Avg. loss: 0.062944\n",
      "Total training time: 379.05 seconds.\n",
      "-- Epoch 4597\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.557587, T: 785562942, Avg. loss: 0.062943\n",
      "Total training time: 379.12 seconds.\n",
      "-- Epoch 4598\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.556175, T: 785733828, Avg. loss: 0.062943\n",
      "Total training time: 379.20 seconds.\n",
      "-- Epoch 4599\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.554762, T: 785904714, Avg. loss: 0.062942\n",
      "Total training time: 379.27 seconds.\n",
      "-- Epoch 4600\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.553351, T: 786075600, Avg. loss: 0.062941\n",
      "Total training time: 379.35 seconds.\n",
      "-- Epoch 4601\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.551940, T: 786246486, Avg. loss: 0.062940\n",
      "Total training time: 379.42 seconds.\n",
      "-- Epoch 4602\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.550529, T: 786417372, Avg. loss: 0.062939\n",
      "Total training time: 379.50 seconds.\n",
      "-- Epoch 4603\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.549119, T: 786588258, Avg. loss: 0.062939\n",
      "Total training time: 379.57 seconds.\n",
      "-- Epoch 4604\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.547708, T: 786759144, Avg. loss: 0.062938\n",
      "Total training time: 379.66 seconds.\n",
      "-- Epoch 4605\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.546298, T: 786930030, Avg. loss: 0.062937\n",
      "Total training time: 379.75 seconds.\n",
      "-- Epoch 4606\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.544887, T: 787100916, Avg. loss: 0.062936\n",
      "Total training time: 379.82 seconds.\n",
      "-- Epoch 4607\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.543478, T: 787271802, Avg. loss: 0.062936\n",
      "Total training time: 379.90 seconds.\n",
      "-- Epoch 4608\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.542069, T: 787442688, Avg. loss: 0.062935\n",
      "Total training time: 379.97 seconds.\n",
      "-- Epoch 4609\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.540661, T: 787613574, Avg. loss: 0.062934\n",
      "Total training time: 380.05 seconds.\n",
      "-- Epoch 4610\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.539252, T: 787784460, Avg. loss: 0.062933\n",
      "Total training time: 380.13 seconds.\n",
      "-- Epoch 4611\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.537843, T: 787955346, Avg. loss: 0.062932\n",
      "Total training time: 380.22 seconds.\n",
      "-- Epoch 4612\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.536435, T: 788126232, Avg. loss: 0.062932\n",
      "Total training time: 380.31 seconds.\n",
      "-- Epoch 4613\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.535028, T: 788297118, Avg. loss: 0.062931\n",
      "Total training time: 380.40 seconds.\n",
      "-- Epoch 4614\n",
      "Norm: 13.34, NNZs: 30, Bias: -117.533621, T: 788468004, Avg. loss: 0.062930\n",
      "Total training time: 380.49 seconds.\n",
      "-- Epoch 4615\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.532215, T: 788638890, Avg. loss: 0.062929\n",
      "Total training time: 380.58 seconds.\n",
      "-- Epoch 4616\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.530808, T: 788809776, Avg. loss: 0.062929\n",
      "Total training time: 380.66 seconds.\n",
      "-- Epoch 4617\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.529400, T: 788980662, Avg. loss: 0.062928\n",
      "Total training time: 380.74 seconds.\n",
      "-- Epoch 4618\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.527994, T: 789151548, Avg. loss: 0.062927\n",
      "Total training time: 380.81 seconds.\n",
      "-- Epoch 4619\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.526587, T: 789322434, Avg. loss: 0.062926\n",
      "Total training time: 380.89 seconds.\n",
      "-- Epoch 4620\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.525182, T: 789493320, Avg. loss: 0.062925\n",
      "Total training time: 380.98 seconds.\n",
      "-- Epoch 4621\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.523777, T: 789664206, Avg. loss: 0.062925\n",
      "Total training time: 381.06 seconds.\n",
      "-- Epoch 4622\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.522371, T: 789835092, Avg. loss: 0.062924\n",
      "Total training time: 381.14 seconds.\n",
      "-- Epoch 4623\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.520967, T: 790005978, Avg. loss: 0.062923\n",
      "Total training time: 381.22 seconds.\n",
      "-- Epoch 4624\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.519563, T: 790176864, Avg. loss: 0.062922\n",
      "Total training time: 381.29 seconds.\n",
      "-- Epoch 4625\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.518159, T: 790347750, Avg. loss: 0.062922\n",
      "Total training time: 381.37 seconds.\n",
      "-- Epoch 4626\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.516755, T: 790518636, Avg. loss: 0.062921\n",
      "Total training time: 381.46 seconds.\n",
      "-- Epoch 4627\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.515351, T: 790689522, Avg. loss: 0.062920\n",
      "Total training time: 381.55 seconds.\n",
      "-- Epoch 4628\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.513947, T: 790860408, Avg. loss: 0.062919\n",
      "Total training time: 381.65 seconds.\n",
      "-- Epoch 4629\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.512544, T: 791031294, Avg. loss: 0.062918\n",
      "Total training time: 381.74 seconds.\n",
      "-- Epoch 4630\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.511142, T: 791202180, Avg. loss: 0.062918\n",
      "Total training time: 381.83 seconds.\n",
      "-- Epoch 4631\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.509739, T: 791373066, Avg. loss: 0.062917\n",
      "Total training time: 381.93 seconds.\n",
      "-- Epoch 4632\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.508337, T: 791543952, Avg. loss: 0.062916\n",
      "Total training time: 382.02 seconds.\n",
      "-- Epoch 4633\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.506935, T: 791714838, Avg. loss: 0.062915\n",
      "Total training time: 382.12 seconds.\n",
      "-- Epoch 4634\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.505532, T: 791885724, Avg. loss: 0.062915\n",
      "Total training time: 382.20 seconds.\n",
      "-- Epoch 4635\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.504132, T: 792056610, Avg. loss: 0.062914\n",
      "Total training time: 382.28 seconds.\n",
      "-- Epoch 4636\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.502731, T: 792227496, Avg. loss: 0.062913\n",
      "Total training time: 382.35 seconds.\n",
      "-- Epoch 4637\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.501330, T: 792398382, Avg. loss: 0.062912\n",
      "Total training time: 382.43 seconds.\n",
      "-- Epoch 4638\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.499930, T: 792569268, Avg. loss: 0.062911\n",
      "Total training time: 382.50 seconds.\n",
      "-- Epoch 4639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.33, NNZs: 30, Bias: -117.498530, T: 792740154, Avg. loss: 0.062911\n",
      "Total training time: 382.58 seconds.\n",
      "-- Epoch 4640\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.497130, T: 792911040, Avg. loss: 0.062910\n",
      "Total training time: 382.66 seconds.\n",
      "-- Epoch 4641\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.495731, T: 793081926, Avg. loss: 0.062909\n",
      "Total training time: 382.75 seconds.\n",
      "-- Epoch 4642\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.494332, T: 793252812, Avg. loss: 0.062908\n",
      "Total training time: 382.83 seconds.\n",
      "-- Epoch 4643\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.492933, T: 793423698, Avg. loss: 0.062908\n",
      "Total training time: 382.91 seconds.\n",
      "-- Epoch 4644\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.491535, T: 793594584, Avg. loss: 0.062907\n",
      "Total training time: 382.99 seconds.\n",
      "-- Epoch 4645\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.490136, T: 793765470, Avg. loss: 0.062906\n",
      "Total training time: 383.07 seconds.\n",
      "-- Epoch 4646\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.488739, T: 793936356, Avg. loss: 0.062905\n",
      "Total training time: 383.16 seconds.\n",
      "-- Epoch 4647\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.487342, T: 794107242, Avg. loss: 0.062905\n",
      "Total training time: 383.24 seconds.\n",
      "-- Epoch 4648\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.485946, T: 794278128, Avg. loss: 0.062904\n",
      "Total training time: 383.31 seconds.\n",
      "-- Epoch 4649\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.484549, T: 794449014, Avg. loss: 0.062903\n",
      "Total training time: 383.39 seconds.\n",
      "-- Epoch 4650\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.483153, T: 794619900, Avg. loss: 0.062902\n",
      "Total training time: 383.46 seconds.\n",
      "-- Epoch 4651\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.481757, T: 794790786, Avg. loss: 0.062901\n",
      "Total training time: 383.54 seconds.\n",
      "-- Epoch 4652\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.480361, T: 794961672, Avg. loss: 0.062901\n",
      "Total training time: 383.63 seconds.\n",
      "-- Epoch 4653\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.478965, T: 795132558, Avg. loss: 0.062900\n",
      "Total training time: 383.72 seconds.\n",
      "-- Epoch 4654\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.477569, T: 795303444, Avg. loss: 0.062899\n",
      "Total training time: 383.81 seconds.\n",
      "-- Epoch 4655\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.476174, T: 795474330, Avg. loss: 0.062898\n",
      "Total training time: 383.91 seconds.\n",
      "-- Epoch 4656\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.474780, T: 795645216, Avg. loss: 0.062898\n",
      "Total training time: 383.99 seconds.\n",
      "-- Epoch 4657\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.473385, T: 795816102, Avg. loss: 0.062897\n",
      "Total training time: 384.07 seconds.\n",
      "-- Epoch 4658\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.471991, T: 795986988, Avg. loss: 0.062896\n",
      "Total training time: 384.15 seconds.\n",
      "-- Epoch 4659\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.470596, T: 796157874, Avg. loss: 0.062895\n",
      "Total training time: 384.22 seconds.\n",
      "-- Epoch 4660\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.469203, T: 796328760, Avg. loss: 0.062894\n",
      "Total training time: 384.30 seconds.\n",
      "-- Epoch 4661\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.467810, T: 796499646, Avg. loss: 0.062894\n",
      "Total training time: 384.37 seconds.\n",
      "-- Epoch 4662\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.466417, T: 796670532, Avg. loss: 0.062893\n",
      "Total training time: 384.45 seconds.\n",
      "-- Epoch 4663\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.465025, T: 796841418, Avg. loss: 0.062892\n",
      "Total training time: 384.52 seconds.\n",
      "-- Epoch 4664\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.463633, T: 797012304, Avg. loss: 0.062891\n",
      "Total training time: 384.60 seconds.\n",
      "-- Epoch 4665\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.462240, T: 797183190, Avg. loss: 0.062891\n",
      "Total training time: 384.67 seconds.\n",
      "-- Epoch 4666\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.460849, T: 797354076, Avg. loss: 0.062890\n",
      "Total training time: 384.75 seconds.\n",
      "-- Epoch 4667\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.459456, T: 797524962, Avg. loss: 0.062889\n",
      "Total training time: 384.82 seconds.\n",
      "-- Epoch 4668\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.458064, T: 797695848, Avg. loss: 0.062888\n",
      "Total training time: 384.90 seconds.\n",
      "-- Epoch 4669\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.456673, T: 797866734, Avg. loss: 0.062888\n",
      "Total training time: 384.97 seconds.\n",
      "-- Epoch 4670\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.455282, T: 798037620, Avg. loss: 0.062887\n",
      "Total training time: 385.05 seconds.\n",
      "-- Epoch 4671\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.453892, T: 798208506, Avg. loss: 0.062886\n",
      "Total training time: 385.12 seconds.\n",
      "-- Epoch 4672\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.452502, T: 798379392, Avg. loss: 0.062885\n",
      "Total training time: 385.20 seconds.\n",
      "-- Epoch 4673\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.451112, T: 798550278, Avg. loss: 0.062884\n",
      "Total training time: 385.27 seconds.\n",
      "-- Epoch 4674\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.449723, T: 798721164, Avg. loss: 0.062884\n",
      "Total training time: 385.34 seconds.\n",
      "-- Epoch 4675\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.448334, T: 798892050, Avg. loss: 0.062883\n",
      "Total training time: 385.42 seconds.\n",
      "-- Epoch 4676\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.446946, T: 799062936, Avg. loss: 0.062882\n",
      "Total training time: 385.49 seconds.\n",
      "-- Epoch 4677\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.445557, T: 799233822, Avg. loss: 0.062881\n",
      "Total training time: 385.57 seconds.\n",
      "-- Epoch 4678\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.444169, T: 799404708, Avg. loss: 0.062881\n",
      "Total training time: 385.65 seconds.\n",
      "-- Epoch 4679\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.442781, T: 799575594, Avg. loss: 0.062880\n",
      "Total training time: 385.73 seconds.\n",
      "-- Epoch 4680\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.441394, T: 799746480, Avg. loss: 0.062879\n",
      "Total training time: 385.82 seconds.\n",
      "-- Epoch 4681\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.440006, T: 799917366, Avg. loss: 0.062878\n",
      "Total training time: 385.90 seconds.\n",
      "-- Epoch 4682\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.438620, T: 800088252, Avg. loss: 0.062878\n",
      "Total training time: 385.97 seconds.\n",
      "-- Epoch 4683\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.437233, T: 800259138, Avg. loss: 0.062877\n",
      "Total training time: 386.05 seconds.\n",
      "-- Epoch 4684\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.435846, T: 800430024, Avg. loss: 0.062876\n",
      "Total training time: 386.12 seconds.\n",
      "-- Epoch 4685\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.434460, T: 800600910, Avg. loss: 0.062875\n",
      "Total training time: 386.20 seconds.\n",
      "-- Epoch 4686\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.433074, T: 800771796, Avg. loss: 0.062875\n",
      "Total training time: 386.29 seconds.\n",
      "-- Epoch 4687\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.431689, T: 800942682, Avg. loss: 0.062874\n",
      "Total training time: 386.39 seconds.\n",
      "-- Epoch 4688\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.430304, T: 801113568, Avg. loss: 0.062873\n",
      "Total training time: 386.48 seconds.\n",
      "-- Epoch 4689\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.428920, T: 801284454, Avg. loss: 0.062872\n",
      "Total training time: 386.58 seconds.\n",
      "-- Epoch 4690\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.427534, T: 801455340, Avg. loss: 0.062871\n",
      "Total training time: 386.67 seconds.\n",
      "-- Epoch 4691\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.426150, T: 801626226, Avg. loss: 0.062871\n",
      "Total training time: 386.76 seconds.\n",
      "-- Epoch 4692\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.424766, T: 801797112, Avg. loss: 0.062870\n",
      "Total training time: 386.86 seconds.\n",
      "-- Epoch 4693\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.423382, T: 801967998, Avg. loss: 0.062869\n",
      "Total training time: 386.95 seconds.\n",
      "-- Epoch 4694\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.421999, T: 802138884, Avg. loss: 0.062868\n",
      "Total training time: 387.04 seconds.\n",
      "-- Epoch 4695\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.420616, T: 802309770, Avg. loss: 0.062868\n",
      "Total training time: 387.14 seconds.\n",
      "-- Epoch 4696\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.419233, T: 802480656, Avg. loss: 0.062867\n",
      "Total training time: 387.23 seconds.\n",
      "-- Epoch 4697\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.417850, T: 802651542, Avg. loss: 0.062866\n",
      "Total training time: 387.32 seconds.\n",
      "-- Epoch 4698\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.416468, T: 802822428, Avg. loss: 0.062865\n",
      "Total training time: 387.41 seconds.\n",
      "-- Epoch 4699\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.415087, T: 802993314, Avg. loss: 0.062865\n",
      "Total training time: 387.51 seconds.\n",
      "-- Epoch 4700\n",
      "Norm: 13.33, NNZs: 30, Bias: -117.413705, T: 803164200, Avg. loss: 0.062864\n",
      "Total training time: 387.60 seconds.\n",
      "-- Epoch 4701\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.412323, T: 803335086, Avg. loss: 0.062863\n",
      "Total training time: 387.70 seconds.\n",
      "-- Epoch 4702\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.410942, T: 803505972, Avg. loss: 0.062862\n",
      "Total training time: 387.79 seconds.\n",
      "-- Epoch 4703\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.409562, T: 803676858, Avg. loss: 0.062861\n",
      "Total training time: 387.89 seconds.\n",
      "-- Epoch 4704\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.408181, T: 803847744, Avg. loss: 0.062861\n",
      "Total training time: 387.98 seconds.\n",
      "-- Epoch 4705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.32, NNZs: 30, Bias: -117.406801, T: 804018630, Avg. loss: 0.062860\n",
      "Total training time: 388.08 seconds.\n",
      "-- Epoch 4706\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.405421, T: 804189516, Avg. loss: 0.062859\n",
      "Total training time: 388.17 seconds.\n",
      "-- Epoch 4707\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.404041, T: 804360402, Avg. loss: 0.062858\n",
      "Total training time: 388.26 seconds.\n",
      "-- Epoch 4708\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.402661, T: 804531288, Avg. loss: 0.062858\n",
      "Total training time: 388.36 seconds.\n",
      "-- Epoch 4709\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.401282, T: 804702174, Avg. loss: 0.062857\n",
      "Total training time: 388.45 seconds.\n",
      "-- Epoch 4710\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.399904, T: 804873060, Avg. loss: 0.062856\n",
      "Total training time: 388.55 seconds.\n",
      "-- Epoch 4711\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.398526, T: 805043946, Avg. loss: 0.062855\n",
      "Total training time: 388.64 seconds.\n",
      "-- Epoch 4712\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.397148, T: 805214832, Avg. loss: 0.062855\n",
      "Total training time: 388.73 seconds.\n",
      "-- Epoch 4713\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.395771, T: 805385718, Avg. loss: 0.062854\n",
      "Total training time: 388.82 seconds.\n",
      "-- Epoch 4714\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.394393, T: 805556604, Avg. loss: 0.062853\n",
      "Total training time: 388.89 seconds.\n",
      "-- Epoch 4715\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.393016, T: 805727490, Avg. loss: 0.062852\n",
      "Total training time: 388.97 seconds.\n",
      "-- Epoch 4716\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.391639, T: 805898376, Avg. loss: 0.062852\n",
      "Total training time: 389.04 seconds.\n",
      "-- Epoch 4717\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.390263, T: 806069262, Avg. loss: 0.062851\n",
      "Total training time: 389.12 seconds.\n",
      "-- Epoch 4718\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.388888, T: 806240148, Avg. loss: 0.062850\n",
      "Total training time: 389.19 seconds.\n",
      "-- Epoch 4719\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.387512, T: 806411034, Avg. loss: 0.062849\n",
      "Total training time: 389.27 seconds.\n",
      "-- Epoch 4720\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.386137, T: 806581920, Avg. loss: 0.062849\n",
      "Total training time: 389.35 seconds.\n",
      "-- Epoch 4721\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.384763, T: 806752806, Avg. loss: 0.062848\n",
      "Total training time: 389.42 seconds.\n",
      "-- Epoch 4722\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.383388, T: 806923692, Avg. loss: 0.062847\n",
      "Total training time: 389.49 seconds.\n",
      "-- Epoch 4723\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.382014, T: 807094578, Avg. loss: 0.062846\n",
      "Total training time: 389.57 seconds.\n",
      "-- Epoch 4724\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.380640, T: 807265464, Avg. loss: 0.062845\n",
      "Total training time: 389.65 seconds.\n",
      "-- Epoch 4725\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.379265, T: 807436350, Avg. loss: 0.062845\n",
      "Total training time: 389.72 seconds.\n",
      "-- Epoch 4726\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.377892, T: 807607236, Avg. loss: 0.062844\n",
      "Total training time: 389.80 seconds.\n",
      "-- Epoch 4727\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.376519, T: 807778122, Avg. loss: 0.062843\n",
      "Total training time: 389.89 seconds.\n",
      "-- Epoch 4728\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.375146, T: 807949008, Avg. loss: 0.062842\n",
      "Total training time: 389.98 seconds.\n",
      "-- Epoch 4729\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.373773, T: 808119894, Avg. loss: 0.062842\n",
      "Total training time: 390.07 seconds.\n",
      "-- Epoch 4730\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.372401, T: 808290780, Avg. loss: 0.062841\n",
      "Total training time: 390.15 seconds.\n",
      "-- Epoch 4731\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.371029, T: 808461666, Avg. loss: 0.062840\n",
      "Total training time: 390.23 seconds.\n",
      "-- Epoch 4732\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.369658, T: 808632552, Avg. loss: 0.062839\n",
      "Total training time: 390.31 seconds.\n",
      "-- Epoch 4733\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.368287, T: 808803438, Avg. loss: 0.062839\n",
      "Total training time: 390.40 seconds.\n",
      "-- Epoch 4734\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.366915, T: 808974324, Avg. loss: 0.062838\n",
      "Total training time: 390.49 seconds.\n",
      "-- Epoch 4735\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.365544, T: 809145210, Avg. loss: 0.062837\n",
      "Total training time: 390.58 seconds.\n",
      "-- Epoch 4736\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.364173, T: 809316096, Avg. loss: 0.062836\n",
      "Total training time: 390.67 seconds.\n",
      "-- Epoch 4737\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.362802, T: 809486982, Avg. loss: 0.062836\n",
      "Total training time: 390.76 seconds.\n",
      "-- Epoch 4738\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.361433, T: 809657868, Avg. loss: 0.062835\n",
      "Total training time: 390.86 seconds.\n",
      "-- Epoch 4739\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.360063, T: 809828754, Avg. loss: 0.062834\n",
      "Total training time: 390.95 seconds.\n",
      "-- Epoch 4740\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.358693, T: 809999640, Avg. loss: 0.062833\n",
      "Total training time: 391.03 seconds.\n",
      "-- Epoch 4741\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.357325, T: 810170526, Avg. loss: 0.062833\n",
      "Total training time: 391.11 seconds.\n",
      "-- Epoch 4742\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.355956, T: 810341412, Avg. loss: 0.062832\n",
      "Total training time: 391.19 seconds.\n",
      "-- Epoch 4743\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.354587, T: 810512298, Avg. loss: 0.062831\n",
      "Total training time: 391.27 seconds.\n",
      "-- Epoch 4744\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.353218, T: 810683184, Avg. loss: 0.062830\n",
      "Total training time: 391.36 seconds.\n",
      "-- Epoch 4745\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.351850, T: 810854070, Avg. loss: 0.062830\n",
      "Total training time: 391.46 seconds.\n",
      "-- Epoch 4746\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.350484, T: 811024956, Avg. loss: 0.062829\n",
      "Total training time: 391.55 seconds.\n",
      "-- Epoch 4747\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.349116, T: 811195842, Avg. loss: 0.062828\n",
      "Total training time: 391.65 seconds.\n",
      "-- Epoch 4748\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.347749, T: 811366728, Avg. loss: 0.062827\n",
      "Total training time: 391.74 seconds.\n",
      "-- Epoch 4749\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.346381, T: 811537614, Avg. loss: 0.062827\n",
      "Total training time: 391.82 seconds.\n",
      "-- Epoch 4750\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.345013, T: 811708500, Avg. loss: 0.062826\n",
      "Total training time: 391.91 seconds.\n",
      "-- Epoch 4751\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.343646, T: 811879386, Avg. loss: 0.062825\n",
      "Total training time: 391.99 seconds.\n",
      "-- Epoch 4752\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.342280, T: 812050272, Avg. loss: 0.062824\n",
      "Total training time: 392.07 seconds.\n",
      "-- Epoch 4753\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.340913, T: 812221158, Avg. loss: 0.062824\n",
      "Total training time: 392.15 seconds.\n",
      "-- Epoch 4754\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.339548, T: 812392044, Avg. loss: 0.062823\n",
      "Total training time: 392.23 seconds.\n",
      "-- Epoch 4755\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.338182, T: 812562930, Avg. loss: 0.062822\n",
      "Total training time: 392.31 seconds.\n",
      "-- Epoch 4756\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.336818, T: 812733816, Avg. loss: 0.062821\n",
      "Total training time: 392.40 seconds.\n",
      "-- Epoch 4757\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.335453, T: 812904702, Avg. loss: 0.062820\n",
      "Total training time: 392.48 seconds.\n",
      "-- Epoch 4758\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.334089, T: 813075588, Avg. loss: 0.062820\n",
      "Total training time: 392.56 seconds.\n",
      "-- Epoch 4759\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.332725, T: 813246474, Avg. loss: 0.062819\n",
      "Total training time: 392.64 seconds.\n",
      "-- Epoch 4760\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.331362, T: 813417360, Avg. loss: 0.062818\n",
      "Total training time: 392.72 seconds.\n",
      "-- Epoch 4761\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.329998, T: 813588246, Avg. loss: 0.062817\n",
      "Total training time: 392.79 seconds.\n",
      "-- Epoch 4762\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.328634, T: 813759132, Avg. loss: 0.062817\n",
      "Total training time: 392.88 seconds.\n",
      "-- Epoch 4763\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.327272, T: 813930018, Avg. loss: 0.062816\n",
      "Total training time: 392.96 seconds.\n",
      "-- Epoch 4764\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.325909, T: 814100904, Avg. loss: 0.062815\n",
      "Total training time: 393.03 seconds.\n",
      "-- Epoch 4765\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.324546, T: 814271790, Avg. loss: 0.062814\n",
      "Total training time: 393.11 seconds.\n",
      "-- Epoch 4766\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.323184, T: 814442676, Avg. loss: 0.062814\n",
      "Total training time: 393.19 seconds.\n",
      "-- Epoch 4767\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.321822, T: 814613562, Avg. loss: 0.062813\n",
      "Total training time: 393.26 seconds.\n",
      "-- Epoch 4768\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.320461, T: 814784448, Avg. loss: 0.062812\n",
      "Total training time: 393.34 seconds.\n",
      "-- Epoch 4769\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.319100, T: 814955334, Avg. loss: 0.062811\n",
      "Total training time: 393.43 seconds.\n",
      "-- Epoch 4770\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.317739, T: 815126220, Avg. loss: 0.062811\n",
      "Total training time: 393.53 seconds.\n",
      "-- Epoch 4771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.32, NNZs: 30, Bias: -117.316379, T: 815297106, Avg. loss: 0.062810\n",
      "Total training time: 393.63 seconds.\n",
      "-- Epoch 4772\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.315018, T: 815467992, Avg. loss: 0.062809\n",
      "Total training time: 393.73 seconds.\n",
      "-- Epoch 4773\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.313658, T: 815638878, Avg. loss: 0.062808\n",
      "Total training time: 393.85 seconds.\n",
      "-- Epoch 4774\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.312299, T: 815809764, Avg. loss: 0.062808\n",
      "Total training time: 393.95 seconds.\n",
      "-- Epoch 4775\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.310939, T: 815980650, Avg. loss: 0.062807\n",
      "Total training time: 394.06 seconds.\n",
      "-- Epoch 4776\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.309579, T: 816151536, Avg. loss: 0.062806\n",
      "Total training time: 394.16 seconds.\n",
      "-- Epoch 4777\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.308221, T: 816322422, Avg. loss: 0.062805\n",
      "Total training time: 394.28 seconds.\n",
      "-- Epoch 4778\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.306862, T: 816493308, Avg. loss: 0.062805\n",
      "Total training time: 394.37 seconds.\n",
      "-- Epoch 4779\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.305504, T: 816664194, Avg. loss: 0.062804\n",
      "Total training time: 394.44 seconds.\n",
      "-- Epoch 4780\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.304145, T: 816835080, Avg. loss: 0.062803\n",
      "Total training time: 394.52 seconds.\n",
      "-- Epoch 4781\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.302787, T: 817005966, Avg. loss: 0.062802\n",
      "Total training time: 394.60 seconds.\n",
      "-- Epoch 4782\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.301429, T: 817176852, Avg. loss: 0.062802\n",
      "Total training time: 394.68 seconds.\n",
      "-- Epoch 4783\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.300072, T: 817347738, Avg. loss: 0.062801\n",
      "Total training time: 394.76 seconds.\n",
      "-- Epoch 4784\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.298714, T: 817518624, Avg. loss: 0.062800\n",
      "Total training time: 394.85 seconds.\n",
      "-- Epoch 4785\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.297358, T: 817689510, Avg. loss: 0.062799\n",
      "Total training time: 394.92 seconds.\n",
      "-- Epoch 4786\n",
      "Norm: 13.32, NNZs: 30, Bias: -117.296001, T: 817860396, Avg. loss: 0.062799\n",
      "Total training time: 395.01 seconds.\n",
      "-- Epoch 4787\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.294645, T: 818031282, Avg. loss: 0.062798\n",
      "Total training time: 395.09 seconds.\n",
      "-- Epoch 4788\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.293289, T: 818202168, Avg. loss: 0.062797\n",
      "Total training time: 395.18 seconds.\n",
      "-- Epoch 4789\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.291934, T: 818373054, Avg. loss: 0.062796\n",
      "Total training time: 395.26 seconds.\n",
      "-- Epoch 4790\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.290579, T: 818543940, Avg. loss: 0.062796\n",
      "Total training time: 395.34 seconds.\n",
      "-- Epoch 4791\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.289224, T: 818714826, Avg. loss: 0.062795\n",
      "Total training time: 395.42 seconds.\n",
      "-- Epoch 4792\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.287869, T: 818885712, Avg. loss: 0.062794\n",
      "Total training time: 395.50 seconds.\n",
      "-- Epoch 4793\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.286514, T: 819056598, Avg. loss: 0.062793\n",
      "Total training time: 395.59 seconds.\n",
      "-- Epoch 4794\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.285160, T: 819227484, Avg. loss: 0.062793\n",
      "Total training time: 395.68 seconds.\n",
      "-- Epoch 4795\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.283806, T: 819398370, Avg. loss: 0.062792\n",
      "Total training time: 395.78 seconds.\n",
      "-- Epoch 4796\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.282453, T: 819569256, Avg. loss: 0.062791\n",
      "Total training time: 395.86 seconds.\n",
      "-- Epoch 4797\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.281099, T: 819740142, Avg. loss: 0.062790\n",
      "Total training time: 395.95 seconds.\n",
      "-- Epoch 4798\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.279746, T: 819911028, Avg. loss: 0.062790\n",
      "Total training time: 396.05 seconds.\n",
      "-- Epoch 4799\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.278393, T: 820081914, Avg. loss: 0.062789\n",
      "Total training time: 396.14 seconds.\n",
      "-- Epoch 4800\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.277041, T: 820252800, Avg. loss: 0.062788\n",
      "Total training time: 396.23 seconds.\n",
      "-- Epoch 4801\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.275689, T: 820423686, Avg. loss: 0.062787\n",
      "Total training time: 396.32 seconds.\n",
      "-- Epoch 4802\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.274338, T: 820594572, Avg. loss: 0.062787\n",
      "Total training time: 396.41 seconds.\n",
      "-- Epoch 4803\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.272986, T: 820765458, Avg. loss: 0.062786\n",
      "Total training time: 396.50 seconds.\n",
      "-- Epoch 4804\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.271635, T: 820936344, Avg. loss: 0.062785\n",
      "Total training time: 396.60 seconds.\n",
      "-- Epoch 4805\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.270284, T: 821107230, Avg. loss: 0.062784\n",
      "Total training time: 396.69 seconds.\n",
      "-- Epoch 4806\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.268933, T: 821278116, Avg. loss: 0.062784\n",
      "Total training time: 396.78 seconds.\n",
      "-- Epoch 4807\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.267582, T: 821449002, Avg. loss: 0.062783\n",
      "Total training time: 396.87 seconds.\n",
      "-- Epoch 4808\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.266232, T: 821619888, Avg. loss: 0.062782\n",
      "Total training time: 396.96 seconds.\n",
      "-- Epoch 4809\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.264882, T: 821790774, Avg. loss: 0.062781\n",
      "Total training time: 397.05 seconds.\n",
      "-- Epoch 4810\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.263532, T: 821961660, Avg. loss: 0.062781\n",
      "Total training time: 397.13 seconds.\n",
      "-- Epoch 4811\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.262184, T: 822132546, Avg. loss: 0.062780\n",
      "Total training time: 397.21 seconds.\n",
      "-- Epoch 4812\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.260835, T: 822303432, Avg. loss: 0.062779\n",
      "Total training time: 397.29 seconds.\n",
      "-- Epoch 4813\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.259487, T: 822474318, Avg. loss: 0.062778\n",
      "Total training time: 397.37 seconds.\n",
      "-- Epoch 4814\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.258138, T: 822645204, Avg. loss: 0.062778\n",
      "Total training time: 397.45 seconds.\n",
      "-- Epoch 4815\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.256790, T: 822816090, Avg. loss: 0.062777\n",
      "Total training time: 397.52 seconds.\n",
      "-- Epoch 4816\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.255443, T: 822986976, Avg. loss: 0.062776\n",
      "Total training time: 397.60 seconds.\n",
      "-- Epoch 4817\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.254095, T: 823157862, Avg. loss: 0.062775\n",
      "Total training time: 397.72 seconds.\n",
      "-- Epoch 4818\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.252748, T: 823328748, Avg. loss: 0.062775\n",
      "Total training time: 397.83 seconds.\n",
      "-- Epoch 4819\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.251401, T: 823499634, Avg. loss: 0.062774\n",
      "Total training time: 397.93 seconds.\n",
      "-- Epoch 4820\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.250054, T: 823670520, Avg. loss: 0.062773\n",
      "Total training time: 398.03 seconds.\n",
      "-- Epoch 4821\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.248707, T: 823841406, Avg. loss: 0.062773\n",
      "Total training time: 398.11 seconds.\n",
      "-- Epoch 4822\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.247361, T: 824012292, Avg. loss: 0.062772\n",
      "Total training time: 398.19 seconds.\n",
      "-- Epoch 4823\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.246015, T: 824183178, Avg. loss: 0.062771\n",
      "Total training time: 398.27 seconds.\n",
      "-- Epoch 4824\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.244669, T: 824354064, Avg. loss: 0.062770\n",
      "Total training time: 398.38 seconds.\n",
      "-- Epoch 4825\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.243324, T: 824524950, Avg. loss: 0.062770\n",
      "Total training time: 398.46 seconds.\n",
      "-- Epoch 4826\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.241979, T: 824695836, Avg. loss: 0.062769\n",
      "Total training time: 398.55 seconds.\n",
      "-- Epoch 4827\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.240635, T: 824866722, Avg. loss: 0.062768\n",
      "Total training time: 398.63 seconds.\n",
      "-- Epoch 4828\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.239290, T: 825037608, Avg. loss: 0.062767\n",
      "Total training time: 398.70 seconds.\n",
      "-- Epoch 4829\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.237947, T: 825208494, Avg. loss: 0.062767\n",
      "Total training time: 398.79 seconds.\n",
      "-- Epoch 4830\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.236602, T: 825379380, Avg. loss: 0.062766\n",
      "Total training time: 398.88 seconds.\n",
      "-- Epoch 4831\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.235258, T: 825550266, Avg. loss: 0.062765\n",
      "Total training time: 398.96 seconds.\n",
      "-- Epoch 4832\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.233915, T: 825721152, Avg. loss: 0.062764\n",
      "Total training time: 399.04 seconds.\n",
      "-- Epoch 4833\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.232573, T: 825892038, Avg. loss: 0.062764\n",
      "Total training time: 399.13 seconds.\n",
      "-- Epoch 4834\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.231229, T: 826062924, Avg. loss: 0.062763\n",
      "Total training time: 399.20 seconds.\n",
      "-- Epoch 4835\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.229887, T: 826233810, Avg. loss: 0.062762\n",
      "Total training time: 399.30 seconds.\n",
      "-- Epoch 4836\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.228545, T: 826404696, Avg. loss: 0.062761\n",
      "Total training time: 399.38 seconds.\n",
      "-- Epoch 4837\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.227204, T: 826575582, Avg. loss: 0.062761\n",
      "Total training time: 399.46 seconds.\n",
      "-- Epoch 4838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.31, NNZs: 30, Bias: -117.225862, T: 826746468, Avg. loss: 0.062760\n",
      "Total training time: 399.55 seconds.\n",
      "-- Epoch 4839\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.224520, T: 826917354, Avg. loss: 0.062759\n",
      "Total training time: 399.64 seconds.\n",
      "-- Epoch 4840\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.223179, T: 827088240, Avg. loss: 0.062758\n",
      "Total training time: 399.71 seconds.\n",
      "-- Epoch 4841\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.221839, T: 827259126, Avg. loss: 0.062758\n",
      "Total training time: 399.80 seconds.\n",
      "-- Epoch 4842\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.220498, T: 827430012, Avg. loss: 0.062757\n",
      "Total training time: 399.89 seconds.\n",
      "-- Epoch 4843\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.219158, T: 827600898, Avg. loss: 0.062756\n",
      "Total training time: 399.97 seconds.\n",
      "-- Epoch 4844\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.217818, T: 827771784, Avg. loss: 0.062755\n",
      "Total training time: 400.06 seconds.\n",
      "-- Epoch 4845\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.216479, T: 827942670, Avg. loss: 0.062755\n",
      "Total training time: 400.14 seconds.\n",
      "-- Epoch 4846\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.215140, T: 828113556, Avg. loss: 0.062754\n",
      "Total training time: 400.22 seconds.\n",
      "-- Epoch 4847\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.213801, T: 828284442, Avg. loss: 0.062753\n",
      "Total training time: 400.31 seconds.\n",
      "-- Epoch 4848\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.212461, T: 828455328, Avg. loss: 0.062752\n",
      "Total training time: 400.39 seconds.\n",
      "-- Epoch 4849\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.211122, T: 828626214, Avg. loss: 0.062752\n",
      "Total training time: 400.47 seconds.\n",
      "-- Epoch 4850\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.209784, T: 828797100, Avg. loss: 0.062751\n",
      "Total training time: 400.56 seconds.\n",
      "-- Epoch 4851\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.208446, T: 828967986, Avg. loss: 0.062750\n",
      "Total training time: 400.65 seconds.\n",
      "-- Epoch 4852\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.207109, T: 829138872, Avg. loss: 0.062749\n",
      "Total training time: 400.73 seconds.\n",
      "-- Epoch 4853\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.205772, T: 829309758, Avg. loss: 0.062749\n",
      "Total training time: 400.81 seconds.\n",
      "-- Epoch 4854\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.204434, T: 829480644, Avg. loss: 0.062748\n",
      "Total training time: 400.90 seconds.\n",
      "-- Epoch 4855\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.203098, T: 829651530, Avg. loss: 0.062747\n",
      "Total training time: 400.98 seconds.\n",
      "-- Epoch 4856\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.201760, T: 829822416, Avg. loss: 0.062747\n",
      "Total training time: 401.08 seconds.\n",
      "-- Epoch 4857\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.200423, T: 829993302, Avg. loss: 0.062746\n",
      "Total training time: 401.17 seconds.\n",
      "-- Epoch 4858\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.199087, T: 830164188, Avg. loss: 0.062745\n",
      "Total training time: 401.25 seconds.\n",
      "-- Epoch 4859\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.197752, T: 830335074, Avg. loss: 0.062744\n",
      "Total training time: 401.34 seconds.\n",
      "-- Epoch 4860\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.196416, T: 830505960, Avg. loss: 0.062744\n",
      "Total training time: 401.43 seconds.\n",
      "-- Epoch 4861\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.195081, T: 830676846, Avg. loss: 0.062743\n",
      "Total training time: 401.54 seconds.\n",
      "-- Epoch 4862\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.193746, T: 830847732, Avg. loss: 0.062742\n",
      "Total training time: 401.66 seconds.\n",
      "-- Epoch 4863\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.192411, T: 831018618, Avg. loss: 0.062741\n",
      "Total training time: 401.79 seconds.\n",
      "-- Epoch 4864\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.191077, T: 831189504, Avg. loss: 0.062741\n",
      "Total training time: 401.90 seconds.\n",
      "-- Epoch 4865\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.189743, T: 831360390, Avg. loss: 0.062740\n",
      "Total training time: 402.02 seconds.\n",
      "-- Epoch 4866\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.188408, T: 831531276, Avg. loss: 0.062739\n",
      "Total training time: 402.11 seconds.\n",
      "-- Epoch 4867\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.187074, T: 831702162, Avg. loss: 0.062738\n",
      "Total training time: 402.23 seconds.\n",
      "-- Epoch 4868\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.185740, T: 831873048, Avg. loss: 0.062738\n",
      "Total training time: 402.32 seconds.\n",
      "-- Epoch 4869\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.184408, T: 832043934, Avg. loss: 0.062737\n",
      "Total training time: 402.43 seconds.\n",
      "-- Epoch 4870\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.183075, T: 832214820, Avg. loss: 0.062736\n",
      "Total training time: 402.54 seconds.\n",
      "-- Epoch 4871\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.181743, T: 832385706, Avg. loss: 0.062735\n",
      "Total training time: 402.65 seconds.\n",
      "-- Epoch 4872\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.180410, T: 832556592, Avg. loss: 0.062735\n",
      "Total training time: 402.75 seconds.\n",
      "-- Epoch 4873\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.179077, T: 832727478, Avg. loss: 0.062734\n",
      "Total training time: 402.87 seconds.\n",
      "-- Epoch 4874\n",
      "Norm: 13.31, NNZs: 30, Bias: -117.177746, T: 832898364, Avg. loss: 0.062733\n",
      "Total training time: 402.97 seconds.\n",
      "-- Epoch 4875\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.176415, T: 833069250, Avg. loss: 0.062733\n",
      "Total training time: 403.09 seconds.\n",
      "-- Epoch 4876\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.175083, T: 833240136, Avg. loss: 0.062732\n",
      "Total training time: 403.21 seconds.\n",
      "-- Epoch 4877\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.173752, T: 833411022, Avg. loss: 0.062731\n",
      "Total training time: 403.33 seconds.\n",
      "-- Epoch 4878\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.172423, T: 833581908, Avg. loss: 0.062730\n",
      "Total training time: 403.43 seconds.\n",
      "-- Epoch 4879\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.171092, T: 833752794, Avg. loss: 0.062730\n",
      "Total training time: 403.51 seconds.\n",
      "-- Epoch 4880\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.169762, T: 833923680, Avg. loss: 0.062729\n",
      "Total training time: 403.60 seconds.\n",
      "-- Epoch 4881\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.168432, T: 834094566, Avg. loss: 0.062728\n",
      "Total training time: 403.69 seconds.\n",
      "-- Epoch 4882\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.167103, T: 834265452, Avg. loss: 0.062727\n",
      "Total training time: 403.77 seconds.\n",
      "-- Epoch 4883\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.165773, T: 834436338, Avg. loss: 0.062727\n",
      "Total training time: 403.87 seconds.\n",
      "-- Epoch 4884\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.164444, T: 834607224, Avg. loss: 0.062726\n",
      "Total training time: 403.96 seconds.\n",
      "-- Epoch 4885\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.163115, T: 834778110, Avg. loss: 0.062725\n",
      "Total training time: 404.05 seconds.\n",
      "-- Epoch 4886\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.161788, T: 834948996, Avg. loss: 0.062724\n",
      "Total training time: 404.15 seconds.\n",
      "-- Epoch 4887\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.160460, T: 835119882, Avg. loss: 0.062724\n",
      "Total training time: 404.25 seconds.\n",
      "-- Epoch 4888\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.159132, T: 835290768, Avg. loss: 0.062723\n",
      "Total training time: 404.33 seconds.\n",
      "-- Epoch 4889\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.157805, T: 835461654, Avg. loss: 0.062722\n",
      "Total training time: 404.41 seconds.\n",
      "-- Epoch 4890\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.156478, T: 835632540, Avg. loss: 0.062721\n",
      "Total training time: 404.49 seconds.\n",
      "-- Epoch 4891\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.155151, T: 835803426, Avg. loss: 0.062721\n",
      "Total training time: 404.57 seconds.\n",
      "-- Epoch 4892\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.153824, T: 835974312, Avg. loss: 0.062720\n",
      "Total training time: 404.66 seconds.\n",
      "-- Epoch 4893\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.152498, T: 836145198, Avg. loss: 0.062719\n",
      "Total training time: 404.75 seconds.\n",
      "-- Epoch 4894\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.151172, T: 836316084, Avg. loss: 0.062719\n",
      "Total training time: 404.85 seconds.\n",
      "-- Epoch 4895\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.149847, T: 836486970, Avg. loss: 0.062718\n",
      "Total training time: 404.94 seconds.\n",
      "-- Epoch 4896\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.148521, T: 836657856, Avg. loss: 0.062717\n",
      "Total training time: 405.03 seconds.\n",
      "-- Epoch 4897\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.147195, T: 836828742, Avg. loss: 0.062716\n",
      "Total training time: 405.11 seconds.\n",
      "-- Epoch 4898\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.145870, T: 836999628, Avg. loss: 0.062716\n",
      "Total training time: 405.19 seconds.\n",
      "-- Epoch 4899\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.144545, T: 837170514, Avg. loss: 0.062715\n",
      "Total training time: 405.26 seconds.\n",
      "-- Epoch 4900\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.143221, T: 837341400, Avg. loss: 0.062714\n",
      "Total training time: 405.34 seconds.\n",
      "-- Epoch 4901\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.141896, T: 837512286, Avg. loss: 0.062713\n",
      "Total training time: 405.41 seconds.\n",
      "-- Epoch 4902\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.140572, T: 837683172, Avg. loss: 0.062713\n",
      "Total training time: 405.49 seconds.\n",
      "-- Epoch 4903\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.139249, T: 837854058, Avg. loss: 0.062712\n",
      "Total training time: 405.57 seconds.\n",
      "-- Epoch 4904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.30, NNZs: 30, Bias: -117.137925, T: 838024944, Avg. loss: 0.062711\n",
      "Total training time: 405.64 seconds.\n",
      "-- Epoch 4905\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.136602, T: 838195830, Avg. loss: 0.062710\n",
      "Total training time: 405.72 seconds.\n",
      "-- Epoch 4906\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.135279, T: 838366716, Avg. loss: 0.062710\n",
      "Total training time: 405.79 seconds.\n",
      "-- Epoch 4907\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.133956, T: 838537602, Avg. loss: 0.062709\n",
      "Total training time: 405.87 seconds.\n",
      "-- Epoch 4908\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.132634, T: 838708488, Avg. loss: 0.062708\n",
      "Total training time: 405.94 seconds.\n",
      "-- Epoch 4909\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.131313, T: 838879374, Avg. loss: 0.062708\n",
      "Total training time: 406.02 seconds.\n",
      "-- Epoch 4910\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.129991, T: 839050260, Avg. loss: 0.062707\n",
      "Total training time: 406.09 seconds.\n",
      "-- Epoch 4911\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.128670, T: 839221146, Avg. loss: 0.062706\n",
      "Total training time: 406.17 seconds.\n",
      "-- Epoch 4912\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.127349, T: 839392032, Avg. loss: 0.062705\n",
      "Total training time: 406.27 seconds.\n",
      "-- Epoch 4913\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.126027, T: 839562918, Avg. loss: 0.062705\n",
      "Total training time: 406.36 seconds.\n",
      "-- Epoch 4914\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.124707, T: 839733804, Avg. loss: 0.062704\n",
      "Total training time: 406.43 seconds.\n",
      "-- Epoch 4915\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.123387, T: 839904690, Avg. loss: 0.062703\n",
      "Total training time: 406.51 seconds.\n",
      "-- Epoch 4916\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.122067, T: 840075576, Avg. loss: 0.062702\n",
      "Total training time: 406.59 seconds.\n",
      "-- Epoch 4917\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.120747, T: 840246462, Avg. loss: 0.062702\n",
      "Total training time: 406.67 seconds.\n",
      "-- Epoch 4918\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.119427, T: 840417348, Avg. loss: 0.062701\n",
      "Total training time: 406.74 seconds.\n",
      "-- Epoch 4919\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.118108, T: 840588234, Avg. loss: 0.062700\n",
      "Total training time: 406.84 seconds.\n",
      "-- Epoch 4920\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.116789, T: 840759120, Avg. loss: 0.062700\n",
      "Total training time: 406.92 seconds.\n",
      "-- Epoch 4921\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.115470, T: 840930006, Avg. loss: 0.062699\n",
      "Total training time: 407.00 seconds.\n",
      "-- Epoch 4922\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.114152, T: 841100892, Avg. loss: 0.062698\n",
      "Total training time: 407.07 seconds.\n",
      "-- Epoch 4923\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.112833, T: 841271778, Avg. loss: 0.062697\n",
      "Total training time: 407.15 seconds.\n",
      "-- Epoch 4924\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.111515, T: 841442664, Avg. loss: 0.062697\n",
      "Total training time: 407.22 seconds.\n",
      "-- Epoch 4925\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.110197, T: 841613550, Avg. loss: 0.062696\n",
      "Total training time: 407.30 seconds.\n",
      "-- Epoch 4926\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.108879, T: 841784436, Avg. loss: 0.062695\n",
      "Total training time: 407.37 seconds.\n",
      "-- Epoch 4927\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.107562, T: 841955322, Avg. loss: 0.062694\n",
      "Total training time: 407.45 seconds.\n",
      "-- Epoch 4928\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.106245, T: 842126208, Avg. loss: 0.062694\n",
      "Total training time: 407.53 seconds.\n",
      "-- Epoch 4929\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.104928, T: 842297094, Avg. loss: 0.062693\n",
      "Total training time: 407.60 seconds.\n",
      "-- Epoch 4930\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.103612, T: 842467980, Avg. loss: 0.062692\n",
      "Total training time: 407.68 seconds.\n",
      "-- Epoch 4931\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.102296, T: 842638866, Avg. loss: 0.062692\n",
      "Total training time: 407.76 seconds.\n",
      "-- Epoch 4932\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.100980, T: 842809752, Avg. loss: 0.062691\n",
      "Total training time: 407.84 seconds.\n",
      "-- Epoch 4933\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.099664, T: 842980638, Avg. loss: 0.062690\n",
      "Total training time: 407.93 seconds.\n",
      "-- Epoch 4934\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.098349, T: 843151524, Avg. loss: 0.062689\n",
      "Total training time: 408.01 seconds.\n",
      "-- Epoch 4935\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.097034, T: 843322410, Avg. loss: 0.062689\n",
      "Total training time: 408.09 seconds.\n",
      "-- Epoch 4936\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.095719, T: 843493296, Avg. loss: 0.062688\n",
      "Total training time: 408.17 seconds.\n",
      "-- Epoch 4937\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.094403, T: 843664182, Avg. loss: 0.062687\n",
      "Total training time: 408.25 seconds.\n",
      "-- Epoch 4938\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.093089, T: 843835068, Avg. loss: 0.062686\n",
      "Total training time: 408.34 seconds.\n",
      "-- Epoch 4939\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.091774, T: 844005954, Avg. loss: 0.062686\n",
      "Total training time: 408.43 seconds.\n",
      "-- Epoch 4940\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.090461, T: 844176840, Avg. loss: 0.062685\n",
      "Total training time: 408.52 seconds.\n",
      "-- Epoch 4941\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.089147, T: 844347726, Avg. loss: 0.062684\n",
      "Total training time: 408.62 seconds.\n",
      "-- Epoch 4942\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.087834, T: 844518612, Avg. loss: 0.062684\n",
      "Total training time: 408.71 seconds.\n",
      "-- Epoch 4943\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.086521, T: 844689498, Avg. loss: 0.062683\n",
      "Total training time: 408.78 seconds.\n",
      "-- Epoch 4944\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.085208, T: 844860384, Avg. loss: 0.062682\n",
      "Total training time: 408.86 seconds.\n",
      "-- Epoch 4945\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.083896, T: 845031270, Avg. loss: 0.062681\n",
      "Total training time: 408.95 seconds.\n",
      "-- Epoch 4946\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.082585, T: 845202156, Avg. loss: 0.062681\n",
      "Total training time: 409.03 seconds.\n",
      "-- Epoch 4947\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.081273, T: 845373042, Avg. loss: 0.062680\n",
      "Total training time: 409.11 seconds.\n",
      "-- Epoch 4948\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.079961, T: 845543928, Avg. loss: 0.062679\n",
      "Total training time: 409.18 seconds.\n",
      "-- Epoch 4949\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.078649, T: 845714814, Avg. loss: 0.062678\n",
      "Total training time: 409.27 seconds.\n",
      "-- Epoch 4950\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.077339, T: 845885700, Avg. loss: 0.062678\n",
      "Total training time: 409.36 seconds.\n",
      "-- Epoch 4951\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.076028, T: 846056586, Avg. loss: 0.062677\n",
      "Total training time: 409.44 seconds.\n",
      "-- Epoch 4952\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.074719, T: 846227472, Avg. loss: 0.062676\n",
      "Total training time: 409.51 seconds.\n",
      "-- Epoch 4953\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.073408, T: 846398358, Avg. loss: 0.062676\n",
      "Total training time: 409.59 seconds.\n",
      "-- Epoch 4954\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.072097, T: 846569244, Avg. loss: 0.062675\n",
      "Total training time: 409.66 seconds.\n",
      "-- Epoch 4955\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.070787, T: 846740130, Avg. loss: 0.062674\n",
      "Total training time: 409.74 seconds.\n",
      "-- Epoch 4956\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.069477, T: 846911016, Avg. loss: 0.062673\n",
      "Total training time: 409.83 seconds.\n",
      "-- Epoch 4957\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.068167, T: 847081902, Avg. loss: 0.062673\n",
      "Total training time: 409.93 seconds.\n",
      "-- Epoch 4958\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.066858, T: 847252788, Avg. loss: 0.062672\n",
      "Total training time: 410.02 seconds.\n",
      "-- Epoch 4959\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.065550, T: 847423674, Avg. loss: 0.062671\n",
      "Total training time: 410.11 seconds.\n",
      "-- Epoch 4960\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.064241, T: 847594560, Avg. loss: 0.062670\n",
      "Total training time: 410.21 seconds.\n",
      "-- Epoch 4961\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.062933, T: 847765446, Avg. loss: 0.062670\n",
      "Total training time: 410.30 seconds.\n",
      "-- Epoch 4962\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.061626, T: 847936332, Avg. loss: 0.062669\n",
      "Total training time: 410.39 seconds.\n",
      "-- Epoch 4963\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.060318, T: 848107218, Avg. loss: 0.062668\n",
      "Total training time: 410.46 seconds.\n",
      "-- Epoch 4964\n",
      "Norm: 13.30, NNZs: 30, Bias: -117.059011, T: 848278104, Avg. loss: 0.062668\n",
      "Total training time: 410.54 seconds.\n",
      "-- Epoch 4965\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.057704, T: 848448990, Avg. loss: 0.062667\n",
      "Total training time: 410.61 seconds.\n",
      "-- Epoch 4966\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.056397, T: 848619876, Avg. loss: 0.062666\n",
      "Total training time: 410.69 seconds.\n",
      "-- Epoch 4967\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.055091, T: 848790762, Avg. loss: 0.062665\n",
      "Total training time: 410.76 seconds.\n",
      "-- Epoch 4968\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.053785, T: 848961648, Avg. loss: 0.062665\n",
      "Total training time: 410.84 seconds.\n",
      "-- Epoch 4969\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.052479, T: 849132534, Avg. loss: 0.062664\n",
      "Total training time: 410.92 seconds.\n",
      "-- Epoch 4970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 13.29, NNZs: 30, Bias: -117.051174, T: 849303420, Avg. loss: 0.062663\n",
      "Total training time: 410.99 seconds.\n",
      "-- Epoch 4971\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.049869, T: 849474306, Avg. loss: 0.062663\n",
      "Total training time: 411.07 seconds.\n",
      "-- Epoch 4972\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.048563, T: 849645192, Avg. loss: 0.062662\n",
      "Total training time: 411.14 seconds.\n",
      "-- Epoch 4973\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.047258, T: 849816078, Avg. loss: 0.062661\n",
      "Total training time: 411.22 seconds.\n",
      "-- Epoch 4974\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.045953, T: 849986964, Avg. loss: 0.062660\n",
      "Total training time: 411.29 seconds.\n",
      "-- Epoch 4975\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.044649, T: 850157850, Avg. loss: 0.062660\n",
      "Total training time: 411.37 seconds.\n",
      "-- Epoch 4976\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.043345, T: 850328736, Avg. loss: 0.062659\n",
      "Total training time: 411.44 seconds.\n",
      "-- Epoch 4977\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.042042, T: 850499622, Avg. loss: 0.062658\n",
      "Total training time: 411.52 seconds.\n",
      "-- Epoch 4978\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.040738, T: 850670508, Avg. loss: 0.062657\n",
      "Total training time: 411.60 seconds.\n",
      "-- Epoch 4979\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.039435, T: 850841394, Avg. loss: 0.062657\n",
      "Total training time: 411.67 seconds.\n",
      "-- Epoch 4980\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.038132, T: 851012280, Avg. loss: 0.062656\n",
      "Total training time: 411.75 seconds.\n",
      "-- Epoch 4981\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.036829, T: 851183166, Avg. loss: 0.062655\n",
      "Total training time: 411.83 seconds.\n",
      "-- Epoch 4982\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.035526, T: 851354052, Avg. loss: 0.062655\n",
      "Total training time: 411.90 seconds.\n",
      "-- Epoch 4983\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.034224, T: 851524938, Avg. loss: 0.062654\n",
      "Total training time: 411.98 seconds.\n",
      "-- Epoch 4984\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.032922, T: 851695824, Avg. loss: 0.062653\n",
      "Total training time: 412.06 seconds.\n",
      "-- Epoch 4985\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.031620, T: 851866710, Avg. loss: 0.062652\n",
      "Total training time: 412.15 seconds.\n",
      "-- Epoch 4986\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.030319, T: 852037596, Avg. loss: 0.062652\n",
      "Total training time: 412.23 seconds.\n",
      "-- Epoch 4987\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.029017, T: 852208482, Avg. loss: 0.062651\n",
      "Total training time: 412.30 seconds.\n",
      "-- Epoch 4988\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.027717, T: 852379368, Avg. loss: 0.062650\n",
      "Total training time: 412.38 seconds.\n",
      "-- Epoch 4989\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.026416, T: 852550254, Avg. loss: 0.062650\n",
      "Total training time: 412.46 seconds.\n",
      "-- Epoch 4990\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.025115, T: 852721140, Avg. loss: 0.062649\n",
      "Total training time: 412.53 seconds.\n",
      "-- Epoch 4991\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.023816, T: 852892026, Avg. loss: 0.062648\n",
      "Total training time: 412.64 seconds.\n",
      "-- Epoch 4992\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.022516, T: 853062912, Avg. loss: 0.062647\n",
      "Total training time: 412.73 seconds.\n",
      "-- Epoch 4993\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.021216, T: 853233798, Avg. loss: 0.062647\n",
      "Total training time: 412.82 seconds.\n",
      "-- Epoch 4994\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.019916, T: 853404684, Avg. loss: 0.062646\n",
      "Total training time: 412.91 seconds.\n",
      "-- Epoch 4995\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.018617, T: 853575570, Avg. loss: 0.062645\n",
      "Total training time: 413.01 seconds.\n",
      "-- Epoch 4996\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.017318, T: 853746456, Avg. loss: 0.062645\n",
      "Total training time: 413.10 seconds.\n",
      "-- Epoch 4997\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.016020, T: 853917342, Avg. loss: 0.062644\n",
      "Total training time: 413.19 seconds.\n",
      "-- Epoch 4998\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.014722, T: 854088228, Avg. loss: 0.062643\n",
      "Total training time: 413.29 seconds.\n",
      "-- Epoch 4999\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.013424, T: 854259114, Avg. loss: 0.062642\n",
      "Total training time: 413.38 seconds.\n",
      "-- Epoch 5000\n",
      "Norm: 13.29, NNZs: 30, Bias: -117.012126, T: 854430000, Avg. loss: 0.062642\n",
      "Total training time: 413.48 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=5000, n_jobs=-1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=3,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.set_params(random_state=42)\n",
    "sgd_clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Predict=sgd_clf.predict(Xte_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170483,    152],\n",
       "       [    43,    208]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,roc_auc_score\n",
    "confusion_matrix(y_Predict,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78876280840849289"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/sklearn/linear_model/stochastic_gradient.py:832: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(self.predict_proba(X))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-1def27e12c8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFinalOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "max(FinalOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.amax(FinalOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FinalSubmition=pd.DataFrame(FinalOutput,columns=['Class1','ClassB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class1</th>\n",
       "      <th>ClassB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.155696e-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.813604e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.883877e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.100523e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.812401e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.473775e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.746984e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.734736e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.028259e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.241324e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.334101e-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.340284e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.438645e-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.792824e-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.543287e-44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.483059e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.101221e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.833508e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.272993e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.843720e-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.348057e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.327689e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.771744e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.931583e-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.849601e-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.746097e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.784927e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.672910e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.393802e-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.639544e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170856</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.966401e-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170857</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.392597e-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170858</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.266882e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170859</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.112084e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170860</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.892452e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170861</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.828913e-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170862</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.252677e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170863</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.100859e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170864</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.017596e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170865</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.596375e-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170866</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.381415e-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170867</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.105526e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170868</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9.708921e-49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170869</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.706003e-42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170870</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.726867e-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170871</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.572860e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170872</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.324634e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170873</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.792088e-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170874</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.960383e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170875</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.114566e-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170876</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.345967e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170877</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.515561e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170878</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.902513e-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170879</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.320912e-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170880</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.727486e-43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170881</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.748140e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170882</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.124147e-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.780081e-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170884</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.883183e-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170885</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.438162e-49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170886 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class1        ClassB\n",
       "0          1.0  3.155696e-49\n",
       "1          1.0  1.813604e-52\n",
       "2          1.0  2.883877e-50\n",
       "3          1.0  9.100523e-52\n",
       "4          1.0  5.812401e-51\n",
       "5          1.0  4.473775e-52\n",
       "6          1.0  3.746984e-52\n",
       "7          1.0  2.734736e-47\n",
       "8          1.0  8.028259e-54\n",
       "9          1.0  2.241324e-52\n",
       "10         1.0  2.334101e-55\n",
       "11         1.0  2.340284e-54\n",
       "12         1.0  2.438645e-57\n",
       "13         1.0  2.792824e-49\n",
       "14         1.0  8.543287e-44\n",
       "15         1.0  3.483059e-53\n",
       "16         1.0  2.101221e-51\n",
       "17         1.0  3.833508e-52\n",
       "18         1.0  1.272993e-47\n",
       "19         1.0  1.843720e-56\n",
       "20         1.0  2.348057e-51\n",
       "21         1.0  3.327689e-51\n",
       "22         1.0  3.771744e-51\n",
       "23         1.0  2.931583e-49\n",
       "24         1.0  6.849601e-60\n",
       "25         1.0  5.746097e-53\n",
       "26         1.0  5.784927e-53\n",
       "27         1.0  1.672910e-53\n",
       "28         1.0  1.393802e-49\n",
       "29         1.0  4.639544e-51\n",
       "...        ...           ...\n",
       "170856     1.0  1.966401e-48\n",
       "170857     1.0  1.392597e-56\n",
       "170858     1.0  2.266882e-51\n",
       "170859     1.0  7.112084e-52\n",
       "170860     1.0  9.892452e-50\n",
       "170861     1.0  1.828913e-53\n",
       "170862     1.0  8.252677e-50\n",
       "170863     1.0  7.100859e-46\n",
       "170864     1.0  1.017596e-47\n",
       "170865     1.0  6.596375e-49\n",
       "170866     1.0  3.381415e-48\n",
       "170867     1.0  3.105526e-52\n",
       "170868     1.0  9.708921e-49\n",
       "170869     1.0  3.706003e-42\n",
       "170870     1.0  6.726867e-48\n",
       "170871     1.0  1.572860e-45\n",
       "170872     1.0  7.324634e-54\n",
       "170873     1.0  1.792088e-48\n",
       "170874     1.0  2.960383e-50\n",
       "170875     1.0  2.114566e-57\n",
       "170876     1.0  1.345967e-51\n",
       "170877     1.0  1.515561e-50\n",
       "170878     1.0  7.902513e-51\n",
       "170879     1.0  5.320912e-48\n",
       "170880     1.0  2.727486e-43\n",
       "170881     1.0  2.748140e-50\n",
       "170882     1.0  7.124147e-52\n",
       "170883     1.0  2.780081e-50\n",
       "170884     1.0  2.883183e-40\n",
       "170885     1.0  3.438162e-49\n",
       "\n",
       "[170886 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinalSubmition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.0\n",
       "1         0.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "5         0.0\n",
       "6         0.0\n",
       "7         0.0\n",
       "8         0.0\n",
       "9         0.0\n",
       "10        0.0\n",
       "11        0.0\n",
       "12        0.0\n",
       "13        0.0\n",
       "14        0.0\n",
       "15        0.0\n",
       "16        0.0\n",
       "17        0.0\n",
       "18        0.0\n",
       "19        0.0\n",
       "20        0.0\n",
       "21        0.0\n",
       "22        0.0\n",
       "23        0.0\n",
       "24        0.0\n",
       "25        0.0\n",
       "26        0.0\n",
       "27        0.0\n",
       "28        0.0\n",
       "29        0.0\n",
       "         ... \n",
       "170856    0.0\n",
       "170857    0.0\n",
       "170858    0.0\n",
       "170859    0.0\n",
       "170860    0.0\n",
       "170861    0.0\n",
       "170862    0.0\n",
       "170863    0.0\n",
       "170864    0.0\n",
       "170865    0.0\n",
       "170866    0.0\n",
       "170867    0.0\n",
       "170868    0.0\n",
       "170869    0.0\n",
       "170870    0.0\n",
       "170871    0.0\n",
       "170872    0.0\n",
       "170873    0.0\n",
       "170874    0.0\n",
       "170875    0.0\n",
       "170876    0.0\n",
       "170877    0.0\n",
       "170878    0.0\n",
       "170879    0.0\n",
       "170880    0.0\n",
       "170881    0.0\n",
       "170882    0.0\n",
       "170883    0.0\n",
       "170884    0.0\n",
       "170885    0.0\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-5d8d8cb15b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFinalOutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "FinalOutput[][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Writing 1 cols but got 2 aliases",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-716c91436656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mFinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFinalSubmition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mFinal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SubmitionOk.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path, index, sep, na_rep, float_format, header, index_label, mode, encoding, date_format, decimal)\u001b[0m\n\u001b[1;32m   2621\u001b[0m                            \u001b[0mindex_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m                            \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdate_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m                            decimal=decimal)\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1473\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1562\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/pandas/formats/format.pyc\u001b[0m in \u001b[0;36m_save_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m                 raise ValueError(('Writing %d cols but got %d aliases'\n\u001b[0;32m-> 1497\u001b[0;31m                                   % (len(cols), len(header))))\n\u001b[0m\u001b[1;32m   1498\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0mwrite_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Writing 1 cols but got 2 aliases"
     ]
    }
   ],
   "source": [
    "Final=FinalSubmition['Class1']\n",
    "Final.to_csv('SubmitionOk.csv',header=['id','Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170855</th>\n",
       "      <td>170856</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170856</th>\n",
       "      <td>170857</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170857</th>\n",
       "      <td>170858</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170858</th>\n",
       "      <td>170859</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170859</th>\n",
       "      <td>170860</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170860</th>\n",
       "      <td>170861</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170861</th>\n",
       "      <td>170862</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170862</th>\n",
       "      <td>170863</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170863</th>\n",
       "      <td>170864</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170864</th>\n",
       "      <td>170865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170865</th>\n",
       "      <td>170866</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170866</th>\n",
       "      <td>170867</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170867</th>\n",
       "      <td>170868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170868</th>\n",
       "      <td>170869</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170869</th>\n",
       "      <td>170870</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170870</th>\n",
       "      <td>170871</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170871</th>\n",
       "      <td>170872</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170872</th>\n",
       "      <td>170873</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170873</th>\n",
       "      <td>170874</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170874</th>\n",
       "      <td>170875</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170875</th>\n",
       "      <td>170876</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170876</th>\n",
       "      <td>170877</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170877</th>\n",
       "      <td>170878</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170878</th>\n",
       "      <td>170879</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170879</th>\n",
       "      <td>170880</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170880</th>\n",
       "      <td>170881</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170881</th>\n",
       "      <td>170882</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170882</th>\n",
       "      <td>170883</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170883</th>\n",
       "      <td>170884</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170884</th>\n",
       "      <td>170885</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170885 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0  1.0\n",
       "0            1  1.0\n",
       "1            2  1.0\n",
       "2            3  1.0\n",
       "3            4  1.0\n",
       "4            5  1.0\n",
       "5            6  1.0\n",
       "6            7  1.0\n",
       "7            8  1.0\n",
       "8            9  1.0\n",
       "9           10  1.0\n",
       "10          11  1.0\n",
       "11          12  1.0\n",
       "12          13  1.0\n",
       "13          14  1.0\n",
       "14          15  1.0\n",
       "15          16  1.0\n",
       "16          17  1.0\n",
       "17          18  1.0\n",
       "18          19  1.0\n",
       "19          20  1.0\n",
       "20          21  1.0\n",
       "21          22  1.0\n",
       "22          23  1.0\n",
       "23          24  1.0\n",
       "24          25  1.0\n",
       "25          26  1.0\n",
       "26          27  1.0\n",
       "27          28  1.0\n",
       "28          29  1.0\n",
       "29          30  1.0\n",
       "...        ...  ...\n",
       "170855  170856  1.0\n",
       "170856  170857  1.0\n",
       "170857  170858  1.0\n",
       "170858  170859  1.0\n",
       "170859  170860  1.0\n",
       "170860  170861  1.0\n",
       "170861  170862  1.0\n",
       "170862  170863  1.0\n",
       "170863  170864  1.0\n",
       "170864  170865  1.0\n",
       "170865  170866  1.0\n",
       "170866  170867  1.0\n",
       "170867  170868  1.0\n",
       "170868  170869  1.0\n",
       "170869  170870  1.0\n",
       "170870  170871  1.0\n",
       "170871  170872  1.0\n",
       "170872  170873  1.0\n",
       "170873  170874  1.0\n",
       "170874  170875  1.0\n",
       "170875  170876  1.0\n",
       "170876  170877  1.0\n",
       "170877  170878  1.0\n",
       "170878  170879  1.0\n",
       "170879  170880  1.0\n",
       "170880  170881  1.0\n",
       "170881  170882  1.0\n",
       "170882  170883  1.0\n",
       "170883  170884  1.0\n",
       "170884  170885  1.0\n",
       "\n",
       "[170885 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sub2=pd.read_csv('Submition2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub2['ID']+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub2.to_csv('Sub2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170886, 30)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xte_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (113922,30) (31,) (113922,30) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-d590897011d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mXte_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/espy-mur/Documents/Machine-Learning/tensorflow/local/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, y, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (113922,30) (31,) (113922,30) "
     ]
    }
   ],
   "source": [
    "X_test=pd.read_csv('test.csv')\n",
    "X_test=X_test.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xte_s = standard_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113922, 30)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xte_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Predict=sgd_clf.predict(Xte_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PFinal=sgd_clf.predict_proba(Xte_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PFinal=pd.DataFrame(PFinal,columns=['Class1','ClassB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1.0\n",
       "1         1.0\n",
       "2         1.0\n",
       "3         1.0\n",
       "4         1.0\n",
       "5         1.0\n",
       "6         1.0\n",
       "7         1.0\n",
       "8         1.0\n",
       "9         1.0\n",
       "10        1.0\n",
       "11        1.0\n",
       "12        1.0\n",
       "13        1.0\n",
       "14        1.0\n",
       "15        1.0\n",
       "16        1.0\n",
       "17        1.0\n",
       "18        1.0\n",
       "19        1.0\n",
       "20        1.0\n",
       "21        1.0\n",
       "22        1.0\n",
       "23        1.0\n",
       "24        1.0\n",
       "25        1.0\n",
       "26        1.0\n",
       "27        1.0\n",
       "28        1.0\n",
       "29        1.0\n",
       "         ... \n",
       "113892    1.0\n",
       "113893    1.0\n",
       "113894    1.0\n",
       "113895    1.0\n",
       "113896    1.0\n",
       "113897    1.0\n",
       "113898    1.0\n",
       "113899    1.0\n",
       "113900    1.0\n",
       "113901    1.0\n",
       "113902    1.0\n",
       "113903    1.0\n",
       "113904    1.0\n",
       "113905    1.0\n",
       "113906    1.0\n",
       "113907    1.0\n",
       "113908    1.0\n",
       "113909    1.0\n",
       "113910    1.0\n",
       "113911    1.0\n",
       "113912    1.0\n",
       "113913    1.0\n",
       "113914    1.0\n",
       "113915    1.0\n",
       "113916    1.0\n",
       "113917    1.0\n",
       "113918    1.0\n",
       "113919    1.0\n",
       "113920    1.0\n",
       "113921    1.0\n",
       "Name: Class1, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PFinal['Class1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFinal['Class1'].to_csv('SubmitionOH34.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final=pd.read_csv('EspoirSub1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113892</th>\n",
       "      <td>113892</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113893</th>\n",
       "      <td>113893</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113894</th>\n",
       "      <td>113894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113895</th>\n",
       "      <td>113895</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113896</th>\n",
       "      <td>113896</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113897</th>\n",
       "      <td>113897</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113898</th>\n",
       "      <td>113898</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113899</th>\n",
       "      <td>113899</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113900</th>\n",
       "      <td>113900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113901</th>\n",
       "      <td>113901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113902</th>\n",
       "      <td>113902</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113903</th>\n",
       "      <td>113903</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113904</th>\n",
       "      <td>113904</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113905</th>\n",
       "      <td>113905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113906</th>\n",
       "      <td>113906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113907</th>\n",
       "      <td>113907</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113908</th>\n",
       "      <td>113908</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113909</th>\n",
       "      <td>113909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113910</th>\n",
       "      <td>113910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113911</th>\n",
       "      <td>113911</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113912</th>\n",
       "      <td>113912</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113913</th>\n",
       "      <td>113913</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113914</th>\n",
       "      <td>113914</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113915</th>\n",
       "      <td>113915</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113916</th>\n",
       "      <td>113916</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113917</th>\n",
       "      <td>113917</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113918</th>\n",
       "      <td>113918</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113919</th>\n",
       "      <td>113919</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113920</th>\n",
       "      <td>113920</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113921</th>\n",
       "      <td>113921</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113922 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  Class\n",
       "0            0    1.0\n",
       "1            1    1.0\n",
       "2            2    1.0\n",
       "3            3    1.0\n",
       "4            4    1.0\n",
       "5            5    1.0\n",
       "6            6    1.0\n",
       "7            7    1.0\n",
       "8            8    1.0\n",
       "9            9    1.0\n",
       "10          10    1.0\n",
       "11          11    1.0\n",
       "12          12    1.0\n",
       "13          13    1.0\n",
       "14          14    1.0\n",
       "15          15    1.0\n",
       "16          16    1.0\n",
       "17          17    1.0\n",
       "18          18    1.0\n",
       "19          19    1.0\n",
       "20          20    1.0\n",
       "21          21    1.0\n",
       "22          22    1.0\n",
       "23          23    1.0\n",
       "24          24    1.0\n",
       "25          25    1.0\n",
       "26          26    1.0\n",
       "27          27    1.0\n",
       "28          28    1.0\n",
       "29          29    1.0\n",
       "...        ...    ...\n",
       "113892  113892    1.0\n",
       "113893  113893    1.0\n",
       "113894  113894    1.0\n",
       "113895  113895    1.0\n",
       "113896  113896    1.0\n",
       "113897  113897    1.0\n",
       "113898  113898    1.0\n",
       "113899  113899    1.0\n",
       "113900  113900    1.0\n",
       "113901  113901    1.0\n",
       "113902  113902    1.0\n",
       "113903  113903    1.0\n",
       "113904  113904    1.0\n",
       "113905  113905    1.0\n",
       "113906  113906    1.0\n",
       "113907  113907    1.0\n",
       "113908  113908    1.0\n",
       "113909  113909    1.0\n",
       "113910  113910    1.0\n",
       "113911  113911    1.0\n",
       "113912  113912    1.0\n",
       "113913  113913    1.0\n",
       "113914  113914    1.0\n",
       "113915  113915    1.0\n",
       "113916  113916    1.0\n",
       "113917  113917    1.0\n",
       "113918  113918    1.0\n",
       "113919  113919    1.0\n",
       "113920  113920    1.0\n",
       "113921  113921    1.0\n",
       "\n",
       "[113922 rows x 2 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final['id']+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final.to_csv('EspoirOKReady.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113922, 2)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ypre=pd.DataFrame(y_Predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypre.to_csv('Class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113922, 1)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ypre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
